1
00:00:00,000 --> 00:00:05,100
Okay.

2
00:00:05,100 --> 00:00:06,100
So welcome back.

3
00:00:06,100 --> 00:00:07,760
I guess those coming in, welcome.

4
00:00:07,760 --> 00:00:09,760
Those continuing to come in, please come in, find a seat.

5
00:00:09,760 --> 00:00:11,060
Try not to stay in the back.

6
00:00:11,060 --> 00:00:14,620
For those who had stayed from the last session, hi.

7
00:00:14,620 --> 00:00:16,760
So today we have a new speaker.

8
00:00:16,760 --> 00:00:19,000
His name is Vinayak Mehta.

9
00:00:19,000 --> 00:00:23,700
And he will be talking about extracting tabular data from PDFs using Camelot and Excalibur.

10
00:00:23,700 --> 00:00:29,760
So please help me in introducing him and welcome him to the stage.

11
00:00:29,760 --> 00:00:32,920
Am I audible?

12
00:00:32,920 --> 00:00:33,920
Yeah.

13
00:00:33,920 --> 00:00:34,920
Hello, everyone.

14
00:00:34,920 --> 00:00:38,520
Is everyone having a good time so far?

15
00:00:38,520 --> 00:00:42,360
Like, who all are first-time attendees?

16
00:00:42,360 --> 00:00:43,600
Nice.

17
00:00:43,600 --> 00:00:45,160
It's my first PyCon 2.

18
00:00:45,160 --> 00:00:53,080
Let's give it up for PSF and the volunteers for organizing such a wonderful event.

19
00:00:53,080 --> 00:00:54,080
So wait.

20
00:00:54,080 --> 00:00:57,080
Why isn't this moving?

21
00:00:58,080 --> 00:01:01,080
I think I'll go there.

22
00:01:01,080 --> 00:01:02,080
Yeah.

23
00:01:02,080 --> 00:01:03,080
So hi.

24
00:01:03,080 --> 00:01:04,320
I'm Vinayak Mehta.

25
00:01:04,320 --> 00:01:06,960
You can follow me on Twitter here if you like.

26
00:01:06,960 --> 00:01:10,880
I work at Grofers as a data engineer in Bangalore, India.

27
00:01:10,880 --> 00:01:16,000
If you'd like to work, if you'd like to know about the things I'd like to, I work on every

28
00:01:16,000 --> 00:01:19,360
day, you can catch me afterwards.

29
00:01:19,360 --> 00:01:23,120
So I'm here to talk about how you can extract tables from PDF files very easily.

30
00:01:23,160 --> 00:01:29,280
I believe each one of us has interacted with a PDF file at some point in our lives, maybe

31
00:01:29,280 --> 00:01:32,440
through resumes or research papers.

32
00:01:32,440 --> 00:01:39,160
In this talk, I'll briefly go through the history of the portable document format.

33
00:01:39,160 --> 00:01:43,640
I'll touch upon some problems I faced while extracting tables from it and then finally

34
00:01:43,640 --> 00:01:48,400
show you some code using which you can do this very easily.

35
00:01:48,400 --> 00:01:50,280
So let's begin with a fun fact.

36
00:01:50,280 --> 00:01:52,280
Why is Python called Python?

37
00:01:54,120 --> 00:01:56,680
Yeah, Monty Python.

38
00:01:56,680 --> 00:02:02,360
So while he began implementing the language, Kwedovan Dawson was also reading the published

39
00:02:02,360 --> 00:02:09,000
scripts from Monty Python's Flying Circus, which is a BBC comedy series from the 70s.

40
00:02:09,000 --> 00:02:14,200
And he thought that he needed something which was short, unique, and slightly mysterious.

41
00:02:14,200 --> 00:02:17,920
And thus we have Python.

42
00:02:17,920 --> 00:02:22,400
There are numerous Monty Python references written throughout the Python ecosystem.

43
00:02:22,680 --> 00:02:24,680
I'll also tell you about some of them today.

44
00:02:24,680 --> 00:02:25,680
Cool.

45
00:02:25,680 --> 00:02:29,680
Let's quickly go through the history of the portable document format.

46
00:02:29,680 --> 00:02:37,320
PDF was born out of the Camelot project to create basically a universal way to communicate

47
00:02:37,320 --> 00:02:44,080
documents across various machine configurations, operating systems, and communication networks.

48
00:02:44,080 --> 00:02:49,040
This is a memo by Jay Warnock, who is the co-founder of Adobe, where he outlines the

49
00:02:49,040 --> 00:02:50,860
Camelot project.

50
00:02:50,860 --> 00:02:53,780
You can check it out at the link below.

51
00:02:53,780 --> 00:02:54,780
It's a PDF.

52
00:02:54,780 --> 00:03:02,540
The goal was to make documents viewable on any display and printable on any modern printer.

53
00:03:02,540 --> 00:03:06,580
It hints the portable document format.

54
00:03:06,580 --> 00:03:11,780
It was built on top of PostScript, which is a page description language that had already

55
00:03:11,780 --> 00:03:15,520
solved this view and print anywhere problem.

56
00:03:15,520 --> 00:03:22,320
So a PDF package is components required to build a document, like text, fonts, vector

57
00:03:22,320 --> 00:03:24,160
graphics, and raster images.

58
00:03:24,160 --> 00:03:29,680
And these components travel with the document wherever it goes.

59
00:03:29,680 --> 00:03:35,440
And a PDF contains instructions to place these components in precise X, Y coordinates relative

60
00:03:35,440 --> 00:03:42,720
to the bottom left corner of the page, which is the origin for a page.

61
00:03:42,720 --> 00:03:46,880
So they're just placed at specific coordinates.

62
00:03:46,880 --> 00:03:51,280
So words are simulated by placing some characters closer than others.

63
00:03:51,280 --> 00:03:55,760
And sentences are simulated by placing words relatively far apart.

64
00:03:55,760 --> 00:03:58,620
How is the table simulated, then?

65
00:03:58,620 --> 00:04:03,720
By just placing words like they would appear in a spreadsheet.

66
00:04:03,720 --> 00:04:11,000
So the portable document format really has no internal representation of a table structure,

67
00:04:11,040 --> 00:04:13,800
which makes it difficult to extract tables out for analysis.

68
00:04:13,800 --> 00:04:21,600
Sadly, a lot of open data is stored in millions or possibly billions of PDFs, which wasn't

69
00:04:21,600 --> 00:04:25,520
designed for tabular data in the first place.

70
00:04:25,520 --> 00:04:32,360
Unlike a CSV, which is very structured, or a JSON, so you guys must be wondering why

71
00:04:32,360 --> 00:04:35,360
are you so obsessed with PDFs?

72
00:04:35,360 --> 00:04:38,680
So here's a short intro.

73
00:04:38,720 --> 00:04:43,800
I joined Social Cops in New Delhi as an intern in January 2016.

74
00:04:43,800 --> 00:04:45,640
It was my final year of undergrad.

75
00:04:45,640 --> 00:04:51,160
And as a student, I had come across various types of PDFs, which were basically resumes,

76
00:04:51,160 --> 00:04:54,640
research papers, software manuals.

77
00:04:54,640 --> 00:04:58,040
It makes sense for those types of documents to be in a PDF, right?

78
00:04:58,040 --> 00:05:04,600
Because you want them to look similar on a variety of machine configurations.

79
00:05:04,600 --> 00:05:09,160
So initially at Social Cops, I worked on escaping tabular data from open data sources, which

80
00:05:09,160 --> 00:05:19,760
were primarily PDF reports, to extract data that could be then used by analysts for the

81
00:05:19,760 --> 00:05:22,280
analysis basically.

82
00:05:22,280 --> 00:05:26,440
So these are some types of PDF tables that I worked with.

83
00:05:26,440 --> 00:05:33,880
Each organization that wants to release open data as PDFs comes up with a bizarre and colorful

84
00:05:33,880 --> 00:05:34,880
table structure.

85
00:05:34,880 --> 00:05:39,520
There isn't any set standard for this.

86
00:05:39,520 --> 00:05:43,520
So what is the first thing you do when you want to solve a new problem?

87
00:05:43,520 --> 00:05:48,280
You look for existing open source projects that might have already solved it.

88
00:05:48,280 --> 00:05:53,800
So similarly, there are already existing PDF table extraction tools.

89
00:05:53,800 --> 00:05:58,640
Some of them are open source, some are closed source, like Tabular, which is open source,

90
00:05:58,640 --> 00:06:02,440
and PDF tables, which is closed source.

91
00:06:02,440 --> 00:06:06,360
So let's go through the problems with existing tools.

92
00:06:06,360 --> 00:06:12,880
This is a table, this is a page from a weekly disease outbreaks report released by the Ministry

93
00:06:12,880 --> 00:06:19,360
of Family Welfare and Health in the Government of India.

94
00:06:19,360 --> 00:06:23,800
It basically contains weekly data about the number of cases and the number of deaths that

95
00:06:23,800 --> 00:06:29,840
were recorded in various Indian districts, along with a comment on what action was taken

96
00:06:29,840 --> 00:06:33,920
to afford those outbreaks.

97
00:06:33,920 --> 00:06:36,720
Looks like a very easy table to extract, right?

98
00:06:36,720 --> 00:06:40,800
Only seven rows and ten columns.

99
00:06:40,800 --> 00:06:47,280
But when you pass it through Tabular, which is an open source tool, you just get this.

100
00:06:47,280 --> 00:06:51,160
So you can see that the header is broken into multiple rows, and the comments column is

101
00:06:51,160 --> 00:06:54,160
shifted into separate columns.

102
00:06:54,160 --> 00:07:01,240
Tabular has a very nice interface, but it either works or it fails miserably.

103
00:07:01,240 --> 00:07:03,680
There's no in between.

104
00:07:03,680 --> 00:07:07,280
This is the output of PDF tables, which is a closed source tool.

105
00:07:07,280 --> 00:07:10,560
It works slightly better, but costs money.

106
00:07:10,560 --> 00:07:14,440
And you're either there or you're nowhere, which is the worst place to be.

107
00:07:14,440 --> 00:07:17,840
It also either works or it fails miserably.

108
00:07:18,840 --> 00:07:26,400
to get even 80 or 90% of a table out, which is not helpful since most of the things in

109
00:07:26,400 --> 00:07:31,560
the real world, including PDF table extraction, are fuzzy.

110
00:07:31,560 --> 00:07:38,700
So a solution that I tried was PDF to text, which just extracts a text from your PDF file

111
00:07:38,700 --> 00:07:42,960
into a text file while preserving the layout using white spaces.

112
00:07:42,960 --> 00:07:48,320
But there's a problem with that too, because the output that you get is a text file, and

113
00:07:48,320 --> 00:07:52,880
there's a post extraction step required to make sense of the underlying text data and

114
00:07:52,880 --> 00:07:55,600
convert it into a table.

115
00:07:55,600 --> 00:08:00,680
You have to write custom code for each different type of table structure, which can become

116
00:08:00,680 --> 00:08:06,500
expensive and time consuming, and that is not scalable.

117
00:08:06,980 --> 00:08:13,860
A solution that we came up at Social Cops was Camelot to overcome the problems of not

118
00:08:13,860 --> 00:08:21,180
having a generic PDF table extraction tool, which had knobs included with it.

119
00:08:21,180 --> 00:08:27,700
So let's take the example of the same table and let's go through a short demo.

120
00:08:27,700 --> 00:08:30,380
Let me just launch a Jupyter notebook.

121
00:08:36,500 --> 00:08:46,540
So you can import by typing it correctly, I can't really see it.

122
00:08:46,540 --> 00:08:48,780
You just import Camelot.

123
00:08:48,780 --> 00:08:59,820
You do a tables is equal to Camelot.readpdf in the name of your PDF.

124
00:08:59,820 --> 00:09:04,860
The API is very similar to pandas, like a read CSV or a read HTML, and then you can

125
00:09:04,860 --> 00:09:08,100
see that the table, is it visible?

126
00:09:08,100 --> 00:09:10,100
Should I enlarge it?

127
00:09:10,100 --> 00:09:14,780
Yeah, I can see it now.

128
00:09:14,780 --> 00:09:20,780
So the tables is basically a table list object, which just tells you that you've got one table

129
00:09:20,780 --> 00:09:22,580
on the PDF page.

130
00:09:22,580 --> 00:09:29,460
You can access the table using the index of the table, which will tell you the shape of

131
00:09:30,460 --> 00:09:35,540
And then you can finally access the table.

132
00:09:35,540 --> 00:09:40,700
There's a .df attribute which will give you a pandas data frame for that table.

133
00:09:40,700 --> 00:09:44,060
So here you can see that it's all extracted very nicely.

134
00:09:44,060 --> 00:09:46,900
All the headers are preserved.

135
00:09:46,900 --> 00:09:51,820
There's a, I can't really see the comments column, but oh, here it is.

136
00:09:51,820 --> 00:09:53,500
So all the comments are intact.

137
00:09:53,500 --> 00:09:58,020
Yeah, let's get back to a presentation.

138
00:09:58,020 --> 00:09:59,020
Yeah.

139
00:09:59,020 --> 00:10:04,020
I can't really change it.

140
00:10:04,020 --> 00:10:10,020
Oh, it got out of present mode.

141
00:10:10,020 --> 00:10:17,980
Yeah, so it's just a screenshot that I put there if the demo didn't work.

142
00:10:17,980 --> 00:10:18,980
So why Camelot?

143
00:10:18,980 --> 00:10:24,660
Camelot gives you complete control over table extraction with some tweakable parameters.

144
00:10:24,660 --> 00:10:29,780
You can override the table areas and columns that were detected by the library itself.

145
00:10:29,780 --> 00:10:36,640
And you can tweak the resolution of the image that would be used to do line recognition

146
00:10:36,640 --> 00:10:40,140
on a PDF page.

147
00:10:40,140 --> 00:10:43,740
And there are some other things that are built into the library itself.

148
00:10:43,740 --> 00:10:49,220
So each table is a pandas data frame, which can be easily integrated into ETL and data

149
00:10:49,220 --> 00:10:51,580
analysis workflows.

150
00:10:51,580 --> 00:10:57,460
You get a parsing report for each table, which tells you the accuracy with which the text

151
00:10:57,460 --> 00:11:03,060
was assigned to a table cell and the percentage of empty cells in a table with which you can

152
00:11:03,060 --> 00:11:05,660
discard back tables.

153
00:11:05,660 --> 00:11:09,900
And there are some other things like you can flag superscripts and subscripts.

154
00:11:09,900 --> 00:11:14,980
So here the superscript is not really a problem because it occurs after a decimal.

155
00:11:14,980 --> 00:11:20,900
But if the decimal wasn't there, then the number 2491 would become 24912.

156
00:11:21,140 --> 00:11:23,500
That would be a problem in your analysis.

157
00:11:23,500 --> 00:11:29,260
So you can just use this keyword argument, and you'll get the superscript flagged with

158
00:11:29,260 --> 00:11:31,260
those tags.

159
00:11:31,260 --> 00:11:36,780
You can strip unnecessary characters, like those dots aren't really required in the text

160
00:11:36,780 --> 00:11:39,580
that is inside that PDF.

161
00:11:39,580 --> 00:11:44,860
You can just use strip text and pass in the characters that you want to strip, and you'll

162
00:11:44,860 --> 00:11:48,580
get a very nice table out of it.

163
00:11:48,660 --> 00:11:54,980
You can shift text in spanning cells.

164
00:11:54,980 --> 00:12:03,580
You can also copy text in spanning cells because, yeah, it's just a nice feature to have.

165
00:12:03,580 --> 00:12:05,500
And there are multiple output formats.

166
00:12:05,500 --> 00:12:12,300
You can export your table to a CSV or JSON or an HTML or an Excel file.

167
00:12:12,300 --> 00:12:15,500
There's a command line interface too that you can use.

168
00:12:15,540 --> 00:12:21,460
So as you can already guess, the library was named after the Camelot project.

169
00:12:21,460 --> 00:12:29,500
Fun fact, Camelot is also the name of the castle in Monty Python in the Holy Grail,

170
00:12:29,500 --> 00:12:34,940
which is a movie by the same comedy group.

171
00:12:34,940 --> 00:12:39,780
Another fun fact, the Python package index was initially called the cheese shop based

172
00:12:39,780 --> 00:12:42,700
on the Monty Python cheese shop sketch.

173
00:12:42,700 --> 00:12:44,860
You should check it out.

174
00:12:44,860 --> 00:12:49,220
You can install Camelot using a very simple pip install.

175
00:12:49,220 --> 00:12:54,580
I've put a comparison with other open source PDF table extraction libraries on that link,

176
00:12:54,580 --> 00:12:57,940
so you can check that out too.

177
00:12:57,940 --> 00:13:03,100
So Camelot is built on top of PDF minor, which is a Python library that lets you access the

178
00:13:03,100 --> 00:13:09,140
text lines in a PDF along with the coordinates at which those text lines occur.

179
00:13:09,140 --> 00:13:10,940
Camelot has two parsing flavors built in.

180
00:13:11,020 --> 00:13:15,100
Lattice, you need to choose between one of the two.

181
00:13:15,100 --> 00:13:21,300
You can use lattice if your table is built using lines and steam if your table is simulated

182
00:13:21,300 --> 00:13:24,740
using white spaces.

183
00:13:24,740 --> 00:13:30,820
The names for these flavors were taken from Tabula, inspired from Tabula.

184
00:13:30,820 --> 00:13:33,580
But what if you don't want to write code?

185
00:13:33,580 --> 00:13:37,780
You can use a web interface that is built on Camelot.

186
00:13:37,780 --> 00:13:38,980
And it is called Excalibur.

187
00:13:39,020 --> 00:13:44,380
You can just run the web interface using Excalibur web server and go to localhost,

188
00:13:44,380 --> 00:13:48,580
colon 5,000.

189
00:13:48,580 --> 00:13:51,860
This page will load up when you go to that URL.

190
00:13:51,860 --> 00:13:59,860
You can access the PDF that you uploaded earlier underneath the upload button.

191
00:13:59,860 --> 00:14:04,180
You can auto detect tables on the PDF page.

192
00:14:04,180 --> 00:14:07,420
This is the same PDF that we were using earlier.

193
00:14:07,860 --> 00:14:16,100
If the table is really buried inside the text inside a PDF, you can specify the table areas

194
00:14:16,100 --> 00:14:24,500
and columns to make your extraction even more accurate.

195
00:14:24,500 --> 00:14:29,020
Excalibur supports all the different tweakable parameters that Camelot comes with.

196
00:14:29,020 --> 00:14:34,260
So you can just enter them here and finally view your data and download it in any format

197
00:14:34,260 --> 00:14:37,100
that you want.

198
00:14:37,780 --> 00:14:38,780
So why Excalibur?

199
00:14:38,780 --> 00:14:39,780
It's a web interface.

200
00:14:39,780 --> 00:14:42,860
It's much easier to use than Python library.

201
00:14:42,860 --> 00:14:48,140
You can save your parsing rules, which were your tweakable parameters, and then use them

202
00:14:48,140 --> 00:14:52,340
on similar tables in the future.

203
00:14:52,340 --> 00:14:57,420
You get to work on your data from the safety of your own home.

204
00:14:57,420 --> 00:14:59,580
Your data is safe on your machine.

205
00:14:59,580 --> 00:15:04,780
And Excalibur can be configured with MySQL and Celery to make your workloads parallel

206
00:15:04,780 --> 00:15:05,780
and distributed.

207
00:15:07,780 --> 00:15:13,140
So again, following the same Arthurian theme, Excalibur was named after the legendary sword

208
00:15:13,140 --> 00:15:16,140
of King Arthur.

209
00:15:16,140 --> 00:15:17,540
Here's another fun fact.

210
00:15:17,540 --> 00:15:22,980
The meta syntactic variables inside the Python literature are called spam and eggs instead

211
00:15:22,980 --> 00:15:28,060
of the default foo and bar.

212
00:15:28,060 --> 00:15:32,020
You can install Excalibur using a simple pip install.

213
00:15:32,020 --> 00:15:35,000
So this is the road ahead with these projects.

214
00:15:35,000 --> 00:15:38,800
Right now you have to choose a parsing flavor.

215
00:15:38,800 --> 00:15:44,840
I'm working on having an auto detection algorithm built in which automatically chooses your

216
00:15:44,840 --> 00:15:47,480
parsing flavor.

217
00:15:47,480 --> 00:15:50,280
Right now Camelot only works with text-based PDFs.

218
00:15:50,280 --> 00:15:56,600
So there's also a plan to add OCR support so that it can work on scanned images.

219
00:15:56,600 --> 00:16:02,520
And there are a couple of minor speed optimizations that can be done here and there.

220
00:16:03,040 --> 00:16:07,720
Since you looked at the web interface, it looked very simple since I'm not a frontend

221
00:16:07,720 --> 00:16:08,720
engineer.

222
00:16:08,720 --> 00:16:14,200
So if any of you know a little bit of frontend, you can help me out there, I think.

223
00:16:14,200 --> 00:16:19,300
These are the links where you can find out more about me and about the projects.

224
00:16:19,300 --> 00:16:22,720
You can check out open issues on the issues tab on GitHub.

225
00:16:22,720 --> 00:16:26,520
And all your peers would be very welcome.

226
00:16:26,520 --> 00:16:28,520
Awesome.

227
00:16:29,520 --> 00:16:33,280
So this is a picture of Team Social Cops.

228
00:16:33,280 --> 00:16:40,280
I want to thank Rishabh Raj, Deepu Thomas-Phillip, Ankita Mathur, Shilpa Rohra, Varun Banka,

229
00:16:40,280 --> 00:16:46,560
and all of the team who gave their inputs and feedback during multiple iterations of

230
00:16:46,560 --> 00:16:47,880
Camelot.

231
00:16:47,880 --> 00:16:53,260
And I also want to thank Jacob Singh, Manoj Tiwari, and Deepu Thomas-Phillip for their

232
00:16:53,260 --> 00:16:56,200
feedback on this talk.

233
00:16:56,200 --> 00:16:58,200
So yeah, I think we can move to questions.

234
00:16:59,200 --> 00:17:07,600
Yeah, so open the floor up for some questions.

235
00:17:07,600 --> 00:17:12,600
So if you do have questions, please come up to one of the mics and we'll go from there.

236
00:17:24,600 --> 00:17:26,600
Hi.

237
00:17:26,680 --> 00:17:30,480
So I've tried to do some PDF parsing.

238
00:17:30,480 --> 00:17:37,000
Some of the libraries I've used are like PDFminer, PyPDF2, and I've noticed that you can feed

239
00:17:37,000 --> 00:17:41,240
it different PDFs from different PDF generators and get different results.

240
00:17:41,240 --> 00:17:48,000
And one thing I recently was surprised by was that when you view a PDF in Chrome, it's

241
00:17:48,000 --> 00:17:49,040
always perfect.

242
00:17:49,480 --> 00:17:56,760
But if you do the Google cache operator on a web PDF, even Google can't convert it into

243
00:17:56,760 --> 00:17:58,320
HTML perfectly.

244
00:17:58,320 --> 00:18:04,840
So how could that be that the browser displays a PDF perfectly, but we can't convert it to

245
00:18:04,840 --> 00:18:09,180
HTML reliably or accurately?

246
00:18:09,180 --> 00:18:14,480
It's possible that the PDF that you're trying to convert is a scanned image instead of a

247
00:18:14,480 --> 00:18:15,960
text-based PDF.

248
00:18:15,960 --> 00:18:20,960
So that could be a problem with the PDF.

249
00:18:20,960 --> 00:18:28,320
Because any tool needs to have access to the internal text to convert that into an HTML

250
00:18:28,320 --> 00:18:29,320
in the first place.

251
00:18:29,320 --> 00:18:35,640
And if it's an image, you can't really access that text without running some sort of OCR

252
00:18:35,640 --> 00:18:37,800
operation on top of that PDF.

253
00:18:38,640 --> 00:18:39,640
Yeah.

254
00:18:43,640 --> 00:18:51,200
Is there some sort of intermediate format that you can get back from Camelot?

255
00:18:51,200 --> 00:18:55,200
I know you have the data frame, which is awesome.

256
00:18:55,200 --> 00:18:59,440
But is there a way to get back some sort of table object where you could merge cells and

257
00:18:59,440 --> 00:19:04,080
do stuff like that before putting it into a data frame?

258
00:19:04,080 --> 00:19:06,920
What sort of format are you looking for?

259
00:19:07,040 --> 00:19:14,440
I'm just, I have dealt with a number of kind of mangled PDFs where I've had to do splice

260
00:19:14,440 --> 00:19:17,200
cells together and stuff like that.

261
00:19:17,200 --> 00:19:19,720
I think you can easily do that on a Pandas data frame.

262
00:19:19,720 --> 00:19:25,400
If you just need to split cells or merge them together.

263
00:19:25,400 --> 00:19:29,640
Right now you can only access that table as a Pandas data frame inside Camelot.

264
00:19:29,640 --> 00:19:30,640
Okay.

265
00:19:30,640 --> 00:19:31,640
Thank you.

266
00:19:31,640 --> 00:19:32,640
Hi.

267
00:19:33,360 --> 00:19:39,760
Kind of adding to the question he had, how successful is Camelot in extracting a multi-index

268
00:19:39,760 --> 00:19:40,760
PDF?

269
00:19:40,760 --> 00:19:44,160
What if a couple of rows are clubbed together?

270
00:19:44,160 --> 00:19:48,160
Can I extract it to a multi-index Pandas data frame as well?

271
00:19:48,160 --> 00:19:49,880
What do you mean by multi-index PDF?

272
00:19:49,880 --> 00:19:55,920
Let's say a few rows in between here and there are merged together and I want to preserve

273
00:19:55,920 --> 00:19:58,520
the exact same format.

274
00:19:58,600 --> 00:20:05,080
It's actually two separate blocks of text which is, in Excel you can do it straightforward.

275
00:20:05,080 --> 00:20:07,240
You can just merge two blocks of text.

276
00:20:07,240 --> 00:20:13,480
But if you are converting an Excel document straight to a PDF, it doesn't look so neat.

277
00:20:13,480 --> 00:20:20,080
But if I try to parse out the data from a PDF, it's not necessarily a straightforward

278
00:20:20,080 --> 00:20:21,080
extract.

279
00:20:22,040 --> 00:20:30,960
If you're talking about those text lines lying in maybe different tables, then you'll get

280
00:20:30,960 --> 00:20:33,160
them as separate tables.

281
00:20:33,160 --> 00:20:37,080
But I think we can talk later.

282
00:20:37,080 --> 00:20:38,760
Maybe you can help me understand it better.

283
00:20:38,760 --> 00:20:41,040
You can take a look at it.

284
00:20:41,040 --> 00:20:49,840
Well, first of all, I can help you with your question, so find me two.

285
00:20:50,840 --> 00:20:53,120
Thank you for building this package.

286
00:20:53,120 --> 00:20:54,120
Much needed.

287
00:20:54,120 --> 00:20:57,400
So everybody here I know is probably really pleased.

288
00:20:57,400 --> 00:21:04,560
Is it possible to extract a list from the PDF, i.e. a table with one cell, because often

289
00:21:04,560 --> 00:21:06,520
that's what we need to get out?

290
00:21:06,520 --> 00:21:10,480
Yeah, it should be possible to extract a table with one column, you mean.

291
00:21:10,480 --> 00:21:11,480
Right, yeah.

292
00:21:11,480 --> 00:21:13,040
Yeah, it should be possible.

293
00:21:13,040 --> 00:21:14,040
Thank you.

294
00:21:14,040 --> 00:21:20,800
I'm curious if you have any, worked on any examples where there are multiple tables in

295
00:21:20,800 --> 00:21:25,120
the same file, if it confuses it, or if you have to reprocess it over and over?

296
00:21:25,120 --> 00:21:32,840
No, so if there are multiple tables on a PDF page, it would extract those as separate tables.

297
00:21:32,840 --> 00:21:36,880
I can send you a link for that example.

298
00:21:36,880 --> 00:21:37,880
It's on the documentation.

299
00:21:37,880 --> 00:21:40,880
Okay, thank you.

300
00:21:41,840 --> 00:21:46,120
Yeah, I wanted to echo the earlier comment that the tool is awesome.

301
00:21:46,120 --> 00:21:50,480
A couple months ago I had a challenge at work where someone said we need to find if this

302
00:21:50,480 --> 00:21:55,120
thing has a table or not, and so we looked at a bunch of different tools and we used

303
00:21:55,120 --> 00:21:56,400
Camelot heavily.

304
00:21:56,400 --> 00:21:58,200
I have a question.

305
00:21:58,200 --> 00:22:05,560
If I recall correctly, there was a feature in Camelot that allowed for a sort of visualization

306
00:22:05,560 --> 00:22:08,040
of the structure of a table.

307
00:22:09,000 --> 00:22:11,360
Okay, I was mixing up the ones and I thought it was Camelot.

308
00:22:11,360 --> 00:22:12,480
Yeah, that is in Camelot.

309
00:22:12,480 --> 00:22:17,200
I didn't include it in the slides because it would have made it longer, but there's

310
00:22:17,200 --> 00:22:20,920
an option for visual debugging where you can visualize the text lines that are lying on

311
00:22:20,920 --> 00:22:25,200
a table in the table that the library detects.

312
00:22:25,200 --> 00:22:26,200
We found that really helpful.

313
00:22:26,200 --> 00:22:30,160
I wonder if you could speak a little bit to how that works.

314
00:22:30,160 --> 00:22:32,680
Maybe I can show you the documentation for that.

315
00:22:32,680 --> 00:22:36,040
Let me see if I can escape this.

316
00:22:36,040 --> 00:22:44,400
So the documentation is on Read the Docs.

317
00:22:44,400 --> 00:22:47,960
You can go to the advanced usage.

318
00:22:47,960 --> 00:22:50,520
There are multiple examples here which you can use.

319
00:22:50,520 --> 00:22:59,480
So there's this whole section on visual debugging where you can basically, let me magnify this.

320
00:22:59,480 --> 00:23:04,880
So you can basically plot all these components that were found by Camelot on a PDF page,

321
00:23:04,920 --> 00:23:10,200
which is text, the table boundaries that were detected by Camelot, the lines that were detected,

322
00:23:10,200 --> 00:23:16,840
the line intersections that were detected in text edges is something that is, I can

323
00:23:16,840 --> 00:23:23,680
explain it to you later maybe, which will just show you the text that was on a PDF page.

324
00:23:23,680 --> 00:23:29,440
It can help you identify the coordinates for table areas and columns that you need to pass

325
00:23:29,440 --> 00:23:31,080
into Camelot.

326
00:23:31,080 --> 00:23:38,560
So this just generates some at plot lib for each of these different types of components.

327
00:23:38,560 --> 00:23:40,960
This is the table that was detected.

328
00:23:40,960 --> 00:23:44,240
This is the table boundary that was detected.

329
00:23:44,240 --> 00:23:48,400
Similarly, lines, line intersections.

330
00:23:48,400 --> 00:23:57,720
So you can play with the different knobs that the library gives you and see if maybe the

331
00:23:58,120 --> 00:24:04,400
intersections were detected or not and tweak them to maybe improve your results.

332
00:24:04,400 --> 00:24:05,400
Yeah.

333
00:24:05,400 --> 00:24:15,640
Is it able to union a one table that spans multiple pages?

334
00:24:15,640 --> 00:24:20,400
No, you will have to write logic to do that yourself.

335
00:24:20,400 --> 00:24:25,200
So each page gets converted to a one data frame and then you would union all of them?

336
00:24:25,400 --> 00:24:30,720
So each table is converted into a data frame and if a page has two tables, you will get

337
00:24:30,720 --> 00:24:34,960
two data frames and then you will have to stitch all those data frames together using

338
00:24:34,960 --> 00:24:35,960
some logic.

339
00:24:35,960 --> 00:24:36,960
Thanks.

340
00:24:36,960 --> 00:24:37,960
Hello.

341
00:24:37,960 --> 00:24:46,040
Have you noticed any functionality differences when you have a scanned and OCR PDF with tables

342
00:24:46,040 --> 00:24:54,360
in it versus a text-based PDF that's generated electronically?

343
00:24:54,360 --> 00:24:56,440
What sort of functionality differences?

344
00:24:56,440 --> 00:25:04,120
Well, a lot of times when you have a scanned PDF where you have to OCR it, the tables come

345
00:25:04,120 --> 00:25:09,480
across differently, at least in that text layer.

346
00:25:09,480 --> 00:25:15,000
So I was curious if you've found that with CamLot, if it works pretty good with those

347
00:25:15,000 --> 00:25:16,480
scanned and OCRed?

348
00:25:16,480 --> 00:25:20,480
No, right now it doesn't work with those scanned tables.

349
00:25:20,480 --> 00:25:22,680
There's a plan to add that as a feature.

350
00:25:23,000 --> 00:25:25,440
Right now it only works with text-based PDFs.

351
00:25:25,440 --> 00:25:26,440
Gotcha.

352
00:25:26,440 --> 00:25:27,440
Okay.

353
00:25:27,440 --> 00:25:28,440
Thank you.

354
00:25:32,440 --> 00:25:37,440
Do you have any interest in generalizing to text extraction as well as tables?

355
00:25:37,440 --> 00:25:43,280
What sort of features are you talking about here?

356
00:25:43,280 --> 00:25:47,440
So if you're interested in data in the PDF beyond just what's contained in tables?

357
00:25:47,440 --> 00:25:48,440
Okay, that way.

358
00:25:48,440 --> 00:25:53,320
Yeah, initially I was thinking about it, but right now it's mostly focused on tables.

359
00:25:53,320 --> 00:25:57,000
But I can add that as an issue and we can talk about it on GitHub.

360
00:25:57,000 --> 00:26:03,000
Did you have a question?

361
00:26:03,000 --> 00:26:08,640
It was more of a comment to the last gentleman.

362
00:26:08,640 --> 00:26:13,480
I recall when we were trying to sort of solve the problem we had, I can't remember if it

363
00:26:13,520 --> 00:26:19,680
was CamLot or Tabula, but one of the libraries had, for some of the things we used OCR on

364
00:26:19,680 --> 00:26:22,920
my PDF and then we passed those things to CamLot.

365
00:26:22,920 --> 00:26:29,240
But either CamLot or Tabula had a method for giving you a probability or a likelihood

366
00:26:29,240 --> 00:26:31,720
that this thing was correct or not.

367
00:26:31,720 --> 00:26:33,280
If that was CamLot, can you speak to that?

368
00:26:33,280 --> 00:26:36,640
I can't remember which one it was, but that may speak to the gentleman's question.

369
00:26:36,640 --> 00:26:42,880
Are you talking about the parsing report that I showed?

370
00:26:42,880 --> 00:26:48,280
Could have been CamLot, I guess.

371
00:26:48,280 --> 00:26:49,960
Are you talking about this parsing report?

372
00:26:49,960 --> 00:26:52,960
Yes, sorry, yes.

373
00:26:52,960 --> 00:26:53,960
Yeah.

374
00:26:53,960 --> 00:26:54,960
Cool.

375
00:26:54,960 --> 00:27:02,280
Thank you all for coming out today to this talk.

376
00:27:02,280 --> 00:27:04,280
So in the next few minutes, I believe there will be some sprints.

377
00:27:04,280 --> 00:27:07,280
I don't believe they're happening in this room, so you can check the schedule.

378
00:27:07,280 --> 00:27:12,440
And I'd like to thank Mr. Mehta for coming and giving his talk.

379
00:27:12,440 --> 00:27:15,880
Thank you.

