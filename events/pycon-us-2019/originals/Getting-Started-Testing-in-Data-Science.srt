1
00:00:00,000 --> 00:00:16,760
Hello.

2
00:00:16,760 --> 00:00:27,400
This talk is going to be getting started testing in data science, and this is Jess Ford.

3
00:00:27,400 --> 00:00:31,960
Hello, everyone.

4
00:00:31,960 --> 00:00:36,160
Thank you so much for coming to one of the last talks on the last day of PyCon.

5
00:00:36,160 --> 00:00:37,160
My name is Jess Ford.

6
00:00:37,160 --> 00:00:42,640
I'm really excited to be talking to you about getting started testing in data science.

7
00:00:42,640 --> 00:00:43,640
So I'm Jess.

8
00:00:43,640 --> 00:00:50,040
I am a data scientist currently working at a company called Recursion in Salt Lake City,

9
00:00:50,040 --> 00:00:51,040
Utah.

10
00:00:51,040 --> 00:00:56,400
We do AI-driven drug discovery, and we are hiring kind of across the board.

11
00:00:56,400 --> 00:01:01,280
So if that interests you, check out our careers page at the bottom there.

12
00:01:01,280 --> 00:01:04,960
My backstory is I'm originally from Alaska.

13
00:01:04,960 --> 00:01:07,440
My first passion in life is for snowboarding.

14
00:01:07,440 --> 00:01:12,560
So I've lived kind of all over the West Coast trying to balance my academic and career pursuits

15
00:01:12,560 --> 00:01:17,400
with snowboarding as much as possible, which is how I ended up in Utah.

16
00:01:17,400 --> 00:01:23,720
I did a PhD in astrophysics and a postdoc in data science after that, and that was where

17
00:01:23,760 --> 00:01:27,520
I was first exposed to actual software testing.

18
00:01:27,520 --> 00:01:31,000
Like a lot of data scientists I've met, I don't have like formal background training

19
00:01:31,000 --> 00:01:36,760
in software best practices, and a lot of data scientists that I've met have never written

20
00:01:36,760 --> 00:01:38,840
tests or have no idea how to get started.

21
00:01:38,840 --> 00:01:43,200
So that was kind of my motivation for the talk today.

22
00:01:43,200 --> 00:01:46,680
So the plan for my presentation, I'm going to start off kind of motivating why you would

23
00:01:46,680 --> 00:01:47,680
want to test.

24
00:01:47,680 --> 00:01:52,160
I'm going to introduce how to get started at a really basic level writing your first

25
00:01:52,200 --> 00:01:56,160
test using PyTest, and then we're going to talk data science specifics.

26
00:01:56,160 --> 00:02:00,320
So we're going to talk about workflows that are kind of unique to working in data science,

27
00:02:00,320 --> 00:02:05,160
and we're going to talk about and go through some example actual bits of code, for examples

28
00:02:05,160 --> 00:02:09,800
of ways and tools that are useful for testing in data science.

29
00:02:09,800 --> 00:02:11,240
Okay.

30
00:02:11,240 --> 00:02:13,080
So why test?

31
00:02:13,080 --> 00:02:17,080
Testing gives you evidence that your code is working as expected, right?

32
00:02:17,080 --> 00:02:21,200
It gives you confidence to make changes without fear of breaking anything, and it can give

33
00:02:21,240 --> 00:02:25,080
other people some more trust in your code.

34
00:02:25,080 --> 00:02:28,600
So that's great, but why wouldn't you want to test, right?

35
00:02:28,600 --> 00:02:34,280
So a variety of reasons, but I think the main thing that people will say is that it takes

36
00:02:34,280 --> 00:02:36,000
time, and that's true.

37
00:02:36,000 --> 00:02:37,440
And so this is my struggle.

38
00:02:37,440 --> 00:02:42,360
So as a data scientist, I'm constantly trying to balance these competing interests of getting

39
00:02:42,360 --> 00:02:48,040
results to my stakeholders as quickly as possible, but also obviously trying to be as confident

40
00:02:48,040 --> 00:02:50,680
as possible that I have the right answer when I do that.

41
00:02:50,680 --> 00:02:55,120
So trying to balance these interests in the optimal way, I think testing gives you a tool

42
00:02:55,120 --> 00:02:58,160
to be able to do that.

43
00:02:58,160 --> 00:03:02,240
So in this talk, I'm not going to insist that you should always write tests, but I'm going

44
00:03:02,240 --> 00:03:06,800
to talk about different scenarios that I find myself in as a data scientist and how I try

45
00:03:06,800 --> 00:03:10,000
to be confident that my results are correct.

46
00:03:10,000 --> 00:03:14,400
I'm going to show you how to get started and some tools for data science testing.

47
00:03:14,400 --> 00:03:18,240
The disclaimer here is that I'm not a testing expert or a software engineer, and there's

48
00:03:18,240 --> 00:03:20,520
a lot of things I don't know.

49
00:03:20,560 --> 00:03:26,200
And data science itself kind of covers a laughably huge range of actual day-to-day job duties,

50
00:03:26,200 --> 00:03:27,280
as I'm sure many of you know.

51
00:03:27,280 --> 00:03:32,400
So formal testing is more important in some of those than it is in others, and we'll talk

52
00:03:32,400 --> 00:03:33,400
about that.

53
00:03:33,400 --> 00:03:34,400
Okay.

54
00:03:34,400 --> 00:03:37,040
So we care about our code getting the right answer.

55
00:03:37,040 --> 00:03:39,320
So how do we know when our code is correct?

56
00:03:39,320 --> 00:03:41,160
There's kind of three levels of this.

57
00:03:41,160 --> 00:03:43,680
You can do some manual sanity checks.

58
00:03:43,680 --> 00:03:47,400
So you run your function, and in your head, you kind of know what you expect, and you

59
00:03:47,400 --> 00:03:48,400
look at the answer.

60
00:03:48,400 --> 00:03:52,600
And in your head, you decide this looks right.

61
00:03:52,600 --> 00:03:55,400
The next level up is defensive programming.

62
00:03:55,400 --> 00:04:02,020
So this is adding checks within your code itself to make sure that things are working

63
00:04:02,020 --> 00:04:04,120
as you expect.

64
00:04:04,120 --> 00:04:09,280
And then there's the third level of having a standalone test suite that can be run automatically.

65
00:04:09,280 --> 00:04:12,640
So let's talk about defensive programming first, because this gives us the building

66
00:04:12,640 --> 00:04:16,340
blocks that we're going to be creating tests with.

67
00:04:16,340 --> 00:04:20,620
So defensive programming is just adding assertions within your code.

68
00:04:20,620 --> 00:04:25,540
So as a kind of silly example, I've got this function hello to all.

69
00:04:25,540 --> 00:04:29,500
It takes in a list of names, and it prints hello to those people.

70
00:04:29,500 --> 00:04:34,660
But before it does that, it actually checks that there are things in that list, and if

71
00:04:34,660 --> 00:04:36,900
not, it's going to raise an error.

72
00:04:36,900 --> 00:04:41,660
So I can print hello to some of my friends, but if I give this function an empty list,

73
00:04:41,660 --> 00:04:43,660
it's going to raise an assertion error.

74
00:04:43,660 --> 00:04:49,980
So these assertions are the building blocks of what we're going to test with.

75
00:04:49,980 --> 00:04:55,620
So I do want to emphasize this before we jump into actual testing, that these are your best

76
00:04:55,620 --> 00:04:56,860
friend as a data scientist.

77
00:04:56,860 --> 00:04:57,860
This is your middle ground.

78
00:04:57,860 --> 00:05:02,300
If you don't have time to go and write the tests that you maybe know you should, this

79
00:05:02,300 --> 00:05:05,040
is your middle ground of checking that things are working.

80
00:05:05,040 --> 00:05:08,800
So check that you don't have duplicates in your data set.

81
00:05:08,800 --> 00:05:13,140
Check for the types of your data columns, things like that.

82
00:05:13,220 --> 00:05:17,200
So this is your takeaway if you don't go write tests, is to at least start adding assertions

83
00:05:17,200 --> 00:05:18,860
all over the place.

84
00:05:18,860 --> 00:05:19,940
Okay.

85
00:05:19,940 --> 00:05:23,000
So let's go to our actual first test example.

86
00:05:23,000 --> 00:05:28,620
So I'm going to start off with a really, really simple toy example, and we will get more advanced

87
00:05:28,620 --> 00:05:29,780
later, I promise.

88
00:05:29,780 --> 00:05:33,420
So here's a simple function backwards all caps.

89
00:05:33,420 --> 00:05:38,140
It takes in a text string, and it just reverses that string and uppercases it.

90
00:05:38,140 --> 00:05:39,140
Okay.

91
00:05:39,700 --> 00:05:44,220
I can write a test for this, or sorry, just to manually check things here.

92
00:05:44,220 --> 00:05:45,420
I'm going to run this on Python.

93
00:05:45,420 --> 00:05:48,860
I get back no teep.

94
00:05:48,860 --> 00:05:52,820
And I can write a test for this function by just defining a function that starts with

95
00:05:52,820 --> 00:05:57,660
test, and then I just add some assertion lines in here, and I just check that running my

96
00:05:57,660 --> 00:06:01,800
function on some known input gives me some known output.

97
00:06:01,800 --> 00:06:04,220
And this is really, really simple.

98
00:06:04,220 --> 00:06:09,460
This is how easy it is to get started writing tests with PyTest.

99
00:06:09,460 --> 00:06:11,000
PyTest is a great framework.

100
00:06:11,000 --> 00:06:16,860
It has much less boilerplate than things like unit test, and it takes care of a lot of things

101
00:06:16,860 --> 00:06:17,860
for you.

102
00:06:17,860 --> 00:06:20,340
There's a lot of stuff you don't have to worry about and a lot of really powerful built-in

103
00:06:20,340 --> 00:06:24,540
features, and we're not going to cover very much of that today, but you can pip install

104
00:06:24,540 --> 00:06:26,840
it and get started.

105
00:06:26,840 --> 00:06:31,220
So I'm going to go through a little demo just to kind of show you what it looks like when

106
00:06:31,220 --> 00:06:35,180
you have like how you actually run your tests and what it looks like when they pass and

107
00:06:35,180 --> 00:06:37,020
they fail.

108
00:06:37,020 --> 00:06:44,420
So let's say that this example I was just showing you is in a file called demo TDD.py,

109
00:06:44,420 --> 00:06:50,740
and I could run these tests on the command line by just saying PyTest, name of the file.

110
00:06:50,740 --> 00:06:56,420
So if I do that, if you can read this up here, it tells me that the test session started,

111
00:06:56,420 --> 00:06:59,660
it prints some information about my platform and the versions, and it says it collected

112
00:06:59,660 --> 00:07:04,460
one item, which is my one test, and then it shows me the name of the file, and there's

113
00:07:04,460 --> 00:07:09,220
this little green dot right here that I'm not sure if you can see, but there is a green

114
00:07:09,220 --> 00:07:12,260
dot, and this symbolizes my passing test.

115
00:07:12,260 --> 00:07:17,340
I could also run the same command with a verbose flag, and this will tell me the name of the

116
00:07:17,340 --> 00:07:22,780
actual test and print passed in bright green letters, and if I had a failing test, this

117
00:07:22,780 --> 00:07:27,380
verbose flag would give me a lot of useful information to figure out what went wrong.

118
00:07:28,060 --> 00:07:32,220
Okay, so let's say that we want to add a new feature to our test function, and we want

119
00:07:32,220 --> 00:07:37,940
to, let's say that we want any white space in text to be actually removed.

120
00:07:37,940 --> 00:07:43,020
So we're going to do this in test-driven development style, so instead of going and adding this

121
00:07:43,020 --> 00:07:46,700
feature right away, we're first going to add a test for this.

122
00:07:46,700 --> 00:07:50,460
We're going to run our test to make sure it fails, then we're going to add our feature

123
00:07:50,460 --> 00:07:52,660
and make sure that our tests pass.

124
00:07:53,220 --> 00:08:00,860
Okay, so I have added a function, testLettersOnly, and I'm testing that giving it Salt Lake City

125
00:08:00,860 --> 00:08:05,340
should return that reverse of that with no spaces.

126
00:08:05,340 --> 00:08:12,220
If I run my test, I'm going to get one green dot for my passing test that I had previously,

127
00:08:12,220 --> 00:08:13,420
and then I get a failure.

128
00:08:13,420 --> 00:08:19,260
So testLettersOnly has failed, and it shows me that I tried to assert that the output

129
00:08:19,260 --> 00:08:24,900
of my function here with spaces was equal to the thing that I hard-coded with no spaces,

130
00:08:24,900 --> 00:08:27,380
and that's not true, so I have a failure.

131
00:08:27,380 --> 00:08:30,580
Okay, so we're going to go in and add this feature now.

132
00:08:30,580 --> 00:08:36,820
So I'm just using the dot replace string method to replace white space with empty string,

133
00:08:36,820 --> 00:08:40,540
and if I run my test again now, I get two passing tests.

134
00:08:40,540 --> 00:08:46,620
Okay, so that's fine, that's how easy it is to write tests and practice this test-driven

135
00:08:46,660 --> 00:08:51,100
development workflow, but you're probably thinking, okay, so these examples were pretty

136
00:08:51,100 --> 00:08:52,100
dumb, right?

137
00:08:52,100 --> 00:08:54,500
So a couple of things here.

138
00:08:54,500 --> 00:08:58,540
These examples don't really seem very applicable to data science work, right?

139
00:08:58,540 --> 00:09:03,460
We do not often, you know, doing simple string manipulation, and this test-driven development

140
00:09:03,460 --> 00:09:08,940
workflow, which I really love and I think is helpful for writing good code, it's not

141
00:09:08,940 --> 00:09:12,820
always a really reasonable way to be working in data science.

142
00:09:12,820 --> 00:09:16,980
We are often kind of exploring things and seeing what new directions you might take,

143
00:09:16,980 --> 00:09:21,540
and it's not, you know, it's not like these well-defined problems that are easy to do

144
00:09:21,540 --> 00:09:24,460
this, like, software best practice with.

145
00:09:24,460 --> 00:09:27,500
Okay, so we're going to talk about each of those pieces.

146
00:09:27,500 --> 00:09:31,820
So data science domain problems, instead of working with a lot of those, like, native

147
00:09:31,820 --> 00:09:36,540
Python data types, we often have pandas data frames, numpy arrays as the inputs and outputs

148
00:09:36,540 --> 00:09:38,220
of our functions.

149
00:09:38,220 --> 00:09:42,780
We might be reading and writing to databases quite a bit, and then, of course, we're generating

150
00:09:42,820 --> 00:09:48,060
these machine learning or probabilistic models that don't necessarily have deterministic

151
00:09:48,060 --> 00:09:49,060
outcomes.

152
00:09:49,060 --> 00:09:54,740
So we might want to think about what are the acceptable tolerances on our results or testing

153
00:09:54,740 --> 00:09:59,820
for properties of these things instead of exact values.

154
00:09:59,820 --> 00:10:01,260
And workflows, right?

155
00:10:01,260 --> 00:10:05,820
So I can kind of break down the types of work I do into roughly three buckets.

156
00:10:05,820 --> 00:10:09,620
There's the one-off analysis that I put in quotes because, you know, you think you're

157
00:10:09,780 --> 00:10:14,660
doing something once and you end up having to come back to it.

158
00:10:14,660 --> 00:10:18,700
And there's the exploratory phase where I spend a ton of my time, you know, maybe you

159
00:10:18,700 --> 00:10:23,220
have a new data set and you need to see what's in it, see what's available, or you're exploring

160
00:10:23,220 --> 00:10:27,380
a new type of model you might apply to some problem.

161
00:10:27,380 --> 00:10:31,700
And then finally, there's the well-defined problem, the elusive thing that comes up occasionally

162
00:10:31,700 --> 00:10:35,180
but is probably a smaller part of our actual workflow.

163
00:10:35,180 --> 00:10:38,500
Okay, so for one-off analysis, I don't write tests.

164
00:10:38,500 --> 00:10:42,860
This is probably something that I'm just doing in a Jupyter notebook and I try to focus on

165
00:10:42,860 --> 00:10:44,500
clear documentation.

166
00:10:44,500 --> 00:10:48,680
Having good documentation is going to save me work in the long run if I do have to come

167
00:10:48,680 --> 00:10:49,680
back to this.

168
00:10:49,680 --> 00:10:52,420
And that's going to be, I think, more effective than writing tests for something that I don't

169
00:10:52,420 --> 00:10:55,340
know I'm going to need again.

170
00:10:55,340 --> 00:10:58,620
If I do come back to this, then I'll consider maybe breaking this out of the notebook, maybe

171
00:10:58,620 --> 00:11:03,660
writing some tests, but that's for down the road.

172
00:11:03,660 --> 00:11:04,660
Exploratory work.

173
00:11:05,100 --> 00:11:10,220
It's definitely impossible to test when you are exploring and going in all different directions,

174
00:11:10,220 --> 00:11:11,220
right?

175
00:11:11,220 --> 00:11:17,340
But the challenge here is I spend a ton of my actual time in this phase of work and I

176
00:11:17,340 --> 00:11:23,380
think nearly every time there's some code that I write while I'm doing this that ends

177
00:11:23,380 --> 00:11:25,740
up being useful down the road.

178
00:11:25,740 --> 00:11:33,140
And so this is this challenge of, as I continue writing more and more functions or bits of

179
00:11:33,180 --> 00:11:37,980
code that are useful in this exploration, I have to decide, you know, when do I think

180
00:11:37,980 --> 00:11:42,220
parts of this are becoming useful enough that I might want to consider writing tests for

181
00:11:42,220 --> 00:11:43,220
them?

182
00:11:43,220 --> 00:11:47,220
So this is challenging.

183
00:11:47,220 --> 00:11:48,620
And finally, the well-defined problem.

184
00:11:48,620 --> 00:11:53,900
This doesn't come up a lot, but when it does, I try to practice test-driven development

185
00:11:53,900 --> 00:11:54,900
here.

186
00:11:54,900 --> 00:11:58,860
This is when I can actually have a chance to write tests while I'm developing my software

187
00:11:59,180 --> 00:12:05,780
and usually end up with some nicer designed code.

188
00:12:05,780 --> 00:12:08,780
And I'm going to add on a fourth bucket here.

189
00:12:08,780 --> 00:12:13,060
As it pertains to testing, there's this issue of working with legacy code.

190
00:12:13,060 --> 00:12:18,140
So this could be code you inherited from somebody else at work or it could be stuff that you

191
00:12:18,140 --> 00:12:23,340
developed yourself while you were in this exploratory mode of your project.

192
00:12:23,340 --> 00:12:26,740
And when I'm in this kind of scenario, you know, you don't want to get overwhelmed thinking

193
00:12:26,780 --> 00:12:31,660
about writing tests for everything that's there, but I try to think about when I modify

194
00:12:31,660 --> 00:12:34,140
that code, adding tests at that time.

195
00:12:34,140 --> 00:12:37,300
And this is inspired by a really good talk from last year that I would encourage you

196
00:12:37,300 --> 00:12:38,300
to look up.

197
00:12:38,300 --> 00:12:43,740
So PyCon 2018, this talk by Justin Crown on testing legacy code bases I thought was really,

198
00:12:43,740 --> 00:12:45,220
really great.

199
00:12:45,220 --> 00:12:46,260
Okay.

200
00:12:46,260 --> 00:12:49,060
So let's get back into some actual code.

201
00:12:49,060 --> 00:12:52,500
So examples of tests for common data science problems.

202
00:12:52,500 --> 00:12:54,620
Well, we'll start off pretty simple here.

203
00:12:54,620 --> 00:12:58,700
So pandas data frames.

204
00:12:58,700 --> 00:13:02,260
There's some really useful things built into pandas that will help you test.

205
00:13:02,260 --> 00:13:08,980
So here I've got a toy data frame of customer orders that were recorded through coming through

206
00:13:08,980 --> 00:13:11,180
different marketing channels.

207
00:13:11,180 --> 00:13:14,680
And some of the simple things you want to do with your data frames is you want to check

208
00:13:14,680 --> 00:13:17,280
for missing values.

209
00:13:17,280 --> 00:13:22,820
You can do that in a few different ways using some built in pandas methods like not null

210
00:13:22,980 --> 00:13:25,100
and is null.

211
00:13:25,100 --> 00:13:31,020
And you can check for duplicate data using the built in duplicated method.

212
00:13:31,020 --> 00:13:36,920
Duplicated will by default check across the entire row of a data frame and you might only

213
00:13:36,920 --> 00:13:38,420
care about a specific one.

214
00:13:38,420 --> 00:13:43,060
So here I've got an order that was recorded twice as coming through different marketing

215
00:13:43,060 --> 00:13:49,660
channels and I might want to assert that I only, that I don't have duplicates just within

216
00:13:49,660 --> 00:13:51,780
the order column, for example.

217
00:13:51,780 --> 00:13:57,020
So I can do that with the subset parameter.

218
00:13:57,020 --> 00:14:02,380
Pandas also has a lot of useful built in tools for testing.

219
00:14:02,380 --> 00:14:06,300
And the one that I use by far the most is assert frame equals.

220
00:14:06,300 --> 00:14:11,780
Assert frame equal lets you compare two data frames and assert that they're equal given

221
00:14:11,780 --> 00:14:13,900
a whole bunch of other qualifying things.

222
00:14:13,900 --> 00:14:17,140
So the ones I use the most are check like.

223
00:14:17,140 --> 00:14:21,260
So check like, if that's true, I'm saying I don't care about the rows and columns of

224
00:14:21,260 --> 00:14:23,220
my data frame being in the same order.

225
00:14:23,220 --> 00:14:27,700
I just care that all the content is there and that that matches up.

226
00:14:27,700 --> 00:14:33,940
Check D type is whether or not you want pandas to really strictly compare the data types

227
00:14:33,940 --> 00:14:34,940
to your columns.

228
00:14:34,940 --> 00:14:39,100
And this is, I find this useful to set to false in some scenarios where I do a bunch

229
00:14:39,100 --> 00:14:43,700
of manipulations on a data frame and I end up with two different kinds of floating points.

230
00:14:43,700 --> 00:14:46,580
The numbers are the same but the data type's not technically the same.

231
00:14:46,580 --> 00:14:50,200
So it can be useful sometimes to set this to false.

232
00:14:50,200 --> 00:14:55,560
And then you can set the precision that you care about comparing things with.

233
00:14:55,560 --> 00:15:01,640
And then finally, assert frame equals handles the nan or none comparisons as you would expect.

234
00:15:01,640 --> 00:15:04,880
So in Python, nan is not equal to nan.

235
00:15:04,880 --> 00:15:08,920
But in the context of comparing an entire data set, what you probably care about is

236
00:15:08,920 --> 00:15:11,640
that the nans are in the same places in both.

237
00:15:11,640 --> 00:15:16,080
So assert frame equals will handle that as you would probably hope.

238
00:15:16,080 --> 00:15:18,680
All right.

239
00:15:18,680 --> 00:15:20,800
What about working with databases?

240
00:15:20,800 --> 00:15:24,740
So let's say that I have a function load data.

241
00:15:24,740 --> 00:15:30,040
It takes in some SQL condition and then it actually queries the database.

242
00:15:30,040 --> 00:15:34,240
So it queries my database and returns some data frame.

243
00:15:34,240 --> 00:15:36,280
And then I apply some transformations to that.

244
00:15:36,280 --> 00:15:43,280
So I do some one-hot encoding and then I set the index of the data frame and return it.

245
00:15:43,280 --> 00:15:51,400
I could test my load data function by defining a test load data that actually runs that function,

246
00:15:51,400 --> 00:15:56,840
passes in some sample condition that I've defined and then checks that the output is

247
00:15:56,840 --> 00:16:00,340
matches some output data frame that I've defined.

248
00:16:00,340 --> 00:16:04,000
But the problem here is that we probably don't want to be querying our database as part of

249
00:16:04,000 --> 00:16:05,280
our tests.

250
00:16:05,280 --> 00:16:09,840
So for a few reasons, it might take a long time to run the query.

251
00:16:09,840 --> 00:16:14,000
You might have different data that exists in your table at different times.

252
00:16:14,000 --> 00:16:16,160
It might not be consistent.

253
00:16:16,160 --> 00:16:18,960
And if you're running your tests as part of a continuous integration, you probably don't

254
00:16:18,960 --> 00:16:21,600
want that system to be hitting your database as well.

255
00:16:21,600 --> 00:16:26,900
So one solution to this problem is to use PyTest mock.

256
00:16:26,900 --> 00:16:31,320
This is a PyTest plugin that you can pip install and it basically lets you kind of patch or

257
00:16:31,320 --> 00:16:35,040
swap out one piece of code for another.

258
00:16:35,040 --> 00:16:40,880
So to show you how that might work, here I've now changed my test load data function so

259
00:16:40,880 --> 00:16:47,480
that I'm pulling in this mocker object and then I call mocker.patch.

260
00:16:47,480 --> 00:16:53,080
And I'm basically saying any time that you encounter this query database function, instead

261
00:16:53,080 --> 00:16:59,880
of doing that, do this other thing and return my sample data input, which I've defined to

262
00:16:59,880 --> 00:17:02,560
be some data frame here.

263
00:17:02,560 --> 00:17:03,960
So what's going to happen now?

264
00:17:03,960 --> 00:17:09,040
I'm going to call my load data function and it doesn't matter anymore whether I actually

265
00:17:09,040 --> 00:17:15,400
pass it a query string because when load data runs and it gets to that query database line,

266
00:17:15,400 --> 00:17:19,040
instead of running that function, it's just going to pass in that data frame.

267
00:17:19,040 --> 00:17:24,120
And so then what I'm doing is I'm basically testing these additional transformations that

268
00:17:24,120 --> 00:17:25,640
I was running in my function.

269
00:17:25,640 --> 00:17:29,840
And you can imagine, obviously, something much more complicated that just has some SQL

270
00:17:29,840 --> 00:17:33,740
query in there and you want to test everything else in your function but just not that one

271
00:17:33,740 --> 00:17:34,740
piece.

272
00:17:34,740 --> 00:17:36,660
Hopefully that should be tested elsewhere.

273
00:17:36,660 --> 00:17:39,260
All right.

274
00:17:39,260 --> 00:17:41,020
Cool.

275
00:17:41,020 --> 00:17:47,660
So in this example, I kind of threw in a couple input and output data frames here but I didn't

276
00:17:47,660 --> 00:17:55,460
actually in this slide include all the boilerplate code for how those data frames would be defined.

277
00:17:55,460 --> 00:17:59,260
And the reason is that would take a lot of lines of code.

278
00:17:59,260 --> 00:18:04,540
Hard coding input and output data frames to your function is extremely verbose.

279
00:18:04,540 --> 00:18:09,780
Even just for a couple example inputs, outputs with, like, you know, really toy data frames,

280
00:18:09,780 --> 00:18:14,920
few rows, few columns, that's a lot of lines of code and it takes a lot of time.

281
00:18:14,920 --> 00:18:19,700
So a really useful library to handle this is called hypothesis.

282
00:18:19,700 --> 00:18:23,060
And you're going to hear a lot more about this in the next talk.

283
00:18:23,060 --> 00:18:27,500
But the idea for my purposes is that this is a way to automatically generate data for

284
00:18:28,060 --> 00:18:30,260
I don't have to hard code things.

285
00:18:30,260 --> 00:18:36,020
So hypothesis has this idea of strategies for different types of input and output data.

286
00:18:36,020 --> 00:18:41,940
And so for the integer strategy, in an interactive session, you can ask hypothesis for examples

287
00:18:41,940 --> 00:18:42,940
of things.

288
00:18:42,940 --> 00:18:47,060
And here I'm just printing out a few different integers that hypothesis might generate if

289
00:18:47,060 --> 00:18:51,780
I were to pass this to a test function.

290
00:18:51,780 --> 00:18:57,460
And going back to our really simple toy example from the start of the talk, I've got my back

291
00:18:57,540 --> 00:18:58,860
all caps function.

292
00:18:58,860 --> 00:19:04,980
So now I can use hypothesis to generate examples to run my test on.

293
00:19:04,980 --> 00:19:08,220
So here I'm using this hypothesis given decorator.

294
00:19:08,220 --> 00:19:15,580
And I'm saying that given some text, according to a text strategy, I'm going to run backwards

295
00:19:15,580 --> 00:19:20,700
all caps on that text generated by hypothesis.

296
00:19:20,700 --> 00:19:27,420
And then I'm just testing that that output, when reversed, is the same as the uppercase

297
00:19:27,420 --> 00:19:28,420
of the input.

298
00:19:28,420 --> 00:19:33,580
So I'm kind of reverse engineering and doing a similar thing in a different way and testing

299
00:19:33,580 --> 00:19:35,180
that that matches up.

300
00:19:35,180 --> 00:19:40,620
And so if I run this now, to run a test using hypothesis, you don't have to change anything.

301
00:19:40,620 --> 00:19:46,620
So you're still just running PyTest, name of your file for running on a specific file.

302
00:19:46,620 --> 00:19:52,540
And here I'm including this extra hypothesis show statistics option here.

303
00:19:52,540 --> 00:19:57,340
And that's going to show me that hypothesis ran 100 different passing examples.

304
00:19:57,340 --> 00:20:02,300
So one line of code here, it ran hundreds of different input text strings.

305
00:20:02,300 --> 00:20:03,300
And they all passed.

306
00:20:03,300 --> 00:20:07,380
It spent about 75% of its time actually generating the data.

307
00:20:07,380 --> 00:20:11,800
And it stopped because it got to the settings max example was 100.

308
00:20:11,800 --> 00:20:13,060
So this is fully configurable.

309
00:20:13,060 --> 00:20:19,780
You could run thousands of examples or fewer examples if it takes a lot of time.

310
00:20:19,780 --> 00:20:25,260
So what's really useful is not just being able to generate text, but being able to generate

311
00:20:25,260 --> 00:20:27,780
pandas data frames and NumPy arrays.

312
00:20:27,780 --> 00:20:29,580
And hypothesis has support for both of those.

313
00:20:29,580 --> 00:20:31,540
And we're just going to talk about pandas.

314
00:20:31,540 --> 00:20:35,300
So you can import the data frames and the column strategy.

315
00:20:35,300 --> 00:20:39,300
And you can build up data frame strategies out of columns.

316
00:20:39,300 --> 00:20:45,160
So here I have a data frame that has three columns, customer, price, and probability

317
00:20:45,160 --> 00:20:46,540
of return.

318
00:20:46,540 --> 00:20:52,420
And the customer column is made up of an integer strategy with values between 0 and 100,000.

319
00:20:52,420 --> 00:20:55,020
And the values have to be unique.

320
00:20:55,020 --> 00:20:57,020
Price is a floating point column.

321
00:20:57,020 --> 00:21:01,140
And probability of return is floating point with values between 0 and 1.

322
00:21:01,140 --> 00:21:03,220
So like a probability.

323
00:21:03,220 --> 00:21:07,580
And I'm asking hypothesis here for one example of a data frame it might give me.

324
00:21:07,580 --> 00:21:09,160
And here it prints out something.

325
00:21:09,160 --> 00:21:14,800
And you'll notice that it's a hypothesis tries to kind of push at the corners of your

326
00:21:14,800 --> 00:21:20,200
code and give you like test cases or examples of code that you might not expect and look

327
00:21:20,200 --> 00:21:21,680
for edge cases in your code.

328
00:21:21,680 --> 00:21:26,040
So it's trying some really large values in the price column.

329
00:21:26,040 --> 00:21:31,240
And it's experimenting with what happens if you don't have unique values in a column.

330
00:21:31,240 --> 00:21:32,720
And so you can configure that.

331
00:21:32,720 --> 00:21:36,400
And you can say you can give bounds on the numbers and things like that.

332
00:21:37,280 --> 00:21:40,280
By default, it'll give you some weird stuff.

333
00:21:40,280 --> 00:21:43,840
Another example, same code here but a different example, is an empty data frame.

334
00:21:43,840 --> 00:21:47,960
I could specify how many rows I wanted to have or a minimum and a max number of rows,

335
00:21:47,960 --> 00:21:48,960
but I didn't.

336
00:21:48,960 --> 00:21:52,880
So hypothesis will see what happens if it gives your code an empty data frame.

337
00:21:52,880 --> 00:21:54,320
Okay.

338
00:21:54,320 --> 00:22:01,240
So as one last example, let's say I have a data frame of customer attributes.

339
00:22:01,240 --> 00:22:06,160
I have the days since they last placed an order for customers who ordered in the last

340
00:22:06,160 --> 00:22:07,160
year.

341
00:22:07,160 --> 00:22:10,720
And I've got the total number of orders that they've placed with me.

342
00:22:10,720 --> 00:22:14,320
And this is a toy data set that's not a seasonal business.

343
00:22:14,320 --> 00:22:16,680
The days since the last order is pretty flat.

344
00:22:16,680 --> 00:22:19,080
A lot of customers have made one or two orders.

345
00:22:19,080 --> 00:22:21,240
Very few have made a lot of orders.

346
00:22:21,240 --> 00:22:25,080
And let's say, just for the sake of argument here, that I think I knew how to calculate

347
00:22:25,080 --> 00:22:28,600
the probability that a customer is loyal to my company.

348
00:22:28,600 --> 00:22:33,960
And let's say, for the sake of argument, that I think applying a logistic function to the

349
00:22:33,960 --> 00:22:38,840
number of total orders and normalizing the days since last order and multiplying those

350
00:22:38,840 --> 00:22:43,280
things will give me a probability that this customer is going to come back.

351
00:22:43,280 --> 00:22:49,280
So here's my distribution of customer probability of being loyal.

352
00:22:49,280 --> 00:22:51,200
And let's say I want to test this function.

353
00:22:51,200 --> 00:22:56,480
And I want to make sure that this function is always going to give me back a valid probability.

354
00:22:56,520 --> 00:23:02,620
So what I could do is I could define a test function that takes in a data frame.

355
00:23:02,620 --> 00:23:07,080
It applies my probability loyal customer function to that data frame.

356
00:23:07,080 --> 00:23:09,920
That gives me back a Panda series.

357
00:23:09,920 --> 00:23:13,880
And here I'm just asserting that all the values in that are between zero and one.

358
00:23:13,880 --> 00:23:17,960
So they're valid probabilities.

359
00:23:17,960 --> 00:23:22,320
Then instead of actually hard coding those input and output data frames, I'm just going

360
00:23:22,320 --> 00:23:29,320
to use hypothesis given to say, given any data frame that has these two columns, integer

361
00:23:29,320 --> 00:23:35,840
values for days since last order, and total number of orders, which is an integer between

362
00:23:35,840 --> 00:23:41,720
say zero and a million, I just want to make sure that this always gives me back probabilities.

363
00:23:41,720 --> 00:23:47,040
So I'm going to run this test with hypothesis.

364
00:23:47,040 --> 00:23:52,920
So I just run py test, name of the file, and I get 100 different passing examples that

365
00:23:52,920 --> 00:23:53,920
pass through my test.

366
00:23:53,920 --> 00:23:56,840
It took a few milliseconds to run.

367
00:23:56,840 --> 00:23:59,240
It spent half its time generating data.

368
00:23:59,240 --> 00:24:02,240
And it stopped at 100 examples.

369
00:24:02,240 --> 00:24:07,440
So this is a pretty huge time-saving tool for me to be able to just specify the types

370
00:24:07,440 --> 00:24:11,960
of data that my function should expect to see and then things that should be true about

371
00:24:11,960 --> 00:24:12,960
the output.

372
00:24:12,960 --> 00:24:15,960
Instead of saying exactly what the output should be, saying stuff that should be true

373
00:24:15,960 --> 00:24:17,560
about it.

374
00:24:17,560 --> 00:24:19,080
All right.

375
00:24:19,080 --> 00:24:25,440
So to wrap up here, data scientists should not always be writing tests, but we should

376
00:24:25,440 --> 00:24:27,800
always be practicing defensive programming.

377
00:24:27,800 --> 00:24:32,000
So those are the assertions within your code.

378
00:24:32,000 --> 00:24:36,060
Any reused or shared piece of code should probably be tested, especially if you're putting

379
00:24:36,060 --> 00:24:37,920
things in production.

380
00:24:37,920 --> 00:24:41,420
And of course, we're trying to strive for this balance between speed and confidence

381
00:24:41,420 --> 00:24:42,560
in our results.

382
00:24:42,560 --> 00:24:43,920
And testing is one tool.

383
00:24:43,920 --> 00:24:48,400
Testing at the right time can help you achieve that in the long run.

384
00:24:48,400 --> 00:24:51,540
Some aspects of data science code are really hard to test.

385
00:24:51,540 --> 00:24:54,420
So machine learning results, probabilistic outcomes.

386
00:24:54,420 --> 00:24:57,240
You want to think about testing properties of your data.

387
00:24:57,240 --> 00:25:02,240
What are things that should be true of the distributions of the data you're getting out?

388
00:25:02,240 --> 00:25:03,480
Is missing data allowed?

389
00:25:03,480 --> 00:25:06,000
Are there certain data types you're expecting?

390
00:25:06,000 --> 00:25:09,420
Testing properties can be really helpful here.

391
00:25:09,420 --> 00:25:14,740
And I'm just going to throw up some of the really useful example resources that I came

392
00:25:14,740 --> 00:25:17,940
across when I was researching this topic.

393
00:25:17,940 --> 00:25:23,160
There's a ton of resources online for general software testing and testing with PyTest,

394
00:25:23,160 --> 00:25:26,740
but this is the best stuff I could find for testing in data science that's really kind

395
00:25:26,740 --> 00:25:29,420
of specific to our use cases.

396
00:25:29,420 --> 00:25:35,140
So there's also a link to my slides in this Jupyter Notebook on GitHub.

397
00:25:35,140 --> 00:25:36,940
So yeah, that's it.

398
00:25:36,940 --> 00:25:38,020
Thank you very much for coming.

399
00:25:39,420 --> 00:25:40,420
Thank you.

400
00:25:40,420 --> 00:25:43,420
Yeah, first time I can take some questions.

401
00:25:43,420 --> 00:25:44,420
Yeah.

402
00:25:44,420 --> 00:25:45,420
Okay.

403
00:25:45,420 --> 00:25:46,420
We have a few minutes.

404
00:25:46,420 --> 00:25:47,420
I was faster than I practiced.

405
00:25:47,420 --> 00:26:08,100
So if there's any questions, I'm happy to talk to you now or afterwards.

406
00:26:09,100 --> 00:26:10,100
Thanks so much for an excellent talk.

407
00:26:10,100 --> 00:26:13,180
The data frames one was particularly useful.

408
00:26:13,180 --> 00:26:19,160
The question I had, do you have any recommendations or resources for testing perhaps the output

409
00:26:19,160 --> 00:26:24,820
of scoring one of your models or even the training process?

410
00:26:24,820 --> 00:26:27,540
Scoring the, sorry, the metrics?

411
00:26:27,540 --> 00:26:30,660
So like for example, let's say you had a model and you wanted to make sure it didn't get

412
00:26:30,660 --> 00:26:37,220
really funky after you retrained it or introduced some new data, something like that.

413
00:26:38,220 --> 00:26:44,140
Yeah, I mean, you could use hypothesis if you had bounds on the types of output that

414
00:26:44,140 --> 00:26:45,140
you expect.

415
00:26:45,140 --> 00:26:49,780
You could code that up and pass in different types of input data that you think you might

416
00:26:49,780 --> 00:26:50,780
see.

417
00:26:50,780 --> 00:26:54,940
Yeah, I mean, you can always get funky stuff depending on how funky your input data gets.

418
00:26:54,940 --> 00:27:01,340
So you have to set your own mental limits on what you think might be reasonable to get

419
00:27:01,340 --> 00:27:05,940
or you want to make sure that your code handles really funky data.

420
00:27:06,220 --> 00:27:10,940
That might be a case really where you want to add the assertions in the code itself to

421
00:27:10,940 --> 00:27:13,540
make sure your input data isn't crazy.

422
00:27:13,540 --> 00:27:15,580
Cool, thank you.

423
00:27:15,580 --> 00:27:22,060
I have a question about the PyTest.moc library that you mentioned.

424
00:27:22,060 --> 00:27:28,180
Are you familiar with the UnitTest.moc and is the PyTest variant set up about the same

425
00:27:28,180 --> 00:27:30,980
way, have the same capabilities?

426
00:27:30,980 --> 00:27:35,660
I have not really used the UnitTest framework so I can't really answer that question.

427
00:27:36,660 --> 00:27:40,620
Someone in the front says they're identical.

428
00:27:40,620 --> 00:27:42,620
Jesse says they're identical.

429
00:27:44,620 --> 00:27:45,820
Hey, thank you for that.

430
00:27:45,820 --> 00:27:46,820
It was a great talk.

431
00:27:46,820 --> 00:27:52,980
I was just wondering if you had any ideas for teams wanting to leverage a shared testing

432
00:27:52,980 --> 00:27:56,540
toolkit across both Python and R?

433
00:27:56,540 --> 00:28:02,940
Oh, I don't have much experience with R so I can't really speak to that, I'm sorry.

434
00:28:03,940 --> 00:28:10,380
Towards the end you made a comment about testing properties rather than testing specific items

435
00:28:10,380 --> 00:28:12,980
of data.

436
00:28:12,980 --> 00:28:17,220
One of the issues I've come across is that some of those properties are themselves inherently

437
00:28:17,220 --> 00:28:18,220
statistical.

438
00:28:18,220 --> 00:28:22,220
They will only be 95, you can only have a 95% confidence that they will be greater than

439
00:28:22,220 --> 00:28:24,180
a mean or greater than a whatever.

440
00:28:24,180 --> 00:28:28,900
Do you have any suggestions of how to manage that in testing?

441
00:28:28,900 --> 00:28:34,860
You can't be guaranteed that your 95% confidence test will always pass, 5% of the time it will fail.

442
00:28:35,860 --> 00:28:38,500
Yeah, that's a tricky question.

443
00:28:38,500 --> 00:28:42,380
Thank you, Russell.

444
00:28:42,380 --> 00:28:45,940
I mean, I guess if it's not something that you're sure should always be true then maybe

445
00:28:45,940 --> 00:28:49,660
that isn't something you hard code in your test but you could...

446
00:28:49,660 --> 00:28:53,660
I'm not going to recommend you run that test 100 times and make sure it passes 95% of the

447
00:28:53,660 --> 00:28:54,940
time, that's not the right approach.

448
00:28:54,940 --> 00:28:55,940
I don't know.

449
00:28:55,940 --> 00:28:56,940
You don't know.

450
00:28:56,940 --> 00:28:57,940
Thanks.

451
00:28:57,980 --> 00:28:58,980
Hi.

452
00:28:58,980 --> 00:29:04,300
What are your thoughts on integration testing in the data center environment?

453
00:29:04,300 --> 00:29:10,220
So like testing all your workflow from processing, collecting the data, processing the data, then

454
00:29:10,220 --> 00:29:13,100
training your model, testing you have a model.

455
00:29:13,100 --> 00:29:16,100
So what are your thoughts on this kind of workflow?

456
00:29:16,100 --> 00:29:17,100
Yeah, yeah.

457
00:29:17,100 --> 00:29:18,300
So that's a good point.

458
00:29:18,300 --> 00:29:22,380
I was really focused here on unit testing, testing like basic units of code and the question

459
00:29:22,380 --> 00:29:29,300
is about doing integration or larger scale tests across many functions or whatever and

460
00:29:29,300 --> 00:29:31,580
I don't really have any experience doing that.

461
00:29:31,580 --> 00:29:35,580
I've kind of been focusing on the little building blocks.

462
00:29:35,580 --> 00:29:36,580
Thank you.

463
00:29:36,580 --> 00:29:37,580
Thanks.

464
00:29:37,580 --> 00:29:42,300
This is in some ways a callback to the first question I guess but it's a slightly different

465
00:29:42,300 --> 00:29:43,660
detail with it.

466
00:29:43,660 --> 00:29:50,900
I work in machine learning as well and I will train models and there's a couple issues with

467
00:29:50,900 --> 00:29:51,900
that.

468
00:29:52,420 --> 00:29:57,820
I can train a model and find that it has low success, whatever metric I'm using, but that

469
00:29:57,820 --> 00:29:59,540
can actually be kind of two things.

470
00:29:59,540 --> 00:30:06,500
One is I made a mistake in the way I set up the features or something dramatically wrong

471
00:30:06,500 --> 00:30:07,980
with hyperparameters.

472
00:30:07,980 --> 00:30:12,500
The other thing is just this isn't a good choice of model and it's not going to be effective

473
00:30:12,500 --> 00:30:14,540
because it was a poor choice.

474
00:30:14,540 --> 00:30:21,380
But if I could somehow test that difference, that would be enormously useful and I wonder

475
00:30:21,380 --> 00:30:24,900
if you have any insight in what approaches might be relevant.

476
00:30:24,900 --> 00:30:29,420
Yeah, so I think when you're talking about trying to choose the right model for your

477
00:30:29,420 --> 00:30:32,940
problem, I think you're not quite in the testing phase yet.

478
00:30:32,940 --> 00:30:37,460
You're really exploring your data and trying to figure out what the best model is.

479
00:30:37,460 --> 00:30:40,860
So I wouldn't use testing to make that choice.

480
00:30:51,380 --> 00:30:53,860
Alright, thank you everyone.

