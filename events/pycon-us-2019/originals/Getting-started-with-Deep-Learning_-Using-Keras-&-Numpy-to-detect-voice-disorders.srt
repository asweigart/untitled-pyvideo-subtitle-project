1
00:00:00,000 --> 00:00:10,280
Hello, everybody.

2
00:00:10,280 --> 00:00:15,280
So welcome to Getting Started with Deep Learning Using Keras and NumPy to Detect Voice Disorders

3
00:00:15,280 --> 00:00:19,960
by Sebastian and Deborah Hennis.

4
00:00:19,960 --> 00:00:24,960
Regarding the Q&A, there will be a short one near the end of the session, provided we have

5
00:00:24,960 --> 00:00:26,480
time.

6
00:00:26,480 --> 00:00:29,480
So without further ado.

7
00:00:29,480 --> 00:00:39,640
Hi, my name is Deborah, and today we're going to talk to you about our journey and getting

8
00:00:39,640 --> 00:00:44,120
started with deep learning using Keras and NumPy to detect voice disorders.

9
00:00:44,120 --> 00:00:45,300
I'm Deborah.

10
00:00:45,300 --> 00:00:47,360
And I'm Sebastian.

11
00:00:47,360 --> 00:00:50,560
To start off, I'll tell you a little bit about myself.

12
00:00:50,640 --> 00:00:56,640
I did my undergraduate at MIT where I studied neuroscience, brain and cognitive sciences,

13
00:00:56,640 --> 00:01:00,800
which is a mix of neuroscience and psychology, and computer science.

14
00:01:00,800 --> 00:01:03,880
And I also did my masters in reinforcement learning.

15
00:01:03,880 --> 00:01:07,800
I spent a year as a Fulbright scholar learning how education translates into job creation,

16
00:01:07,800 --> 00:01:11,280
particularly in the technology sector.

17
00:01:11,280 --> 00:01:16,520
I spent some time working as an early software engineer at a startup in San Francisco.

18
00:01:16,600 --> 00:01:23,280
And then I decided to quit life and start a PhD.

19
00:01:23,280 --> 00:01:24,280
Just kidding.

20
00:01:24,280 --> 00:01:27,280
I had an amazing time at Harvard and got to work on a lot of really cool machine learning

21
00:01:27,280 --> 00:01:33,240
projects and meet a lot of awesome people like Sebastian.

22
00:01:33,240 --> 00:01:37,380
And while I was there, I also did some projects with Google Brain.

23
00:01:37,380 --> 00:01:43,620
And then I started a software company called Sparrow, which provides software that makes

24
00:01:43,620 --> 00:01:47,460
it simple for companies to provide their employees with extended leave, like family

25
00:01:47,460 --> 00:01:49,140
leave and medical leave.

26
00:01:49,140 --> 00:01:51,540
Hi, I'm Sebastian.

27
00:01:51,540 --> 00:01:58,100
I started programming when I founded a robotics club with my other sister, Patricia, in Nebraska.

28
00:01:58,100 --> 00:02:04,460
At the time, the only few robot clubs there were were exclusively boys.

29
00:02:04,460 --> 00:02:11,680
So our robotics club was all genders, all races inclusive.

30
00:02:11,740 --> 00:02:17,740
I did an internship at Sycamore Education, which is a company that develops software

31
00:02:17,740 --> 00:02:19,860
for under-resourced schools.

32
00:02:19,860 --> 00:02:25,200
I got to do an internship at the University of Nebraska in Omaha in their cybersecurity

33
00:02:25,200 --> 00:02:30,320
department where I combined machine learning with cybersecurity to detect attacks over

34
00:02:30,320 --> 00:02:31,700
Bluetooth.

35
00:02:31,700 --> 00:02:39,020
And finally, I did a research internship at MIT's CSAIL where I did the project that

36
00:02:39,360 --> 00:02:43,920
we'll be using as an example in this talk.

37
00:02:43,920 --> 00:02:50,620
So to give you an overview of what's coming, we'll start with looking at our data.

38
00:02:50,620 --> 00:02:56,940
And then Deborah will talk about deep learning and selecting a neural network appropriate

39
00:02:56,940 --> 00:02:57,940
to your problem.

40
00:02:57,940 --> 00:03:00,900
Then we'll bring that back to our example.

41
00:03:00,900 --> 00:03:07,340
And then we'll talk about some common issues that I had that many people will likely have

42
00:03:07,340 --> 00:03:12,900
when starting with deep learning.

43
00:03:12,900 --> 00:03:18,660
So our goal is to detect whether or not a patient has vocal hyperfunction just from

44
00:03:18,660 --> 00:03:21,440
the vibrations of their throat.

45
00:03:21,440 --> 00:03:27,380
So vocal hyperfunction is when you consistently overwork your voice and it becomes damaged.

46
00:03:27,380 --> 00:03:30,240
You can get vocal nodes and whatnot.

47
00:03:30,240 --> 00:03:34,580
And then the accelerometers, as I said, just resting on the neck.

48
00:03:34,580 --> 00:03:41,820
So we don't have recordings of all of the patient's conversations for weeks, just the

49
00:03:41,820 --> 00:03:43,520
vibrations.

50
00:03:43,520 --> 00:03:46,860
So here's an example of what our data might look like.

51
00:03:46,860 --> 00:03:51,140
We have a period of silence leading up to the utterance.

52
00:03:51,140 --> 00:03:59,040
The utterance is a period of continuous speaking with no more than half a second of silence.

53
00:03:59,040 --> 00:04:01,820
We have time on the x-axis amplitude on the y.

54
00:04:02,060 --> 00:04:06,760
Under that we have our breath group vector, which is what we use to indicate whether or

55
00:04:06,760 --> 00:04:14,920
not the patient was speaking.

56
00:04:14,920 --> 00:04:18,860
So our squiggly line is going to be our utterance.

57
00:04:18,860 --> 00:04:25,160
We want to take out the utterance and leave behind all the long periods of silence.

58
00:04:25,160 --> 00:04:30,340
So we pad our breath group vector, diff it so we make each element equal to the next

59
00:04:30,340 --> 00:04:32,100
one minus itself.

60
00:04:32,100 --> 00:04:37,840
And then all the ones mark the beginning, all the negative ones mark the end.

61
00:04:37,840 --> 00:04:43,640
And then we multiply by the length of the frames that the breath group vector has to

62
00:04:43,640 --> 00:04:46,860
get the beginning and endings of our utterances.

63
00:04:46,860 --> 00:04:48,780
So then we extract all of those out.

64
00:04:48,780 --> 00:04:55,540
So that's an example of what you might have to do when preparing your data before doing

65
00:04:55,540 --> 00:04:56,900
any deep learning on it.

66
00:04:56,900 --> 00:05:01,660
So now I'll pass it over to Debra to talk about deep learning.

67
00:05:01,660 --> 00:05:05,500
So Sebastian just told you about everything he had to do to prepare the data to get it

68
00:05:05,500 --> 00:05:11,420
ready for the deep learning that he did.

69
00:05:11,420 --> 00:05:16,940
And so now I'll tell you a little bit more about some of the landscape in getting started

70
00:05:16,940 --> 00:05:18,860
with deep learning.

71
00:05:18,860 --> 00:05:22,540
First of all, I would like to congratulate all of you for choosing to get started with

72
00:05:22,540 --> 00:05:27,300
Python because this is an amazing place to start if you want to get started with deep

73
00:05:27,300 --> 00:05:34,260
learning because there are a lot of great tools that you can use that are Python based.

74
00:05:34,260 --> 00:05:40,340
So often people will use something like scikit learn for a lot of their data processing because

75
00:05:40,340 --> 00:05:45,740
they have a lot of nice libraries for that or a lot of nice built-in tools.

76
00:05:45,740 --> 00:05:54,180
And then Keras is a Python wrapper that wraps around a lot of the other tools like theano,

77
00:05:54,180 --> 00:05:55,780
PyTorch and TensorFlow.

78
00:05:55,780 --> 00:06:03,200
And recently TensorFlow has had the Keras interface built into it as well.

79
00:06:03,200 --> 00:06:07,340
But you can use Keras over theano, PyTorch or TensorFlow.

80
00:06:07,340 --> 00:06:14,500
And the Keras makes everything nice and simple so it can just be a few lines of code.

81
00:06:14,500 --> 00:06:19,140
But if you want to do something more complicated, you'll probably need to use something like

82
00:06:19,140 --> 00:06:23,520
theano, PyTorch or TensorFlow.

83
00:06:23,520 --> 00:06:26,940
So to start off with, let's look at this picture of neurons.

84
00:06:26,940 --> 00:06:30,900
It's a really nice picture, right?

85
00:06:30,900 --> 00:06:32,220
There's a lot going on here.

86
00:06:32,220 --> 00:06:36,860
Like there are a lot of neuronal connections.

87
00:06:36,860 --> 00:06:39,180
Some of them are stronger than others.

88
00:06:39,180 --> 00:06:43,060
There are all these electrical impulses going through them.

89
00:06:43,060 --> 00:06:50,820
And this is probably just like one very, very, very, very, very small section of your brain.

90
00:06:50,820 --> 00:06:54,740
And if you were to look at a neuroscience textbook, it would model it as something like

91
00:06:54,740 --> 00:06:55,740
this.

92
00:06:55,740 --> 00:06:58,780
So it still is kind of complicated, but it's not too bad.

93
00:06:58,780 --> 00:07:03,060
It's like you have this cell body and has some dendrites which attach to something else.

94
00:07:03,060 --> 00:07:08,500
They accept the electrical impulses and the electrical impulses travel down the axon,

95
00:07:08,500 --> 00:07:13,080
which is insulated by myelin, and end up down at the axon terminal, which then rests on

96
00:07:13,080 --> 00:07:14,420
another soma.

97
00:07:14,420 --> 00:07:17,420
So there are all these electrical impulses going through this.

98
00:07:17,420 --> 00:07:21,580
And if there are a lot of electrical impulses that go through it, it will get thicker and

99
00:07:21,580 --> 00:07:22,880
there will be a stronger connection.

100
00:07:22,880 --> 00:07:26,000
And if there are fewer, there will be less.

101
00:07:26,000 --> 00:07:32,980
So some time, a long time ago, maybe 40 or 50 years, some dude looked at this and he's

102
00:07:32,980 --> 00:07:39,660
like, I bet I can do that with some math.

103
00:07:39,660 --> 00:07:43,900
And he came up with this thing, which is a perceptron, and it's like a very, very simplified

104
00:07:43,900 --> 00:07:45,900
version of a neuron.

105
00:07:45,900 --> 00:07:50,380
Which you can see there are some sort of basic similarities in that there are some inputs,

106
00:07:50,380 --> 00:07:54,880
sort of like the electrical impulses, except these aren't electrical impulses.

107
00:07:54,880 --> 00:07:57,280
These are numbers, like zeros and ones.

108
00:07:57,280 --> 00:08:00,540
So if you're looking at something like an image as input, chances are it's going to

109
00:08:01,100 --> 00:08:08,780
if it's a 100 by 100 image, it will probably be 100 by 100 matrix going into the inputs.

110
00:08:08,780 --> 00:08:14,460
And then you can decide how important these are using the weights, how important each

111
00:08:14,460 --> 00:08:15,740
input is.

112
00:08:15,740 --> 00:08:19,460
And then there's a function that does something to it.

113
00:08:19,460 --> 00:08:24,180
And something varies widely based on the architecture.

114
00:08:24,180 --> 00:08:25,920
But here it's just a sigmoid function.

115
00:08:25,920 --> 00:08:33,100
So you take those inputs, you put it into a function, and something else comes out.

116
00:08:33,100 --> 00:08:35,760
So this isn't going to play AlphaGo for us.

117
00:08:35,760 --> 00:08:37,680
It's pretty simple.

118
00:08:37,680 --> 00:08:42,200
So if we but we've seen all these things in the news recently of, you know, deep learning

119
00:08:42,200 --> 00:08:48,540
being used to play video games, being used to make videos, all sorts of things.

120
00:08:48,540 --> 00:08:54,480
So how do we do that?

121
00:08:54,480 --> 00:08:57,860
The answer here is we stack more layers.

122
00:08:57,860 --> 00:09:02,640
So often what we just described was a fairly simple neural network.

123
00:09:02,640 --> 00:09:07,040
And as you add more and more layers, you can sort of keep adding more and more things that

124
00:09:07,040 --> 00:09:09,200
the network can do.

125
00:09:09,200 --> 00:09:13,240
So we'll go a little we'll make this a little bit more complicated in that now we have a

126
00:09:13,240 --> 00:09:14,620
feed forward neural network.

127
00:09:14,620 --> 00:09:20,160
So you can see the yellow circles are where the inputs go in, the orange are where the

128
00:09:20,160 --> 00:09:23,200
outputs go out, and then the green are the hidden layers.

129
00:09:23,200 --> 00:09:27,480
So we can see what's going on with the inputs and we can see what's going on with the outputs,

130
00:09:27,480 --> 00:09:30,240
but we can't see what's going on in the hidden layers.

131
00:09:30,240 --> 00:09:41,120
And usually if you have more than one hidden layer, then it becomes a deep neural network.

132
00:09:41,120 --> 00:09:45,780
Partially because everyone wants their network to be deep.

133
00:09:45,780 --> 00:09:50,380
So here we have so this is an animation of what this looks like.

134
00:09:50,380 --> 00:09:57,780
So you can feed a neural network some pictures like cats, like pictures of cats and dogs.

135
00:09:57,780 --> 00:10:03,260
If these are chances are what is going in though is actually numbers, maybe RGB values,

136
00:10:03,260 --> 00:10:07,040
whether or not a certain feature is present.

137
00:10:07,040 --> 00:10:09,060
And that's what the neural network is learning off of.

138
00:10:09,060 --> 00:10:13,860
And you will see lots and lots of training examples and then it will learn some similarities

139
00:10:13,860 --> 00:10:15,900
if you label these training examples.

140
00:10:15,900 --> 00:10:21,940
So maybe it will learn that cats tend to have pointier ears than dogs or they have

141
00:10:21,940 --> 00:10:28,660
longer whiskers than dogs or they're just cuter than dogs.

142
00:10:28,660 --> 00:10:32,980
But in any case, we get some output and then it's able to identify with some level of accuracy

143
00:10:32,980 --> 00:10:37,640
that this is a cat or this is a dog.

144
00:10:37,640 --> 00:10:43,400
So at this point, we have we've gone through some of the basics of how a neural network

145
00:10:43,400 --> 00:10:44,860
is built.

146
00:10:44,860 --> 00:10:50,740
But like we said, they still do some fairly simple what we just saw still does some fairly

147
00:10:50,740 --> 00:10:51,740
simple things.

148
00:10:51,740 --> 00:10:56,820
It's like a cat detector, honestly, which I mean people are much more complicated than

149
00:10:56,820 --> 00:10:59,860
being just cat detectors.

150
00:10:59,860 --> 00:11:05,560
So I'll give you in some sort of like very broad strokes what some of the architectures

151
00:11:05,560 --> 00:11:10,160
are and tell you a little bit about what they do and try to point you to some resources

152
00:11:10,160 --> 00:11:12,740
for some of the more complicated architectures.

153
00:11:12,740 --> 00:11:17,460
Because there are like hundreds of these coming out every year.

154
00:11:17,460 --> 00:11:20,060
So one is a convolutional neural network.

155
00:11:20,060 --> 00:11:22,020
And this is kind of cool.

156
00:11:22,020 --> 00:11:26,780
Because what it does is it actually takes in a lot of information and results in less

157
00:11:26,780 --> 00:11:31,300
information, which actually is something that on some level people do as well.

158
00:11:31,300 --> 00:11:35,340
So like if I'm looking around this room, like technically, if a photon of light goes and

159
00:11:35,340 --> 00:11:39,180
bounces off of anything in the room and then hits my retina, I've seen it.

160
00:11:39,180 --> 00:11:42,580
But I'm definitely not aware of everything going on in this room.

161
00:11:42,580 --> 00:11:46,620
And chances are when you guys walk into a big room, you aren't either.

162
00:11:46,620 --> 00:11:52,300
So similarly, what a convolutional neural network does is it takes a lot of information

163
00:11:52,300 --> 00:11:56,320
and it pulls that information down usually into an average of that.

164
00:11:56,320 --> 00:11:58,620
And then it makes its detection off of that.

165
00:11:58,620 --> 00:12:05,080
And this kind of neural network is often used for classification or detection.

166
00:12:05,080 --> 00:12:08,900
So there's a good chance that that last neural network we saw that was cats versus dogs was

167
00:12:08,900 --> 00:12:14,460
probably a convolutional neural network.

168
00:12:14,460 --> 00:12:18,100
Another cool architecture is the recurrent neural network.

169
00:12:18,100 --> 00:12:24,340
And usually these neural networks, they're not actually very smart on their own.

170
00:12:24,340 --> 00:12:26,360
They only do exactly what they're told.

171
00:12:26,360 --> 00:12:29,740
And they only know what's going on at any given time step.

172
00:12:29,740 --> 00:12:32,620
So you can think if you think of this as like sort of a time series and you show something

173
00:12:32,620 --> 00:12:35,220
an image, it only sees that image.

174
00:12:35,220 --> 00:12:39,300
It only sees that those numbers that you put into it at that moment.

175
00:12:39,300 --> 00:12:43,900
As soon as you show it another example, it's automatically forgotten the last example.

176
00:12:43,900 --> 00:12:48,500
But the nice thing about recurrent neural networks is it introduces the first a very,

177
00:12:48,500 --> 00:12:54,200
very simplified idea of memory in that what it does is it has a feedback loop.

178
00:12:54,200 --> 00:12:59,300
So not only does it know what happened on this time step, it also knows what happened

179
00:12:59,300 --> 00:13:04,940
on the last time step because of that feedback loop.

180
00:13:04,940 --> 00:13:11,380
So then a kind of recurrent neural network is the LSTM.

181
00:13:11,380 --> 00:13:16,020
And what this does is it has that feedback loop.

182
00:13:16,020 --> 00:13:17,860
But it's a little bit more complicated than that.

183
00:13:17,860 --> 00:13:21,540
And it introduces the notion of state.

184
00:13:21,540 --> 00:13:29,180
So you can define not only how it remembers the last time step, but you can define it

185
00:13:30,180 --> 00:13:31,900
several time steps back.

186
00:13:31,900 --> 00:13:37,180
Or maybe it pays certain, it remembers some features longer than others.

187
00:13:37,180 --> 00:13:41,860
And these are all things that you just tune with variables, you know, like in this case,

188
00:13:41,860 --> 00:13:45,180
C, X, things like this.

189
00:13:45,180 --> 00:13:50,320
So these are all things that you define as mathematical equations.

190
00:13:50,320 --> 00:13:56,860
And this was actually the architecture that Sebastian chose to use for his project.

191
00:13:56,860 --> 00:14:00,140
And now I will pass it off to him.

192
00:14:00,140 --> 00:14:01,140
All right.

193
00:14:01,140 --> 00:14:04,820
So we have all of our utterances from before.

194
00:14:04,820 --> 00:14:07,460
We feed them into this magical black box.

195
00:14:07,460 --> 00:14:14,540
And then it's supposed to spit out a classification as either somebody who does have vocal trauma

196
00:14:14,540 --> 00:14:19,560
or just a typical member of the population.

197
00:14:19,560 --> 00:14:25,700
But first I'll give some of the big libraries that I used.

198
00:14:25,700 --> 00:14:32,620
NumPy is a very common library for handling numerical data of any sort.

199
00:14:32,620 --> 00:14:38,660
And as Deborah said, even if what you're training on isn't numbers, they'll be made into numbers

200
00:14:38,660 --> 00:14:40,300
before you feed them in.

201
00:14:40,300 --> 00:14:46,780
And so it's great for manipulating any arrays of numbers.

202
00:14:46,780 --> 00:14:53,860
And there are a few links to tutorials that you can look at afterwards to get started

203
00:14:53,860 --> 00:14:55,360
with NumPy.

204
00:14:55,360 --> 00:15:01,040
And then Keras, again, as Deborah said earlier, is a really easy to use high-level wrapper

205
00:15:01,040 --> 00:15:02,280
over the other things.

206
00:15:02,280 --> 00:15:09,520
We'll see soon how just in a few lines of code you can make a neural network that works

207
00:15:09,520 --> 00:15:11,440
really well.

208
00:15:11,440 --> 00:15:14,480
And again, here are a couple of links.

209
00:15:14,480 --> 00:15:16,160
Okay.

210
00:15:16,160 --> 00:15:22,000
So here's an example of some code.

211
00:15:22,160 --> 00:15:28,800
Above this, you want to separate out the training data and the testing data because if you test

212
00:15:28,800 --> 00:15:33,880
on the same data you train on, it will be like if you kept letting a student retake

213
00:15:33,880 --> 00:15:39,360
the same exam and they would just memorize the answers rather than learning the material

214
00:15:39,360 --> 00:15:40,840
itself.

215
00:15:40,840 --> 00:15:46,080
And so then we can get an accurate evaluation of what kind of generalities our model is

216
00:15:46,080 --> 00:15:47,760
actually learning.

217
00:15:47,760 --> 00:15:53,160
And then we need to pad all of the data to the same length or truncate it just because

218
00:15:53,160 --> 00:15:57,480
that's what we need to do to feed it into neural network.

219
00:15:57,480 --> 00:16:00,620
Then we define our model.

220
00:16:00,620 --> 00:16:05,700
We define various parameters just to get it started.

221
00:16:05,700 --> 00:16:12,000
And then that one line, add LSTM with 100 layers, that's it.

222
00:16:12,000 --> 00:16:14,600
It's that easy to use an LSTM.

223
00:16:14,600 --> 00:16:23,600
Then we define our activation function, wrap it all together and fit it to our data, evaluate

224
00:16:23,600 --> 00:16:27,080
it and we have an answer.

225
00:16:27,080 --> 00:16:30,340
But that's not the end as we'll see later.

226
00:16:30,340 --> 00:16:35,520
So let's talk about some common issues.

227
00:16:35,520 --> 00:16:41,400
Neural networks require a lot of data usually to get good results.

228
00:16:41,400 --> 00:16:45,280
And so there are a lot of issues that come with handling a lot of data.

229
00:16:45,280 --> 00:16:49,440
You probably won't be able to hold all of it in memory at once.

230
00:16:49,440 --> 00:16:56,000
And if you are used to using something like Pickle, you'll have problems when using large

231
00:16:56,000 --> 00:16:57,820
data sets.

232
00:16:57,820 --> 00:17:02,680
You might run it on some server somewhere else because your machine may not be powerful

233
00:17:02,680 --> 00:17:03,680
enough.

234
00:17:03,680 --> 00:17:05,000
So there are issues with that.

235
00:17:05,000 --> 00:17:10,340
And then Deborah will talk about analyzing your errors.

236
00:17:10,340 --> 00:17:16,940
So we have a whole lot of data but not a lot of RAM.

237
00:17:16,940 --> 00:17:22,140
And so what we do instead is just take a little bit of data at a time and train on it and

238
00:17:22,140 --> 00:17:31,100
do it in small batches.

239
00:17:31,100 --> 00:17:38,140
So then Pickle, it works great most of the time for most little things.

240
00:17:38,140 --> 00:17:43,940
You just dump Python binary data to a file, pull it back, everything works like magic

241
00:17:43,940 --> 00:17:45,780
and it's great.

242
00:17:45,780 --> 00:17:53,620
Until you work with large data sets and then stuff breaks and you have no idea why and

243
00:17:53,620 --> 00:17:55,060
everything is on fire.

244
00:17:55,060 --> 00:17:56,060
So instead...

245
00:17:56,060 --> 00:18:01,300
It shows up as so many end of file errors and corrupted files.

246
00:18:01,300 --> 00:18:06,020
So instead you can use something like Joblib or H5Py.

247
00:18:06,060 --> 00:18:13,180
I used H5Py which stores the data in an HDF5 format so it's hierarchically stored and

248
00:18:13,180 --> 00:18:20,020
you can just save or load in little pieces at a time so that we can do things like run

249
00:18:20,020 --> 00:18:24,140
our mini batches like earlier.

250
00:18:24,140 --> 00:18:35,740
So now you might start this on your laptop and then connect through SSH to a remote server

251
00:18:35,860 --> 00:18:40,740
and then close your laptop and then it will kill your SSH session and kill your program

252
00:18:40,740 --> 00:18:41,740
too.

253
00:18:41,740 --> 00:18:45,500
And we don't want our program to get killed until it's done running.

254
00:18:45,500 --> 00:18:50,220
So instead we can use TMUX or Screen to easily manage our sessions.

255
00:18:50,220 --> 00:18:53,580
I personally use TMUX.

256
00:18:53,580 --> 00:18:58,260
We have a little screenshot tutorial demo with Screen.

257
00:18:58,260 --> 00:19:06,260
So you take out your laptop, connect, open up Screen, run your program that runs forever,

258
00:19:06,260 --> 00:19:10,660
detach, close your laptop, take it off your desk, otherwise it will be a desktop, take

259
00:19:10,660 --> 00:19:17,460
it to the coffee shop, open it back up, reconnect and it's still running.

260
00:19:17,460 --> 00:19:20,260
And eventually it will finish, hopefully.

261
00:19:20,260 --> 00:19:22,100
We can only hope.

262
00:19:22,100 --> 00:19:27,660
So now I'll pass it back to Deborah to talk about analyzing your errors.

263
00:19:27,660 --> 00:19:34,220
So Sebastian has talked about a lot of things that go into getting your deep learning algorithm

264
00:19:34,220 --> 00:19:35,220
to run.

265
00:19:35,220 --> 00:19:37,420
And there are a lot of things that go into it.

266
00:19:37,420 --> 00:19:44,100
And while we managed to get through it in about 20 minutes, it takes a lot longer than

267
00:19:44,100 --> 00:19:45,100
that.

268
00:19:45,100 --> 00:19:47,060
There's all this pre-processing the data.

269
00:19:47,060 --> 00:19:52,340
As you can tell in those last three common issues he went through, any one of those could

270
00:19:52,340 --> 00:19:54,100
keep you hung up for a while.

271
00:19:54,100 --> 00:20:01,940
So I think very often people will go, they'll write there a few lines of Keras, they'll

272
00:20:01,940 --> 00:20:11,500
get a result and they'll be like, yes, I finally have an answer, it has 90% accuracy, I'm done,

273
00:20:11,500 --> 00:20:15,720
but the answer, but actually at that point you're not done.

274
00:20:15,720 --> 00:20:20,740
If you do that, you're doing something a little bit like this.

275
00:20:20,780 --> 00:20:24,820
In that you're putting a lot of data into your algorithm and you're getting some results

276
00:20:24,820 --> 00:20:32,180
out, but you don't actually know what's going on in all of those hidden layers.

277
00:20:32,180 --> 00:20:35,400
And you don't know exactly what it's learning.

278
00:20:35,400 --> 00:20:41,900
And so even if you have a really high accuracy, you should always take a moment to say, even

279
00:20:41,900 --> 00:20:47,140
if you have 95% accuracy, that means your algorithm got 5% wrong.

280
00:20:47,140 --> 00:20:53,900
And it's worth looking at what was going on with that 5%.

281
00:20:53,900 --> 00:21:01,580
So sort of a textbook example of this is Joy Bealam-Winnie's story.

282
00:21:01,580 --> 00:21:05,420
So she is a graduate student at the MIT Media Lab.

283
00:21:05,420 --> 00:21:10,100
And she does a lot of work with facial detection algorithms.

284
00:21:10,100 --> 00:21:14,020
And so there are all these, when she started this maybe five years ago, there were all

285
00:21:14,020 --> 00:21:20,100
of these out of the box facial detection algorithms that, for the most part, large companies had

286
00:21:20,100 --> 00:21:22,540
built.

287
00:21:22,540 --> 00:21:24,980
But they would never recognize her face.

288
00:21:24,980 --> 00:21:30,620
And it turns out that what actually happened is if you think about what data you use to

289
00:21:30,620 --> 00:21:35,920
train a facial detection algorithm, you use the information, you use probably pictures

290
00:21:35,920 --> 00:21:40,300
that you find on the internet, because you can never snap enough pictures to train it,

291
00:21:40,300 --> 00:21:47,660
at which point you end up, we have probably like a lot of pictures of actors who are mostly

292
00:21:47,660 --> 00:21:55,980
white or politicians who are mostly white or ads who are mostly targeting white people

293
00:21:55,980 --> 00:21:58,220
and are mostly white.

294
00:21:58,220 --> 00:22:03,420
So the end result is, well, everyone thought that they were building these facial detection

295
00:22:03,420 --> 00:22:06,060
algorithms with 97% accuracy.

296
00:22:06,060 --> 00:22:11,540
Actually what they had built was something that just recognizes something light, oval,

297
00:22:11,540 --> 00:22:14,860
with something that looks sort of like eyes, nose, and a mouth.

298
00:22:14,860 --> 00:22:23,160
So Joy found that she couldn't test her algorithms because it didn't recognize her face.

299
00:22:23,160 --> 00:22:26,420
So first she would try to get friends to try to test her algorithms with her.

300
00:22:26,420 --> 00:22:27,980
But I mean, your friends aren't there all the time.

301
00:22:27,980 --> 00:22:29,820
You need to spend a lot of time debugging.

302
00:22:29,820 --> 00:22:34,300
So she's like, OK, I'll try this mask, which looks absolutely nothing like a face.

303
00:22:34,300 --> 00:22:38,700
And it recognized that instead.

304
00:22:38,700 --> 00:22:43,220
Just showing sort of like just how ridiculous this is and how it can be really difficult

305
00:22:43,220 --> 00:22:49,980
to and your algorithm isn't always doing what you think it is.

306
00:22:49,980 --> 00:22:55,780
So it's just sort of one first thing that you can do here to get started is you can

307
00:22:55,780 --> 00:22:58,380
take a look at something like a confusion matrix.

308
00:22:58,380 --> 00:23:03,120
And it's possible you have not seen this introductory to statistics.

309
00:23:03,120 --> 00:23:07,680
But what it does is this is built specifically for a two case classification task.

310
00:23:07,680 --> 00:23:13,280
But you can say, like in the case of Sebastian, he's predicting, does someone have vocal trauma

311
00:23:13,280 --> 00:23:14,420
or not?

312
00:23:14,420 --> 00:23:17,920
And so if he predicts that they have vocal trauma and they actually do, that's a true

313
00:23:17,920 --> 00:23:19,680
positive.

314
00:23:19,680 --> 00:23:23,440
If the algorithm says that they don't have vocal trauma and they don't, that's a true

315
00:23:23,440 --> 00:23:25,120
negative.

316
00:23:25,120 --> 00:23:36,600
If the algorithm says that it says that they have vocal trauma, but they don't, then that

317
00:23:36,600 --> 00:23:40,060
is a false positive.

318
00:23:40,060 --> 00:23:44,200
And then vice versa, if it turns out they actually have vocal trauma, but the algorithm

319
00:23:44,200 --> 00:23:47,520
says they don't, then that's a false negative.

320
00:23:47,520 --> 00:23:49,920
So what you can do.

321
00:23:49,920 --> 00:23:52,120
So it's really important to look at these errors.

322
00:23:52,120 --> 00:23:57,680
Like it's maybe you have all false positives, at which point it's very easy to get all false

323
00:23:57,680 --> 00:24:00,000
positives.

324
00:24:00,000 --> 00:24:04,080
In some cases, maybe you just predict everything is positive.

325
00:24:04,080 --> 00:24:07,320
So your algorithm isn't actually doing anything.

326
00:24:07,320 --> 00:24:15,360
So it's worth looking at the algorithm, understanding what your errors are, why your algorithm is

327
00:24:15,360 --> 00:24:21,760
making them, and potentially even thinking about what fairness means in your algorithm.

328
00:24:21,800 --> 00:24:26,160
One definition of fairness is making sure that different categories have the same number

329
00:24:26,160 --> 00:24:28,640
of errors.

330
00:24:28,640 --> 00:24:32,720
So it's worth thinking about what that means in your case, but in any case, a first step

331
00:24:32,720 --> 00:24:37,680
is just making sure that you see what kind of errors you have.

332
00:24:37,680 --> 00:24:41,920
And as it turns out, this story actually has a happy ending.

333
00:24:41,920 --> 00:24:48,360
Joy published her research comparing all of these different facial detection algorithms

334
00:24:48,360 --> 00:24:50,680
through Microsoft, Amazon, et cetera.

335
00:24:50,680 --> 00:24:56,400
And she found that, as you would expect, they have a very high accuracy for particularly

336
00:24:56,400 --> 00:24:57,560
light-skinned males.

337
00:24:57,560 --> 00:25:02,960
The worst, I think, was dark-skinned women.

338
00:25:02,960 --> 00:25:07,560
But she published this research, and most of the companies went and they went out and

339
00:25:07,560 --> 00:25:13,360
they got more training data to make their algorithms more accurate.

340
00:25:13,360 --> 00:25:20,280
So yeah, super exciting, right?

341
00:25:20,280 --> 00:25:24,400
So in any case, make sure that you look at your errors.

342
00:25:24,400 --> 00:25:29,160
Otherwise, you're just sort of stirring data around and you don't actually know what it's doing.

343
00:25:29,160 --> 00:25:33,880
I'd like to give a special thanks to Professor Marzia Gassemi for letting me work with her

344
00:25:33,880 --> 00:25:40,640
on this project and Professor Peter Solovich for letting me work in his lab.

345
00:25:40,640 --> 00:25:47,400
Here are a whole bunch of links to things to help you get started in deep learning.

346
00:25:47,520 --> 00:25:53,960
What I found was that there were some times where it really helped to have a real person

347
00:25:53,960 --> 00:25:59,600
help me through my problem rather than just trying to find tutorials that I don't know

348
00:25:59,600 --> 00:26:01,840
which ones apply to me.

349
00:26:01,840 --> 00:26:07,320
So if you'd like to reach out to either of us on Twitter for anything, those are both

350
00:26:07,320 --> 00:26:09,480
of our Twitter handles.

351
00:26:09,480 --> 00:26:11,080
So thank you.

352
00:26:11,080 --> 00:26:12,080
That's it.

353
00:26:12,760 --> 00:26:14,760
Thank you.

354
00:26:21,760 --> 00:26:25,080
All right, so we seem to have a bit of time.

355
00:26:25,080 --> 00:26:29,600
So if anybody has any questions, the mic is right over there.

356
00:26:29,600 --> 00:26:31,600
Just head on towards it.

357
00:26:42,600 --> 00:26:44,600
Hello?

358
00:26:44,600 --> 00:26:48,600
Yeah, I saw your code.

359
00:26:48,600 --> 00:26:52,600
So you didn't see cross validation there?

360
00:26:52,600 --> 00:26:54,600
Maybe I missed it.

361
00:26:54,600 --> 00:27:08,600
So is it just time consuming, too time consuming to do a cross validation on LSTM or you just

362
00:27:09,120 --> 00:27:14,120
decided to simplify the code?

363
00:27:14,120 --> 00:27:15,120
For the example, yes.

364
00:27:15,120 --> 00:27:17,040
That was very simplified.

365
00:27:17,040 --> 00:27:19,040
But yeah, you did it, right?

366
00:27:19,040 --> 00:27:21,040
I mean the cross validation.

367
00:27:21,040 --> 00:27:23,560
Yeah, there was a cross validation.

368
00:27:23,560 --> 00:27:25,200
We just didn't show it here.

369
00:27:25,200 --> 00:27:26,200
Makes sense.

370
00:27:26,200 --> 00:27:29,040
Thanks.

371
00:27:29,040 --> 00:27:33,600
So given that you were working with the medical data, were you under IRB?

372
00:27:33,600 --> 00:27:38,320
Did you have any specific issues surrounding data acquisition and disposal when you were

373
00:27:38,320 --> 00:27:42,320
done or anything like that?

374
00:27:42,320 --> 00:27:47,680
Thankfully, since I was working with Marzi and her team on this project, I didn't have

375
00:27:47,680 --> 00:27:54,080
to worry about acquiring the data or handling it afterwards.

376
00:27:54,080 --> 00:28:01,280
But I did have to take some tests and sign some things and all that to work on this.

377
00:28:01,280 --> 00:28:07,280
So you had to get the HIPAA certification and the general project was under IRB.

378
00:28:07,280 --> 00:28:08,280
Okay.

379
00:28:08,280 --> 00:28:11,280
Thank you.

380
00:28:11,280 --> 00:28:13,280
Hi.

381
00:28:13,280 --> 00:28:19,560
Have you tried using Spark actually, regards to those issues that you had with memory and

382
00:28:19,560 --> 00:28:21,720
disk usage?

383
00:28:21,720 --> 00:28:26,400
I don't know if I heard the whole question, but no, I haven't used Spark for this.

384
00:28:26,400 --> 00:28:27,400
Okay.

385
00:28:27,400 --> 00:28:34,280
Because it uses clusters actually, so that could help resolve some of your issues.

386
00:28:34,280 --> 00:28:35,280
Oh, okay.

387
00:28:35,280 --> 00:28:41,880
I was using MIT servers that they gave to me.

388
00:28:41,880 --> 00:28:48,400
For the voice data itself, in addition to separating out when the parts where they're

389
00:28:48,400 --> 00:28:53,360
talking, did you have to do any other kind of processing or filtering of the data or

390
00:28:53,360 --> 00:28:58,200
were you able to just feed that into the network?

391
00:28:58,200 --> 00:29:03,200
After separating it out, I'm making sure each utterance was labeled.

392
00:29:03,200 --> 00:29:04,440
That was all I did.

393
00:29:04,520 --> 00:29:12,680
I could have done other things like maybe trained on chunks of utterances at a time

394
00:29:12,680 --> 00:29:16,520
rather than just one utterance at a time, but there are all sorts of things I could

395
00:29:16,520 --> 00:29:17,520
have done.

396
00:29:17,520 --> 00:29:19,520
But yes, I just did it simple way.

397
00:29:19,520 --> 00:29:20,520
Hi.

398
00:29:20,520 --> 00:29:24,120
Thanks for your talk.

399
00:29:24,120 --> 00:29:26,000
It's very impressive.

400
00:29:26,000 --> 00:29:30,480
I have two more general questions about deep learning applications.

401
00:29:30,480 --> 00:29:37,800
One is that besides those cognitive applications such as image recognition or speech recognition,

402
00:29:37,800 --> 00:29:45,240
are you aware of any other successful application of deep learning in time series forecasting

403
00:29:45,240 --> 00:29:50,200
or any general planning procedure rather than those cognitive areas?

404
00:29:50,200 --> 00:29:51,200
Yes.

405
00:29:51,200 --> 00:29:58,280
Yeah, there is research using deep learning for, like you said, time series forecasting

406
00:29:58,280 --> 00:30:03,440
for interpolating some of that data and what was the other thing you mentioned?

407
00:30:03,440 --> 00:30:10,880
Like general planning, any type of strategic planning, tactical planning, more like traditional

408
00:30:10,880 --> 00:30:12,360
operational related?

409
00:30:12,360 --> 00:30:15,400
Yeah, there are.

410
00:30:15,400 --> 00:30:21,240
In terms of planning, I've seen a lot of deep reinforcement learning, but at that point

411
00:30:21,240 --> 00:30:24,760
the reinforcement is actually doing a lot of the optimization whereas the deep learning

412
00:30:24,760 --> 00:30:30,360
is sort of like a lookup table to figure out where you're going.

413
00:30:30,360 --> 00:30:36,720
But I've seen a little bit less with planning, but I haven't searched that specifically

414
00:30:36,720 --> 00:30:39,080
and I would expect that there is research there.

415
00:30:39,080 --> 00:30:42,240
It seems like people are trying to use deep learning for everything at the moment, even

416
00:30:42,240 --> 00:30:45,120
things it isn't actually a good application for.

417
00:30:45,120 --> 00:30:47,280
Yeah, that's actually my concern.

418
00:30:47,280 --> 00:30:49,600
But another thing real quick about image recognition.

419
00:30:49,600 --> 00:30:57,440
So how good is the OCR or image recognition out there now regarding detecting very similar

420
00:30:57,440 --> 00:31:02,600
items such as like cartons, boxes?

421
00:31:02,600 --> 00:31:07,160
They have just very similar appearances, but then...

422
00:31:07,160 --> 00:31:12,400
Yeah, I actually haven't looked at the recent literature there.

423
00:31:12,400 --> 00:31:16,800
I think that the numbers that I would be citing would be like what I looked at in my masters,

424
00:31:16,800 --> 00:31:19,720
which at this point is like five years old.

425
00:31:19,720 --> 00:31:22,520
So I would recommend Google Scholar for that.

426
00:31:22,520 --> 00:31:26,360
Okay, thanks very much.

427
00:31:26,360 --> 00:31:27,840
Thanks a bunch for the talk.

428
00:31:27,840 --> 00:31:31,560
Deborah, I think this falls upon something you just said in response to that question,

429
00:31:31,560 --> 00:31:35,840
which was people trying to use deep learning for all sorts of stuff.

430
00:31:35,840 --> 00:31:40,480
Was your thought in using the neural net here that you wanted to use a neural net for the

431
00:31:40,480 --> 00:31:44,080
sake of learning about neural nets or was it you had a problem and you knew neural nets

432
00:31:44,080 --> 00:31:45,920
would be the best way to solve it?

433
00:31:46,200 --> 00:31:50,080
If that's the case, which I presume it is, what are some mental filters that you worked

434
00:31:50,080 --> 00:31:54,280
through once you have a problem to try to get to the exact model type that you want

435
00:31:54,280 --> 00:31:59,280
to end up using to solve that problem?

436
00:31:59,280 --> 00:32:06,040
That's a difficult question actually.

437
00:32:06,040 --> 00:32:12,160
So one thing that I resource that we shared here was the neural network, which is sort

438
00:32:12,160 --> 00:32:16,640
of nice in that it's essentially a cheat sheet of a lot of the sort of like main level

439
00:32:16,640 --> 00:32:20,600
architectures and some of what they're used for.

440
00:32:20,600 --> 00:32:24,120
So something like that is really helpful.

441
00:32:24,120 --> 00:32:28,480
But I think that at this point, a lot of it, there aren't a lot of really good summaries.

442
00:32:28,480 --> 00:32:32,240
There's also like Ian Goodfellow's deep learning book, which is pretty good, I'd say,

443
00:32:32,240 --> 00:32:36,000
particularly for what you're talking about, like the middle section of that book would

444
00:32:36,000 --> 00:32:37,560
be what you were looking at.

445
00:32:37,640 --> 00:32:44,920
But a lot of it is actually going to the papers and saying, what has someone else used for this?

446
00:32:44,920 --> 00:32:48,520
I think that right now there are sort of so many architectures that sometimes it's hard

447
00:32:48,520 --> 00:32:53,680
to keep track of everything that you could be using.

448
00:32:53,680 --> 00:32:58,480
So I would recommend probably if you're starting a new project to start with something like

449
00:32:58,480 --> 00:33:06,360
the neural network, Sue, or some Google searches of what sorts of architectures other people

450
00:33:06,440 --> 00:33:09,880
are using for that, and then sort of expanding out from there.

451
00:33:09,880 --> 00:33:15,240
But I'd say what is right for what on some level is still an open research area.

452
00:33:15,240 --> 00:33:17,920
Thank you both.

453
00:33:17,920 --> 00:33:21,640
Basic question, are you making your slides available online?

454
00:33:21,640 --> 00:33:26,000
Yes, we will tweet them out afterwards.

455
00:33:26,000 --> 00:33:32,360
We've seen over the course of the last few years technology greatly change how deep learning

456
00:33:32,360 --> 00:33:37,240
models are made with GPUs greatly speeding up the training time.

457
00:33:37,240 --> 00:33:40,520
Do you know how NVMe's might change how we do things?

458
00:33:40,520 --> 00:33:43,720
I'm sorry, can you repeat the last part of it?

459
00:33:43,720 --> 00:33:50,280
Yeah, NVMe, the solid state hard drives, they have about six times the read speed of SSDs.

460
00:33:50,280 --> 00:33:51,760
They're like memory fast.

461
00:33:51,760 --> 00:33:52,760
Yeah.

462
00:33:52,760 --> 00:33:58,760
I'm not familiar with them, so I'm not sure I can comment intelligently to that.

463
00:33:58,760 --> 00:34:02,120
Okay, thank you.

464
00:34:02,120 --> 00:34:07,200
So a lot of vocal disorders kind of manifest themselves in breaks in the voice where, like

465
00:34:07,200 --> 00:34:11,800
for someone like me who is a person with vocal issues, what happens is you start speaking

466
00:34:11,800 --> 00:34:15,000
and then there'll be various breaks because your vocal cords physically can't vibrate

467
00:34:15,000 --> 00:34:16,240
properly.

468
00:34:16,240 --> 00:34:22,680
And so I'm curious how data scrubbing where you remove those breaks and those pauses,

469
00:34:22,680 --> 00:34:28,160
is that over sanitizing the way that the voice is actually working and making you miss a

470
00:34:28,160 --> 00:34:30,120
lot of stuff potentially?

471
00:34:30,120 --> 00:34:31,120
That's a great point.

472
00:34:31,120 --> 00:34:39,240
I was not, I didn't do much research into vocal disorders when doing this project.

473
00:34:39,240 --> 00:34:45,480
As long as it's less than half a second pause, it should have caught it, or a second depending

474
00:34:45,480 --> 00:34:48,400
on where the frames cut off.

475
00:34:48,400 --> 00:34:55,280
But yes, also it may have learned that shorter lengths consistently were associated with

476
00:34:55,280 --> 00:34:56,280
voice disorders.

477
00:34:56,280 --> 00:34:59,080
I don't know.

478
00:34:59,080 --> 00:35:02,960
But yeah, that's my only thoughts.

479
00:35:02,960 --> 00:35:03,960
Thank you.

480
00:35:03,960 --> 00:35:04,960
Thank you.

481
00:35:04,960 --> 00:35:08,200
I love how many questions everybody had.

482
00:35:08,200 --> 00:35:10,440
Anyways, thank you very much, Sebastian.

483
00:35:10,440 --> 00:35:13,680
Oh, I'm so sorry.

484
00:35:13,680 --> 00:35:20,500
I don't know if I missed this, but was there any metrics on performance of this model?

485
00:35:20,500 --> 00:35:26,560
They weren't in the slides, but I got close to 90% accuracy.

486
00:35:26,560 --> 00:35:32,960
But again, that was before thorough analysis of my results, like what Deborah talked about.

487
00:35:32,960 --> 00:35:40,400
Yeah, this was sort of like a first, I'd say, few steps through the project.

488
00:35:40,400 --> 00:35:43,960
There are definitely still a lot of ways to improve it.

489
00:35:43,960 --> 00:35:50,040
Okay, so it's not necessarily being used actively to sort of treat voice disorders or anything

490
00:35:50,040 --> 00:35:52,120
like that or identify them?

491
00:35:52,120 --> 00:35:53,120
This model, no.

492
00:35:53,120 --> 00:35:56,000
Okay, thank you.

493
00:35:56,000 --> 00:35:58,520
There might be similar ones, but not this one.

494
00:35:58,520 --> 00:36:00,960
Again, I'm really sorry about that.

495
00:36:00,960 --> 00:36:02,760
Well, thank you very much.

496
00:36:02,760 --> 00:36:03,760
And thank you.

497
00:36:03,760 --> 00:36:04,760
Thank you.

498
00:36:04,760 --> 00:36:05,760
Thank you.

499
00:36:05,760 --> 00:36:05,780
Thank you.

