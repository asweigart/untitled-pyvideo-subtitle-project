1
00:00:00,000 --> 00:00:02,000
Anyway, so quick introduction about myself.

2
00:00:02,000 --> 00:00:02,840
I'm Grishma Jainer.

3
00:00:02,840 --> 00:00:06,440
I work as a cognitive software engineer with IBM Watson.

4
00:00:06,440 --> 00:00:09,440
Many people ask me, what exactly do you mean by cognitive software engineer?

5
00:00:09,440 --> 00:00:13,480
It's honestly just a really fancy term for a data scientist who does a bit of

6
00:00:13,480 --> 00:00:16,560
software engineering on the side.

7
00:00:16,560 --> 00:00:21,520
So before we start off, I have a few questions for you.

8
00:00:21,520 --> 00:00:26,240
How much data do you think is produced every year?

9
00:00:26,240 --> 00:00:28,800
Anyone?

10
00:00:28,880 --> 00:00:30,400
Sorry?

11
00:00:30,400 --> 00:00:32,160
Infinite, okay.

12
00:00:32,160 --> 00:00:34,240
Let's talk figures.

13
00:00:34,240 --> 00:00:36,120
Megabytes?

14
00:00:36,120 --> 00:00:38,280
Terabytes?

15
00:00:38,280 --> 00:00:39,200
Hexabytes?

16
00:00:39,200 --> 00:00:41,200
Hexabytes, okay.

17
00:00:41,200 --> 00:00:42,680
Anyone else?

18
00:00:46,120 --> 00:00:49,200
All of the data in the world, like.

19
00:00:49,200 --> 00:00:53,440
Yeah, all the data in the digital universe, everything that's online.

20
00:00:53,440 --> 00:00:57,280
Yeah, it's going pretty big, right?

21
00:00:57,280 --> 00:00:59,600
So it's actually 16.3 zettabytes.

22
00:00:59,600 --> 00:01:03,600
They had to come up with a new unit called zettabytes, where one zettabyte is

23
00:01:03,600 --> 00:01:08,920
one trillion gigabytes, just because that's the amount of magnitude of data

24
00:01:08,920 --> 00:01:12,280
that's there today.

25
00:01:12,280 --> 00:01:13,880
Okay.

26
00:01:13,880 --> 00:01:18,040
So to place this in a bit of context, how much data do you think the brain would

27
00:01:18,040 --> 00:01:19,040
hold?

28
00:01:19,040 --> 00:01:22,880
Depends on the day.

29
00:01:22,880 --> 00:01:26,320
Depends on the day, very true.

30
00:01:26,320 --> 00:01:30,560
Do you think it would be more than zettabytes?

31
00:01:30,560 --> 00:01:32,640
No?

32
00:01:32,640 --> 00:01:34,640
Has to be more than megabytes, right?

33
00:01:34,640 --> 00:01:38,720
I mean, I would like to think we are a little better than our standard pen

34
00:01:38,720 --> 00:01:41,520
drives and hard drives.

35
00:01:41,520 --> 00:01:45,520
Probably gigabytes?

36
00:01:45,520 --> 00:01:46,240
Okay.

37
00:01:46,240 --> 00:01:50,960
So it's actually 2.5 petabytes, where one petabyte is one million gigabytes.

38
00:01:50,960 --> 00:01:56,120
So the digital universe was a zettabyte, which is one trillion gigabytes, and here

39
00:01:56,120 --> 00:01:57,800
we're talking about one million gigabytes.

40
00:01:57,800 --> 00:02:00,560
So it's orders of magnitude lesser.

41
00:02:00,560 --> 00:02:05,080
So to give you a little bit more context, 2.5 petabytes, just think of your

42
00:02:05,080 --> 00:02:09,880
favorite TV show playing for three million hours.

43
00:02:09,880 --> 00:02:14,920
So back in the days where everyone used to use a video recorder to tape shows,

44
00:02:14,920 --> 00:02:20,120
that video recorder would be continuously playing for 300 years.

45
00:02:20,120 --> 00:02:20,920
So just imagine.

46
00:02:20,920 --> 00:02:23,040
And that's only the capacity of the brain.

47
00:02:23,080 --> 00:02:27,760
So multiply that by orders of magnitude to get the amount of data that's there

48
00:02:27,760 --> 00:02:33,040
in today's digital universe.

49
00:02:33,040 --> 00:02:33,760
Okay.

50
00:02:33,760 --> 00:02:39,760
So what we're going to do is, this is a small presentation to give you a gist of

51
00:02:39,760 --> 00:02:43,920
some concepts, to give you an understanding of what the basic data science

52
00:02:43,920 --> 00:02:48,600
pipeline looks like, and then we'll delve deeper into actually coding and using

53
00:02:48,600 --> 00:02:49,960
our Jupyter notebooks.

54
00:02:50,000 --> 00:02:55,480
A quick question was, everyone able to install Jupyter or able to access Google

55
00:02:55,480 --> 00:02:57,000
Core Lab?

56
00:02:57,000 --> 00:02:58,480
Is there anyone who faced problems?

57
00:03:02,200 --> 00:03:04,920
Okay, I'll take that as a no.

58
00:03:04,920 --> 00:03:06,120
All right.

59
00:03:06,120 --> 00:03:11,840
So my objective behind giving you these statistics is just to make you realize

60
00:03:11,840 --> 00:03:17,600
that the amount of data that we generate is way, way more than we actually realize.

61
00:03:17,600 --> 00:03:22,160
In fact, there are some estimates that say that by 2020, that is by next year,

62
00:03:22,160 --> 00:03:27,720
every human on Earth is going to be generating 1.7 megabytes per second.

63
00:03:27,720 --> 00:03:30,960
So that's going to be your location data, your medical data, all your tracking

64
00:03:30,960 --> 00:03:35,320
devices, your emails, your blogs, videos, and whatnot.

65
00:03:39,160 --> 00:03:43,040
So before that, let's actually get down to the very basic terms.

66
00:03:43,040 --> 00:03:45,040
What do you mean by data?

67
00:03:45,040 --> 00:03:48,920
Data is just any piece of information that can be stored, that can be processed.

68
00:03:48,920 --> 00:03:50,200
You can manipulate it.

69
00:03:50,200 --> 00:03:52,200
You can access it.

70
00:03:52,200 --> 00:03:56,680
Data science particularly refers to some algorithms, some techniques, some heuristics

71
00:03:56,680 --> 00:04:00,200
that you use on that data to get some insights.

72
00:04:02,080 --> 00:04:07,360
There's no real consensus on how much amount of data is considered big data.

73
00:04:07,360 --> 00:04:11,360
So the only consensus is that anything that your traditional database processing

74
00:04:11,360 --> 00:04:14,400
systems cannot handle, that's called big data.

75
00:04:14,400 --> 00:04:19,480
Or another definition is if the data can't fit on your local machine, it's big data.

76
00:04:21,320 --> 00:04:26,120
Artificial intelligence specifically talks about agents and trying to give them some

77
00:04:26,120 --> 00:04:27,920
semblance of cognition.

78
00:04:27,920 --> 00:04:32,560
So you're trying to develop so-called intelligent systems over there.

79
00:04:32,560 --> 00:04:37,840
And finally, machine learning is a particular field where you don't try to tell the

80
00:04:37,840 --> 00:04:41,400
program, you don't try to explain to the software what are the patterns, but the

81
00:04:41,400 --> 00:04:45,360
software tries to understand it after you give it the data and tries to analyze what

82
00:04:45,360 --> 00:04:46,840
are the different patterns.

83
00:04:46,840 --> 00:04:49,840
These are the kind of different trends that you're seeing.

84
00:04:49,840 --> 00:04:51,840
And that's machine learning.

85
00:04:54,280 --> 00:04:59,920
OK, so data science is really good at doing common tasks, but quickly and more efficiently

86
00:04:59,920 --> 00:05:05,160
than humans do because it's able to process lots of data quickly.

87
00:05:05,160 --> 00:05:09,320
Another application it's really good at is predicting and forecasting results, making

88
00:05:09,320 --> 00:05:10,600
customized recommendations.

89
00:05:10,600 --> 00:05:14,160
So think about Amazon, think about Netflix, think about Spotify.

90
00:05:14,160 --> 00:05:18,520
It's really good at making recommendations that are good for you as an individual.

91
00:05:19,960 --> 00:05:23,920
Optimizes procedures and actions, of course, and really good at finding the needle in the

92
00:05:23,920 --> 00:05:28,840
haystack or trying to identify patterns that are not as easily identified by humans.

93
00:05:31,000 --> 00:05:35,080
OK, so this is a snapshot of what the data science pipeline looks like.

94
00:05:35,080 --> 00:05:38,600
You start off with a question and the data at hand.

95
00:05:38,600 --> 00:05:40,400
Then you finally dangle the data.

96
00:05:40,400 --> 00:05:46,040
You clean it, you explore it, you try to get an understanding of what is the data like?

97
00:05:46,040 --> 00:05:47,280
What are the different features?

98
00:05:47,280 --> 00:05:48,240
What are the characteristics?

99
00:05:48,240 --> 00:05:49,160
Is it text-based?

100
00:05:49,160 --> 00:05:50,200
Is it sound-based?

101
00:05:50,200 --> 00:05:51,840
Is it a combination of both?

102
00:05:53,360 --> 00:05:57,120
That iterative, you can see that there's from explore to preprocess to model is kind of

103
00:05:57,120 --> 00:06:01,520
an iterative cycle because oftentimes you might create a model and you might not get

104
00:06:01,520 --> 00:06:03,200
really good performance.

105
00:06:03,200 --> 00:06:07,160
So then you go back and you try to take more features from the data or try to do more of

106
00:06:07,160 --> 00:06:10,280
cleaning and then start the model building process again.

107
00:06:10,400 --> 00:06:14,320
And finally, when you're happy, you validate the model, you're happy with the performance,

108
00:06:14,320 --> 00:06:18,280
you tell a story, which hopefully will give you some actionable insight.

109
00:06:21,200 --> 00:06:28,200
OK, so what kind of questions can we use data science to answer?

110
00:06:28,200 --> 00:06:30,360
So pretty basic.

111
00:06:30,360 --> 00:06:36,080
All of us use Gmail or some other mail service and you see a lot of emails going to your

112
00:06:36,080 --> 00:06:39,560
spam folder, right, or your junk folder.

113
00:06:39,560 --> 00:06:43,560
That's data science at the back end because it helps you identify which emails are likely

114
00:06:43,560 --> 00:06:48,560
to be marked as spam or which are spam and which ones are probably important emails that

115
00:06:48,560 --> 00:06:50,560
you need to see.

116
00:06:50,560 --> 00:06:54,320
Another really common example is oftentimes you use your credit cards and you might get

117
00:06:54,320 --> 00:06:59,960
some text alerts saying that, hey, your credit card was used for so-and-so transaction.

118
00:06:59,960 --> 00:07:01,400
Was that really you?

119
00:07:01,400 --> 00:07:05,920
That's because in their machine learning system, it got triggered as an anomaly, something

120
00:07:05,920 --> 00:07:11,760
either probably the retailer you went to was not one where you go to usually, or maybe

121
00:07:11,760 --> 00:07:16,120
you stay in the US and it got used in some other country.

122
00:07:16,120 --> 00:07:20,680
So those kind of things stand out as anomalies, so that's data science.

123
00:07:20,680 --> 00:07:26,040
Like I mentioned, Amazon, Netflix, even Facebook, they have these recommender algorithms.

124
00:07:26,040 --> 00:07:31,760
So how likely are you to engage with a particular article or how likely are you to listen to

125
00:07:32,760 --> 00:07:38,960
a sound, how likely you are to buy a particular product, and it also helps in allowing you

126
00:07:38,960 --> 00:07:39,960
to predict things.

127
00:07:39,960 --> 00:07:43,960
For example, you're trying to predict who is going to be the primary candidate for Democrats

128
00:07:43,960 --> 00:07:49,000
in the upcoming elections, or you're trying to predict which team is going to win in a

129
00:07:49,000 --> 00:07:50,640
certain sports league.

130
00:07:50,640 --> 00:07:56,160
So it's a lot of wide variety of applications, but the algorithms behind most of these applications

131
00:07:56,160 --> 00:08:03,320
are kind of the same, and we'll be seeing them shortly.

132
00:08:03,320 --> 00:08:07,520
So once we have the question at hand, when we have identified what stakeholders we want

133
00:08:07,520 --> 00:08:12,760
who are involved in the decision making and who want the answers to the questions, you

134
00:08:12,760 --> 00:08:16,840
obviously need the data at hand, because you won't be able to perform data science without

135
00:08:16,840 --> 00:08:18,740
the data.

136
00:08:18,740 --> 00:08:23,920
So data comes in a lot of different formats from a lot of different sources, but you can

137
00:08:23,920 --> 00:08:30,520
categorize them into three main categories, which is structured, unstructured, and semi-structured.

138
00:08:30,520 --> 00:08:34,680
So structured, think of your traditional databases where you have a tabular format, you have

139
00:08:34,680 --> 00:08:37,400
the row and column format.

140
00:08:37,400 --> 00:08:40,000
Unstructured is the opposite end of the spectrum.

141
00:08:40,000 --> 00:08:44,960
Think about your audios, your videos, your documents, where there is no standard structure

142
00:08:44,960 --> 00:08:46,720
that gets followed.

143
00:08:46,720 --> 00:08:50,400
And finally semi-structured, which kind of sits in the middle of these two, where there

144
00:08:50,400 --> 00:08:52,400
is some sort of structure associated.

145
00:08:52,400 --> 00:08:57,080
For example, think about web pages, you have HTML tags, but within those HTML tags the

146
00:08:57,080 --> 00:08:59,600
content could be anything, which is unstructured.

147
00:08:59,600 --> 00:09:03,780
So it's a bit of both structured and semi-structured.

148
00:09:03,780 --> 00:09:09,720
Most of the data in the world today is actually unstructured, which is kind of a challenge,

149
00:09:09,720 --> 00:09:13,520
because if you have structured data you know what to expect and you know how to handle

150
00:09:13,520 --> 00:09:14,640
it, how to access it.

151
00:09:14,640 --> 00:09:18,160
But with unstructured data there could be a combination of data formats, combination

152
00:09:19,160 --> 00:09:24,160
and becomes a little challenging in accessing and manipulating it.

153
00:09:24,160 --> 00:09:30,160
Okay, so you got the question, you have the data at hand.

154
00:09:30,160 --> 00:09:34,320
You start off with something that's called as data wrangling or the data cleansing, data

155
00:09:34,320 --> 00:09:39,720
cleaning process, where what you're trying to do is try to make sure that your data is

156
00:09:39,720 --> 00:09:45,880
in a format that makes it accessible, that makes it accessible, that allows you to derive

157
00:09:45,880 --> 00:09:46,880
insights better.

158
00:09:47,440 --> 00:09:52,040
So data wrangling is nothing but the process of gathering and selecting data, transforming

159
00:09:52,040 --> 00:09:55,040
it to make it useful.

160
00:09:55,040 --> 00:09:58,240
Examples include you would standardize multiple sources if you're trying to combine different

161
00:09:58,240 --> 00:09:59,240
data sets.

162
00:09:59,240 --> 00:10:06,520
Let's say for example one data set has the column name called gender and another data

163
00:10:06,520 --> 00:10:08,440
set has the column name called sex.

164
00:10:08,440 --> 00:10:13,680
So both of these two mean the same thing, right, but the computer is not going to understand

165
00:10:13,680 --> 00:10:14,740
that.

166
00:10:14,740 --> 00:10:23,060
So you can standardize it by performing, by giving the same name to both of the columns.

167
00:10:23,060 --> 00:10:28,340
There is often the problem of dealing with missing data because real world data is messy.

168
00:10:28,340 --> 00:10:34,220
Let's say for example you send out a survey, maybe someone fills their human age as 200

169
00:10:34,220 --> 00:10:35,220
years.

170
00:10:35,220 --> 00:10:40,020
Now to the best of our knowledge nobody like that exists, so that's going to be a wrong

171
00:10:40,620 --> 00:10:45,740
or maybe someone doesn't want to reveal some information and it's just like blank over

172
00:10:45,740 --> 00:10:46,740
there.

173
00:10:46,740 --> 00:10:51,300
So you could either discard the data or you could try filling it, interpolating it, you

174
00:10:51,300 --> 00:10:55,660
could fill it with the median or the mode or the maximum and whatnot.

175
00:10:55,660 --> 00:11:00,980
Also you can convert categories to numbers, let's say like in the spam detection example

176
00:11:00,980 --> 00:11:06,100
you have the email records labeled as spam or not spam, so you can assign a value of

177
00:11:06,100 --> 00:11:09,500
one to spam and you can assign a value of zero to not spam.

178
00:11:09,500 --> 00:11:16,820
Okay, so after the initial process of data cleaning you go through exploration which

179
00:11:16,820 --> 00:11:21,540
is where think of it as getting your feet wet with the data and you're trying to understand

180
00:11:21,540 --> 00:11:24,900
what are the different features that are present and what are the characteristics, what do

181
00:11:24,900 --> 00:11:29,180
they look like, what is the distribution like, what are the different values that those features

182
00:11:29,180 --> 00:11:35,200
can take and hopefully by the end of it you have some idea of what looks interesting,

183
00:11:35,400 --> 00:11:39,800
is pretty obvious what is something unexpected and you've formed some sort of hypothesis

184
00:11:39,800 --> 00:11:40,800
about the data.

185
00:11:40,800 --> 00:11:46,840
So it'd be things like okay this looks pretty obvious, perhaps I don't want to delve deeper

186
00:11:46,840 --> 00:11:51,800
into it but this is kind of unexpected, I would like to further investigate and see

187
00:11:51,800 --> 00:11:56,600
is it something that is pretty obvious, is it something not obvious, is it something

188
00:11:56,600 --> 00:12:01,400
surprising, I might help answer the question and this step also involves a lot of data

189
00:12:01,400 --> 00:12:05,800
visualization, you try to create graphs to see the distributions of data and understand

190
00:12:05,800 --> 00:12:08,600
the correlations among the features.

191
00:12:08,600 --> 00:12:16,200
Okay, and finally we head on to the model building phase where you create a lot of features,

192
00:12:16,200 --> 00:12:19,600
you have the features, you create some more meaningful features using a combination of

193
00:12:19,600 --> 00:12:23,600
these and then finally you divide the data into training and test sets, you choose a

194
00:12:23,600 --> 00:12:27,960
machine learning model or a particular algorithm that you want to apply depending on the kind

195
00:12:27,960 --> 00:12:33,960
of output that you want, keep iterating, like I mentioned it can be an iterative process,

196
00:12:33,960 --> 00:12:38,760
maybe you want to go back and get some more features that give you more information and

197
00:12:38,760 --> 00:12:42,560
then finally you end up with evaluating the model.

198
00:12:42,560 --> 00:12:49,560
Okay, so hopefully I gave you a quick brief overview of the entire process, so let's get

199
00:12:49,680 --> 00:12:55,080
down to coding.

200
00:12:55,080 --> 00:13:02,080
You should be able to access this by PyCon ID.

201
00:13:10,480 --> 00:13:11,480
Yeah.

202
00:13:17,480 --> 00:13:18,480
Is this better?

203
00:13:18,880 --> 00:13:25,880
So, this is the URL, it's bid.ly slash PyCon IDS which is into the data science.

204
00:13:28,880 --> 00:13:35,880
Yeah, sure.

205
00:13:36,880 --> 00:13:43,880
Oh, okay.

206
00:14:14,280 --> 00:14:21,280
Okay, you should be able to access it now.

207
00:14:34,880 --> 00:14:39,880
Was everyone able to access it?

208
00:14:39,880 --> 00:14:46,880
It's bid.ly slash PyCon IDS.

209
00:14:46,880 --> 00:14:53,880
Yeah, I can do that.

210
00:15:10,480 --> 00:15:17,480
Thank you.

211
00:15:31,600 --> 00:15:38,600
Mr. Elliott?

212
00:15:39,880 --> 00:15:46,880
So, let me just actually write it in the world.

213
00:15:46,880 --> 00:15:47,880
Sorry?

214
00:15:47,880 --> 00:15:54,880
Oh, okay.

215
00:16:17,880 --> 00:16:24,880
Was everyone able to access it?

216
00:16:24,880 --> 00:16:25,880
Okay.

217
00:16:25,880 --> 00:16:38,880
What browser are you using?

218
00:16:38,880 --> 00:16:39,880
Okay.

219
00:17:08,880 --> 00:17:29,880
So, now I have two options.

220
00:17:29,880 --> 00:17:34,880
For those of you who already have Jupyter installed, you can run it on your local machine,

221
00:17:34,880 --> 00:17:37,880
or you can just run it in the browser using Google Colab.

222
00:17:37,880 --> 00:17:46,880
So, let me just show you quickly how you can run it.

223
00:17:46,880 --> 00:17:50,880
So, this is the first cell of code.

224
00:17:50,880 --> 00:18:01,880
You can click on the left-hand panel, and you will see the Play button, and just click it to run it.

225
00:18:01,880 --> 00:18:06,880
And then you can see it rerun the cell.

226
00:18:06,880 --> 00:18:13,880
And for those of you who are using Jupyter, you can download this notebook.

227
00:18:13,880 --> 00:18:16,880
There should be a download button somewhere here.

228
00:18:16,880 --> 00:18:20,880
I probably cannot see it.

229
00:18:20,880 --> 00:18:21,880
Oh, okay. Yeah.

230
00:18:21,880 --> 00:18:24,880
Because, yeah, it's magnified, so I'm not able to see it,

231
00:18:24,880 --> 00:18:32,880
but you should be able to download this notebook and place it in your Jupyter.

232
00:18:32,880 --> 00:18:37,880
Or just place it anywhere in your documents.

233
00:18:37,880 --> 00:18:40,880
And then start up a terminal.

234
00:18:40,880 --> 00:18:53,880
Oh, terminal, sorry.

235
00:18:53,880 --> 00:19:02,880
So, just type Jupyter notebook in the terminal for those of you using Jupyter on your local machine.

236
00:19:02,880 --> 00:19:10,880
And that will open up the Jupyter ID for you in one of your browser tabs.

237
00:19:10,880 --> 00:19:13,880
And then access wherever you have stored your notebook.

238
00:19:13,880 --> 00:19:23,880
So for me, it's here.

239
00:19:23,880 --> 00:19:29,880
And then you should be able to run it using the Run button.

240
00:19:29,880 --> 00:19:33,880
How many of you are using Jupyter?

241
00:19:33,880 --> 00:19:35,880
Okay, I guess a majority of you. Fine.

242
00:19:35,880 --> 00:20:01,880
Then I'll keep it in Jupyter.

243
00:20:01,880 --> 00:20:04,880
Is the size okay for everyone?

244
00:20:04,880 --> 00:20:09,880
Otherwise, you should be able to access the notebook as well.

245
00:20:09,880 --> 00:20:12,880
Okay. So this has all of the code.

246
00:20:12,880 --> 00:20:20,880
Feel free to run it over here or feel free to open up a new notebook and just try to run it on your own.

247
00:20:20,880 --> 00:20:24,880
Okay, so I already gave you a bit of introduction about data science.

248
00:20:24,880 --> 00:20:28,880
What does the data science pipeline look like?

249
00:20:28,880 --> 00:20:33,880
Question to answer and of course the data.

250
00:20:33,880 --> 00:20:42,880
Okay, so before we go into that, there are a few tools you can see with the heading Python tools mentioned at different intervals.

251
00:20:42,880 --> 00:20:46,880
So the first one is NumPy. How many of you are familiar with NumPy?

252
00:20:46,880 --> 00:20:49,880
Okay, I think some of you aren't.

253
00:20:49,880 --> 00:20:53,880
Okay, so NumPy is just this really cool package.

254
00:20:53,880 --> 00:20:55,880
It stands for numerical Python.

255
00:20:55,880 --> 00:20:59,880
It's a part of the scientific computing or SciPy stack in Python.

256
00:20:59,880 --> 00:21:06,880
And what it does is it gives you this really high-performing multi-dimensional array that you can use.

257
00:21:06,880 --> 00:21:11,880
So if you're familiar with MATLAB or the way MATLAB works, it's all in matrix form.

258
00:21:11,880 --> 00:21:14,880
So that's what NumPy does for you but in Python.

259
00:21:14,880 --> 00:21:23,880
It gives you a multi-dimensional array and it's super fast because the operations that are taking place are on the matrix instead of the scalars.

260
00:21:23,880 --> 00:21:26,880
You can use Conda or PIP to install NumPy.

261
00:21:26,880 --> 00:21:33,880
For those of you using Google Colab, all of the packages should already be accessible.

262
00:21:33,880 --> 00:21:34,880
You don't have to install them.

263
00:21:34,880 --> 00:21:39,880
But for those of you who are using Jupyter and local machine, you might already have the package installed.

264
00:21:39,880 --> 00:21:44,880
Otherwise, you can just install it using PIP and Conda.

265
00:21:44,880 --> 00:21:49,880
Okay, similarly, pandas, NumPy and pandas almost always go hand in hand.

266
00:21:49,880 --> 00:22:02,880
Pandas is this, let's say it's kind of a data frame or if it's an object that tries to model the data into what an Excel spreadsheet would look like.

267
00:22:02,880 --> 00:22:09,880
So think of rows, think of different column headers, and that is what your pandas data frame would look like.

268
00:22:09,880 --> 00:22:16,880
It came from the word panel data, which I believe is used in economics.

269
00:22:16,880 --> 00:22:20,880
And again, you can go ahead and install pandas using Conda or PIP.

270
00:22:20,880 --> 00:22:24,880
How many of you are familiar with pandas?

271
00:22:24,880 --> 00:22:26,880
Okay, again, most of you.

272
00:22:26,880 --> 00:22:33,880
Is there anyone who would like me to go through pandas in a little more detail?

273
00:22:33,880 --> 00:22:34,880
Okay, a few hands.

274
00:22:34,880 --> 00:22:36,880
Okay, I'll do that.

275
00:22:36,880 --> 00:22:39,880
Okay, so there are a few different ways to use panda.

276
00:22:39,880 --> 00:22:47,880
So you can start off with a list, a dictionary, or a NumPy array and just load it directly into a pandas data frame.

277
00:22:47,880 --> 00:22:50,880
Or you can open a local file on your machine.

278
00:22:50,880 --> 00:22:54,880
So think of a CSV file and you can load that into your data frame.

279
00:22:54,880 --> 00:23:02,880
And finally, you can connect it to a remote database or you can try to scrape the information from a website and load that into a data frame.

280
00:23:02,880 --> 00:23:06,880
So let's take a look at a quick example.

281
00:23:06,880 --> 00:23:12,880
Let's go ahead and import NumPy as NP and pandas as PD so we don't have to type the entire name always.

282
00:23:12,880 --> 00:23:20,880
And here I'm just creating a simple list with the first few numbers of the Fibonacci series.

283
00:23:20,880 --> 00:23:23,880
So this is a list that's user defined.

284
00:23:23,880 --> 00:23:29,880
And then the way you would convert it to a data frame is pandas or PD.dataFrame.

285
00:23:29,880 --> 00:23:32,880
You pass the list or the data that you want.

286
00:23:32,880 --> 00:23:38,880
And then you say that I want the column names to be a list of whatever column names you want.

287
00:23:38,880 --> 00:23:45,880
Since we have only one column over here, let's give the name as value and see what happens.

288
00:23:45,880 --> 00:23:49,880
So this is what a pandas data frame looks like.

289
00:23:49,880 --> 00:23:57,880
You have value as the column, you have 0, 1, 2, 7 as the different rows, and the 0, 1, 2, 7 are also the index numbers.

290
00:24:02,880 --> 00:24:09,880
Okay. So another way to load a data frame is like I mentioned, a CSV file.

291
00:24:09,880 --> 00:24:12,880
So you can go ahead and access any CSV file on your computer.

292
00:24:12,880 --> 00:24:22,880
Or there's one of these raw data sets on GitHub, which is a list of countries and the regions they are in.

293
00:24:22,880 --> 00:24:26,880
So let's try to go ahead and read that in our pandas data frame.

294
00:24:26,880 --> 00:24:31,880
So you'd go pd.read.csv and then finally give it the file name.

295
00:24:31,880 --> 00:24:34,880
In this case, it's the URL name.

296
00:24:34,880 --> 00:24:41,880
And you can print out the shape or the dimensions using pandas, the data frame dot shape.

297
00:24:41,880 --> 00:25:01,880
And you can also print out some information about the metadata using the data frame dot info.

298
00:25:01,880 --> 00:25:07,880
So you can see the dimensions are 194, where 194 are the number of rows, 2 is the number of columns.

299
00:25:07,880 --> 00:25:17,880
It's an object of type pandas dot data frame and tells you some more metadata about what are the different kind of columns present, what are the data types for them.

300
00:25:17,880 --> 00:25:39,880
And then you can also print the first five or the first end data points or rows in the data frame using the head function.

301
00:25:39,880 --> 00:25:41,880
Or if you want the last ones, you use the tail function.

302
00:25:41,880 --> 00:25:46,880
So it works in a similar way.

303
00:25:46,880 --> 00:25:56,880
So you can see these are the first five rows in our data frame.

304
00:25:56,880 --> 00:26:11,880
There are some more functions that you can use in the pandas data frame like, okay, very important, you access it using, if you want to access a column, you access it using the data frame name with in square brackets the name of the column.

305
00:26:11,880 --> 00:26:19,880
You can also use indexing over here, pretty similar to how our arrays work, except you have to use ILOC, which is, I believe, the index location.

306
00:26:19,880 --> 00:26:24,880
And then you give it zero zero as, for example, the first very first element.

307
00:26:24,880 --> 00:26:29,880
You can perform some other operations like filtering, grouping, selecting.

308
00:26:29,880 --> 00:26:32,880
And this is the kind of syntax what you would use for doing that.

309
00:26:32,880 --> 00:26:39,880
So this gives you all of the data points where the region is North America.

310
00:26:39,880 --> 00:26:45,880
And finally, you can also group by region and then see how many countries are there in those particular regions.

311
00:26:45,880 --> 00:26:51,880
So this is what the output looks like.

312
00:26:51,880 --> 00:26:54,880
This was the very first element in our data frame.

313
00:26:54,880 --> 00:26:58,880
These are all of the countries where North America is the region.

314
00:26:58,880 --> 00:27:04,880
And finally, this is a count where after you group it by regions.

315
00:27:04,880 --> 00:27:08,880
OK, any questions so far?

316
00:27:08,880 --> 00:27:12,880
OK.

317
00:27:12,880 --> 00:27:16,880
So this is another way to access a data set.

318
00:27:16,880 --> 00:27:19,880
There's another package called sklearn, which stands for scikit-learn.

319
00:27:19,880 --> 00:27:21,880
We'll be seeing that in detail a little later.

320
00:27:21,880 --> 00:27:26,880
But there are a few data sets that are already included in this package.

321
00:27:26,880 --> 00:27:28,880
You don't really have to download any data set.

322
00:27:28,880 --> 00:27:33,880
We can just work internally and try to perform some sort of model building.

323
00:27:33,880 --> 00:27:42,880
So another really famous data set is called as the Iris data set, which is basically some sort of characteristics, some sort of information about flowers.

324
00:27:42,880 --> 00:27:47,880
You have sepal length, sepal width, petal length, and so on and so forth.

325
00:27:47,880 --> 00:27:49,880
It's just completely numerical data.

326
00:27:49,880 --> 00:27:51,880
You can't see any text over here.

327
00:27:51,880 --> 00:27:57,880
And the way to load it would be you give, you convert it into a numpy array.

328
00:27:57,880 --> 00:28:00,880
And then you see that this is all of the data.

329
00:28:00,880 --> 00:28:09,880
And then finally, target is what the label is associated with the data and the different column names, which are nothing but the feature names plus the target.

330
00:28:09,880 --> 00:28:17,880
And then you can see what the initial few points in the data set look like.

331
00:28:17,880 --> 00:28:24,880
We won't be using this data set, but this is just to give you an example of how there are inbuilt data sets in the package sklearn.

332
00:28:24,880 --> 00:28:29,880
And that's how we can access them.

333
00:28:29,880 --> 00:28:31,880
OK, moving on.

334
00:28:31,880 --> 00:28:35,880
So now we have our data or rather toy data set sample data sets.

335
00:28:35,880 --> 00:28:39,880
We go into data cleaning or data rankling.

336
00:28:39,880 --> 00:28:41,880
So like I mentioned, real world data is often messy.

337
00:28:41,880 --> 00:28:46,880
There can be points where the value doesn't really make sense.

338
00:28:46,880 --> 00:28:49,880
Like I mentioned, age, human age being 200 years.

339
00:28:49,880 --> 00:28:56,880
Or there are data sets where you have some missing values or null values.

340
00:28:56,880 --> 00:29:02,880
You could also have categories and we would convert them into numbers.

341
00:29:02,880 --> 00:29:20,880
And another important point is we must ensure that a data set is unique or at least as unique as we can make it, because we don't want the model to get a false weightage of the most frequent occurring data points.

342
00:29:20,880 --> 00:29:26,880
OK, so remember we had a user defined list of Fibonacci series which we converted into a data frame.

343
00:29:26,880 --> 00:29:32,880
So let's perform a few simple data cleaning steps on that.

344
00:29:32,880 --> 00:29:47,880
So if you see in the initial list or in the initial data frame for Fibonacci, you'd see that the last value is any n, which is basically kind of a null value.

345
00:29:47,880 --> 00:29:56,880
And I intentionally put it there so we can see how the cleaning happens.

346
00:29:56,880 --> 00:30:02,880
OK, so there's this nifty little function called isNull.

347
00:30:02,880 --> 00:30:06,880
What you do is you call the data frame dot isNull and then do a sum.

348
00:30:06,880 --> 00:30:10,880
So you can the sum just tells you tells you that it OK.

349
00:30:10,880 --> 00:30:12,880
So isNull is going to return.

350
00:30:12,880 --> 00:30:13,880
Let's see what it returns.

351
00:30:13,880 --> 00:30:20,880
It's going to return a series of true or false values where if the particular value was null, it's going to return true.

352
00:30:20,880 --> 00:30:25,880
And internally, if you use a dot sum, it gets mapped to zeros and ones.

353
00:30:25,880 --> 00:30:26,880
And you finally find the sum.

354
00:30:26,880 --> 00:30:32,880
So if it's not zero, you realize that there are some values which are null.

355
00:30:32,880 --> 00:30:40,880
So like in this case, the sum was one because there was one null value.

356
00:30:40,880 --> 00:30:51,880
And the way you would handle it is let's say for instance, I want to fill that missing null value using the average for that particular row or for that particular column.

357
00:30:51,880 --> 00:30:55,880
So I just use the mean since there is only one column in the data set.

358
00:30:55,880 --> 00:31:02,880
And I'd say Fibonacci PD, which is our data frame, dot fill any fill the empty value with the mean.

359
00:31:02,880 --> 00:31:04,880
And this would fill all of the any values.

360
00:31:04,880 --> 00:31:06,880
Just in our example, there's only one.

361
00:31:06,880 --> 00:31:07,880
So it's going to fill one.

362
00:31:07,880 --> 00:31:13,880
And you can see it's filled it with 2.85, the actual average for the numbers.

363
00:31:13,880 --> 00:31:21,880
So this is usually the procedure you follow when you are a little pressed for data and you don't have enough data points.

364
00:31:21,880 --> 00:31:31,880
But if you do have a lot of data points or a really small percentage of data points that are missing values, you can just go ahead and completely discard them.

365
00:31:31,880 --> 00:31:32,880
That works too.

366
00:31:33,880 --> 00:31:37,880
And the way you would discard it is using the drop any function.

367
00:31:37,880 --> 00:31:45,880
In place is equal to true just means that it's going to perform the operation in that on the data frame itself.

368
00:31:45,880 --> 00:31:49,880
So you don't need to save it or you don't need to allocate the result into another data frame.

369
00:31:49,880 --> 00:31:53,880
And then you can see over here the value is gone.

370
00:31:53,880 --> 00:31:54,880
Yeah.

371
00:32:03,880 --> 00:32:06,880
It really depends on the application that you're going for.

372
00:32:06,880 --> 00:32:14,880
So in fact, while I was preparing this tutorial, I replaced one of the column names in place.

373
00:32:14,880 --> 00:32:18,880
And then I later realized I actually needed the original column.

374
00:32:18,880 --> 00:32:26,880
So if you do see that you might have a need for the original column, it's better to assign it to a different data frame or a different column name.

375
00:32:26,880 --> 00:32:28,880
So kind of like a duplicate column.

376
00:32:28,880 --> 00:32:31,880
So you're pretty sure that you don't want anything else to do with it.

377
00:32:31,880 --> 00:32:33,880
Just you can do it in place.

378
00:32:33,880 --> 00:32:34,880
Yeah.

379
00:32:34,880 --> 00:32:36,880
Any other questions?

380
00:32:38,880 --> 00:32:39,880
OK.

381
00:32:39,880 --> 00:32:42,880
Similarly, let's go to the country toy data set.

382
00:32:44,880 --> 00:32:51,880
And we can get an idea of what are the unique values for the region column using countries of region.unique.

383
00:32:51,880 --> 00:32:55,880
So these are the different values.

384
00:32:55,880 --> 00:32:56,880
OK.

385
00:32:56,880 --> 00:33:05,880
Remember how we mentioned that we would want to standardize the data set or convert the categories, the string names to some sort of an integer mapping.

386
00:33:05,880 --> 00:33:07,880
So this is what we're trying to do over here.

387
00:33:07,880 --> 00:33:12,880
We've just given all of the different regions an integer from one to six.

388
00:33:12,880 --> 00:33:22,880
And the way we would go about mapping it is let's create another column name called region category, which is the integer map integer mapping.

389
00:33:22,880 --> 00:33:29,880
Let's assign it to region first and then using our mapping, we would use the replace function.

390
00:33:29,880 --> 00:33:37,880
So the ones like, for example, South America would get a value of six like you can see over here.

391
00:33:41,880 --> 00:33:49,880
So whenever we have any sort of categories in your data set, go ahead and perform a mapping so that it's easier to work with numbers later on.

392
00:33:50,880 --> 00:33:52,880
Any questions so far?

393
00:33:52,880 --> 00:33:53,880
Yeah.

394
00:33:53,880 --> 00:33:55,880
Is there a way to have it do that?

395
00:33:55,880 --> 00:33:58,880
I noticed these are alphabetic, right?

396
00:33:58,880 --> 00:33:59,880
Yeah.

397
00:33:59,880 --> 00:34:02,880
So they don't look like it's supposed to say Africa is one of the issues too.

398
00:34:02,880 --> 00:34:07,880
Is there a way to just have it map that automatically?

399
00:34:07,880 --> 00:34:08,880
Yeah.

400
00:34:08,880 --> 00:34:14,880
You could just run a for loop and start like an iterator and have it map it that way.

401
00:34:14,880 --> 00:34:15,880
Yeah.

402
00:34:15,880 --> 00:34:17,880
But I just wanted to keep it simple over here.

403
00:34:17,880 --> 00:34:19,880
Any other questions?

404
00:34:22,880 --> 00:34:23,880
Okay.

405
00:34:23,880 --> 00:34:27,880
So now that we have got the data, we have a question that we want to answer.

406
00:34:27,880 --> 00:34:29,880
We've cleaned the data.

407
00:34:29,880 --> 00:34:33,880
We start with the data exploration phase, which is just prior to the model building phase.

408
00:34:33,880 --> 00:34:41,880
Think of it as getting your feet wet, where you're trying to understand what the data looks like, what are the different features, what are their characteristics,

409
00:34:42,880 --> 00:34:47,880
and it involves a lot of visualizations, drawing, plotting a lot of graphs.

410
00:34:47,880 --> 00:34:51,880
So another tool that comes in handy over here is Matplotlib.

411
00:34:51,880 --> 00:34:54,880
How many of you are familiar with Matplotlib?

412
00:34:54,880 --> 00:34:55,880
Okay.

413
00:34:55,880 --> 00:34:57,880
Fewer hands this time.

414
00:34:57,880 --> 00:35:01,880
So just think of it as a 2D plotting library for Python.

415
00:35:01,880 --> 00:35:03,880
It helps you create graphs.

416
00:35:03,880 --> 00:35:08,880
So think about line charts, your box plots, your distributions, histograms, and whatnot.

417
00:35:09,880 --> 00:35:14,880
Similar to how you install the other packages, you can go ahead and use Conda and PIP.

418
00:35:14,880 --> 00:35:17,880
So let's take a look at how Matplotlib works.

419
00:35:27,880 --> 00:35:32,880
So before we do that, let's try to explore what the different columns look like.

420
00:35:32,880 --> 00:35:37,880
We already know that Fibonacci series has only one particular column, which is value.

421
00:35:38,880 --> 00:35:47,880
The data types for the different columns is you use .dtypes, and it says that there's only one column value with data type float64.

422
00:35:47,880 --> 00:35:54,880
And there's another function called describe, which tries to give you all of the different statistics, the numerical statistics,

423
00:35:54,880 --> 00:35:58,880
to think about your quartiles, your mean, your count, min, max,

424
00:35:58,880 --> 00:36:06,880
and it gives you a snapshot of those statistics for each of the columns, numerical columns in your data frame.

425
00:36:07,880 --> 00:36:08,880
So you can see it over here.

426
00:36:11,880 --> 00:36:17,880
So oftentimes when you try to use Matplotlib, your graph might not show up,

427
00:36:17,880 --> 00:36:23,880
in which case you would use this magic line where you see Matplotlib inline,

428
00:36:23,880 --> 00:36:28,880
which says that I want the graphing to come as part of this code or the cells output.

429
00:36:28,880 --> 00:36:30,880
So it has to be inline with everything else.

430
00:36:30,880 --> 00:36:40,880
Okay, let's go ahead and import from Matplotlib pyplot, and let's use it as PLT so that we don't have to have the name.

431
00:36:40,880 --> 00:36:45,880
And we just say plt.plot and pass it the pandas data frame.

432
00:36:45,880 --> 00:36:47,880
And that gives you a line chart.

433
00:36:47,880 --> 00:36:51,880
Go ahead and feel free to write the title, name the axis.

434
00:36:51,880 --> 00:36:56,880
You can also change the intervals for the different axes using extx or ytx.

435
00:37:01,880 --> 00:37:03,880
So this is what the line chart looks like.

436
00:37:03,880 --> 00:37:09,880
But this is the index, and remember the last value was 8, which is over here.

437
00:37:11,880 --> 00:37:16,880
Let's try to use a similar strategy on the country data set.

438
00:37:18,880 --> 00:37:24,880
Value.counts tells you the different categories that are present and the frequency for those.

439
00:37:25,880 --> 00:37:29,880
So let's try to plot a histogram for the frequency of the different regions in there.

440
00:37:31,880 --> 00:37:41,880
So you can see South America is the lowest, and Africa and African countries in the data set are highest or the most occurring.

441
00:37:44,880 --> 00:37:54,880
So you can also go ahead and plot distributions, box plots, trying to see if it's a normal distribution, and a lot of other things over there.

442
00:37:55,880 --> 00:38:04,880
Okay. Another visualization tool that's pretty popular, that's very commonly used, is called cBond, which is built upon matplotlib.

443
00:38:04,880 --> 00:38:07,880
So just think of it as advanced matplotlib.

444
00:38:07,880 --> 00:38:09,880
We'll be seeing a few examples later on.

445
00:38:10,880 --> 00:38:17,880
It looks a little prettier. It gives you more information, and it's used mainly in the statistical graphing sense.

446
00:38:18,880 --> 00:38:21,880
Installation remains the same with PIPConda.

447
00:38:22,880 --> 00:38:31,880
Okay. So we took the question, we have the data, we performed some sort of analysis on it, we cleaned it, we explored it.

448
00:38:32,880 --> 00:38:36,880
Now let's get to what is considered as the meaty part of it, which is called model building.

449
00:38:40,880 --> 00:38:44,880
So like I mentioned earlier, model building first starts off with feature engineering,

450
00:38:44,880 --> 00:38:56,880
where you try to think of what features might help you answer the question that you have at hand, or what features, if combined together, might give you a more informative feature.

451
00:38:56,880 --> 00:39:04,880
So think, for example, you're trying to detect credit card fraud, and you have a list of transactions with each of their timestamps.

452
00:39:04,880 --> 00:39:14,880
Now the timestamp on its own is not going to be an important feature, because it's just going to be a series of human readable date, time, time zone.

453
00:39:14,880 --> 00:39:25,880
But if you use that timestamp to convert it to maybe, let's say, days since last transaction, or hours since last transaction, that might help give you a more meaningful feature.

454
00:39:26,880 --> 00:39:38,880
So let's say, you know, if you weren't using the credit card for maybe like a year, and suddenly there's a transaction, it might get flagged as fraud, because you usually don't use the credit card, and suddenly you've used it.

455
00:39:38,880 --> 00:39:53,880
So that is where feature engineering comes into play. It's also helpful to have a domain expert, like let's say in the case of medical imaging data, someone with a medical background, usually data scientists, they don't come from medical backgrounds, right?

456
00:39:53,880 --> 00:40:03,880
So you do need doctors, nurses, bioinformaticians to help you understand what exactly do those features mean. Is it something that's important?

457
00:40:03,880 --> 00:40:08,880
Is it something that's indicative of trying to predict if a cancer exists, if a tumor exists or not?

458
00:40:08,880 --> 00:40:16,880
Or is it something that another feature already represents? So you can just kind of like, you know, drop that feature and use the other feature that holds the same information.

459
00:40:16,880 --> 00:40:20,880
So domain expertise is also important. It really depends on the application.

460
00:40:21,880 --> 00:40:27,880
Okay. Once you have the data, we perform what's known as a training and testing split.

461
00:40:27,880 --> 00:40:34,880
So remember how in school we would be given homework, so we'd be taught in the class? That is the training that's happening for us.

462
00:40:34,880 --> 00:40:41,880
And then finally, the semesters would culminate with an examination or a project, which is where your performance or your testing happens.

463
00:40:42,880 --> 00:40:51,880
So it's the same logic for a model. We're trying to give it a majority of data as training data or scene data on which it can learn some sort of patterns, get some insights.

464
00:40:51,880 --> 00:40:56,880
And then finally, we want it to be evaluated in a fair and objective manner.

465
00:40:56,880 --> 00:41:03,880
So you're not going to give it the exact same data points, but you're going to give it unseen data to see how well it has actually created a model.

466
00:41:04,880 --> 00:41:13,880
Yeah, good question. So this one is random, but oftentimes what happens is, let's say for instance, let's take the example of you're trying to predict cancer.

467
00:41:13,880 --> 00:41:16,880
And what you're trying to predict is a very rare type of cancer.

468
00:41:16,880 --> 00:41:26,880
So you're probably going to have like maybe 90 or 95 percent of your data set where it's predicted as not cancer and five to 10 percent or a really small percentage where it's predicted as cancer.

469
00:41:26,880 --> 00:41:32,880
Now, if you try to do a very simple model, you're going to get a very small percentage of data that's predicted as cancer.

470
00:41:32,880 --> 00:41:43,880
Now, if you try to do a random train test split, you're probably going to end up with like, you know, most of the splits being not cancer, whereas you're trying to build a model that's trying to predict cancer.

471
00:41:43,880 --> 00:41:50,880
So it's going to be difficult, right? So in those cases, you use something that's called as stratified sampling where you try to balance the data.

472
00:41:50,880 --> 00:41:56,880
You say, OK, I'm going to I have a very small I have maybe 10 percent of cases where cancer exists.

473
00:41:56,880 --> 00:42:00,880
So I'm going to learn to balance it and split it accordingly.

474
00:42:01,880 --> 00:42:07,880
So even my training has some of these samples and even my testing has some of these samples.

475
00:42:07,880 --> 00:42:10,880
Another issue that also comes with those kind of data sets.

476
00:42:10,880 --> 00:42:16,880
So those kind of assets are what we call imbalanced class or because there are two classes, right?

477
00:42:16,880 --> 00:42:21,880
Cancer and non-cancer. And they are really different in proportions.

478
00:42:21,880 --> 00:42:27,880
The other strategy that you can take is called sampling, which is over sampling or under sampling.

479
00:42:27,880 --> 00:42:34,880
So like I mentioned, if you have 90 percent of non-cancer non-cancer data points, you can down sample it.

480
00:42:34,880 --> 00:42:40,880
You can reduce the number, the proportion in it and bring it a little closer to 10 percent.

481
00:42:40,880 --> 00:42:50,880
Or alternatively, you can over sample the minority class where you take the 10 percent and you keep duplicating the data points so that it tries to learn a general model.

482
00:42:50,880 --> 00:42:52,880
Does that make sense?

483
00:42:52,880 --> 00:42:55,880
Any questions?

484
00:42:55,880 --> 00:43:00,880
OK. All right.

485
00:43:00,880 --> 00:43:07,880
OK. SKA learn, scikit learn, that is what forms the crux of most of our machine learning algorithms.

486
00:43:07,880 --> 00:43:13,880
And it works in conjunction with NumPy and SciPy, which we have already installed.

487
00:43:13,880 --> 00:43:22,880
OK. So like I mentioned in the slides, there are two main categories of algorithms, supervised and unsupervised.

488
00:43:22,880 --> 00:43:31,880
Supervised is it has labels involved with the data like cancer, not cancer, spam, not spam, fraudulent, not fraudulent.

489
00:43:31,880 --> 00:43:34,880
Those kind of labels are associated with the data.

490
00:43:34,880 --> 00:43:38,880
So when you get the data set, you have those kind of labels already over there.

491
00:43:38,880 --> 00:43:46,880
That's why it's called supervised, because you have some sort of supervision or some sort of knowledge to inform if you're trying to predict the label correctly or not.

492
00:43:46,880 --> 00:43:51,880
Unsupervised is the other end of the spectrum where there are no labels associated.

493
00:43:51,880 --> 00:43:54,880
You don't know what is a right answer, what is the wrong answer.

494
00:43:54,880 --> 00:43:57,880
But in those cases, you're usually not looking for the right or wrong answer.

495
00:43:57,880 --> 00:44:02,880
What you're trying to do is you're trying to understand what is the structure of data like.

496
00:44:02,880 --> 00:44:08,880
Like, for example, you're trying to create, let's say, some sort of recommendation algorithm for Netflix.

497
00:44:08,880 --> 00:44:15,880
If I know that my taste and your taste, let's say for both of us, like action superhero movies,

498
00:44:15,880 --> 00:44:23,880
then we're going to come in the same cluster because the kind of movies that we've watched or the kinds of movies we would be interested in watching are going to be similar.

499
00:44:23,880 --> 00:44:30,880
So that helps us cluster our group objects or people in the same same categories.

500
00:44:30,880 --> 00:44:33,880
But like I said, there is no right or wrong answer.

501
00:44:33,880 --> 00:44:37,880
So it's unsupervised because there's no supervision to go offer.

502
00:44:37,880 --> 00:44:40,880
Any questions so far?

503
00:44:40,880 --> 00:44:48,880
OK. There's a third type, which is again like how we had structured and structured and semi-structured.

504
00:44:48,880 --> 00:44:51,880
The third type is semi-supervised.

505
00:44:51,880 --> 00:44:57,880
Semi-supervised basically means you have a data set where you have some of the labels, but most of them are unlabeled.

506
00:44:57,880 --> 00:45:03,880
So let's say for if you have an archive of photos, your images, some of them might have captions in them,

507
00:45:03,880 --> 00:45:09,880
but a majority of them wouldn't have any captions involved or they might have location tags or a majority would not have location tags.

508
00:45:09,880 --> 00:45:11,880
So that is semi-supervised.

509
00:45:11,880 --> 00:45:14,880
And the fourth type is reinforcement learning.

510
00:45:14,880 --> 00:45:17,880
Let me quickly go down to that.

511
00:45:17,880 --> 00:45:23,880
We're not going to be looking at semi-supervised reinforcement learning, but since those terms are pretty important,

512
00:45:23,880 --> 00:45:26,880
I just wanted to mention it and give you just of what they mean.

513
00:45:30,880 --> 00:45:33,880
So this is unsupervised.

514
00:45:33,880 --> 00:45:36,880
This is semi-supervised.

515
00:45:36,880 --> 00:45:39,880
This is reinforcement learning.

516
00:45:39,880 --> 00:45:45,880
So there was this news a few years back where they tried to teach a robot to flip pancakes.

517
00:45:45,880 --> 00:45:48,880
And you can see that it's doing really bad at start.

518
00:45:48,880 --> 00:45:53,880
It's just, you know, trying to go all for it and having fun with it.

519
00:45:53,880 --> 00:45:55,880
So what happens in reinforcement learning?

520
00:45:55,880 --> 00:46:01,880
It is quite similar to how humans have goals and it's a very goal oriented learning.

521
00:46:01,880 --> 00:46:05,880
So given an environment, there are a set of actions you can take.

522
00:46:05,880 --> 00:46:08,880
Let's say, for example, you have an examination tomorrow.

523
00:46:08,880 --> 00:46:15,880
You can either go off to sleep and not really care about the examination or you can pull up an all nighter and, you know,

524
00:46:15,880 --> 00:46:17,880
try to do your best on the examination.

525
00:46:17,880 --> 00:46:19,880
So you have two options over here.

526
00:46:19,880 --> 00:46:25,880
Based on past performances, you see that, OK, I am able to manage the test, the exam.

527
00:46:25,880 --> 00:46:26,880
They're usually easy.

528
00:46:26,880 --> 00:46:28,880
I pay attention in class.

529
00:46:28,880 --> 00:46:34,880
Or you may say like, you may say that, you know, if I pull an all nighter, I'm going to really perform worse than I should

530
00:46:34,880 --> 00:46:36,880
because I won't remember anything.

531
00:46:36,880 --> 00:46:39,880
So you have two different options or two different actions you can take.

532
00:46:39,880 --> 00:46:44,880
And on your past performance, you understand if a particular action gave you a reward,

533
00:46:44,880 --> 00:46:49,880
like yes, the risk paid off where you can go off to sleep comfortably and still pass.

534
00:46:49,880 --> 00:46:54,880
Or no, if you do pull an all nighter, your performance is going to be worse than usual.

535
00:46:54,880 --> 00:46:55,880
So that's the penalty.

536
00:46:55,880 --> 00:47:01,880
So you kind of weigh the reward and the penalty using your past information or your past performance.

537
00:47:01,880 --> 00:47:04,880
And then you try to fine tune your learning later on.

538
00:47:04,880 --> 00:47:08,880
So this is what the robot flipping pancake does.

539
00:47:08,880 --> 00:47:11,880
See, it finally was able to do it correctly, right?

540
00:47:11,880 --> 00:47:18,880
Because after a lot of trials and errors and a lot of feedback being given to it saying that, OK, if I put a lot of force

541
00:47:18,880 --> 00:47:23,880
and I try to like, you know, really flip it high up in the air, it's probably not going to land correctly.

542
00:47:23,880 --> 00:47:28,880
But if I be really gentle and I just put a little bit of force, it's probably going to be correct.

543
00:47:28,880 --> 00:47:35,880
And those kind of that kind of feedback mechanism or that kind of reward penalty systems helps it learn what is the right way to do.

544
00:47:35,880 --> 00:47:37,880
And this was like just a trial error.

545
00:47:37,880 --> 00:47:44,880
There was no information really given to the robot where, you know, this is how you're supposed to flip a pancake.

546
00:47:44,880 --> 00:47:48,880
OK, so that was reinforcement learning that's often used in robots.

547
00:47:48,880 --> 00:47:56,880
There was another really cool link of Google had this deep learning system where it learned to play Atari video game.

548
00:48:02,880 --> 00:48:04,880
So I'm just going to run it in.

549
00:48:04,880 --> 00:48:14,880
So like they mentioned, there was no domain knowledge given.

550
00:48:14,880 --> 00:48:18,880
All it was told was you have to maximize the score that you see on the screen.

551
00:48:18,880 --> 00:48:19,880
That's it.

552
00:48:19,880 --> 00:48:27,880
So you can see it's not doing a great job because the ball keeps falling and it keeps losing lives.

553
00:48:27,880 --> 00:48:32,880
And then after I believe what was 10 minutes of training, it's doing a better job, right?

554
00:48:32,880 --> 00:48:36,880
It's being able to balance the ball and also trying to hit the blocks.

555
00:48:36,880 --> 00:48:45,880
So it realizes that digging a tunnel is the best way to do because it gives it some time to like hit the other blocks, yet not fall.

556
00:48:52,880 --> 00:48:55,880
So you can see it hit that tunnel over it created a tunnel over there, right?

557
00:48:55,880 --> 00:48:58,880
And that was the most optimized way to play the game.

558
00:48:58,880 --> 00:49:05,880
So pretty cool applications of reinforcement learning, but they involve a lot more knowledge.

559
00:49:05,880 --> 00:49:07,880
So we won't be dealing with that today.

560
00:49:10,880 --> 00:49:16,880
OK, shall I continue or would you like a five or 10 minute break?

561
00:49:20,880 --> 00:49:21,880
Could use a break.

562
00:49:21,880 --> 00:49:23,880
OK, five minutes or 10 minutes.

563
00:49:26,880 --> 00:49:27,880
OK, sure.

564
00:49:28,880 --> 00:49:29,880
Let's take a break.

565
00:49:41,880 --> 00:49:42,880
Hey, I'm Eshma.

566
00:49:42,880 --> 00:49:43,880
Nice to meet you.

567
00:49:43,880 --> 00:49:45,880
So I've been curious.

568
00:49:45,880 --> 00:49:50,880
I'm not from a data science background, but I'm really interested in the field.

569
00:49:50,880 --> 00:49:54,880
And you made a comment about like consulting with domain experts.

570
00:49:54,880 --> 00:50:06,880
And I'm wondering if there's like a trend in the field of people like from that domain sort of becoming data scientists or is it mostly like two separate roles that collaborate?

571
00:50:06,880 --> 00:50:07,880
There are both.

572
00:50:07,880 --> 00:50:10,880
Both of action scenarios where both of those happen.

573
00:50:10,880 --> 00:50:14,880
I think it really depends on the company or the department of the team you're working in.

574
00:50:14,880 --> 00:50:20,880
Like for my work, what we do is we are a central team of data scientists and then we keep changing, switching projects.

575
00:50:20,880 --> 00:50:23,880
So each of us will work on maybe a few months on one project, a few months on another project.

576
00:50:23,880 --> 00:50:38,880
But if you're working in, let's say, a company that's, for example, focused on the medicine domain, then you would probably try to have your existing employees in the skills of data science because you already have the background knowledge of the domain expertise.

577
00:50:38,880 --> 00:50:39,880
Right.

578
00:50:39,880 --> 00:50:44,880
You can just learn a few statistical concepts, learn a bit of programming or just use data science.

579
00:50:45,880 --> 00:50:46,880
Okay.

580
00:50:46,880 --> 00:50:47,880
Yeah. So I work for Boeing.

581
00:50:47,880 --> 00:50:59,880
And so we are involved in a project where we're basically like building tools to like try and get engineers to like figure out how to use data science.

582
00:50:59,880 --> 00:51:00,880
Okay.

583
00:51:00,880 --> 00:51:04,880
And so we've just started out, but it's proving a little difficult.

584
00:51:04,880 --> 00:51:05,880
It's kind of surprising.

585
00:51:05,880 --> 00:51:12,880
I think we tried, you know, like, for example, using Jupyter notebooks to display math that we know the people are familiar with.

586
00:51:12,880 --> 00:51:14,880
And they're like, that's code. I don't want to see that.

587
00:51:14,880 --> 00:51:16,880
Oh, wow.

588
00:51:16,880 --> 00:51:25,880
Oh, so by the way, I don't know if you're already familiar with, there are a few lines that you can write in this part of the notebook, which hides all the code.

589
00:51:25,880 --> 00:51:27,880
Well, the thing is we wanted to show them.

590
00:51:27,880 --> 00:51:28,880
Oh, okay.

591
00:51:28,880 --> 00:51:36,880
We were like trying to use a combination of like the markdown, the text equations with the code to try to get people to understand it.

592
00:51:36,880 --> 00:51:39,880
But apparently it's scary.

593
00:51:39,880 --> 00:51:44,880
Okay. I would say maybe just starting off with some sort of interactive virtualizations, get them comfortable with that.

594
00:51:44,880 --> 00:51:54,880
And then once they already know, like, okay, for example, this is the clustering algorithm or the classification algorithm, maybe just slowly start to put in a bit of code.

595
00:51:54,880 --> 00:51:56,880
But yeah, sounds pretty exciting.

596
00:51:56,880 --> 00:52:04,880
Yeah, it's pretty neat. I hope it starts to pick up some traction and people start to be less afraid.

597
00:52:04,880 --> 00:52:08,880
Cool. Thank you.

598
00:52:08,880 --> 00:52:10,880
Hey.

599
00:52:10,880 --> 00:52:23,880
So by all the experience with data science on this side, things that I've seen in, you know, in academics and in classes and stuff, how does this sort of sort of compare to the type of work you do every day?

600
00:52:23,880 --> 00:52:30,880
It's actually pretty similar, but like, you know, slightly simplified.

601
00:52:30,880 --> 00:52:34,880
I think at least one of the things that I noticed was huge differentiator.

602
00:52:34,880 --> 00:52:39,880
And I think from that is a, the toy data sets are really natural.

603
00:52:39,880 --> 00:52:43,880
You know what they mean. They're going to be similar to what we're working with.

604
00:52:43,880 --> 00:52:46,880
Right.

605
00:52:46,880 --> 00:52:50,880
You can't understand what the different columns mean.

606
00:52:50,880 --> 00:52:56,880
You don't know why there's like maybe 90% of goodness and how you're supposed to perform analysis.

607
00:52:56,880 --> 00:52:58,880
That's number one.

608
00:52:58,880 --> 00:53:00,880
It doesn't fit in your local as well.

609
00:53:00,880 --> 00:53:08,880
So you often have to use your data processing frameworks like Spark, Hadoop, Hive, all of that.

610
00:53:08,880 --> 00:53:16,880
And I think the third one is because you're working in the industry or you have specific deadlines, specific milestones to meet.

611
00:53:16,880 --> 00:53:21,880
Like in academics, it's, you know, like if you can improve it by one percentage point, that's great.

612
00:53:21,880 --> 00:53:23,880
Like you need to publish papers.

613
00:53:23,880 --> 00:53:28,880
But in the industry, it's more like, okay, this is our deadline.

614
00:53:28,880 --> 00:53:35,880
Our deadline is tomorrow. Is it good enough? Is it like 80%?

615
00:53:35,880 --> 00:53:40,880
And then like so the first thing you mentioned, the data isn't as clean as it's going to be.

616
00:53:40,880 --> 00:53:47,880
So I'm going to say, are there techniques that you have to deal with that are taught in academics?

617
00:53:47,880 --> 00:53:51,880
Or is it mainly just figured out in the situation?

618
00:53:51,880 --> 00:53:57,880
I think you're given like some sort of groundwork, some sort of like you're probably told like, okay, this is what you can do.

619
00:53:57,880 --> 00:54:02,880
This is what you can do. You don't know how exactly to do it or you know what does the data look like.

620
00:54:02,880 --> 00:54:10,880
And another thing that you often use in the real world is humans to label a lot of things.

621
00:54:10,880 --> 00:54:12,880
Okay.

622
00:54:12,880 --> 00:54:16,880
You do have that human label, but it's not going to be completely automated.

623
00:54:16,880 --> 00:54:18,880
You do have humans in the room for labeling the data.

624
00:54:18,880 --> 00:54:25,880
So you do have humans for evaluating what the machine is having to say before it makes sense to you.

625
00:54:25,880 --> 00:54:27,880
Okay.

626
00:54:27,880 --> 00:54:30,880
Yeah. What, did you go to school?

627
00:54:30,880 --> 00:54:32,880
No, I graduated.

628
00:55:00,880 --> 00:55:02,880
Okay.

629
00:55:30,880 --> 00:55:32,880
Okay.

630
00:56:00,880 --> 00:56:02,880
Okay.

631
00:56:30,880 --> 00:56:32,880
Okay.

632
00:57:00,880 --> 00:57:02,880
Okay.

633
00:57:30,880 --> 00:57:32,880
Okay.

634
00:58:00,880 --> 00:58:02,880
Okay.

635
00:58:30,880 --> 00:58:32,880
Okay.

636
00:59:00,880 --> 00:59:02,880
Okay.

637
00:59:30,880 --> 00:59:32,880
Okay.

638
01:00:00,880 --> 01:00:02,880
Okay.

639
01:00:30,880 --> 01:00:32,880
Okay.

640
01:01:00,880 --> 01:01:02,880
Okay.

641
01:01:30,880 --> 01:01:32,880
Okay.

642
01:02:00,880 --> 01:02:02,880
Okay.

643
01:02:30,880 --> 01:02:32,880
Okay.

644
01:02:32,880 --> 01:02:34,880
Okay.

645
01:02:50,880 --> 01:02:52,880
Okay, shall we begin?

646
01:02:52,880 --> 01:03:02,000
Okay, how's the pace so far?

647
01:03:02,000 --> 01:03:03,000
Is it okay?

648
01:03:03,000 --> 01:03:04,000
Is it too fast?

649
01:03:04,000 --> 01:03:05,000
Too slow?

650
01:03:05,000 --> 01:03:06,000
Okay.

651
01:03:06,000 --> 01:03:07,000
All right.

652
01:03:07,000 --> 01:03:12,000
So, yeah.

653
01:03:12,000 --> 01:03:14,800
Now we're going to get into model building.

654
01:03:14,800 --> 01:03:19,320
So we'll quickly see a few more slides just to understand the different concepts and then

655
01:03:19,640 --> 01:03:22,080
go back to coding.

656
01:03:22,080 --> 01:03:23,480
Okay.

657
01:03:23,480 --> 01:03:30,680
So, we've already covered about feature engineering where we start to select the important features,

658
01:03:30,680 --> 01:03:35,800
maybe construct a few useful new ones and then divide the data set into training and

659
01:03:35,800 --> 01:03:37,640
test sets.

660
01:03:37,640 --> 01:03:42,080
Create the machine learning model where it could be supervised, which is classification

661
01:03:42,080 --> 01:03:45,440
or regression, where you already have labels associated with the data.

662
01:03:45,680 --> 01:03:49,480
Or it could be unsupervised where there are no labels, but you're just trying to understand

663
01:03:49,480 --> 01:03:51,440
the structure of the data.

664
01:03:51,440 --> 01:03:57,640
You tune the model parameters, just some models, the parameters, some input values associated

665
01:03:57,640 --> 01:03:59,920
with the way the model works.

666
01:03:59,920 --> 01:04:03,280
I'm often asked how exactly do we go about tuning them.

667
01:04:03,280 --> 01:04:07,960
Honestly, a lot of it is trial and error.

668
01:04:07,960 --> 01:04:11,200
And then you've trained the model, monitor against overfitting.

669
01:04:12,160 --> 01:04:16,440
Evaluate the model and unseen data where you're trying to see how well it performs.

670
01:04:16,440 --> 01:04:18,040
And like I mentioned, it could be an iterative process.

671
01:04:18,040 --> 01:04:23,040
If you're not happy with the model performance, you can either go ahead and change the algorithm

672
01:04:23,040 --> 01:04:26,840
that you're using in your models or you can go back and try to use a different subset

673
01:04:26,840 --> 01:04:27,840
of features.

674
01:04:27,840 --> 01:04:34,080
And you can also have an ensemble of models where you're trying to combine a lot of different

675
01:04:34,080 --> 01:04:40,920
types of models with each other and create this huge, bigger model.

676
01:04:41,920 --> 01:04:48,880
Let's say if we have an apple as our object or the data frame, its features would be things

677
01:04:48,880 --> 01:04:54,040
like color, type, shape, so on and so forth.

678
01:04:54,040 --> 01:04:56,920
We've already seen some examples of that.

679
01:04:56,920 --> 01:05:02,720
There's this XKCD comic which I find really relevant where the first person says, okay,

680
01:05:02,720 --> 01:05:03,720
I'm seeing this huge pile.

681
01:05:03,720 --> 01:05:06,480
Is this your machine learning system?

682
01:05:06,520 --> 01:05:11,120
And the second person goes, yeah, it's this huge big black box.

683
01:05:11,120 --> 01:05:17,000
It's just a lot of linear algebra and all of these fancy numbers and calculations.

684
01:05:17,000 --> 01:05:19,600
So you just pour in all of your data.

685
01:05:19,600 --> 01:05:23,200
And on the other side, you magically get all of the answers.

686
01:05:23,200 --> 01:05:26,160
And the first person goes, but how do you know if the answers are wrong?

687
01:05:26,160 --> 01:05:27,160
Like what do you do then?

688
01:05:27,160 --> 01:05:29,720
And the second person goes, you know what?

689
01:05:29,720 --> 01:05:34,560
Just start stirring the pile till they start looking right, which is pretty much what we

690
01:05:34,600 --> 01:05:41,360
do with tuning model parameters, trying model buildings, evaluating what features are good

691
01:05:41,360 --> 01:05:42,360
or not.

692
01:05:42,360 --> 01:05:47,320
So I guess my main objective behind all of this is saying that data science is a field

693
01:05:47,320 --> 01:05:51,240
that comes with a lot of uncertainty involved.

694
01:05:51,240 --> 01:05:56,000
And that's something that might seem a little odd at the start.

695
01:05:56,000 --> 01:06:02,360
Lot of questions you might have in your mind, things like how much data is enough?

696
01:06:02,360 --> 01:06:05,200
How do you know if the quality of data is good?

697
01:06:05,200 --> 01:06:09,400
How do you know if the quality of your model or the performance is good enough or not?

698
01:06:09,400 --> 01:06:11,760
And there's one constant answer to this.

699
01:06:11,760 --> 01:06:13,440
It depends.

700
01:06:13,440 --> 01:06:17,160
It depends on are you trying to build a production ready model?

701
01:06:17,160 --> 01:06:21,920
It depends on are you trying to detect rare type of cancer?

702
01:06:21,920 --> 01:06:26,880
Are you trying to detect maybe something a little more not a little less important?

703
01:06:26,880 --> 01:06:31,280
Maybe you're trying to give some sort of recommendations for music.

704
01:06:31,320 --> 01:06:34,760
It depends on how much data can you get more?

705
01:06:34,760 --> 01:06:38,680
If you can, if it's easy to get that kind of data, that amount of data, go ahead and

706
01:06:38,680 --> 01:06:39,680
do it.

707
01:06:39,680 --> 01:06:43,600
But if it's really going to be difficult, probably concentrate on trying to improve

708
01:06:43,600 --> 01:06:47,920
your model with different features, with different algorithms.

709
01:06:47,920 --> 01:06:51,920
So yeah, there's just a lot of question marks, but hopefully it's something you'll ease

710
01:06:51,920 --> 01:06:57,400
into and figure out some heuristics as time goes by.

711
01:06:57,400 --> 01:06:59,320
Okay.

712
01:06:59,320 --> 01:07:05,040
So we already covered this supervised, unsupervised, semi-supervised and reinforcement learning.

713
01:07:05,040 --> 01:07:06,360
Okay.

714
01:07:06,360 --> 01:07:11,960
Now let's get into what exactly are the different kinds of algorithms and what are the applications.

715
01:07:11,960 --> 01:07:15,320
So the first algorithm is classification.

716
01:07:15,320 --> 01:07:21,040
Very simple example, giving the computer an image and trying to let it guess if the image

717
01:07:21,040 --> 01:07:27,040
is that of a cat or a dog or maybe something completely else.

718
01:07:27,080 --> 01:07:33,080
A slightly more nuanced example of this would be given a patient's history, try to predict

719
01:07:33,080 --> 01:07:38,720
if this person is going to suffer from heart failure or not.

720
01:07:38,720 --> 01:07:42,440
So classification is a type of supervised learning since we have some sort of labels

721
01:07:42,440 --> 01:07:44,320
associated with the data, right?

722
01:07:44,320 --> 01:07:48,000
We know that, okay, this person suffered heart attack or we know that this image is that

723
01:07:48,000 --> 01:07:52,480
of a cat or a dog or something completely else.

724
01:07:52,480 --> 01:07:56,480
So it falls under supervised and the features, let's say for example, of trying to predict

725
01:07:56,560 --> 01:08:00,600
if heart failure is going to occur to a patient or not would be things like the patient's

726
01:08:00,600 --> 01:08:06,520
medical notes, the kind of environment, the lifestyle the patient leads, what is the history,

727
01:08:06,520 --> 01:08:13,520
is it something that runs in the family, is the patient taking the medications or not,

728
01:08:13,840 --> 01:08:17,760
those kind of things would be the features.

729
01:08:17,760 --> 01:08:22,800
The second type is called regression, which also falls under supervised learning, except

730
01:08:22,880 --> 01:08:29,880
how in classification you had categories, in regression you have numbers or values.

731
01:08:30,600 --> 01:08:37,600
So a very simple example of that would be you're trying to predict how much or how many.

732
01:08:39,600 --> 01:08:44,880
Perhaps you're trying to predict your company's next quarter's revenue or you're trying to

733
01:08:44,880 --> 01:08:50,720
predict future disease outbreaks where your features could be things about population

734
01:08:50,720 --> 01:08:57,280
health, if there's a lot of travel, international travel going on, like the recent outbreak

735
01:08:57,280 --> 01:08:58,640
of measles.

736
01:08:58,640 --> 01:09:04,680
So you can look at features saying is there a lot of travel from probably New York, I

737
01:09:04,680 --> 01:09:09,800
believe that's where it originated, people from there traveling or are there a lot of

738
01:09:09,800 --> 01:09:15,140
people who didn't receive vaccinations, climate change, contamination of food and water supplies

739
01:09:15,140 --> 01:09:17,240
for different questions.

740
01:09:17,240 --> 01:09:21,560
Regressions could also be used.

741
01:09:21,560 --> 01:09:26,160
So those two, regression and classification, fall in supervised learning.

742
01:09:26,160 --> 01:09:29,960
The next one is unsupervised learning and the most common example would be clustering.

743
01:09:29,960 --> 01:09:33,840
So let's say you have a bunch of objects and you're trying to create groups to understand

744
01:09:33,840 --> 01:09:36,760
how exactly these objects are organized.

745
01:09:36,760 --> 01:09:41,760
So you can see like triangle circles and crosses get separated.

746
01:09:42,760 --> 01:09:47,840
Another example would be trying to use clustering for customer segmentation.

747
01:09:47,840 --> 01:09:52,000
Like I mentioned for Netflix, for Spotify, for Amazon, you would have certain groups

748
01:09:52,000 --> 01:09:57,160
of customers which interact with your website or with your products in a similar manner

749
01:09:57,160 --> 01:09:58,840
or which would be interested in the same thing.

750
01:09:58,840 --> 01:10:02,960
So those are your clusters where you're trying to segment customers.

751
01:10:02,960 --> 01:10:07,800
Features would be things like what has been your purchase history or what have been the

752
01:10:07,800 --> 01:10:11,960
things you've clicked on, you've tried to see if you want to buy or not or added them

753
01:10:11,960 --> 01:10:12,960
to cart.

754
01:10:12,960 --> 01:10:14,480
What are your demographics like?

755
01:10:14,480 --> 01:10:19,160
For example, people in San Francisco in a certain age group might tend to buy something

756
01:10:19,160 --> 01:10:26,160
more than someone from let's say New York and on an activity like I mentioned.

757
01:10:27,320 --> 01:10:33,160
Another type is called anomaly detection where you're trying to see is this particular data

758
01:10:33,160 --> 01:10:35,480
point weird or not?

759
01:10:35,480 --> 01:10:39,760
Like in the case of credit card fraud detection, is the particular transaction fraudulent?

760
01:10:39,760 --> 01:10:43,080
Is it abnormal for that person involved?

761
01:10:43,080 --> 01:10:47,040
And features might be the amount you're spending per transaction.

762
01:10:47,040 --> 01:10:51,080
Let's say you only use a credit card for probably everything less than $50 and suddenly there's

763
01:10:51,080 --> 01:10:53,240
like a $10,000 charge on your credit card.

764
01:10:53,240 --> 01:10:55,400
It's probably going to get flagged.

765
01:10:55,400 --> 01:10:59,680
The transaction time, let's say there's a transaction that happens at like four in the

766
01:10:59,680 --> 01:11:04,560
morning that could be flagged as an anomaly.

767
01:11:04,560 --> 01:11:10,400
The merchant location, the code, like I mentioned, if it's something that you don't usually spend,

768
01:11:10,400 --> 01:11:12,760
use your credit card on and the transaction method.

769
01:11:12,760 --> 01:11:17,080
Let's say you use your credit card all the time online and not in person and then you

770
01:11:17,080 --> 01:11:23,120
suddenly use it in person, it might get flagged.

771
01:11:23,120 --> 01:11:27,760
So after we use the algorithms to create a model, we do want to evaluate how well the

772
01:11:27,760 --> 01:11:34,400
model's performing or we want to validate if our model is giving the right answers or not.

773
01:11:34,400 --> 01:11:40,000
So there can be cases where it's either false positive or false negative, which means that

774
01:11:40,000 --> 01:11:46,000
in the first case it's called type one error, which says something is falsely positive.

775
01:11:46,000 --> 01:11:50,120
So basically in the first picture you can see that's like an easy way to remember.

776
01:11:50,120 --> 01:11:53,560
The doctor's examining a man and saying that, oh, you're pregnant.

777
01:11:53,560 --> 01:11:56,920
So you're giving it positive, but that's actually a false positive.

778
01:11:56,920 --> 01:11:57,920
It should have been a negative.

779
01:11:57,920 --> 01:12:04,040
And the type two error is the converse, which is a false negative, where this doctor is

780
01:12:04,040 --> 01:12:09,560
tracking a lady patient and she's clearly pregnant, well, in this case, and then the

781
01:12:09,560 --> 01:12:11,240
doctor goes, but you're not pregnant.

782
01:12:11,240 --> 01:12:18,280
So that's false negative, giving it, predicting it as negative when it in fact is positive.

783
01:12:18,280 --> 01:12:23,280
We look deeper into those, why exactly we use those and how they make sense.

784
01:12:23,280 --> 01:12:27,840
Some other metrics to consider are a very simple one, accuracy.

785
01:12:27,840 --> 01:12:31,800
How well are you predicting or how correct are your predictions?

786
01:12:31,800 --> 01:12:35,960
Precision and recall, we'll be looking at them again in the codes.

787
01:12:35,960 --> 01:12:40,120
F1 score, which is just a combination of precision and recall.

788
01:12:40,120 --> 01:12:44,960
So you look at the false positives, false negatives, true positives, true negatives.

789
01:12:44,960 --> 01:12:47,920
True positives, true negatives are what got correctly labeled.

790
01:12:47,920 --> 01:12:51,480
And you use them to calculate their precision and recall, like you can see in the example

791
01:12:51,480 --> 01:12:55,440
over there.

792
01:12:55,440 --> 01:12:58,720
And finally, after you have the results, you're happy with your model, you create some sort

793
01:12:58,720 --> 01:13:02,600
of visualizations to summarize your model's results.

794
01:13:02,600 --> 01:13:07,480
And there's another term that's another step that's come up a lot is data storytelling,

795
01:13:07,480 --> 01:13:11,960
where you don't just present your results, but you try to understand the whys or the

796
01:13:11,960 --> 01:13:16,520
reasoning behind why something is happening and try to give that to the stakeholders,

797
01:13:16,520 --> 01:13:21,000
ideally with a recommendation for a step that they could take, an action that they could

798
01:13:21,000 --> 01:13:22,360
take.

799
01:13:22,360 --> 01:13:24,800
And of course, you have to tie it back to the original question that you were trying

800
01:13:24,800 --> 01:13:26,880
to answer.

801
01:13:27,040 --> 01:13:32,040
Another comment that I find really relevant is this PhD student who is working on trying

802
01:13:32,040 --> 01:13:38,120
to get the data for three years, trying to interpret the data for two years, trying to

803
01:13:38,120 --> 01:13:41,880
have some sort of documentation model building for one and a half years.

804
01:13:41,880 --> 01:13:46,720
And finally, the number of slides that she presents is just one and everybody's like,

805
01:13:46,720 --> 01:13:49,280
seriously, that's all you did for all of these years.

806
01:13:49,280 --> 01:13:55,640
So yeah, that's why storytelling is important, because you need to explain in layman's terms

807
01:13:55,920 --> 01:13:57,480
what exactly was it that you did?

808
01:13:57,480 --> 01:13:58,840
Why was the question important?

809
01:13:58,840 --> 01:14:03,400
How did you go about finding the answers and what were the conclusions for it?

810
01:14:03,400 --> 01:14:08,400
Okay, let's go back to our Jupyter notebook.

811
01:14:14,400 --> 01:14:20,040
Okay, so now we'll be seeing a really specific example for supervised learning, specifically

812
01:14:20,040 --> 01:14:21,040
for classification.

813
01:14:21,040 --> 01:14:23,400
We're given a data set.

814
01:14:23,400 --> 01:14:25,200
Again it's a part of the SQL on library.

815
01:14:25,760 --> 01:14:29,400
Please go ahead and install SQL on if you haven't already.

816
01:14:29,400 --> 01:14:35,760
This data set is actually a list of characteristics that were derived from images.

817
01:14:35,760 --> 01:14:42,000
These images were cell nuclei from breast masses and a lot of information about the

818
01:14:42,000 --> 01:14:43,000
cell nuclei.

819
01:14:43,000 --> 01:14:48,000
So it's really medical information that wouldn't make sense to people outside of the industry.

820
01:14:48,000 --> 01:14:52,960
But we're going to use it for now and see how it works.

821
01:14:53,000 --> 01:14:58,160
So our question is that given some characteristics about a breast mass, about the cell nuclei,

822
01:14:58,160 --> 01:15:03,320
can we predict if the tumor is malignant or benign?

823
01:15:03,320 --> 01:15:04,800
So it's a classification problem, right?

824
01:15:04,800 --> 01:15:11,040
You're going to look at the data points and you're trying to predict if it is malignant,

825
01:15:11,040 --> 01:15:15,640
that is class A, or if it is benign, that is class B.

826
01:15:15,640 --> 01:15:19,320
So let's go ahead and see how we do that.

827
01:15:19,320 --> 01:15:22,100
Like I mentioned, SQL already has some inbuilt data sets.

828
01:15:22,100 --> 01:15:24,140
So this is one of them.

829
01:15:24,140 --> 01:15:29,180
We can go ahead and import it from SQL on data sets.

830
01:15:29,180 --> 01:15:32,140
You load the data in, let's say for example, raw data.

831
01:15:36,140 --> 01:15:42,140
Or let's actually make this tumor data.

832
01:15:42,180 --> 01:15:55,180
And remember the target over there is what forms are labeled, which says whether it's

833
01:15:55,180 --> 01:15:56,180
malignant.

834
01:15:56,180 --> 01:15:57,620
If it's malignant, it's one.

835
01:15:57,620 --> 01:16:01,260
And if it's benign, it's zero.

836
01:16:01,260 --> 01:16:09,100
And let's go ahead and run that.

837
01:16:09,100 --> 01:16:12,960
So this is what the data set looks like.

838
01:16:12,960 --> 01:16:18,700
The different features called radius, texture, parameter area, so characteristics for that

839
01:16:18,700 --> 01:16:22,440
particular cell mass.

840
01:16:22,440 --> 01:16:24,840
And finally you have the target, which is the label.

841
01:16:24,840 --> 01:16:30,540
So these are all zeroes, so they're all benign.

842
01:16:30,540 --> 01:16:34,980
So let's take a look at what were all of the features of the columns present in it.

843
01:16:35,860 --> 01:16:42,460
You can do that using the dot columns.

844
01:16:42,460 --> 01:16:45,620
And this is a list of all of the different features of the column names that are present.

845
01:16:45,620 --> 01:16:55,460
Mean radius, compactness, symmetry error, texture, and finally the label of cause.

846
01:16:55,460 --> 01:16:57,460
So now we have an idea of, yeah.

847
01:16:57,940 --> 01:17:01,940
Yeah, I did change the variable name.

848
01:17:07,940 --> 01:17:10,100
Okay.

849
01:17:10,100 --> 01:17:12,260
So now we know what the data set looks like.

850
01:17:12,260 --> 01:17:16,540
Let's try to perform some sort of exploration for the data.

851
01:17:16,540 --> 01:17:20,820
Like I mentioned, graphing or visualization is a huge step of this process.

852
01:17:20,820 --> 01:17:26,540
So let's go ahead and try to see the distribution of these two classes, the malignant and benign.

853
01:17:26,620 --> 01:17:27,620
Are they symmetric?

854
01:17:27,620 --> 01:17:29,340
Are they almost equal?

855
01:17:29,340 --> 01:17:32,500
Or are they completely imbalanced?

856
01:17:32,500 --> 01:17:36,100
And we'd be using matplotlib inline because we want the graph to show right after the

857
01:17:36,100 --> 01:17:37,100
cell output.

858
01:17:37,100 --> 01:17:43,500
We'd be using labels since that is the column name or that is the feature name that we're

859
01:17:43,500 --> 01:17:44,900
interested in.

860
01:17:44,900 --> 01:17:49,820
Value counts just tells you the frequency for that particular column.

861
01:17:49,820 --> 01:17:55,060
And then we want a pie chart to see the percentage distribution.

862
01:17:55,580 --> 01:17:57,580
So let's go ahead and run that.

863
01:18:01,580 --> 01:18:03,580
Okay.

864
01:18:03,580 --> 01:18:06,580
So it is actually the opposite.

865
01:18:06,580 --> 01:18:11,580
It has malignant as the majority, which is great because that is what we're trying to

866
01:18:11,580 --> 01:18:12,580
predict.

867
01:18:12,580 --> 01:18:19,580
And it has benign as the minority at slightly less than 40%.

868
01:18:20,100 --> 01:18:25,100
So it's not equal, but it's not terribly disproportionate either, which is good.

869
01:18:25,100 --> 01:18:28,420
Otherwise we would have to use the sampling techniques that I talked about, where you

870
01:18:28,420 --> 01:18:33,820
try to give extra weightage by oversampling the minority class, or you try to downplay

871
01:18:33,820 --> 01:18:40,820
the weightage of the majority class by downsampling it, that is removing some data points.

872
01:18:40,820 --> 01:18:43,500
Okay.

873
01:18:43,500 --> 01:18:49,140
So let's go ahead and break this huge data frame into two subsets, where the first one

874
01:18:49,140 --> 01:18:56,140
is all of the malignant data points and second one is all of the benign data points.

875
01:18:56,140 --> 01:19:03,140
And we're using our Pandas indexing and filtering procedure over here.

876
01:19:10,660 --> 01:19:15,660
So I didn't print out anything here, but it's very free to print it out.

877
01:19:15,660 --> 01:19:17,500
Okay.

878
01:19:17,500 --> 01:19:22,620
So now what we're going to do is, we already have these two different sub-datasets, where

879
01:19:22,620 --> 01:19:24,180
malignant and benign.

880
01:19:24,180 --> 01:19:30,180
Let's try to plot a few features in these datasets and see if there is any starking

881
01:19:30,180 --> 01:19:32,340
difference between these two.

882
01:19:32,340 --> 01:19:37,460
So it's going to be easy to see visually if the distributions is different for the two

883
01:19:37,460 --> 01:19:39,800
categories.

884
01:19:39,800 --> 01:19:43,220
So I'm just running two for loops over here.

885
01:19:43,260 --> 01:19:47,580
That goes over the different features or the different columns in our malignant and benign

886
01:19:47,580 --> 01:19:52,540
datasets, and it's trying to plot histograms and overlaying them one on top of each other

887
01:19:52,540 --> 01:19:55,540
so we can see the differences between them.

888
01:19:55,540 --> 01:20:00,540
So let's go ahead and run that.

889
01:20:00,540 --> 01:20:03,540
Okay, bins is not defined.

890
01:20:03,540 --> 01:20:08,540
Oh, because it's number of bins.

891
01:20:13,540 --> 01:20:16,540
Okay.

892
01:20:16,540 --> 01:20:23,540
So you can see this huge list of graphs.

893
01:20:43,540 --> 01:20:46,540
Let's try to go through them one by one.

894
01:20:46,540 --> 01:20:49,260
So the first feature under consideration is mean radians.

895
01:20:49,260 --> 01:20:52,260
You can see there's some difference in distribution.

896
01:20:52,260 --> 01:20:59,260
For malignant, the mean radius tends to be higher, almost around 75, 50, 75, and it tends

897
01:20:59,260 --> 01:21:00,260
to be lower for benign.

898
01:21:00,260 --> 01:21:04,980
Similarly, we can look at all of the other features and see there are some overlaps.

899
01:21:04,980 --> 01:21:10,780
So let's see if we can find any feature that might be a good indicator of distinguishing

900
01:21:10,980 --> 01:21:13,580
between the two types.

901
01:21:13,580 --> 01:21:18,580
Mean concavity, this could be a good indicator because the distribution's remarkably different.

902
01:21:18,580 --> 01:21:23,580
Let's see, another one.

903
01:21:23,580 --> 01:21:30,580
Oh, it could be worst concave points since almost everything less than 0.1 is malignant

904
01:21:30,740 --> 01:21:32,940
and greater than 0.1 tends to be benign.

905
01:21:32,940 --> 01:21:36,300
There's a very little overlap over here.

906
01:21:36,300 --> 01:21:40,620
So like I mentioned, data exploration is an initial investigation.

907
01:21:40,620 --> 01:21:46,380
It helps us create some sort of hypothesis, some sort of interesting things that we might

908
01:21:46,380 --> 01:21:47,620
look into.

909
01:21:47,620 --> 01:21:53,500
So I guess the hypothesis that we can agree on over here is that worst concave points

910
01:21:53,500 --> 01:21:58,820
might actually be an important feature, might be a distinguishing feature for trying to

911
01:21:58,820 --> 01:22:01,540
predict if something is malignant or benign.

912
01:22:01,540 --> 01:22:08,540
And then we'll try to verify it with our models, of course.

913
01:22:09,140 --> 01:22:14,140
Any questions so far?

914
01:22:14,140 --> 01:22:16,420
Okay.

915
01:22:16,420 --> 01:22:22,380
So before we start model building, we should do something that's called scaling the features.

916
01:22:22,380 --> 01:22:25,620
So all of these different numerical features are on different scales, right?

917
01:22:25,620 --> 01:22:28,900
Probably some of them are on 0 to 1, some of them are on 0 to 100 and whatnot.

918
01:22:28,900 --> 01:22:33,860
We don't want those numbers, like just because something is 100, we don't want it to get

919
01:22:33,860 --> 01:22:35,700
extra weightage, correct?

920
01:22:35,700 --> 01:22:39,340
So what we're going to do is we try to scale it, bring all of these features on a similar

921
01:22:39,340 --> 01:22:42,380
scale and then accordingly give the values.

922
01:22:42,380 --> 01:22:48,060
And the way we would do that is using a standard scalar.

923
01:22:48,060 --> 01:22:52,660
And then we're transforming the data over here, so let's go ahead and run that.

924
01:22:52,660 --> 01:22:57,200
So X is basically all of your column names except the last column.

925
01:22:57,200 --> 01:23:01,060
The last column is the one that has the label.

926
01:23:01,060 --> 01:23:08,060
And Y is just the label.

927
01:23:08,060 --> 01:23:09,060
Okay.

928
01:23:09,060 --> 01:23:16,300
So you can see it's a NumPy array with some numbers.

929
01:23:16,300 --> 01:23:17,300
It's okay.

930
01:23:17,300 --> 01:23:18,980
We don't really need to make sense of that.

931
01:23:18,980 --> 01:23:24,060
Let's just take it for granted that it's working the way it's supposed to.

932
01:23:24,060 --> 01:23:25,540
Okay.

933
01:23:25,540 --> 01:23:27,540
So now we go into the model building.

934
01:23:27,540 --> 01:23:28,540
Yeah?

935
01:23:28,540 --> 01:23:29,540
So how do you scale it?

936
01:23:29,540 --> 01:23:34,540
For example, if you're dealing with dry data and you want to know the transaction size

937
01:23:34,540 --> 01:23:38,540
of the column, you can always do it.

938
01:23:38,540 --> 01:23:40,460
No, it's not necessary to always do it.

939
01:23:40,460 --> 01:23:43,340
You need to look at the different features that are involved.

940
01:23:43,340 --> 01:23:49,940
And if they are on similar scales or the similar ranges, then you don't need to do it.

941
01:23:49,940 --> 01:23:55,740
In this case, if you look at the data, some of them are in points and some of them are

942
01:23:55,740 --> 01:23:56,740
in hundreds.

943
01:23:56,740 --> 01:23:59,740
So there's a lot of degree of variation.

944
01:23:59,740 --> 01:24:06,740
Yeah, it should be okay.

945
01:24:06,740 --> 01:24:08,740
Okay.

946
01:24:08,740 --> 01:24:13,980
So like we saw earlier, we need to divide it into training set and test set, where training

947
01:24:13,980 --> 01:24:18,420
set is what actually builds the model, helps it learn, and test set is where you evaluate

948
01:24:18,420 --> 01:24:21,940
the performance of the model and try to validate it.

949
01:24:21,940 --> 01:24:28,420
The common two common ratios that are used for the split is you either use a 70-30 split,

950
01:24:28,420 --> 01:24:33,940
that is 70 training 30 test, or use an 80-20 split.

951
01:24:33,940 --> 01:24:35,620
Okay.

952
01:24:35,620 --> 01:24:41,220
So this is really handy function called train test split in SQL on model selection.

953
01:24:41,220 --> 01:24:47,300
We just pass our X and Y datasets where, remember, X is all of our features and Y is just the

954
01:24:47,300 --> 01:24:49,580
label, the very last column.

955
01:24:49,580 --> 01:24:54,580
We see that test size is 20% of the data.

956
01:24:54,580 --> 01:25:04,740
So you can see that the training set is 455 and the test set has 114 rows, which is roughly

957
01:25:04,740 --> 01:25:07,980
about 80-20 split.

958
01:25:07,980 --> 01:25:10,180
Okay.

959
01:25:10,180 --> 01:25:11,900
So now comes algorithms.

960
01:25:11,900 --> 01:25:17,900
We're going to use decision tree classifier over here because it's one of the most intuitive

961
01:25:18,220 --> 01:25:20,580
and most interpretable models.

962
01:25:20,580 --> 01:25:22,940
Decision tree is pretty much how we also function, right?

963
01:25:22,940 --> 01:25:26,900
If you're feeling hungry, you would ideally go and eat something.

964
01:25:26,900 --> 01:25:29,660
And if you're feeling sleepy, you would ideally go off to sleep, right?

965
01:25:29,660 --> 01:25:35,100
So we have this decision structure, the decision tree in our head where, given the current

966
01:25:35,100 --> 01:25:39,540
situation, you would choose one action or one path over the other.

967
01:25:39,540 --> 01:25:41,900
So that's pretty much what this algorithm is going to do.

968
01:25:41,900 --> 01:25:44,180
Let's take a look at how it does that.

969
01:25:44,180 --> 01:25:50,580
So let's go ahead and from sklearn.tree call our decision tree classifier, which is what

970
01:25:50,580 --> 01:25:53,380
actually is going to create the model.

971
01:25:53,380 --> 01:25:57,940
Let's assign it to CLF classifier.

972
01:25:57,940 --> 01:26:03,180
And then all you have to do is on the model, that is the decision tree classifier, call

973
01:26:03,180 --> 01:26:07,060
the fit function and pass it to your training set.

974
01:26:07,060 --> 01:26:11,580
So your training X, that is all of the features except the label, and your training Y, which

975
01:26:11,580 --> 01:26:19,500
is the output or which is the target labels.

976
01:26:19,500 --> 01:26:23,220
So it's trained and it's given us some sort of an output.

977
01:26:23,220 --> 01:26:27,820
So this is just metadata about the decision tree classifier or about the model that you're

978
01:26:27,820 --> 01:26:33,420
trying to build, where it says that I don't want classes to be given any extra weight.

979
01:26:33,420 --> 01:26:37,460
Since they are almost similar in proportion, we are not going to do that.

980
01:26:37,700 --> 01:26:43,180
So the next one is Gini, which is a specific type of how to decide to split the nodes.

981
01:26:43,180 --> 01:26:45,340
We'll be looking into that.

982
01:26:45,340 --> 01:26:48,540
Max depth is where you're trying to control the tree that gets formed.

983
01:26:48,540 --> 01:26:53,220
If you want to place in limitations on the tree shouldn't go up to a certain beyond a

984
01:26:53,220 --> 01:26:55,540
certain depth.

985
01:26:55,540 --> 01:26:59,140
Similarly for features leaf nodes, you're just trying to set bounds or restrictions

986
01:26:59,140 --> 01:27:01,140
in it.

987
01:27:01,140 --> 01:27:04,140
Yeah, okay.

988
01:27:04,820 --> 01:27:11,860
So if you go into the documentation for sklearn, you would get a better idea of all the different

989
01:27:11,860 --> 01:27:14,860
parameters that are involved and what exactly they mean.

990
01:27:14,860 --> 01:27:20,860
We're not concerned with concern ourselves with them for now.

991
01:27:20,860 --> 01:27:22,460
Okay.

992
01:27:22,460 --> 01:27:27,180
So here we have a model that's been trained on our training data.

993
01:27:27,180 --> 01:27:33,140
What we're going to do next is since it's a decision tree, let's try to visualize the

994
01:27:33,140 --> 01:27:38,860
tree itself and see what features it's deeming as important and how is it exactly making

995
01:27:38,860 --> 01:27:43,660
the split between malignant and benign.

996
01:27:43,660 --> 01:27:49,140
So we use another library that's called pi.plus over here.

997
01:27:49,140 --> 01:27:56,580
This is just a bunch of syntax for having the classifier being an input for the graphing

998
01:27:56,580 --> 01:27:59,820
for the visualization.

999
01:27:59,820 --> 01:28:02,820
This is what the graph would look like.

1000
01:28:02,820 --> 01:28:03,820
Oops.

1001
01:28:03,820 --> 01:28:08,820
Data is not defined because I changed the name.

1002
01:28:14,820 --> 01:28:18,820
So you can see this is like a huge tree.

1003
01:28:18,820 --> 01:28:23,820
Let's see if we can, yeah, you're not able to see it, right?

1004
01:28:23,820 --> 01:28:26,820
Let's see if we can zoom in.

1005
01:28:26,820 --> 01:28:28,820
Otherwise, yeah, it's not working.

1006
01:28:28,820 --> 01:28:31,820
So I hope you can see it on your machines.

1007
01:28:31,820 --> 01:28:33,820
So let me read all the first ones.

1008
01:28:33,820 --> 01:28:34,820
Oh, yeah.

1009
01:28:34,820 --> 01:28:37,820
So another thing about you're looking at the colors, right?

1010
01:28:37,820 --> 01:28:41,820
So the colors, and there's a gradient associated with the color.

1011
01:28:41,820 --> 01:28:48,820
It's for what class forms the majority of samples in that particular node.

1012
01:28:48,820 --> 01:28:54,820
And the higher a node is at the root, the root is at the top, the more important that feature is

1013
01:28:54,820 --> 01:28:59,820
the more discriminatory that feature is that helps you distinguish between what's malignant

1014
01:28:59,820 --> 01:29:01,820
and what's benign.

1015
01:29:01,820 --> 01:29:08,820
So over here, you can see that the most important feature is worst concave points, where if

1016
01:29:08,820 --> 01:29:20,820
worst concave points is less than 0.4, it goes to the blue class, which is I think it's

1017
01:29:20,820 --> 01:29:22,820
for malignant or benign.

1018
01:29:22,820 --> 01:29:23,820
I'm not sure.

1019
01:29:23,820 --> 01:29:24,820
Let me check that.

1020
01:29:24,820 --> 01:29:27,820
And the opposite is the other class.

1021
01:29:27,820 --> 01:29:31,820
And you can see that there are samples written over there, which just tells how many data

1022
01:29:31,820 --> 01:29:33,820
points fit that criteria.

1023
01:29:33,820 --> 01:29:38,820
So all the way from the root of the tree to the node under consideration, those are the

1024
01:29:38,820 --> 01:29:41,820
samples that satisfy all of the criteria over there.

1025
01:29:41,820 --> 01:29:45,820
And then so on and so forth, depending on the features and the values, you keep getting

1026
01:29:45,820 --> 01:29:47,820
additional splits.

1027
01:29:52,820 --> 01:29:54,820
Okay, any questions so far?

1028
01:30:00,820 --> 01:30:04,820
Does the decision tree algorithm make sense?

1029
01:30:04,820 --> 01:30:08,820
So you're just trying to see all of the different features and looking at each of the individual

1030
01:30:08,820 --> 01:30:14,820
features, you see that, okay, if I consider just this feature, does this show any difference

1031
01:30:14,820 --> 01:30:16,820
for benign versus any difference for malignant?

1032
01:30:16,820 --> 01:30:18,820
How much of a difference does it show?

1033
01:30:18,820 --> 01:30:20,820
Okay, and you're creating the splits based on that.

1034
01:30:20,820 --> 01:30:24,820
And then you consider the next feature and so on and so forth, and then you finally have

1035
01:30:24,820 --> 01:30:26,820
the tree in hand.

1036
01:30:35,820 --> 01:30:38,820
You can have multiple classes for decision trees, yeah.

1037
01:30:38,820 --> 01:30:40,820
Okay.

1038
01:30:46,820 --> 01:30:54,820
Another algorithm that we are not seeing over here is logistic regression, which is a type

1039
01:30:54,820 --> 01:31:01,820
of regression, but we're using it for classification since it can handle with zero and one values.

1040
01:31:01,820 --> 01:31:06,820
If you would like to try it, you can just go ahead and import logistic regression from

1041
01:31:06,820 --> 01:31:10,820
sklearn.logistic or .linear, and then it's the same way.

1042
01:31:10,820 --> 01:31:15,820
You just change this over here, what algorithm you're calling, train the classifier the same

1043
01:31:15,820 --> 01:31:17,820
way, and try to see the output.

1044
01:31:17,820 --> 01:31:21,820
If you have time, I can come back to it at the end.

1045
01:31:21,820 --> 01:31:23,820
Okay, so now we trained our model.

1046
01:31:23,820 --> 01:31:29,820
The most natural step to do next would be test how good it's working, right?

1047
01:31:29,820 --> 01:31:34,820
So let's go and see the model validation part of this.

1048
01:31:36,820 --> 01:31:48,820
Okay, yeah.

1049
01:31:48,820 --> 01:31:54,820
So remember we talked about precision and recall, and we have the notion of false positive

1050
01:31:54,820 --> 01:31:56,820
and false negatives.

1051
01:31:56,820 --> 01:32:02,820
Precision is the fraction of information you got that is relevant.

1052
01:32:02,820 --> 01:32:07,820
So for our very particular example where we're trying to predict tumor or cancer, we're

1053
01:32:07,820 --> 01:32:11,820
trying to say how many of them actually have cancer.

1054
01:32:11,820 --> 01:32:15,820
And recall is similar but different.

1055
01:32:15,820 --> 01:32:20,820
It's a fraction of relevant information that was retrieved where you're trying to say that

1056
01:32:20,820 --> 01:32:27,820
of the people who actually have cancer or have the tumor, how many have we correctly detected?

1057
01:32:27,820 --> 01:32:32,820
So there's a fine difference between them, but precision is how many of our predictions

1058
01:32:32,820 --> 01:32:33,820
actually have cancer?

1059
01:32:33,820 --> 01:32:39,820
And recall is how many of the ones who actually have cancer have we predicted?

1060
01:32:39,820 --> 01:32:45,820
There's another thing called the classification report, which gives you a snapshot of the

1061
01:32:45,820 --> 01:32:47,820
false positives, the false negatives.

1062
01:32:47,820 --> 01:32:49,820
We'll see the different details for that.

1063
01:32:49,820 --> 01:32:54,820
So it's a good snapshot where you get an understanding of how well your model is doing.

1064
01:32:54,820 --> 01:32:59,820
And finally, you have something that's called as the confusion matrix, where you have the

1065
01:32:59,820 --> 01:33:04,820
predicted on one hand, predicted labels, and the actual labels on the other hand.

1066
01:33:04,820 --> 01:33:07,820
And if it's positive and you predicted as positive, great.

1067
01:33:07,820 --> 01:33:08,820
That's true positive.

1068
01:33:08,820 --> 01:33:10,820
Similarly, for negative, that's true negative.

1069
01:33:10,820 --> 01:33:16,820
But false positive is where it should have been negative, but you predicted as positive,

1070
01:33:16,820 --> 01:33:20,820
and false negative is just the opposite.

1071
01:33:20,820 --> 01:33:24,820
And the way to calculate precision is recall is using this formula, where you consider

1072
01:33:24,820 --> 01:33:28,820
the false positives and negatives in play.

1073
01:33:28,820 --> 01:33:30,820
Okay.

1074
01:33:30,820 --> 01:33:32,820
Yeah.

1075
01:33:50,820 --> 01:34:05,820
You would ideally go back and try to tune the model parameters and see how, because

1076
01:34:05,820 --> 01:34:10,820
that might help you change the importance of the features.

1077
01:34:10,820 --> 01:34:15,820
Or else you might also consider using a slightly different algorithm.

1078
01:34:15,820 --> 01:34:21,820
Because some algorithms work really well if the data is linearly separable, but some

1079
01:34:21,820 --> 01:34:25,820
of them are really good at detecting mixtures of the classes and seeing, you know, like,

1080
01:34:25,820 --> 01:34:28,820
okay, how can we differentiate amongst them?

1081
01:34:28,820 --> 01:34:30,820
Yeah.

1082
01:34:30,820 --> 01:34:31,820
Okay.

1083
01:34:31,820 --> 01:34:35,820
So like I mentioned, the most obvious metric to use is accuracy, where you're trying to

1084
01:34:35,820 --> 01:34:40,820
understand how many were predicted correctly, whether they were false, whether they were

1085
01:34:40,820 --> 01:34:43,820
true, whether they were benign, or whether they were malignant.

1086
01:34:43,820 --> 01:34:47,820
And then finally we have the classification report being printed over here.

1087
01:34:47,820 --> 01:34:50,820
So let's take a look at what that looks like.

1088
01:34:50,820 --> 01:34:55,820
So it gives us an accuracy of 92%, which is great, right?

1089
01:34:55,820 --> 01:34:56,820
It's in the 90s.

1090
01:34:56,820 --> 01:34:57,820
I think that's good.

1091
01:34:57,820 --> 01:35:00,820
Let's look at the precision recall scores.

1092
01:35:00,820 --> 01:35:02,820
So that's for each of the classes.

1093
01:35:02,820 --> 01:35:08,820
For the benign class, the precision is 0.85 and recall is 0.95.

1094
01:35:08,820 --> 01:35:12,820
And for the malignant class, the recall is slightly lower.

1095
01:35:12,820 --> 01:35:17,820
So it depends on a specific use case if you're happy with those numbers or not.

1096
01:35:17,820 --> 01:35:21,820
F1 score is just the harmonic mean of the precision and recall.

1097
01:35:21,820 --> 01:35:26,820
Support is just the number of instances or number of classes in the testing set that

1098
01:35:26,820 --> 01:35:28,820
satisfy the criteria.

1099
01:35:28,820 --> 01:35:33,820
So this is for the benign cases and this is for the malignant cases.

1100
01:35:33,820 --> 01:35:37,820
Some more averages statistics about this.

1101
01:35:37,820 --> 01:35:39,820
Okay.

1102
01:35:39,820 --> 01:35:43,820
So oftentimes, I have a question for you.

1103
01:35:43,820 --> 01:35:51,820
Do you think false positives and false negatives should be treated the same or not?

1104
01:35:51,820 --> 01:35:52,820
Correct, yeah.

1105
01:35:52,820 --> 01:35:56,820
Like I mentioned, right, the answer, if you're not sure of what to answer, just say it depends

1106
01:35:56,820 --> 01:36:00,820
and you are going to be right 99% of the time.

1107
01:36:00,820 --> 01:36:01,820
Okay.

1108
01:36:01,820 --> 01:36:05,820
So let's try to give a bit more context to this.

1109
01:36:05,820 --> 01:36:10,820
Let's say if a person does indeed have cancer and you're saying that person that, no, you

1110
01:36:10,820 --> 01:36:12,820
are in the clear you don't have cancer.

1111
01:36:12,820 --> 01:36:17,820
Is that worse versus a person that does not have cancer but you're telling that person

1112
01:36:17,820 --> 01:36:20,820
does have cancer, right?

1113
01:36:20,820 --> 01:36:25,820
I mean, both situations are really bad, which is where the whole ethics in data science

1114
01:36:25,820 --> 01:36:27,820
and AI comes into play.

1115
01:36:27,820 --> 01:36:34,820
But you would ideally want the false, let's see, what would you want?

1116
01:36:34,820 --> 01:36:39,820
You would want that a person who does have cancer to be correctly detected, right, before

1117
01:36:39,820 --> 01:36:41,820
it's too late.

1118
01:36:41,820 --> 01:36:44,820
So there's this notion of asymmetric penalty.

1119
01:36:44,820 --> 01:36:51,820
Similarly, there's been this huge debate about how in airports you're screened and you're

1120
01:36:51,820 --> 01:36:52,820
questioned a lot.

1121
01:36:52,820 --> 01:37:00,820
So if a person who is not a terrorist is questioned and interrogated, although it's not great,

1122
01:37:00,820 --> 01:37:08,820
it's not good, but that is okay to do compared to having a terrorist actually escape, right?

1123
01:37:08,820 --> 01:37:12,820
So there's this notion of asymmetric penalty involved.

1124
01:37:12,820 --> 01:37:13,820
Okay.

1125
01:37:13,820 --> 01:37:21,820
So we looked at the precision and recall scores and they are probably in the high 80s and

1126
01:37:21,820 --> 01:37:23,820
90s, which is good.

1127
01:37:23,820 --> 01:37:28,820
What can happen, like I mentioned, if you're in this case, we had fairly balanced classes,

1128
01:37:28,820 --> 01:37:29,820
which is good.

1129
01:37:29,820 --> 01:37:34,820
What can happen in imbalanced cases, imbalanced classes, let's say for instance, you have

1130
01:37:34,820 --> 01:37:40,820
90% of the data where it is benign and 10% where it's malignant, okay?

1131
01:37:40,820 --> 01:37:50,820
And let's say if I were to create a model that just randomly spits out, everything is benign.

1132
01:37:50,820 --> 01:37:53,820
It would be correct 90% of the time, right?

1133
01:37:53,820 --> 01:37:56,820
Because 90% of the data is benign.

1134
01:37:56,820 --> 01:38:02,820
So that is the instance where, which this is the instance of overfitting happening,

1135
01:38:02,820 --> 01:38:08,820
where what you're trying to do is you fit your model so well on the data that it's going

1136
01:38:08,820 --> 01:38:12,820
to give you amazing accuracies, but it's not going to be generalized.

1137
01:38:12,820 --> 01:38:16,820
So if you have a completely different set of data points coming in, it's going to do

1138
01:38:16,820 --> 01:38:18,820
really bad at that.

1139
01:38:18,820 --> 01:38:24,820
An example of this was there were scientists that came up with this computer vision algorithm

1140
01:38:24,820 --> 01:38:29,820
to look at images and predict huskies, and they got these amazing accuracies of like

1141
01:38:29,820 --> 01:38:33,820
90, 95%, and they presented it in a conference.

1142
01:38:33,820 --> 01:38:40,820
And it turns out what they actually built was not a model to predict huskies, but a

1143
01:38:40,820 --> 01:38:43,820
model to predict images of snow.

1144
01:38:43,820 --> 01:38:48,820
Because all of the training examples that they gave were huskies with a background of

1145
01:38:48,820 --> 01:38:49,820
snow.

1146
01:38:50,820 --> 01:38:54,820
So the model became really good at predicting snow, and they were really happy with the

1147
01:38:54,820 --> 01:38:57,820
accuracy because, hey, the data set has just snow.

1148
01:38:57,820 --> 01:39:02,820
And when the model was given pictures of huskies without snow, it failed.

1149
01:39:02,820 --> 01:39:05,820
So this is a classic example of overfitting.

1150
01:39:05,820 --> 01:39:10,820
And this whole debate about how there's not enough diversity as far as training set examples

1151
01:39:10,820 --> 01:39:17,820
are concerned and how there are a lot of racial algorithms being used, it's not that the algorithm

1152
01:39:17,820 --> 01:39:18,820
is racist on its own.

1153
01:39:18,820 --> 01:39:22,820
It's because you give garbage and you're going to get garbage out, right?

1154
01:39:22,820 --> 01:39:27,820
So if your data is not representative, your data is not varied.

1155
01:39:27,820 --> 01:39:33,820
Like there was this instance of, I believe, all white teams were working on this, and

1156
01:39:33,820 --> 01:39:39,820
they failed to test out the model, the face recognition model on people with darker skin

1157
01:39:39,820 --> 01:39:40,820
colors.

1158
01:39:40,820 --> 01:39:47,820
And this is also an object detection model, and it actually was very racist, and it detected

1159
01:39:47,820 --> 01:39:50,820
people with darker skins as gorillas.

1160
01:39:50,820 --> 01:39:52,820
And this was by Google.

1161
01:39:52,820 --> 01:39:59,820
So if a company with seemingly infinite resources can do something stupid like this, imagine

1162
01:39:59,820 --> 01:40:03,820
how careful we have to be as individuals and smaller companies.

1163
01:40:03,820 --> 01:40:08,820
So basically, I just wanted to point out that it's really important for our data set to

1164
01:40:08,820 --> 01:40:14,820
be diverse and representative, especially where we have these kind of machine learning

1165
01:40:14,820 --> 01:40:22,820
algorithms taking judgments on really serious issues, like who to grant bail to, who to

1166
01:40:22,820 --> 01:40:27,820
arrest, who is more likely to commit a crime again, who is not.

1167
01:40:27,820 --> 01:40:33,820
And these data sets are often skewed against racially diverse people, because that's the

1168
01:40:33,820 --> 01:40:35,820
way the data has been given.

1169
01:40:35,820 --> 01:40:42,820
And that's the way data in the past has been handled, that they've not been granted bail.

1170
01:40:42,820 --> 01:40:47,820
So the model is going to learn that from the biases in the humans.

1171
01:40:47,820 --> 01:40:48,820
OK.

1172
01:40:50,820 --> 01:40:51,820
All right.

1173
01:40:51,820 --> 01:40:52,820
So now we have the models.

1174
01:40:52,820 --> 01:40:55,820
It's 92% accuracy, and the precisions and recalls look good.

1175
01:40:55,820 --> 01:40:58,820
So we know that we have not overfitted our model.

1176
01:40:58,820 --> 01:41:00,820
We have trained it, and it's a generalized model.

1177
01:41:00,820 --> 01:41:01,820
That's great.

1178
01:41:01,820 --> 01:41:04,820
Let's go on to visualizing the data.

1179
01:41:04,820 --> 01:41:08,820
So I remember after Matplotlib, I mentioned this under the package called C-Born, which

1180
01:41:08,820 --> 01:41:09,820
is built on Matplotlib.

1181
01:41:09,820 --> 01:41:13,820
So just consider it as an advanced step of Matplotlib.

1182
01:41:13,820 --> 01:41:18,820
And let's go ahead and try to visualize the confusion matrix in this.

1183
01:41:18,820 --> 01:41:26,820
And the way we would do is we would pass the confusion matrix to a heat map for C-Born,

1184
01:41:26,820 --> 01:41:31,820
and then we're trying to say, let's look at the actual and predicted classes.

1185
01:41:31,820 --> 01:41:34,820
So this is what a confusion matrix looks like.

1186
01:41:34,820 --> 01:41:38,820
Your x-axis is the predicted classes, and your y-axis is the actual classes.

1187
01:41:38,820 --> 01:41:43,820
So it's doing a great job of true positives and true negatives.

1188
01:41:43,820 --> 01:41:48,820
And it's doing not so bad, because it's just single digits, fours, and sevens on false

1189
01:41:48,820 --> 01:41:52,820
positives and false negatives, which is OK.

1190
01:41:52,820 --> 01:41:57,820
So this is just a visualization to look at what we were seeing in the classification

1191
01:41:57,820 --> 01:41:59,820
report and the confusion matrix.

1192
01:42:01,820 --> 01:42:03,820
And then, like I mentioned, data storytelling.

1193
01:42:03,820 --> 01:42:04,820
You tell a story with data.

1194
01:42:04,820 --> 01:42:06,820
You try to explain the why's.

1195
01:42:06,820 --> 01:42:11,820
And the final conclusion you're saying is that the current model is able to predict

1196
01:42:11,820 --> 01:42:15,820
malignant or benign masses with, it should be, 92% accuracy over here.

1197
01:42:15,820 --> 01:42:16,820
Yeah.

1198
01:42:19,820 --> 01:42:20,820
OK.

1199
01:42:20,820 --> 01:42:25,820
Also, if you keep running the model again and again, and you don't have a random seed

1200
01:42:25,820 --> 01:42:29,820
set, it's going to give you different accuracies, because the way the splitting happens is

1201
01:42:29,820 --> 01:42:30,820
random, right?

1202
01:42:30,820 --> 01:42:34,820
So the data points in the training and test set are going to keep changing, and that's

1203
01:42:34,820 --> 01:42:37,820
where the accuracy is going to slightly lower or increase.

1204
01:42:38,820 --> 01:42:43,820
Another thing that I have not mentioned here, but I'll link a resource to, is something

1205
01:42:43,820 --> 01:42:46,820
that's called as k-fold cross-validation.

1206
01:42:46,820 --> 01:42:53,820
So k-fold cross-validation just means, like, how in this case, we're just dividing the

1207
01:42:53,820 --> 01:42:56,820
data set into training and testing once, right?

1208
01:42:56,820 --> 01:43:00,820
So we could get really lucky with the way the split is happening, and we could get extremely

1209
01:43:00,820 --> 01:43:04,820
high accuracies, or we could get unlucky and get really low accuracies.

1210
01:43:04,820 --> 01:43:06,820
It's all random, so we don't know.

1211
01:43:06,820 --> 01:43:10,820
So the way to counteract this is you keep doing this iteratively.

1212
01:43:11,820 --> 01:43:15,820
So that's called k-fold, because you'll have k, let's say, if your k is fair, then you'll

1213
01:43:15,820 --> 01:43:17,820
have five-fold cross-validation.

1214
01:43:17,820 --> 01:43:23,820
So what happens in that case is, let's say, if this is your entire data set, so your first

1215
01:43:23,820 --> 01:43:28,820
one-fifth would become the test set in the first iteration, and the rest would become

1216
01:43:28,820 --> 01:43:29,820
your training set.

1217
01:43:29,820 --> 01:43:34,820
In the second iteration, your second one-fifth becomes the test and the others training.

1218
01:43:34,820 --> 01:43:39,820
So that way, you have each portion becoming the test once and becoming the training four

1219
01:43:39,820 --> 01:43:40,820
times.

1220
01:43:40,820 --> 01:43:44,820
So that way, it helps you create more of a generalized model and have generalized performances

1221
01:43:44,820 --> 01:43:49,820
that are not going to give you unexpected results when you finally test it out on unseen

1222
01:43:49,820 --> 01:43:50,820
data.

1223
01:43:53,820 --> 01:43:58,820
Okay, any questions about that, about classification?

1224
01:44:08,820 --> 01:44:09,820
Okay.

1225
01:44:10,820 --> 01:44:11,820
Yeah, sure.

1226
01:44:12,820 --> 01:44:18,820
So in the end, you're predicting whether or not the tumor is malignant or not.

1227
01:44:18,820 --> 01:44:19,820
Right.

1228
01:44:19,820 --> 01:44:20,820
Right.

1229
01:44:49,820 --> 01:44:58,820
It was a combination of all of the features with different weightages.

1230
01:44:58,820 --> 01:45:00,820
So let me just go back to the tree.

1231
01:45:00,820 --> 01:45:02,820
And thank you for bringing it up.

1232
01:45:02,820 --> 01:45:03,820
I actually forgot to mention that.

1233
01:45:03,820 --> 01:45:07,820
So I believe what I mentioned was the convexity or the concavity.

1234
01:45:07,820 --> 01:45:10,820
Let's go back and see.

1235
01:45:10,820 --> 01:45:11,820
Okay.

1236
01:45:11,820 --> 01:45:14,820
This is a graph.

1237
01:45:14,820 --> 01:45:26,820
Yeah, I believe it was the worst concave points, correct?

1238
01:45:26,820 --> 01:45:33,820
So let's go and see what is the importance that's been given to that.

1239
01:45:33,820 --> 01:45:38,820
So worst concave points is up over here.

1240
01:45:38,820 --> 01:45:39,820
So it's not the first.

1241
01:45:39,820 --> 01:45:40,820
It's not the second.

1242
01:45:40,820 --> 01:45:41,820
It's not the third.

1243
01:45:41,820 --> 01:45:43,820
But about the fourth most important feature.

1244
01:45:43,820 --> 01:45:49,820
So it's still pretty high up with a dataset of 29, 30 features is the fourth most important.

1245
01:45:49,820 --> 01:45:51,820
So it's still doing a pretty good job.

1246
01:45:51,820 --> 01:45:57,820
But if you open close inspection of this tree, you can see these are the one at the top is

1247
01:45:57,820 --> 01:45:59,820
the most important feature.

1248
01:45:59,820 --> 01:46:03,820
And then slowly as you go down bottom, it decreases in importance.

1249
01:46:03,820 --> 01:46:06,820
So it's a combination of all of the features involved.

1250
01:46:06,820 --> 01:46:09,820
You can go ahead and also try to see how well it does on one feature.

1251
01:46:09,820 --> 01:46:12,820
It might actually just do great on one feature.

1252
01:46:12,820 --> 01:46:16,820
But if you have more data and more features, it might do slightly better.

1253
01:46:16,820 --> 01:46:22,820
Oh, yeah, it is also at the top.

1254
01:46:22,820 --> 01:46:24,820
Thank you for pointing that out.

1255
01:46:24,820 --> 01:46:30,820
Yeah, so it's also like, yeah, it depends on it's trying to like really define the intervals.

1256
01:46:30,820 --> 01:46:32,820
So the first one is the biggest split.

1257
01:46:32,820 --> 01:46:36,820
And then the second one is the slightly smaller split that's dependent on other features.

1258
01:46:36,820 --> 01:46:38,820
Yeah, thank you.

1259
01:46:38,820 --> 01:46:40,820
Yeah.

1260
01:46:40,820 --> 01:46:46,820
I guess typically in the actual output of the model in terms of the interface of what's

1261
01:46:46,820 --> 01:46:54,820
given to the medical professional race, sort of extrapolating on this pretty far, are you,

1262
01:46:54,820 --> 01:47:01,820
I guess you kind of think of each one of these sort of top level leads as effectively a justification

1263
01:47:01,820 --> 01:47:05,820
for like this is a reason why the model is this way.

1264
01:47:05,820 --> 01:47:10,820
So in the output of the model, are those justifications typically given out as well?

1265
01:47:10,820 --> 01:47:19,820
So saying like, I think this is a malignant tumor because of these five sets of things that led me to this conclusion.

1266
01:47:19,820 --> 01:47:20,820
No, unfortunately not.

1267
01:47:20,820 --> 01:47:22,820
But if that were the case, then we wouldn't have any role to play.

1268
01:47:22,820 --> 01:47:25,820
Like we would just run and automate that.

1269
01:47:25,820 --> 01:47:28,820
But this is why in decision tree it's helpful to visualize this because as humans we can

1270
01:47:28,820 --> 01:47:31,820
understand that, OK, these features are pretty important.

1271
01:47:31,820 --> 01:47:34,820
These features are, you know, a little less important.

1272
01:47:34,820 --> 01:47:40,820
There's a slightly related technique that you can use which is called as feature importance,

1273
01:47:40,820 --> 01:47:46,820
which is where it does give you as an output, like this is the different weightages or the

1274
01:47:46,820 --> 01:47:48,820
different coefficients for the features.

1275
01:47:48,820 --> 01:47:54,820
But oftentimes it's not as interpretable or it might not even be absolutely correct.

1276
01:47:54,820 --> 01:48:02,820
I guess I'm also thinking about the medical professional who might be wary about trusting the model.

1277
01:48:03,820 --> 01:48:04,820
Right, right.

1278
01:48:04,820 --> 01:48:09,820
Which is why there's this whole debate on I'm not sure if you're aware of, but IBM Watson came out with

1279
01:48:09,820 --> 01:48:15,820
this oncology tool that helps professionals or medical professionals understand if, you know,

1280
01:48:15,820 --> 01:48:19,820
it is a particular type of cancer, what are the different, what are the different.

1281
01:48:19,820 --> 01:48:29,820
So basically what it does is given a patient's history and medical case, it gives you the top 10 approaches

1282
01:48:29,820 --> 01:48:32,820
or methodologies that might be successful.

1283
01:48:32,820 --> 01:48:38,820
And then it says that based on, you know, my review and my reading of these millions of papers in the

1284
01:48:38,820 --> 01:48:41,820
database, the top two are most likely to work.

1285
01:48:41,820 --> 01:48:44,820
The bottom two are probably like the worst, do not try them.

1286
01:48:44,820 --> 01:48:47,820
And the middle ones are like, you know, they might work, they might not work.

1287
01:48:47,820 --> 01:48:49,820
It really depends on the particular case.

1288
01:48:49,820 --> 01:48:55,820
And doctors are very happy because this is something that's pretty revolutionary in the medical field, right?

1289
01:48:55,820 --> 01:49:02,820
You have a system that can in a matter of minutes, if not seconds, read through millions of research papers

1290
01:49:02,820 --> 01:49:08,820
and try to find out what are the new approaches, what are the new, you know, remedies that are coming up that

1291
01:49:08,820 --> 01:49:09,820
might work well.

1292
01:49:09,820 --> 01:49:17,820
But the problem was that the model interpretability what you're talking about, it wasn't able to justify

1293
01:49:17,820 --> 01:49:23,820
why it selected a particular technique or remedy for that particular patient, which is where the trust

1294
01:49:23,820 --> 01:49:24,820
issue comes in, right?

1295
01:49:24,820 --> 01:49:31,820
Would you rather trust, you know, this huge, literally this huge pile of linear algebra, or would you trust

1296
01:49:31,820 --> 01:49:38,820
someone who has been maybe for 10 years of grad school, 20 years of experience in the field and who has

1297
01:49:38,820 --> 01:49:43,820
actually seen what happens, you know, like as a human?

1298
01:49:43,820 --> 01:49:49,820
So that does come into play a lot where the interpretability and the explanation of models is important,

1299
01:49:49,820 --> 01:49:55,820
which is why models or algorithms like the decision tree, they're pretty explainable, right?

1300
01:49:55,820 --> 01:50:00,820
You can see the snapshot of the tree and you can understand that, okay, this was rated as important and

1301
01:50:00,820 --> 01:50:02,820
because of this, the split happened like that.

1302
01:50:02,820 --> 01:50:08,820
But in slightly more complex models, especially in deep learning models, where you give it some input and

1303
01:50:08,820 --> 01:50:12,820
you get some output out, there is not much interpretability.

1304
01:50:12,820 --> 01:50:18,820
You don't know what exactly is happening in the black box, which is where all of these fears of, you know,

1305
01:50:18,820 --> 01:50:20,820
machines might just take over the world.

1306
01:50:20,820 --> 01:50:28,820
There was this experiment by Facebook a few years back where two programs were chatting with each other.

1307
01:50:28,820 --> 01:50:34,820
And this was a deep learning one because they were trying to look at, trying to make them speak languages

1308
01:50:34,820 --> 01:50:37,820
like humans and interact the way humans do.

1309
01:50:37,820 --> 01:50:44,820
And what happened was at the end of it, they started spewing garbage out.

1310
01:50:44,820 --> 01:50:50,820
So it would just be like, I, I, I, this, this, this, this, like a lot of repetitions and words and sentences

1311
01:50:50,820 --> 01:50:52,820
that didn't make any sense.

1312
01:50:52,820 --> 01:50:58,820
And the Facebook researchers stopped the experiment because clearly the objective, the outcome was a failure.

1313
01:50:58,820 --> 01:51:07,820
And in newspapers, it was this yellow journalism that was completely centralized, which said that

1314
01:51:07,820 --> 01:51:12,820
two Facebook programs were caught talking to each other in a language that nobody could understand.

1315
01:51:12,820 --> 01:51:18,820
They invented their own language and, oh my God, it's the, you know, humanity is at the edge of extinction.

1316
01:51:18,820 --> 01:51:19,820
This is what's going to happen.

1317
01:51:19,820 --> 01:51:21,820
Like, no, that is not what happened.

1318
01:51:21,820 --> 01:51:28,820
But because it's not interpretable, because we can't understand what's going on, it creates, it creates this atmosphere of fear,

1319
01:51:28,820 --> 01:51:33,820
which is also there in like so many other AI applications right now.

1320
01:51:33,820 --> 01:51:36,820
But yeah, that was that.

1321
01:51:36,820 --> 01:51:42,820
Okay. So we have about a little over an hour more.

1322
01:51:42,820 --> 01:51:46,820
Would you like another break or should I continue?

1323
01:51:46,820 --> 01:51:50,820
Who would want another break?

1324
01:51:50,820 --> 01:51:51,820
Okay. Everyone seems pretty good.

1325
01:51:51,820 --> 01:51:52,820
Okay, cool.

1326
01:51:52,820 --> 01:51:54,820
So we have two options.

1327
01:51:54,820 --> 01:51:57,820
Oh my God, I misspelled regression.

1328
01:51:57,820 --> 01:51:58,820
We have two options.

1329
01:51:58,820 --> 01:52:05,820
We can look at another supervised learning problem, but regression, where remember we are trying to predict

1330
01:52:05,820 --> 01:52:06,820
numbers or values.

1331
01:52:06,820 --> 01:52:10,820
You're like, for example, you're trying to predict your next quarter's revenue.

1332
01:52:10,820 --> 01:52:13,820
Or we can look at an example of unsupervised learning.

1333
01:52:13,820 --> 01:52:18,820
What would you like to take a look at?

1334
01:52:18,820 --> 01:52:23,820
How many for supervised, like staying unsupervised but regression?

1335
01:52:23,820 --> 01:52:24,820
Okay, a few hands.

1336
01:52:24,820 --> 01:52:26,820
And how many for unsupervised?

1337
01:52:26,820 --> 01:52:28,820
Okay, more hands for unsupervised.

1338
01:52:28,820 --> 01:52:32,820
So we'll try to finish unsupervised quickly and then hopefully we'll have time to come back.

1339
01:52:32,820 --> 01:52:38,820
If not, you have the code and all of the details already.

1340
01:52:38,820 --> 01:52:48,820
Okay.

1341
01:52:48,820 --> 01:52:53,820
So just to give a quick recap, unsupervised learning is where we have no labels associated with the data.

1342
01:52:53,820 --> 01:52:55,820
So there's no right or no wrong answer.

1343
01:52:55,820 --> 01:53:00,820
But what we're trying to do is we're just trying to find out the underlying structure, the distribution of the data,

1344
01:53:00,820 --> 01:53:09,820
and hopefully get some meaningful clusters out of it.

1345
01:53:09,820 --> 01:53:10,820
Okay.

1346
01:53:10,820 --> 01:53:19,820
The most I would say used and important algorithm as far as clustering is concerned is something that's called as K-means algorithm,

1347
01:53:19,820 --> 01:53:27,820
which is where K is an input that you give to the algorithm as a user, which stands for the number of clusters that you want.

1348
01:53:27,820 --> 01:53:32,820
And means just imagine your data points on a 2D plot.

1349
01:53:32,820 --> 01:53:34,820
It's just like all over.

1350
01:53:34,820 --> 01:53:43,820
You're trying to figure out three data points, if K is equal to three, three data points that could serve as good means for three different clusters.

1351
01:53:43,820 --> 01:53:47,820
So it's based on finding a mean for a particular cluster.

1352
01:53:47,820 --> 01:53:52,820
We'll take a look at how exactly it works in this code over here.

1353
01:53:52,820 --> 01:53:54,820
Okay.

1354
01:53:54,820 --> 01:53:59,820
So we're going to import something that's called make blobs, which is pretty much what it sounds like.

1355
01:53:59,820 --> 01:54:04,820
It's going to create random blobs of data on the plot from SKLearn.

1356
01:54:04,820 --> 01:54:13,820
So let's say we want 200 data points with two features, five centers, and that is, you know,

1357
01:54:13,820 --> 01:54:17,820
five clusters with the standard deviation and this random state.

1358
01:54:17,820 --> 01:54:27,820
And let's go ahead and see what that looks like.

1359
01:54:27,820 --> 01:54:30,820
So it's a bunch of.

1360
01:54:30,820 --> 01:54:32,820
Remember, we talked about two features.

1361
01:54:32,820 --> 01:54:33,820
There are two columns.

1362
01:54:33,820 --> 01:54:36,820
There are 200 data points, so 200 rows.

1363
01:54:36,820 --> 01:54:51,820
And the way they were generated was in a way where you can form five distinct clusters out of it.

1364
01:54:51,820 --> 01:55:01,820
So what we're going to do now is we're going to use some visualization and try to plot a 2D scatter graph of these data points that we have generated right now.

1365
01:55:01,820 --> 01:55:08,820
And the way we would do it, we already have the data about how they are centered, right, that there are in five different five distinct clusters.

1366
01:55:08,820 --> 01:55:15,820
So let's plot each of the clusters in a different color and see what that looks like.

1367
01:55:15,820 --> 01:55:19,820
So this is what it looks like where each of the five clusters have different color.

1368
01:55:19,820 --> 01:55:28,820
There's some overlap, but mostly I would say it's pretty distinguishable.

1369
01:55:28,820 --> 01:55:33,820
OK.

1370
01:55:33,820 --> 01:55:35,820
So this is kind of like reverse engineering.

1371
01:55:35,820 --> 01:55:38,820
We already know what the answer is supposed to be or what it's supposed to look like.

1372
01:55:38,820 --> 01:55:44,820
And then we'll apply our K-means algorithm and see if we're getting a similar result or not.

1373
01:55:44,820 --> 01:55:50,820
So from sklearn.cluster, let's import the K-means algorithm that helps us decide the cluster.

1374
01:55:50,820 --> 01:55:56,820
For now, let's say K is equal to five because we do know that the data we simulated or created had five clusters.

1375
01:55:56,820 --> 01:56:03,820
So let's keep it at five. Let's try to give it, you know, the best shot at performance.

1376
01:56:03,820 --> 01:56:09,820
And then as an input to K-means, you would say K is the number of clusters, which is five.

1377
01:56:09,820 --> 01:56:14,820
And then finally, K-means.fit pretty similar to how we use it in our decision tree classifier.

1378
01:56:14,820 --> 01:56:21,820
Use the model name.fit and then you pass the data that you want to it.

1379
01:56:21,820 --> 01:56:26,820
And these are different cluster centers. Since K is five and there are only two features,

1380
01:56:26,820 --> 01:56:31,820
we've gotten five rows of five data points with two features or two columns each.

1381
01:56:31,820 --> 01:56:35,820
So X, Y coordinates.

1382
01:56:35,820 --> 01:56:38,820
OK. So now we've created a model on the data.

1383
01:56:38,820 --> 01:56:44,820
Let's go ahead and try to see how well it's going to predict,

1384
01:56:44,820 --> 01:56:51,820
how well it's going to create clusters out of that model.

1385
01:56:51,820 --> 01:56:55,820
So these are the clusters that created. You can see with the different colors.

1386
01:56:55,820 --> 01:57:02,820
OK, so we see three clusters at the bottom and at the top side of the figure,

1387
01:57:02,820 --> 01:57:06,820
we have two more clusters with a little bit of overlap between them.

1388
01:57:06,820 --> 01:57:11,820
Let's go and see what our data was actually like and see how well it did.

1389
01:57:11,820 --> 01:57:16,820
So three more clusters at the bottom, two clusters at the top, a little bit of overlap.

1390
01:57:16,820 --> 01:57:19,820
Yes, it looks like that.

1391
01:57:19,820 --> 01:57:21,820
You can see it's a little more spread out over here.

1392
01:57:21,820 --> 01:57:24,820
I guess it's that because the scaling is different. No.

1393
01:57:24,820 --> 01:57:29,820
And it's a little more tightly wound over here. But overall, it did a pretty good job, right?

1394
01:57:29,820 --> 01:57:34,820
Most of the clusters would get classified as the predictions would be the same

1395
01:57:34,820 --> 01:57:38,820
as what the initial data values would be.

1396
01:57:38,820 --> 01:57:43,820
Now let's go ahead and change the value of K. Let's increase and decrease it and see what happens.

1397
01:57:43,820 --> 01:57:48,820
Let's make it three and see what happens.

1398
01:57:48,820 --> 01:57:53,820
Why did this not work?

1399
01:57:53,820 --> 01:57:59,820
So now it's become three clusters, right?

1400
01:57:59,820 --> 01:58:03,820
Where you can see the top two clusters have kind of merged and become one.

1401
01:58:03,820 --> 01:58:08,820
And the blue and the red at the sides are each cluster.

1402
01:58:08,820 --> 01:58:13,820
And the middle cluster is kind of now merged into red and blue.

1403
01:58:13,820 --> 01:58:24,820
So this is what it looked like. So the light green cluster and I believe that's purple, dark purple clusters kind of like a part of the other clusters now.

1404
01:58:24,820 --> 01:58:32,820
So what this algorithm is doing is just trying to find those center points that would form the means for that particular cluster.

1405
01:58:32,820 --> 01:58:39,820
And then all of the data points around it would form the body of the cluster.

1406
01:58:39,820 --> 01:58:48,820
Let's increase K and let's see what happens. Let's make it 10, for instance.

1407
01:58:48,820 --> 01:58:57,820
Oh, yeah, it won't work at 10 because I have only given it one, two, three, four, five, six, seven, eight colors.

1408
01:58:57,820 --> 01:59:04,820
So let's keep it as eight.

1409
01:59:04,820 --> 01:59:06,820
So we do have eight clusters over here.

1410
01:59:06,820 --> 01:59:16,820
And what happened was our initial five clusters got split into sub clusters with a little bit of overlap and not too much distinction amongst them.

1411
01:59:16,820 --> 01:59:22,820
But yeah, we do have eight clusters now.

1412
01:59:22,820 --> 01:59:27,820
OK, any questions about that? Yeah.

1413
01:59:27,820 --> 01:59:36,820
Yeah, I'll do that. Let's go to the next part of the code and then hopefully you'll get a better idea.

1414
01:59:36,820 --> 01:59:48,820
Any more questions?

1415
01:59:48,820 --> 02:00:01,820
So like I mentioned, an application of this would be if you have two users, let's say on Netflix, and if they look at similar shows, you probably have them in the same cluster.

1416
02:00:01,820 --> 02:00:06,820
And depending on the cluster, maybe you could have clusters, let's for example, based on the genre of the movie.

1417
02:00:06,820 --> 02:00:14,820
So you would have one cluster that like sci fi, another cluster that likes rom-com, and the cluster that likes maybe world cinema.

1418
02:00:14,820 --> 02:00:24,820
So that would be one application of it where your features would be the movies that they've seen in the past or probably the movies that they've looked at trailers on but not watched it.

1419
02:00:24,820 --> 02:00:28,820
The kind of ratings that they've given to the different movies that would be your features.

1420
02:00:28,820 --> 02:00:39,820
And over there, what you're trying to do is you're trying to find similarities between groups of users and see what kind of patterns match with what kind of users and group them together.

1421
02:00:39,820 --> 02:00:53,820
And then based on that clustering, you would say that, okay, if this cluster or this group of users see sci fi movies, I should probably recommend, you know, Avengers to them maybe or if they are used to superhero, maybe Avengers is also another good one.

1422
02:00:53,820 --> 02:00:59,820
Or if they never see superhero movies and they've downloaded all superhero movies, probably not recommend that.

1423
02:00:59,820 --> 02:01:01,820
So that would be kind of an example of it.

1424
02:01:01,820 --> 02:01:06,820
Let me post a link to a slightly more concrete coding example for k-means.

1425
02:01:06,820 --> 02:01:11,820
But let's go into the next one, which is also clustering but in a slightly different format.

1426
02:01:11,820 --> 02:01:14,820
Any other questions so far?

1427
02:01:19,820 --> 02:01:20,820
Okay.

1428
02:01:20,820 --> 02:01:27,820
So what we saw till now was all just numbers and we were trying to create models out of that.

1429
02:01:27,820 --> 02:01:33,820
There's another field that's called natural language processing, which deals mainly with textual data.

1430
02:01:33,820 --> 02:01:34,820
Right.

1431
02:01:34,820 --> 02:01:38,820
And how can we create some sort of predictive algorithms for those?

1432
02:01:38,820 --> 02:01:47,820
So the way we would go about to do this is there's a library that's called Jensim that is used for a lot of natural language processing tasks.

1433
02:01:47,820 --> 02:01:51,820
We won't go into the details since it's not an NLP tutorial.

1434
02:01:51,820 --> 02:01:53,820
Excuse me.

1435
02:01:53,820 --> 02:01:55,820
Okay.

1436
02:01:56,820 --> 02:02:07,820
So what we're going to do is we're going to use the Wikipedia API and we're going to extract articles from Wikipedia on particular topics.

1437
02:02:07,820 --> 02:02:11,820
And those topics we are then going to try to cluster.

1438
02:02:11,820 --> 02:02:14,820
Again, so we already know kind of like how we did back in k-means.

1439
02:02:14,820 --> 02:02:17,820
We already know what the clusters are supposed to look like.

1440
02:02:17,820 --> 02:02:19,820
But we'll just see how well is that algorithm working.

1441
02:02:19,820 --> 02:02:23,820
Is it going to give us same clusters or not?

1442
02:02:23,820 --> 02:02:24,820
Okay.

1443
02:02:24,820 --> 02:02:32,820
So what this function is doing over here, it's using the Wikipedia API and it's going to retrieve articles to random articles.

1444
02:02:32,820 --> 02:02:34,820
This is what this line does.

1445
02:02:34,820 --> 02:02:42,820
And then it's going to retrieve additional articles on music, gardening, reading, San Francisco and Mountain View.

1446
02:02:42,820 --> 02:02:47,820
Mountain View is another city in the Bay Area.

1447
02:02:47,820 --> 02:02:56,820
And then it's just going to take all of the data on those pages and use that as our data set.

1448
02:02:56,820 --> 02:02:59,820
So let's go ahead and run that.

1449
02:02:59,820 --> 02:03:01,820
Okay.

1450
02:03:01,820 --> 02:03:05,820
So here cleaning of textual data is a little different from numbers.

1451
02:03:05,820 --> 02:03:07,820
We don't just look at what are the missing values.

1452
02:03:07,820 --> 02:03:13,820
We don't look at what are irrelevant or abnormal values because it's all text.

1453
02:03:13,820 --> 02:03:15,820
So it's difficult to generalize that way.

1454
02:03:15,820 --> 02:03:16,820
Okay.

1455
02:03:16,820 --> 02:03:24,820
What we do instead over here is since we are retrieving this from web pages, what we'd like to do is we would like to remove HTML tags.

1456
02:03:24,820 --> 02:03:30,820
And we'd also like to remove anything that is not a word.

1457
02:03:30,820 --> 02:03:36,820
So things like numbers, special characters, emojis, we're just going to get rid of them.

1458
02:03:36,820 --> 02:03:41,820
And the way we do that is using regex, regular expressions.

1459
02:03:41,820 --> 02:03:44,820
How many of you are familiar with regular expressions?

1460
02:03:44,820 --> 02:03:45,820
Okay.

1461
02:03:45,820 --> 02:03:55,820
So just to fit is that you're giving it a pattern where anything that meets the pattern stays and anything that doesn't meet the pattern gets filtered out.

1462
02:03:55,820 --> 02:03:57,820
So W plus stands here for words.

1463
02:03:57,820 --> 02:03:58,820
W stands for words.

1464
02:03:58,820 --> 02:04:00,820
So anything that is a word stays.

1465
02:04:00,820 --> 02:04:03,820
Anything else just gets filtered out.

1466
02:04:03,820 --> 02:04:13,820
And over here we are going to make everything lowercase because we don't want there to be a difference between all caps or camel case or lowercase if the word is the same.

1467
02:04:13,820 --> 02:04:21,820
Then to clean the articles, what we're going to do is we're going to use a list of stop words in the English language.

1468
02:04:21,820 --> 02:04:27,820
Stop words are all of your filler words or words that don't carry any meaning on their own.

1469
02:04:27,820 --> 02:04:32,820
So think about prepositions, words like the, of, and, but, in.

1470
02:04:32,820 --> 02:04:35,820
On their own they don't really mean anything.

1471
02:04:35,820 --> 02:04:39,820
But grammatically they need to be used for a sentence to be correct.

1472
02:04:39,820 --> 02:04:43,820
But since they don't mean anything we're just going to filter them out.

1473
02:04:43,820 --> 02:04:46,820
So this is what this line of code does over here.

1474
02:04:46,820 --> 02:04:50,820
And then finally there's something called stemmer.

1475
02:04:50,820 --> 02:04:55,820
So each of the words in English language have a base word associated with it.

1476
02:04:55,820 --> 02:05:00,820
Let's say for instance you're looking at the words running, ran, runs.

1477
02:05:00,820 --> 02:05:02,820
They all mean the same thing, right?

1478
02:05:02,820 --> 02:05:06,820
At the end of the day they are all just different forms of the base word run, right?

1479
02:05:07,820 --> 02:05:10,820
So for the purpose of this, there are two purposes for doing this.

1480
02:05:10,820 --> 02:05:18,820
Number one is that sometimes the vocabulary size or the number of words that are in your data set is so huge that it might not fit in memory

1481
02:05:18,820 --> 02:05:22,820
or it might take a really long time for your algorithm to compute models.

1482
02:05:22,820 --> 02:05:27,820
So stemming helps you to collapse the vocabulary while still retaining the meaning of the word.

1483
02:05:27,820 --> 02:05:32,820
The second way is that because they all mean the same thing and I'm not really,

1484
02:05:32,820 --> 02:05:36,820
I'm not really interested in knowing whether it was running or whether it was ran or whether it was run.

1485
02:05:36,820 --> 02:05:39,820
We're just going to get it down to the base word.

1486
02:05:42,820 --> 02:05:46,820
Any questions so far about the cleaning processes for textual data?

1487
02:05:48,820 --> 02:05:50,820
We'll take a look at what it looks like.

1488
02:05:54,820 --> 02:06:00,820
So here is where we are calling each of the functions and let's see what happens.

1489
02:06:02,820 --> 02:06:10,820
So we're getting the data from Wikipedia based on the list of articles, list of topics that we gave it and two random articles.

1490
02:06:10,820 --> 02:06:15,820
And then it's going to process, go through the process of cleaning the entire data,

1491
02:06:15,820 --> 02:06:20,820
which is where you're removing your stop words, stemming it, lower casing it, removing numbers.

1492
02:06:20,820 --> 02:06:25,820
And then finally you create something that's called as bag of words.

1493
02:06:25,820 --> 02:06:32,820
So just think of a matrix where your row numbers or your rows are each of the documents

1494
02:06:32,820 --> 02:06:36,820
and your columns are each of the words present in your vocabulary.

1495
02:06:36,820 --> 02:06:44,820
So let's say for instance, it is my sentence is this is good, the first sentence.

1496
02:06:44,820 --> 02:06:47,820
And my second sentence is this is bad.

1497
02:06:47,820 --> 02:06:49,820
So there are four words in my entire vocabulary.

1498
02:06:49,820 --> 02:06:51,820
This is good, bad.

1499
02:06:51,820 --> 02:06:57,820
For the first sentence, for this good, this is good, bad.

1500
02:06:57,820 --> 02:06:59,820
These are the column names or the feature names.

1501
02:06:59,820 --> 02:07:07,820
We would have one, one, one, zero, where one says if that particular word or that particular feature is present in your sentence.

1502
02:07:07,820 --> 02:07:09,820
So this is good, we'll all have one.

1503
02:07:09,820 --> 02:07:12,820
But bad would be zero because bad is not present in the first sentence.

1504
02:07:12,820 --> 02:07:18,820
Similarly, for the second sentence, it would be one, one, zero, one, because good, the third feature is not present in the sentence,

1505
02:07:18,820 --> 02:07:21,820
but bad is present, so that would have one.

1506
02:07:21,820 --> 02:07:29,820
So this is just this matrix has a fancy term that's called bag of words because you're losing the contextual meaning of the words.

1507
02:07:29,820 --> 02:07:34,820
You don't know what exactly the word means, but you still have a collection of the words.

1508
02:07:34,820 --> 02:07:38,820
It's like, you know, a bag of popcorn where you have each of the kernels where the words are there.

1509
02:07:38,820 --> 02:07:45,820
So you have the collection of the words, but you don't know what the words mean or what the sentence means.

1510
02:07:46,820 --> 02:07:49,820
Okay, name clean is not defined.

1511
02:07:54,820 --> 02:08:01,820
Okay, so these are the articles that we have, Music, Gardening, Reading, San Francisco Mountain View, which were the ones that we used to define.

1512
02:08:01,820 --> 02:08:06,820
And it went ahead and selected two more random articles where the first one is the De Vinci's Challenge

1513
02:08:06,820 --> 02:08:12,820
and the second one is Siege of Fadrian Opel 1912-1913, some event that happened in history.

1514
02:08:12,820 --> 02:08:13,820
Okay.

1515
02:08:14,820 --> 02:08:19,820
And then we have something that's called LDA, which is a very specific type of algorithm.

1516
02:08:19,820 --> 02:08:33,820
LDA stands for Latent Directly Allocation, which just means that every document is a proportion of topics and every topic is a proportion of words.

1517
02:08:35,820 --> 02:08:37,820
Does that make sense?

1518
02:08:37,820 --> 02:08:40,820
Every document is a proportion of different topics.

1519
02:08:40,820 --> 02:08:49,820
So every document is going to have multiple topics that it's talking about, and each of the topics has different words, different proportion of words that it's talking about.

1520
02:08:50,820 --> 02:08:51,820
Let's try to look at the results.

1521
02:08:51,820 --> 02:08:54,820
Hopefully, you'll get a better understanding of what it does.

1522
02:08:54,820 --> 02:09:07,820
So we're going to create a model that is going to use this algorithm, LDA, and then we're going to try to pass our words or our articles and see how does it cluster them.

1523
02:09:09,820 --> 02:09:15,820
And over here we said that we want to look at, we want six clusters or six topics to come out at the end.

1524
02:09:17,820 --> 02:09:21,820
We're going to build word clouds that helps us visualize this better.

1525
02:09:24,820 --> 02:09:33,820
Okay, so these are what the topics look like.

1526
02:09:33,820 --> 02:09:35,820
So this is a form of clustering.

1527
02:09:35,820 --> 02:09:39,820
The first topic or topic zero is probably about San Francisco.

1528
02:09:39,820 --> 02:09:41,820
Remember, San Francisco was one of our topics.

1529
02:09:41,820 --> 02:09:45,820
It's talking about things like California State, San Francisco City.

1530
02:09:45,820 --> 02:09:49,820
The second one is talking about the siege command artillery battle.

1531
02:09:49,820 --> 02:09:56,820
If you see, you would find the spellings of the word a little weird because these are the stemmed versions.

1532
02:09:56,820 --> 02:09:58,820
So these are the base words of them.

1533
02:09:58,820 --> 02:10:04,820
So like siege, siege could be siege, could be sieged, could be sieging.

1534
02:10:06,820 --> 02:10:09,820
Similarly for command, it could be command, commandment, commanding.

1535
02:10:11,820 --> 02:10:17,820
Okay, so the second one is probably about that random event, that historical event that took place, the siege.

1536
02:10:20,820 --> 02:10:24,820
The third topic is about instrument, classic, form, play, music.

1537
02:10:24,820 --> 02:10:26,820
So it probably is the one about music.

1538
02:10:27,820 --> 02:10:31,820
The next one is about a game or a pattern.

1539
02:10:31,820 --> 02:10:34,820
And we know that the Da Vinci challenge was one of the randomly selected topics.

1540
02:10:34,820 --> 02:10:36,820
So it's forming a cluster of that.

1541
02:10:38,820 --> 02:10:43,820
The next one is probably about reading, text, learn, word comprehension.

1542
02:10:44,820 --> 02:10:48,820
And finally, the last one is about gardening, landscape plan.

1543
02:10:48,820 --> 02:10:50,820
So it's probably something about gardening.

1544
02:10:50,820 --> 02:10:55,820
So you won't really get the topic names directly from the algorithm.

1545
02:10:55,820 --> 02:11:02,820
But once you take a look at the different words that form the topic, you can kind of gather what this particular cluster is about.

1546
02:11:02,820 --> 02:11:11,820
If you notice, we selected seven topics and we have only formed clusters of six because we kept the seventh topic as the testing data,

1547
02:11:13,820 --> 02:11:15,820
which is Mountain View.

1548
02:11:19,820 --> 02:11:20,820
Okay.

1549
02:11:20,820 --> 02:11:27,820
And then we have something called a similarity where we are trying to see that, okay, all of the words that are present in Mountain View article,

1550
02:11:27,820 --> 02:11:30,820
how similar it is to one of these clusters.

1551
02:11:30,820 --> 02:11:38,820
The same way how Netflix or Amazon does, it has like, if you're a new user and you have done some sort of activity, some sort of transactions,

1552
02:11:38,820 --> 02:11:44,820
then they pitch you against the different clusters, different users that they've already formed,

1553
02:11:44,820 --> 02:11:49,820
and then see which one are you most similar to so that they can give you better personalized recommendations.

1554
02:11:50,820 --> 02:11:56,820
So over here, it says that the given topic, which is Mountain View, is most similar to topic zero with a similarity of point A3.

1555
02:11:56,820 --> 02:12:00,820
So the similarity scale is from zero to one, so point A3 is pretty high.

1556
02:12:01,820 --> 02:12:03,820
And let's see what topic zero was.

1557
02:12:03,820 --> 02:12:07,820
Topic zero was San Francisco, which is correct because Mountain View is also another city in the Bay Area.

1558
02:12:08,820 --> 02:12:15,820
So this is another example of clustering, and I took this example because I wanted to give you a glimpse of natural language processing

1559
02:12:15,820 --> 02:12:19,820
and that data sets don't always have to be numerical in nature.

1560
02:12:19,820 --> 02:12:26,820
They can also be text, and the way you would go about handling a textual data, the cleaning, the processing, the understanding is slightly different

1561
02:12:26,820 --> 02:12:30,820
and leans more towards linguistic knowledge and natural language processing,

1562
02:12:30,820 --> 02:12:35,820
but it does apply the same predictive or modeling algorithms.

1563
02:12:37,820 --> 02:12:39,820
Any questions so far?

1564
02:12:48,820 --> 02:12:50,820
Should I move on to the next one?

1565
02:12:52,820 --> 02:12:58,820
So now we can go back to our regression example.

1566
02:13:08,820 --> 02:13:10,820
Does anyone want to break?

1567
02:13:13,820 --> 02:13:15,820
Yes? No?

1568
02:13:16,820 --> 02:13:18,820
Okay, let's take a five-minute break.

1569
02:13:37,820 --> 02:13:39,820
Okay.

1570
02:14:07,820 --> 02:14:09,820
Okay.

1571
02:14:37,820 --> 02:14:39,820
Okay.

1572
02:15:00,820 --> 02:15:02,820
Hey. Sure.

1573
02:15:02,820 --> 02:15:10,820
I used a fraud detection algorithm to figure out if transactions are either fraudulent or not fraudulent.

1574
02:15:10,820 --> 02:15:23,820
And I used random forests, regression, logistic regression, and I was wondering if naive base is a good alternative to that.

1575
02:15:23,820 --> 02:15:26,820
Or if there's any other thing that I can...

1576
02:15:26,820 --> 02:15:29,820
Have you looked at time series algorithms?

1577
02:15:29,820 --> 02:15:31,820
That is probably something you should look at.

1578
02:15:31,820 --> 02:15:37,820
That is one of the first things that is really useful for detection algorithms.

1579
02:15:37,820 --> 02:15:43,820
And so, primarily because anomaly detection is, you know, it's like a time series data since it's dependent on time,

1580
02:15:43,820 --> 02:15:48,820
and that is an important metric to understand if something is anomalous or not.

1581
02:15:48,820 --> 02:15:55,820
Something very basic that you can start off with is just don't get into the modeling part, just do the visualization.

1582
02:15:55,820 --> 02:16:00,820
And see what, you know, visually for yourself, you see there's like a high peak in probably the transaction amount,

1583
02:16:00,820 --> 02:16:03,820
or there's a big gap between two transactions there.

1584
02:16:03,820 --> 02:16:09,820
And if that gap or that particular value is greater than, let's say, two or three standard deviations,

1585
02:16:09,820 --> 02:16:11,820
it's probably something that's anomalous.

1586
02:16:11,820 --> 02:16:12,820
Okay.

1587
02:16:12,820 --> 02:16:15,820
That's like another approach to just like...

1588
02:16:15,820 --> 02:16:16,820
Yeah.

1589
02:16:16,820 --> 02:16:20,820
So we should try what you did there with the different features.

1590
02:16:20,820 --> 02:16:21,820
For clustering?

1591
02:16:21,820 --> 02:16:25,820
No, no, the different features of the two of my data.

1592
02:16:25,820 --> 02:16:26,820
Right.

1593
02:16:26,820 --> 02:16:27,820
And you had those little...

1594
02:16:27,820 --> 02:16:29,820
The graphs, yes.

1595
02:16:29,820 --> 02:16:30,820
Yeah, yeah, yeah.

1596
02:16:30,820 --> 02:16:31,820
You can try that.

1597
02:16:31,820 --> 02:16:33,820
And you can also try clustering.

1598
02:16:33,820 --> 02:16:34,820
Wow.

1599
02:16:34,820 --> 02:16:35,820
I'll use the satellite.

1600
02:16:35,820 --> 02:16:38,820
Oh, okay.

1601
02:16:38,820 --> 02:16:39,820
Oh, okay.

1602
02:16:39,820 --> 02:16:43,820
Is that better?

1603
02:16:43,820 --> 02:16:44,820
Yeah.

1604
02:16:44,820 --> 02:16:50,820
And you can also try clustering, because then what would happen is probably transactions with similar amounts

1605
02:16:50,820 --> 02:16:52,820
might get clustered into the same thing.

1606
02:16:52,820 --> 02:16:55,820
Like I mentioned, right, if there's a transaction with $10,000,

1607
02:16:55,820 --> 02:16:58,820
and everything else is probably below 50 or in the context,

1608
02:16:58,820 --> 02:17:01,820
then 10,000 is going to be one lone point on your graph.

1609
02:17:01,820 --> 02:17:06,820
So do I also have to do normalization of scaling?

1610
02:17:06,820 --> 02:17:13,820
Because I have transactions that are $20,000, and then you've got $5.

1611
02:17:13,820 --> 02:17:14,820
Right.

1612
02:17:14,820 --> 02:17:18,820
No, I would suggest you don't do it over there, because that value actually means something, right?

1613
02:17:18,820 --> 02:17:21,820
Like 20,000 is very different from $5.

1614
02:17:21,820 --> 02:17:22,820
Okay, so in this instance...

1615
02:17:22,820 --> 02:17:23,820
Yeah, in this case, you don't need it.

1616
02:17:23,820 --> 02:17:24,820
Awesome.

1617
02:17:24,820 --> 02:17:25,820
Thank you.

1618
02:17:25,820 --> 02:17:31,820
Sure.

1619
02:17:31,820 --> 02:17:41,820
Why is this not charging?

1620
02:18:01,820 --> 02:18:11,820
Okay.

1621
02:18:31,820 --> 02:18:41,820
Okay.

1622
02:19:01,820 --> 02:19:11,820
Okay.

1623
02:19:31,820 --> 02:19:41,820
Okay.

1624
02:19:41,820 --> 02:19:51,820
Okay.

1625
02:20:11,820 --> 02:20:21,820
Okay.

1626
02:20:41,820 --> 02:20:51,820
Okay.

1627
02:21:11,820 --> 02:21:21,820
Okay.

1628
02:21:41,820 --> 02:21:51,820
Okay.

1629
02:22:11,820 --> 02:22:21,820
Okay.

1630
02:22:41,820 --> 02:22:51,820
Okay.

1631
02:23:11,820 --> 02:23:21,820
Okay.

1632
02:23:41,820 --> 02:23:51,820
Okay.

1633
02:24:11,820 --> 02:24:21,820
Okay.

1634
02:24:21,820 --> 02:24:31,820
Is the lighting okay for everyone?

1635
02:24:51,820 --> 02:25:01,820
Okay.

1636
02:25:01,820 --> 02:25:11,820
Okay.

1637
02:25:11,820 --> 02:25:21,820
Okay.

1638
02:25:21,820 --> 02:25:31,820
Okay.

1639
02:25:31,820 --> 02:25:41,820
Okay.

1640
02:25:41,820 --> 02:25:51,820
Okay.

1641
02:25:51,820 --> 02:26:01,820
Okay.

1642
02:26:11,820 --> 02:26:21,820
Okay.

1643
02:26:41,820 --> 02:26:51,820
Okay.

1644
02:27:11,820 --> 02:27:21,820
Okay.

1645
02:27:41,820 --> 02:27:51,820
Okay.

1646
02:27:51,820 --> 02:28:01,820
Okay.

1647
02:28:01,820 --> 02:28:11,820
Shall we begin?

1648
02:28:11,820 --> 02:28:17,820
Okay.

1649
02:28:17,820 --> 02:28:27,820
Okay.

1650
02:28:47,820 --> 02:28:57,820
Okay.

1651
02:29:17,820 --> 02:29:27,820
Okay.

1652
02:29:27,820 --> 02:29:37,820
Okay.

1653
02:29:37,820 --> 02:29:47,820
Okay.

1654
02:29:47,820 --> 02:29:57,820
Okay.

1655
02:29:57,820 --> 02:30:07,820
Okay.

1656
02:30:27,820 --> 02:30:37,820
Okay.

1657
02:30:37,820 --> 02:30:43,820
Okay.

1658
02:30:43,820 --> 02:30:47,820
Okay.

1659
02:30:47,820 --> 02:30:51,820
Okay.

1660
02:30:51,820 --> 02:30:55,820
Okay.

1661
02:30:55,820 --> 02:31:01,820
Okay.

1662
02:31:01,820 --> 02:31:05,820
Okay.

1663
02:31:05,820 --> 02:31:11,820
Okay.

1664
02:31:11,820 --> 02:31:17,820
Okay.

1665
02:31:17,820 --> 02:31:23,820
Okay.

1666
02:31:23,820 --> 02:31:27,820
Okay.

1667
02:31:27,820 --> 02:31:33,820
Okay.

1668
02:31:33,820 --> 02:31:37,820
Okay.

1669
02:31:37,820 --> 02:31:41,820
Okay.

1670
02:31:41,820 --> 02:31:45,820
Okay.

1671
02:31:45,820 --> 02:31:51,820
Okay.

1672
02:31:51,820 --> 02:31:57,820
Okay.

1673
02:31:57,820 --> 02:32:03,820
Okay.

1674
02:32:03,820 --> 02:32:09,820
Okay.

1675
02:32:09,820 --> 02:32:15,820
Okay.

1676
02:32:15,820 --> 02:32:21,820
Okay.

1677
02:32:21,820 --> 02:32:27,820
Okay.

1678
02:32:27,820 --> 02:32:33,820
Okay.

1679
02:32:33,820 --> 02:32:39,820
Okay.

1680
02:32:39,820 --> 02:32:45,820
Okay.

1681
02:32:45,820 --> 02:32:51,820
Okay.

1682
02:32:51,820 --> 02:32:57,820
Okay.

1683
02:32:57,820 --> 02:33:07,820
What happened? Oh, yeah.

1684
02:33:07,820 --> 02:33:17,820
Make sure to add price.

1685
02:33:17,820 --> 02:33:23,820
Okay.

1686
02:33:23,820 --> 02:33:37,820
So, it varies quite a bit from zero surprises in thousands of dollars, so it goes up to 50,000, but I'd say the majority is around 20 to 30,000.

1687
02:33:37,820 --> 02:33:43,820
Okay.

1688
02:33:43,820 --> 02:33:51,820
We're going to try something a little different here because there are a lot of features involved and we don't have a good understanding of what each of those mean.

1689
02:33:51,820 --> 02:34:05,820
Let's try to create a correlation matrix where we're trying to see how each of the features are dependent on the others and how all of those influence price, which is the feature we're most interested in since we're trying to predict the price of the house.

1690
02:34:05,820 --> 02:34:19,820
The way you would do that is in Seaborn, create a correlation matrix using the call function on your Pandas data frame, round it up to two decimal digits if you want, otherwise it's going to be a lot of digits.

1691
02:34:19,820 --> 02:34:29,820
And then you have to use the heat map function, pass the correlation matrix as the data, and annotation true just says that these numbers, these labels will show up.

1692
02:34:29,820 --> 02:34:33,820
So, let's go ahead and do that.

1693
02:34:33,820 --> 02:34:42,820
So, we have a really huge matrix because of the number of features involved and it's going to be a little difficult to interpret at first, but let's break it down.

1694
02:34:42,820 --> 02:34:55,820
So, it's basically an end by end matrix where n are a number of features and you can see each of the features are along the x and the y axis.

1695
02:34:55,820 --> 02:35:04,820
And as expected, this diagonal is going to be the highest correlation because it's just correlation of itself with itself.

1696
02:35:04,820 --> 02:35:09,820
And correlation is on a scale of negative one to positive one.

1697
02:35:09,820 --> 02:35:16,820
Negative just means that they are correlated, but if one goes up, the other goes down, so they are inversely correlated.

1698
02:35:16,820 --> 02:35:23,820
And positive means they are positively correlated where if one increases, the other will also increase.

1699
02:35:23,820 --> 02:35:27,820
And the actual value is the magnitude of how highly correlated they are.

1700
02:35:27,820 --> 02:35:37,820
So, let's take a look at price and see what features are correlated highly with price.

1701
02:35:37,820 --> 02:35:49,820
So, we're going to look for lighter regions because lighter regions indicate higher correlation or extremely darker regions which indicate negative correlation.

1702
02:35:49,820 --> 02:36:01,820
So, LSTAT seems pretty high, negative 0.74, which is pretty high, negative correlation. 0.33 is mild, not as high, not as high.

1703
02:36:01,820 --> 02:36:08,820
0.7 also seems pretty high up, positively correlated RM.

1704
02:36:08,820 --> 02:36:11,820
And the other are more or less, they are not as important.

1705
02:36:11,820 --> 02:36:17,820
Let's go back to our data set and see what RM and LSTAT exactly meant.

1706
02:36:17,820 --> 02:36:28,820
So, let's go back to our description and see where RM is. RM is the average number of rooms for dwelling, which makes sense, right?

1707
02:36:28,820 --> 02:36:33,820
A studio apartment is probably going to be the cheapest with one bed and five bed probably most expensive.

1708
02:36:33,820 --> 02:36:38,820
And that seems to have a high correlation, which even like common sense or our heuristics also tell.

1709
02:36:38,820 --> 02:36:45,820
Okay, so that's great. What is LSTAT? LSTAT is the lower status of the population.

1710
02:36:45,820 --> 02:36:49,820
Percentage of lower status of the population.

1711
02:36:49,820 --> 02:36:57,820
So, I guess that tells, that depends on the location and how affordable it is in a way.

1712
02:36:57,820 --> 02:37:03,820
Let's see further and find out what exactly, how informative they are.

1713
02:37:03,820 --> 02:37:13,820
Okay, so we selected these two features, the RM and the LSTAT as our two most important features from our initial exploratory data analysis.

1714
02:37:13,820 --> 02:37:22,820
Let's try to plot scatter plots for these two features with price and see if we can see any more trends or any more variations in it.

1715
02:37:22,820 --> 02:37:30,820
So, we're going to select only LSTAT and RM and we're going to try to plot it against price and see what it looks like.

1716
02:37:30,820 --> 02:37:37,820
So, these are the scatter plots we created.

1717
02:37:37,820 --> 02:37:51,820
So, you can see they seem to be linearly correlated, right? You can see that you can kind of form a line, but this is negative correlation and this one is positive correlation.

1718
02:37:51,820 --> 02:38:04,820
Because if LSTAT is low, then the price is high and if RM is high, the price is high, which also is what we saw in the correlation matrix. So, it makes sense, right?

1719
02:38:04,820 --> 02:38:15,820
Okay, so our hypothesis for now is that these two features are probably going to be the most important or the most indicative features as far as the price of a house is concerned.

1720
02:38:15,820 --> 02:38:21,820
Let's try to verify those claims. Any questions so far?

1721
02:38:21,820 --> 02:38:34,820
Okay, so what we're going to do is, like in previous examples, we're going to have X as all of the columns except our output column or our target column or our label column, which forms the Y dataset.

1722
02:38:34,820 --> 02:38:42,820
So, we're going to remove price and have all the other features in X and then we're going to have price as the only feature in Y.

1723
02:38:42,820 --> 02:38:50,820
So, we have 506 columns, 13 features and one feature over here. This blank means one.

1724
02:38:50,820 --> 02:39:00,820
We're going to scale over here because these are all numerical features on different scales and again, we don't want one of them to have a lot of weightage just because the number is high.

1725
02:39:00,820 --> 02:39:08,820
So, let's go ahead and scale it.

1726
02:39:08,820 --> 02:39:20,820
And then similar to how we did in our previous supervised learning, we will split them into training and test. We'll still go with the 80-20 split using the train test split.

1727
02:39:20,820 --> 02:39:36,820
We passed the transformed versions.

1728
02:39:36,820 --> 02:39:43,820
Again, over here, like I mentioned, instead of using the decision reclassifier, we're using linear regression over here.

1729
02:39:43,820 --> 02:39:50,820
So, classifiers are used for classification where you want to categorize the data points into certain categories.

1730
02:39:50,820 --> 02:40:00,820
Regression is where you're trying to predict a particular value, a particular amount. So, we're going to use linear regression, which is the most basic model for regression.

1731
02:40:00,820 --> 02:40:12,820
So, we just call the model, .fit, give it your training data set, the X and Y values, so our features and our output.

1732
02:40:12,820 --> 02:40:21,820
And it creates similar to our decision reclassifier. It finally creates a model based on all of that data.

1733
02:40:21,820 --> 02:40:32,820
And we've kept aside the training data set, the 20% that was remaining. So, we'll try to predict the results on that 20% of the data and use some metrics that we can see.

1734
02:40:32,820 --> 02:40:37,820
So, over here, we're not going to really have false positives or false negatives since this is not classification.

1735
02:40:37,820 --> 02:40:48,820
So, we're going to have slightly different metrics, which are called RMSE, root mean square error, and we're going to have R-square. I'll explain about what they mean.

1736
02:40:48,820 --> 02:41:01,820
So, you can import those metrics from sklearn.metrics, mean squared error, and R2 score, which is R-square.

1737
02:41:01,820 --> 02:41:04,820
And then we look at the model performance.

1738
02:41:04,820 --> 02:41:11,820
So, for the model performance for training set, we had RMSE of 4.6 and R-square of 0.7.

1739
02:41:11,820 --> 02:41:22,820
So, RMSE is an absolute metric where the actual numbers, where the actual numbers or the actual values influence that particular metric.

1740
02:41:22,820 --> 02:41:29,820
But R-square is independent of the magnitude. So, it's always going to be between 0 and 1. It's kind of like a percentage.

1741
02:41:29,820 --> 02:41:35,820
RMSE looks at the difference between what was the predicted value and what was the actual value.

1742
02:41:35,820 --> 02:41:41,820
And if that difference is extremely high, it's going to be high. But if the difference is low, it's going to be low, right?

1743
02:41:41,820 --> 02:41:47,820
It's going to be difficult to say if this RMSE is high or not without having the data and context.

1744
02:41:47,820 --> 02:41:55,820
Since our prices are in thousands, an RMSE of 4, 4 is much smaller compared to thousands. This is good.

1745
02:41:55,820 --> 02:42:03,820
But let's say if you had to predict click rates, for example, and click rates are always between 0 and 1 because it's expressed as a percentage.

1746
02:42:03,820 --> 02:42:10,820
In that case, an RMSE of something like 0.7 would be extremely high because the range itself goes from 0 to 1.

1747
02:42:10,820 --> 02:42:15,820
So, in that case, 0.7 is extremely high. So, over here, I think RMSE looks good.

1748
02:42:15,820 --> 02:42:20,820
R-square talks about the variability within the price.

1749
02:42:20,820 --> 02:42:32,820
So, it's just another way of saying that given these features, how well can these features explain the variation in the price that we're seeing, the highs and the lows that we're seeing?

1750
02:42:32,820 --> 02:42:42,820
So, it's doing a job of 73% of explaining it, which is 0.73. So, it's definitely better than average, but it's not really got a really amazing.

1751
02:42:42,820 --> 02:42:46,820
It's just doing like 73%, slightly above average, you can say.

1752
02:42:46,820 --> 02:42:52,820
But this is for the training set, mind you. So, this is something that the model has been trained on and the model is good on.

1753
02:42:52,820 --> 02:42:58,820
We definitely don't want these to be extremely high because otherwise that would be an indication of us overfitting the model.

1754
02:42:58,820 --> 02:43:05,820
Remember the Huskies example where it was just predicting snow instead of trying to predict Huskies, trying to detect Huskies.

1755
02:43:05,820 --> 02:43:12,820
So, we don't want it to be extremely high. We want to keep it a little lower so that we can generalize the model.

1756
02:43:12,820 --> 02:43:17,820
So, let's go ahead and finally evaluate the model on the test set.

1757
02:43:17,820 --> 02:43:22,820
We're going to use the same metrics and let's see what happens here.

1758
02:43:22,820 --> 02:43:31,820
So, the RMSE is 4.86, which is similar to the training set, which is good. It's not fallen completely.

1759
02:43:31,820 --> 02:43:39,820
And the R-square is about 76%, which is a little higher than training, which is also good because it's able to explain slightly more.

1760
02:43:39,820 --> 02:43:45,820
The model is able to explain the features and the variability and the price slightly more.

1761
02:43:48,820 --> 02:43:51,820
Any questions so far? Yeah.

1762
02:44:09,820 --> 02:44:30,820
Yes, I definitely agree that there's a lot of confusion where people think correlation and causation are the same things, which is where your domain experts also come into play, right?

1763
02:44:30,820 --> 02:44:43,820
So, if someone from a medical profession comes into play and says that, yes, this is something that's proven that perhaps if the radius is extremely high of the tumor, it's probably malignant or something like that, which is where the domain expert comes in.

1764
02:44:43,820 --> 02:44:55,820
So, data science cannot always tell you the causations. That is left to how well you understand the context of the problem, how well you understand the data and how well the model is interpretable.

1765
02:44:55,820 --> 02:45:02,820
So, it gives you a good starting point, but of course, it's not going to be all end all, otherwise we would all probably be out of jobs by now.

1766
02:45:04,820 --> 02:45:06,820
Okay. Any other questions?

1767
02:45:08,820 --> 02:45:14,820
So, this is a really short example, but I just wanted to give you an idea of another application of supervised learning.

1768
02:45:14,820 --> 02:45:43,820
So, I know on the face of it, it seems that coding for data science is simple. You just go to SKLearn, you import some model and you keep trying it on a bunch of predefined metrics, but trying to understand what the models are doing internally, trying to understand how the metrics, are they good enough, are they making sense to you, are they able to predict it, or are they just over-fitting and over-generalizing everything?

1769
02:45:43,820 --> 02:45:52,820
That is kind of the tricky part of data science, I would say. And all of those skills are only learned when you practice a lot with the data.

1770
02:45:52,820 --> 02:46:10,820
So, my recommendation is pick up an interesting data set. It could be something about your favorite sports team. There's another really great data set about one million songs that has all of the features, the audio features of each of the songs, and you can like cluster them and see.

1771
02:46:10,820 --> 02:46:37,820
Or you can even look at lyrics. There's another application someone built that's a little bit on the NLP site, but it was an application where you tell the app what Beatles song you like the most, and it gives you a recommendation based on clustering, whether another Beatles song is something that you would like or it's something that you would hate, looking at the lyrics and the different audio features in the song.

1772
02:46:37,820 --> 02:47:04,820
Yeah, I think that's pretty much it. I can talk a little bit about the data science ethics part, since I think that's also very important and it's an often neglected portion. We already covered a bit about when we talked about it, when we talked about how our training data set needs to be pretty diverse, needs to be representative, doesn't need to, shouldn't have the biases that humans have, otherwise the point is kind of lost.

1773
02:47:05,820 --> 02:47:18,820
There was this, I was reading actually just yesterday we had this chat with a colleague of mine, and this person was trying to advocate the cause of introducing humanities in data science.

1774
02:47:19,820 --> 02:47:26,820
And a lot of people initially would be like, what humanities and science engineering tech, really that doesn't make sense, it's so different.

1775
02:47:27,820 --> 02:47:35,820
But let me give you one particular example, which is two examples actually, they're quite tragic, but it really shows the need of ethics in data science.

1776
02:47:37,820 --> 02:47:45,820
So did you hear about this instance where Target actually predicted the pregnancy of a person before the person themselves found out?

1777
02:47:46,820 --> 02:48:03,820
Right, some of you did, okay. I think it was a teenage pregnancy, I don't recollect, right, but Target actually predicted, I'm guessing it was probably based on her purchase activity, the kind of product she was buying and the frequency with which she was buying.

1778
02:48:03,820 --> 02:48:10,820
And they just sent her this coupon for some, you know, like get a discount on some baby care product, blah, blah, blah.

1779
02:48:12,820 --> 02:48:20,820
And this was before she even herself knew she was pregnant. So it's just like creepy. But consider the slightly other extreme of it.

1780
02:48:21,820 --> 02:48:27,820
So all these algorithms are really good at tracking the kind of activities we do online, right?

1781
02:48:28,820 --> 02:48:36,820
And if a person is going to look at baby care products, then it's not difficult to jump to the conclusion that the person is expecting or someone in the family is expecting.

1782
02:48:37,820 --> 02:48:45,820
But what happens if unfortunately the mother undergoes a miscarriage and you still continue to show baby care products to that person?

1783
02:48:45,820 --> 02:48:50,820
It's not ethical, it's going to be emotionally very traumatic for the mother.

1784
02:48:51,820 --> 02:48:59,820
But as engineers or as software practitioners, data scientists, we don't really consider that use case, right?

1785
02:49:00,820 --> 02:49:06,820
Like nobody could have even thought of that because you were just trying to give personalized recommendations and make the users happy.

1786
02:49:06,820 --> 02:49:12,820
But there are these kind of certain use cases where you need to take a slightly more human approach and where ethics come into play.

1787
02:49:13,820 --> 02:49:18,820
There was another case of someone who actually had quite an outburst where...

1788
02:49:19,820 --> 02:49:23,820
Have you seen those Facebook friend-worsy videos?

1789
02:49:24,820 --> 02:49:32,820
Like if you...the day on which you became friends with person X, Y, Z, they showed you a picture of a baby.

1790
02:49:32,820 --> 02:49:41,820
The day on which you became friends with person X, Y, Z, they showed you a short video of your pictures together and how many likes you've shared and so on and so forth.

1791
02:49:43,820 --> 02:49:46,820
So this person received a friend-worsary video.

1792
02:49:47,820 --> 02:49:57,820
And as part of the video on the common pictures in which both of you are tagged, there are these small graphical cartoons that are jumping around and saying, you know, like, happy friend-worsary and the balloons are going up.

1793
02:49:58,820 --> 02:50:02,820
This happened on someone's mother's grave's picture.

1794
02:50:03,820 --> 02:50:07,820
And they brought it up and they were like, oh, happy friend-worsary with your mother.

1795
02:50:08,820 --> 02:50:12,820
And that is just not...that's inhumane, right?

1796
02:50:13,820 --> 02:50:14,820
Like just imagine how traumatic it must have been.

1797
02:50:15,820 --> 02:50:16,820
So these are really tragic examples.

1798
02:50:16,820 --> 02:50:35,820
These are really tragic examples, but as you all are starting off in data science, whether you continue it personally, pursue it professionally or just, you know, do it as a hobby, I would really love it for you to be mindful of all the use cases the applications could be used in.

1799
02:50:36,820 --> 02:50:38,820
What are the disadvantages and how could it negatively affect humans?

1800
02:50:39,820 --> 02:50:43,820
Because at the end of the day, we are using machines, we're using algorithms to make lives easier for us.

1801
02:50:43,820 --> 02:50:44,820
They are the ones who are, you know, working for us.

1802
02:50:45,820 --> 02:50:46,820
We are not slaves to them.

1803
02:50:47,820 --> 02:50:50,820
So these kind of ethical issues definitely need to be talked about.

1804
02:50:51,820 --> 02:50:54,820
Another example that comes to mind is the MIT model machine.

1805
02:50:55,820 --> 02:50:57,820
Have you heard of that?

1806
02:50:58,820 --> 02:51:05,820
Okay, so it comes from this classic trolley problem, which says that...let me give you one instance of it.

1807
02:51:06,820 --> 02:51:26,820
If you're a self-driving car and you see that there's probably a truck in front of you and you have to swerve one way or the other, and on one side there is one person who is crossing the road legally because the green light is walking for that person.

1808
02:51:27,820 --> 02:51:32,820
On the other side of the road, there are five people who are crossing the road who are, you know, like jaywalking.

1809
02:51:32,820 --> 02:51:34,820
Who should you kill?

1810
02:51:35,820 --> 02:51:39,820
Should you kill that one person because it's one compared to five?

1811
02:51:40,820 --> 02:51:43,820
But that one person was legally, lawfully obeying everything.

1812
02:51:44,820 --> 02:51:46,820
So should you go kill the other five people?

1813
02:51:47,820 --> 02:52:01,820
Similarly, just to twist it around a little, if it was the driver's fault, would you kill the pedestrian who was walking legally or would you, you know, rather the driver?

1814
02:52:02,820 --> 02:52:05,820
Should the car meet an accident and the driver gets injured?

1815
02:52:06,820 --> 02:52:10,820
Like ideally it should be the driver who should get injured because the driver is at fault.

1816
02:52:11,820 --> 02:52:13,820
But if that is the case, who will buy a self-driving car?

1817
02:52:14,820 --> 02:52:16,820
Nobody, right?

1818
02:52:17,820 --> 02:52:19,820
Sorry, let me show you quickly.

1819
02:52:23,820 --> 02:52:26,820
So they built this app which has all of these simulations.

1820
02:52:26,820 --> 02:52:29,820
So you start judging what should the self-driving car do.

1821
02:52:30,820 --> 02:52:32,820
That's where you see like these are all scars.

1822
02:52:33,820 --> 02:52:40,820
Like do you want to kill them because they were crossing it illegally or do you go there and enjoy yourself and kill these people?

1823
02:52:43,820 --> 02:52:44,820
Sorry?

1824
02:52:45,820 --> 02:52:50,820
They are collecting data, yes, to facilitate conversations about this.

1825
02:52:51,820 --> 02:52:52,820
Yeah.

1826
02:52:52,820 --> 02:52:53,820
Hopefully not the train, no.

1827
02:52:56,820 --> 02:53:12,820
But yeah, I think after you finish all of these 13 steps, at least when I checked it last, it gives you a breakdown of how similar have people performed actions like you or how dissimilar have the majority of the people performed actions like you.

1828
02:53:13,820 --> 02:53:20,820
And it brings up a really interesting debate of who is the judge and how do we act in a way that is similar to the judge.

1829
02:53:20,820 --> 02:53:23,820
How do we actually regulate these algorithms?

1830
02:53:24,820 --> 02:53:25,820
How do you add the human touch?

1831
02:53:26,820 --> 02:53:27,820
How do you consider the ethics of it all?

1832
02:53:28,820 --> 02:53:34,820
Which is why humanities and arts kind of are going to play an important role in these kind of debates in the future.

1833
02:53:35,820 --> 02:53:36,820
They certainly don't have it.

1834
02:53:37,820 --> 02:53:39,820
What's the difference between self-driving cars and self-driving cars?

1835
02:53:40,820 --> 02:53:47,820
Yeah, I don't think they do it in this, but I wouldn't be surprised if they do it for like actual self-driving cars or something.

1836
02:53:47,820 --> 02:53:48,820
Because it's pretty easy to collect that data.

1837
02:53:49,820 --> 02:53:50,820
I wouldn't be surprised if they do.

1838
02:53:55,820 --> 02:54:01,820
Okay, I think I have covered pretty much everything I wanted in this tutorial.

1839
02:54:03,820 --> 02:54:05,820
Are there any other questions about the code that we went through?

1840
02:54:11,820 --> 02:54:15,820
Okay, so I'm going to update this notebook with a few more examples.

1841
02:54:15,820 --> 02:54:17,820
There was another example for k-means clustering.

1842
02:54:19,820 --> 02:54:21,820
It's actually used in image compression.

1843
02:54:22,820 --> 02:54:26,820
So I also found out about this example, I think, last month when I was preparing for another tutorial.

1844
02:54:27,820 --> 02:54:34,820
So image compression, if you originally look at a high definition image, it's probably going to have thousands, if not millions of colors, different colors.

1845
02:54:35,820 --> 02:54:42,820
And the way image compression works is you look at one pixel and you pick which other colored pixel is it closest to.

1846
02:54:42,820 --> 02:54:47,820
So kind of like how we did in clustering, we picked one center, one mean point, right?

1847
02:54:48,820 --> 02:54:52,820
And all of the points nearby would take that cluster.

1848
02:54:53,820 --> 02:55:00,820
Similarly, you pick one data point which is representative of that particular color and all of the other colors collapse to that color.

1849
02:55:01,820 --> 02:55:05,820
So if you have like pale white and off white and ivory, they would all probably come down to like white.

1850
02:55:07,820 --> 02:55:09,820
That is a way of compressing the image.

1851
02:55:09,820 --> 02:55:14,820
So you can see like this is the original image and this is the image compressed with just 30 colors.

1852
02:55:15,820 --> 02:55:17,820
So that's another application of k-means algorithm.

1853
02:55:18,820 --> 02:55:22,820
So in that case, they're not reviewing the number of pixels?

1854
02:55:23,820 --> 02:55:24,820
Yeah, exactly.

1855
02:55:26,820 --> 02:55:29,820
I can send a link in the resources as well.

1856
02:55:30,820 --> 02:55:31,820
This is my contact information.

1857
02:55:32,820 --> 02:55:34,820
Feel free to ask me any questions.

1858
02:55:34,820 --> 02:55:38,820
And just a snapshot of what are the skills that data scientists in today's world should have.

1859
02:55:39,820 --> 02:55:40,820
Definitely maths and statistics.

1860
02:55:41,820 --> 02:55:46,820
We did look at a lot of statistics today, but that was just really the tip of the iceberg.

1861
02:55:47,820 --> 02:55:51,820
Programming and database, of course, because you need to have coding knowledge to be able to create these models.

1862
02:55:52,820 --> 02:55:57,820
Domain knowledge and soft skills, domain knowledge to understand the context of the data and the applications better.

1863
02:55:58,820 --> 02:56:02,820
Soft skills to be able to communicate the results and the challenges with the data.

1864
02:56:02,820 --> 02:56:07,820
And visualisation so that you're able to tell a good story, a coherent story about what was the data, what exactly did you perform, why did it have such kind of results.

1865
02:56:08,820 --> 02:56:12,820
Or even sometimes it could be something like it's inconclusive or the data is not enough and we need more data.

1866
02:56:13,820 --> 02:56:14,820
Yeah, that's it about me.

1867
02:56:15,820 --> 02:56:16,820
Feel free to ask me any other questions.

1868
02:56:17,820 --> 02:56:19,820
So I'm going to go ahead and start with the question of the data.

1869
02:56:20,820 --> 02:56:22,820
So I'm going to start with the question of the data.

1870
02:56:23,820 --> 02:56:25,820
So I'm going to start with the question of the data.

1871
02:56:26,820 --> 02:56:28,820
Yeah, that's it about me.

1872
02:56:29,820 --> 02:56:30,820
Feel free to ask me any other questions.

1873
02:56:31,820 --> 02:56:38,820
Yeah, another really cool example I wanted to mention that was slightly again more natural language processing.

1874
02:56:39,820 --> 02:56:51,820
So that's actually my expertise area was I mentor this group of three high school girls as part of AI for All, amazing profit that's trying to involve kids into artificial intelligence at a young age.

1875
02:56:51,820 --> 02:56:58,820
And they created this application that passes 911 EMS emergency medical service calls.

1876
02:56:59,820 --> 02:57:04,820
And based on that, it detects if where exactly should the ambulance go.

1877
02:57:05,820 --> 02:57:19,820
San Francisco and in the recent year, San Francisco has had a huge ambulance crisis where there are not enough ambulances and ambulances can take as long as up to 40 minutes to arrive, which is ridiculous.

1878
02:57:19,820 --> 02:57:26,820
So this application, it goes through the transcripts of what the you know, the audit record is of what you're seeing.

1879
02:57:27,820 --> 02:57:34,820
And then it detects keywords saying things like, okay, if someone had a fall, it's probably lower priority versus someone who's had a heart attack.

1880
02:57:35,820 --> 02:57:40,820
And it prioritizes that and then puts it all in a map, like what is the closest location and what is the high priority.

1881
02:57:41,820 --> 02:57:42,820
So it's like a blinking red.

1882
02:57:43,820 --> 02:57:46,820
And then a slightly lower priority would be like, you know, a yellow or green and things like that.

1883
02:57:47,820 --> 02:57:50,820
So there are a lot of really cool applications for data science.

1884
02:57:51,820 --> 02:57:55,820
It could be something another early important resource.

1885
02:57:56,820 --> 02:57:58,820
So useful resource I like is 538 by Nate Silver.

1886
02:57:59,820 --> 02:58:03,820
If you're aware of him, he was pretty popular for predicting the election results.

1887
02:58:04,820 --> 02:58:09,820
And there was this huge fiasco of how even he wasn't able to predict the last election results correctly.

1888
02:58:09,820 --> 02:58:21,820
But they usually publish statistical blogs, but they do a very good job of explaining why, for instance, Liverpool has a 4% chance of making it to the finals in the league.

1889
02:58:22,820 --> 02:58:25,820
I don't know if any of you follow soccer and watch that.

1890
02:58:26,820 --> 02:58:29,820
But so then they also target other sports.

1891
02:58:30,820 --> 02:58:36,820
They also target elections and they kind of explain how statistics informs their models.

1892
02:58:36,820 --> 02:58:42,820
And how when they say 75% probability of something happening, that is completely different from 70% probability happening.

1893
02:58:43,820 --> 02:58:49,820
And why is that difference of 5%, which might seem really negligible to us, is actually important, statistically important.

1894
02:58:51,820 --> 02:58:52,820
Yeah, I think that's it from me.

1895
02:58:53,820 --> 02:58:54,820
I'm just going to have it on now.

1896
02:58:55,820 --> 02:58:57,820
But feel free to ask me any questions if you have.

1897
02:58:58,820 --> 02:58:59,820
I hope you enjoyed the tutorial.

1898
02:59:00,820 --> 02:59:02,820
I will be sending out a link.

1899
02:59:02,820 --> 02:59:05,820
I'll be sending out a tweet with the updated slides.

1900
02:59:06,820 --> 02:59:08,820
It's still going to be on the same link that you accessed.

1901
02:59:09,820 --> 02:59:11,820
I would also love to receive any feedback.

1902
02:59:12,820 --> 02:59:16,820
I usually do one to two hour tutorials, so this three hour was something new for me as well.

1903
02:59:17,820 --> 02:59:18,820
But I hope it wasn't tiring.

1904
02:59:18,820 --> 02:59:22,820
I hope you all got something out of it and you definitely have the notebooks and resources to refer to.

1905
02:59:23,820 --> 02:59:29,820
And I hope I've sparked some interest of data science in all of you when you're going back home with Mona Lisa.

1906
02:59:29,820 --> 02:59:30,820
Thank you.

