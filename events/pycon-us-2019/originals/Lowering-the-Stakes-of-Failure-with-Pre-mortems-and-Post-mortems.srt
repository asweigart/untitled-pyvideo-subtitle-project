1
00:00:00,000 --> 00:00:06,960
Good afternoon, everybody, and welcome to this session of PyCon 2019.

2
00:00:06,960 --> 00:00:11,000
Our next speaker is Liz Sander, and she'll be talking about lowering the stakes of failure

3
00:00:11,000 --> 00:00:12,880
with premortems and postmortems.

4
00:00:12,880 --> 00:00:13,880
Thank you very much.

5
00:00:13,880 --> 00:00:16,880
Make a full welcome.

6
00:00:16,880 --> 00:00:20,160
Hi, everyone.

7
00:00:20,160 --> 00:00:24,440
So, failure.

8
00:00:24,440 --> 00:00:26,840
It's scary.

9
00:00:26,840 --> 00:00:28,680
For all of us.

10
00:00:28,680 --> 00:00:32,520
But it can look really different depending on what you do.

11
00:00:32,520 --> 00:00:38,600
So if you're here because you're familiar with postmortems, maybe you think of an incident

12
00:00:38,600 --> 00:00:44,340
or a failure in this sort of traditional site reliability engineer context where it means

13
00:00:44,340 --> 00:00:46,400
system downtime.

14
00:00:46,400 --> 00:00:52,400
But maybe depending on your job, it looks more like a security vulnerability or shipping

15
00:00:52,400 --> 00:00:56,120
a critical bug in something that isn't a web service.

16
00:00:56,120 --> 00:01:01,480
If you're a data scientist, maybe you shipped a model that's really wrong on some subset

17
00:01:01,480 --> 00:01:07,040
of data or it's unfair with respect to a protected class.

18
00:01:07,040 --> 00:01:12,320
Maybe you're a consultant and it looks more like a net loss on a consulting engagement.

19
00:01:12,320 --> 00:01:17,020
And for all of us who are under deadlines of some kind, maybe you miss a critical deadline.

20
00:01:17,020 --> 00:01:23,400
And that's also something important that you want to mitigate and avoid in the future.

21
00:01:23,680 --> 00:01:28,200
So I think that pre-mortems and postmortems are great tools for all of these kinds of

22
00:01:28,200 --> 00:01:32,200
failure and not just for SRE.

23
00:01:32,200 --> 00:01:34,200
Why is failure so scary?

24
00:01:34,200 --> 00:01:36,480
There are a couple of obvious reasons, right?

25
00:01:36,480 --> 00:01:38,320
It costs the company money.

26
00:01:38,320 --> 00:01:39,640
It takes up your time.

27
00:01:39,640 --> 00:01:41,640
It takes up your team's time.

28
00:01:41,640 --> 00:01:44,800
Maybe external users are affected and it costs them time and money.

29
00:01:44,800 --> 00:01:46,760
It makes them unhappy.

30
00:01:46,760 --> 00:01:51,080
But I think there's also this big emotional component to it, too, right?

31
00:01:51,320 --> 00:01:56,560
I think it's easy to feel really embarrassed and ashamed if you feel like you're responsible

32
00:01:56,560 --> 00:01:58,200
for failing.

33
00:01:58,200 --> 00:02:02,440
You feel like you let your team down or your company or your users.

34
00:02:02,440 --> 00:02:08,000
And so it becomes really difficult to talk about failure because there's these high emotional

35
00:02:08,000 --> 00:02:09,000
stakes.

36
00:02:09,000 --> 00:02:13,720
Fortunately, I'm here to tell you that failure isn't about you.

37
00:02:13,720 --> 00:02:16,160
Or at least it's not just about you.

38
00:02:16,160 --> 00:02:19,040
These mistakes happen in a context.

39
00:02:19,040 --> 00:02:23,800
If you're working with a team, that team has time pressures.

40
00:02:23,800 --> 00:02:28,680
There are sort of informal or formal incentives and norms that affect what you put your time

41
00:02:28,680 --> 00:02:33,040
into and what things you try to finish quickly.

42
00:02:33,040 --> 00:02:38,200
And then there's the matter of how well-trained you are and how much training your team has.

43
00:02:38,200 --> 00:02:42,160
Does your team have the expertise it needs to be successful?

44
00:02:42,160 --> 00:02:48,280
And then there are also process elements that maybe you have a little bit more control over.

45
00:02:48,320 --> 00:02:53,480
So if you're pushing code into production, you probably do some kind of testing.

46
00:02:53,480 --> 00:02:54,800
How automated is that?

47
00:02:54,800 --> 00:02:59,160
Are there manual steps that are easy to skip or get wrong?

48
00:02:59,160 --> 00:03:01,640
How well-documented is the code?

49
00:03:01,640 --> 00:03:04,920
Is it easy to introduce bugs because it's hard to understand what's happening in the

50
00:03:04,920 --> 00:03:06,440
code?

51
00:03:06,440 --> 00:03:10,320
And is the release process itself well-documented?

52
00:03:10,320 --> 00:03:15,240
If you're running into timeline slippages, maybe the issues that you don't do time or

53
00:03:15,240 --> 00:03:17,000
issue tracking.

54
00:03:17,000 --> 00:03:21,280
Do you know whether you're on track for a project at any given time?

55
00:03:21,280 --> 00:03:26,320
And then finally, you may want to think about whether someone else takes a look at your

56
00:03:26,320 --> 00:03:31,440
code or methods before it goes into production and having some kind of formal code or methods

57
00:03:31,440 --> 00:03:33,800
review.

58
00:03:33,800 --> 00:03:40,000
The key idea here is that individuals are fallible and we're all going to make mistakes.

59
00:03:40,000 --> 00:03:44,440
We can try to improve over time, too, but we're just not going to be perfect, especially

60
00:03:44,440 --> 00:03:50,160
in a really high-stress situation like pushing a critical bug into production.

61
00:03:50,160 --> 00:03:55,760
And so we need to think as teams so that we can establish systems that catch and mitigate

62
00:03:55,760 --> 00:03:59,320
the effects of failure.

63
00:03:59,320 --> 00:04:02,080
And this is why blameless postmortems are great.

64
00:04:02,080 --> 00:04:08,200
They're a tool to help lower the emotional stakes and it lets us think of incidents as

65
00:04:08,200 --> 00:04:13,320
not just failure but a learning opportunity and something that we can use to get better

66
00:04:13,320 --> 00:04:16,080
over time.

67
00:04:16,080 --> 00:04:18,880
So what is a postmortem exactly?

68
00:04:18,880 --> 00:04:26,320
So broadly it's a process to document an incident, identify the root cause, and figure out what

69
00:04:26,320 --> 00:04:31,480
actions you should take to avoid or mitigate the impact of similar types of problems in

70
00:04:31,480 --> 00:04:33,480
the future.

71
00:04:33,480 --> 00:04:39,800
And again, I just want to reinforce that even though these are really common in site reliability

72
00:04:40,680 --> 00:04:42,480
postmortems aren't just for SREs.

73
00:04:42,480 --> 00:04:46,080
They can be applied to all the types of failures that I mentioned at the beginning of the talk

74
00:04:46,080 --> 00:04:49,720
and lots of others that didn't occur to me.

75
00:04:49,720 --> 00:04:51,960
It's a very general process.

76
00:04:51,960 --> 00:04:56,940
It's really just a meeting where you talk about the incident in a structured way.

77
00:04:56,940 --> 00:05:03,720
And the deliverable is a document that goes through what happened and writes out what

78
00:05:03,720 --> 00:05:07,000
you need to take action on.

79
00:05:07,000 --> 00:05:09,640
So I mentioned the phrase blameless postmortem.

80
00:05:09,640 --> 00:05:12,400
What does the blameless part mean?

81
00:05:12,400 --> 00:05:22,120
So the idea here is that it's very easy to for a meeting about an incident to turn into

82
00:05:22,120 --> 00:05:23,120
finger pointing.

83
00:05:23,120 --> 00:05:24,120
Right?

84
00:05:24,120 --> 00:05:25,480
Like you're talking about a failure that happened.

85
00:05:25,480 --> 00:05:27,640
You want to identify why it happened.

86
00:05:27,640 --> 00:05:31,000
And it's easy to say, oh, it happened because of that person.

87
00:05:31,000 --> 00:05:35,760
But that makes it difficult for people to feel safe reporting incidents and talk about

88
00:05:35,760 --> 00:05:37,200
them.

89
00:05:37,200 --> 00:05:41,040
If you think you're at risk of being blamed or getting in trouble, you're not going to

90
00:05:41,040 --> 00:05:42,960
talk about these things very openly.

91
00:05:42,960 --> 00:05:48,000
So you need a blameless process for people to feel comfortable talking about these things.

92
00:05:48,000 --> 00:05:52,800
And the focus needs to be on understanding the root causes of the incident, the systems

93
00:05:52,800 --> 00:05:58,440
underlying it, so that we can improve as a team rather than assigning blame to individuals.

94
00:05:58,440 --> 00:06:04,040
And the idea here is that every individual is accountable for helping the team function,

95
00:06:04,040 --> 00:06:09,480
but no one person is responsible for a specific incident.

96
00:06:09,480 --> 00:06:14,640
So the first time I heard about postmortems, my first thought was, yeah, okay.

97
00:06:14,640 --> 00:06:17,400
But like, what if it's really one person's fault?

98
00:06:17,400 --> 00:06:18,400
Right?

99
00:06:18,400 --> 00:06:23,520
So I do want to underline this really isn't true most of the time.

100
00:06:23,520 --> 00:06:26,640
People take actions within a context.

101
00:06:26,640 --> 00:06:32,720
And the idea behind a blamelessly written postmortem is that everyone involved had good

102
00:06:32,760 --> 00:06:37,320
intentions and was doing the right thing with the information they had.

103
00:06:37,320 --> 00:06:41,680
But maybe the information was incomplete or confusing.

104
00:06:41,680 --> 00:06:44,760
And that's where there are opportunities to improve.

105
00:06:44,760 --> 00:06:48,960
If you feel like you were really directly responsible for an incident, it's great to

106
00:06:48,960 --> 00:06:53,000
reflect on what you individually could improve on.

107
00:06:53,000 --> 00:06:55,640
But that's really not the goal of a postmortem.

108
00:06:55,640 --> 00:07:02,640
And it doesn't make sense to turn the focus of the meeting into, like, your own personal

109
00:07:02,680 --> 00:07:05,040
feelings or concerns.

110
00:07:05,040 --> 00:07:10,240
And again, if someone on the team has recurring performance issues, that is also important.

111
00:07:10,240 --> 00:07:13,440
But that's an issue for them to address with their manager.

112
00:07:13,440 --> 00:07:17,640
And again, it's really not the focus of a postmortem.

113
00:07:17,640 --> 00:07:21,280
So to ground this in a specific example, I want to talk about the first postmortem that

114
00:07:21,280 --> 00:07:22,840
I did.

115
00:07:22,840 --> 00:07:29,960
So failure for me as a data scientist looks like releasing buggy data science code.

116
00:07:30,520 --> 00:07:35,640
So I helped maintain this library that's essentially a generalized modeling tool.

117
00:07:35,640 --> 00:07:39,680
My maintainer, who is also my manager, was out of town.

118
00:07:39,680 --> 00:07:42,880
But this was a really small bug fix release.

119
00:07:42,880 --> 00:07:44,680
And so I wasn't too worried about it.

120
00:07:44,680 --> 00:07:48,880
There were just a couple of bugs and a minor internal dependency change.

121
00:07:48,880 --> 00:07:51,920
I ran my unit tests, I ran some integration tests.

122
00:07:51,920 --> 00:07:53,080
Everything worked fine.

123
00:07:53,080 --> 00:07:55,320
I released it into production.

124
00:07:55,320 --> 00:07:56,320
Everything broke.

125
00:07:56,320 --> 00:07:59,000
Every single job failed.

126
00:07:59,080 --> 00:08:00,440
I was pretty new to the company.

127
00:08:00,440 --> 00:08:02,520
I totally panicked.

128
00:08:02,520 --> 00:08:03,880
I worked with IT.

129
00:08:03,880 --> 00:08:10,400
So the way that this code works is it auto builds versioned Docker images that then end

130
00:08:10,400 --> 00:08:13,680
up being the version that runs in production.

131
00:08:13,680 --> 00:08:20,480
And so everyone's in the internal company, everyone's code was broken.

132
00:08:20,480 --> 00:08:25,120
So I worked with IT to try to revert the Docker images, and we weren't able to do that.

133
00:08:25,120 --> 00:08:27,480
Then I brought in sort of a backup co-maintainer.

134
00:08:27,480 --> 00:08:31,680
We tried to debug for a while, and eventually at the end of the day, we decided just to

135
00:08:31,680 --> 00:08:36,840
release a new patch version that essentially just reverted it back until we could do it

136
00:08:36,840 --> 00:08:39,400
the right way.

137
00:08:39,400 --> 00:08:42,520
So my manager came back, and I felt really bad.

138
00:08:42,520 --> 00:08:46,920
I talked to him about what happened, and he said, that's fine.

139
00:08:46,920 --> 00:08:51,120
We should have a postmortem and talk about it so that we can learn from it.

140
00:08:51,120 --> 00:08:53,120
So what exactly did that look like?

141
00:08:53,120 --> 00:08:57,800
So first you need to figure out who you're going to invite.

142
00:08:57,800 --> 00:09:02,280
And you want to bring, it should be a fairly small group of people who are directly involved

143
00:09:02,280 --> 00:09:03,520
in the incident.

144
00:09:03,520 --> 00:09:08,480
In this case, it was just me, the co-maintainer who helped me out, and my manager who acted

145
00:09:08,480 --> 00:09:10,480
as a facilitator.

146
00:09:10,480 --> 00:09:14,240
We could have also brought in IT who worked with me on the Docker images, but since that

147
00:09:14,240 --> 00:09:18,800
didn't actually resolve the issue, we decided to save them the meeting.

148
00:09:18,800 --> 00:09:23,560
If this had been a more major incident that affected external users, then we would have

149
00:09:23,560 --> 00:09:28,120
probably wanted to bring in someone who had worked directly with the clients, maybe a

150
00:09:28,120 --> 00:09:32,520
client success representative, and maybe a product manager who was more focused on the

151
00:09:32,520 --> 00:09:36,320
product side.

152
00:09:36,320 --> 00:09:40,560
Then you'll have a postmortem template, and you want to try to fill in a lot of major

153
00:09:40,560 --> 00:09:44,800
parts of that, and then you can discuss it in the meeting itself.

154
00:09:44,800 --> 00:09:47,420
So those things are the incident period.

155
00:09:47,420 --> 00:09:50,820
So that's just the time span that was affected.

156
00:09:50,820 --> 00:09:55,780
The current status, which is hopefully resolved, but maybe there are ongoing issues, and if

157
00:09:55,780 --> 00:09:58,100
so, you want to mention those.

158
00:09:58,100 --> 00:10:00,420
A summary of the incident.

159
00:10:00,420 --> 00:10:02,700
How it affected users.

160
00:10:02,700 --> 00:10:06,780
The trigger, so that's the specific thing that caused the incident.

161
00:10:06,780 --> 00:10:11,340
How it was detected, which in this case was me running some integration tests on the actual

162
00:10:11,340 --> 00:10:13,260
production code.

163
00:10:13,260 --> 00:10:17,180
How it was resolved, including things you tried that didn't work.

164
00:10:17,340 --> 00:10:22,740
And any ideas that you have up front for action items.

165
00:10:22,740 --> 00:10:27,780
So then you want your facilitator to probably not be the person who is most directly involved

166
00:10:27,780 --> 00:10:31,780
in the incident, because you want someone who can kind of moderate the discussion, make

167
00:10:31,780 --> 00:10:36,620
sure it's staying productive, and keep the flow of the meeting going.

168
00:10:36,620 --> 00:10:40,600
And you want to start by reading through a timeline so that everyone agrees on the basic

169
00:10:40,600 --> 00:10:42,700
facts of the situation.

170
00:10:42,700 --> 00:10:46,860
In this case, I'm just saying the general time is like two around the hour, because

171
00:10:46,860 --> 00:10:52,180
I wasn't under any kind of SLA as far as the uptime of this library was concerned.

172
00:10:52,180 --> 00:10:56,260
But if you are working in more of an SRE context, maybe it's important to say to the minute

173
00:10:56,260 --> 00:11:00,060
or second what times things happened.

174
00:11:00,060 --> 00:11:04,700
So again, the basic flow is that I tagged this release, I ran some tests and discovered

175
00:11:04,700 --> 00:11:06,060
the bug.

176
00:11:06,060 --> 00:11:10,060
Then I spent a couple hours working with IT and trying to revert the images.

177
00:11:10,060 --> 00:11:15,220
In the afternoon, I brought in a co-maintainer, and at the end of the day, we decided to release

178
00:11:15,220 --> 00:11:20,100
a version to revert the broken code.

179
00:11:20,100 --> 00:11:25,020
Now that you have those basic facts, you want to agree on the issues that are essentially

180
00:11:25,020 --> 00:11:28,140
underlying the incident.

181
00:11:28,140 --> 00:11:31,780
So the trigger is the specific immediate cause.

182
00:11:31,780 --> 00:11:37,860
And in that case, it was this internal dependency where the bug didn't show up until the actual

183
00:11:38,340 --> 00:11:40,940
production.

184
00:11:40,940 --> 00:11:43,540
Then the impact is the effect on the users.

185
00:11:43,540 --> 00:11:46,200
And in this case, it was an internal release only.

186
00:11:46,200 --> 00:11:53,420
So the impact was that there was about a day of downtime for our internal data scientists.

187
00:11:53,420 --> 00:11:58,420
And fortunately, no client deliverables were affected.

188
00:11:58,420 --> 00:12:00,860
Then you all want to agree about the root causes.

189
00:12:00,860 --> 00:12:05,520
And this is the really critical part, because this is the underlying systems that resulted

190
00:12:05,520 --> 00:12:07,500
in the problem.

191
00:12:08,140 --> 00:12:14,500
This was that we didn't have a great way to test our code against the actual production

192
00:12:14,500 --> 00:12:15,500
environment.

193
00:12:15,500 --> 00:12:20,180
I was running all of my tests on a slightly outdated version of our dependencies, and

194
00:12:20,180 --> 00:12:25,980
so we weren't actually testing everything together.

195
00:12:25,980 --> 00:12:33,300
Now that you have those underlying root causes, you can talk about generally what went well.

196
00:12:34,100 --> 00:12:38,400
There you want to focus on what parts of the process to keep and replicate elsewhere.

197
00:12:38,400 --> 00:12:44,620
It's also a nice way to recognize the work that people involved in the incident did.

198
00:12:44,620 --> 00:12:48,200
And it, again, lowers the emotional temperature a little bit.

199
00:12:48,200 --> 00:12:53,780
So in this case, I ran these acceptance tests and caught the bug immediately and was able

200
00:12:53,780 --> 00:12:58,940
to talk to everyone in the company and give them a workaround.

201
00:12:59,580 --> 00:13:03,880
And so it didn't affect anyone without their knowledge.

202
00:13:03,880 --> 00:13:08,280
And this meant that we had a little bit more breathing room to try to solve the bug.

203
00:13:08,280 --> 00:13:10,000
Then you want to talk about what went badly.

204
00:13:10,000 --> 00:13:15,560
And those are the areas that need attention, where you want to focus your action items.

205
00:13:15,560 --> 00:13:19,960
And in this case, it was that we didn't have a production environment to test our code

206
00:13:19,960 --> 00:13:22,040
in.

207
00:13:22,040 --> 00:13:24,120
Then you want to think about where you got lucky.

208
00:13:24,120 --> 00:13:27,660
This seems like kind of a weird question at first, like, why do you care?

209
00:13:27,920 --> 00:13:32,420
The idea here is that you want to identify areas that didn't break this time but easily

210
00:13:32,420 --> 00:13:36,400
could have and could have caused a more catastrophic incident.

211
00:13:36,400 --> 00:13:41,600
You also want to think about action items here because you can avoid future problems

212
00:13:41,600 --> 00:13:43,280
that are similar.

213
00:13:43,280 --> 00:13:48,420
And in this case, I got lucky that we had a backup maintainer for me to work with and

214
00:13:48,420 --> 00:13:50,580
that it was only an internal release.

215
00:13:50,580 --> 00:13:54,180
If this had been an external release, then clients would have been affected.

216
00:13:54,200 --> 00:13:57,780
We would have been under more time pressure, but we wouldn't necessarily have had better

217
00:13:57,780 --> 00:13:59,080
tools to fix it.

218
00:14:01,340 --> 00:14:04,060
Once you have those, you can talk about the actual action items.

219
00:14:04,060 --> 00:14:07,560
And you want to assign them owners so that there's accountability.

220
00:14:07,560 --> 00:14:11,360
And in this case, it was mostly updates to our release checklist.

221
00:14:11,360 --> 00:14:16,160
We came up with a process for running the tests in an environment that actually matches

222
00:14:16,160 --> 00:14:17,860
production.

223
00:14:17,860 --> 00:14:22,800
And we also added a note to never make a release without more than two maintainers available.

224
00:14:22,800 --> 00:14:26,780
That way, if another problem like this occurs, there's always someone to do code review

225
00:14:26,780 --> 00:14:29,360
to help you fix the bug.

226
00:14:29,360 --> 00:14:33,240
Then you can talk about more general lessons learned that you can bring to the project

227
00:14:33,240 --> 00:14:35,160
and to other projects.

228
00:14:35,160 --> 00:14:39,080
So one, obviously, is it's important to test in the production environment before you release

229
00:14:39,080 --> 00:14:40,540
your code.

230
00:14:40,540 --> 00:14:46,580
But also, we came up with a process for triaging these critically buggy releases.

231
00:14:46,580 --> 00:14:52,060
And we decided that you just want to immediately cut a new version that reverts back to the

232
00:14:52,060 --> 00:14:56,320
working version so that you have working code as quickly as possible.

233
00:14:56,320 --> 00:15:04,180
We tried to avoid this at first because we didn't want to have kind of a messy release

234
00:15:04,180 --> 00:15:05,180
change log.

235
00:15:05,180 --> 00:15:11,080
But we decided that it was worth it to have as much uptime as possible.

236
00:15:11,080 --> 00:15:12,700
So then what happens next?

237
00:15:12,700 --> 00:15:14,940
You want to follow up on those action items, of course.

238
00:15:14,940 --> 00:15:18,420
But also, you want to make the document available to the company.

239
00:15:18,420 --> 00:15:21,300
And potentially to the outside world, too.

240
00:15:21,300 --> 00:15:27,100
It's important to keep all these things together so that you can reference them in the future.

241
00:15:27,100 --> 00:15:31,200
And hopefully, the action items you came up with are things that go well in the future.

242
00:15:31,200 --> 00:15:34,340
This actually happened for this project a few months ago.

243
00:15:34,340 --> 00:15:41,140
I ran into kind of a related issue for a different library that was also related to Python dependency

244
00:15:41,140 --> 00:15:42,600
problems.

245
00:15:42,600 --> 00:15:48,460
And we knew that as soon as there was this critical bug, we just cut a new release reverting

246
00:15:48,460 --> 00:15:54,740
it back and then we could debug with minimal downtime.

247
00:15:54,740 --> 00:16:00,460
So postmortems are a really good way to iteratively improve and learn from past failure.

248
00:16:00,460 --> 00:16:04,100
And these should sort of compound on each other so that you have this accumulation of

249
00:16:04,100 --> 00:16:09,360
things that you've learned and processes that help you respond to incidents effectively.

250
00:16:09,360 --> 00:16:12,560
But what if you're starting a big new project and you want to avoid these pitfalls in the

251
00:16:12,560 --> 00:16:14,820
first place?

252
00:16:14,820 --> 00:16:18,660
Maybe we can postmortem a project before it actually fails.

253
00:16:18,660 --> 00:16:21,500
And that's where pre-mortems come in.

254
00:16:21,500 --> 00:16:24,540
So just to ground this in an example again, I'm going to talk about the first pre-mortem

255
00:16:24,540 --> 00:16:27,540
that I did.

256
00:16:27,540 --> 00:16:32,860
The project was a Flask app to explore audiences, essentially segments within a customer base.

257
00:16:32,860 --> 00:16:35,820
And it was a pretty big project with a lot of moving parts.

258
00:16:35,820 --> 00:16:41,380
We were working in cross-functional teams that were fairly new, including engineers,

259
00:16:41,380 --> 00:16:43,760
data scientists, and product people.

260
00:16:43,760 --> 00:16:48,280
There was a lot of data and we had both data and models in our database and we needed to

261
00:16:48,280 --> 00:16:49,880
handle them differently.

262
00:16:49,880 --> 00:16:55,040
And then we had different clients who had different needs for their data and their visualizations.

263
00:16:55,040 --> 00:16:59,880
We also had some hard deadlines we were working with and a lot of uncertainty about the process.

264
00:16:59,880 --> 00:17:03,080
So people were understandably anxious about it.

265
00:17:03,080 --> 00:17:07,280
And then my colleague Henry, whose talk on model fairness you may have seen yesterday,

266
00:17:07,280 --> 00:17:11,840
decided, well, we should have a pre-mortem and just talk about these things rather than

267
00:17:11,840 --> 00:17:14,960
silently all being anxious about it.

268
00:17:14,960 --> 00:17:18,040
And so he put together a pre-mortem meeting.

269
00:17:18,040 --> 00:17:20,080
This looks in some ways like a post-mortem.

270
00:17:20,080 --> 00:17:23,360
You want to have a facilitator who's orchestrating everything.

271
00:17:23,360 --> 00:17:27,120
But in this case, you want to have a lot of stakeholders across different departments

272
00:17:27,120 --> 00:17:29,320
because you don't know what the incident is going to look like.

273
00:17:29,320 --> 00:17:31,800
So you want to cast the net wide.

274
00:17:31,800 --> 00:17:36,280
So we had engineers, data scientists, people from product, and then also people who are

275
00:17:36,280 --> 00:17:41,080
going to be selling the tool and working with clients.

276
00:17:41,080 --> 00:17:43,480
So then you're ready to have your actual meeting.

277
00:17:43,480 --> 00:17:48,680
The basic pre-mortem structure is saying, our project has failed.

278
00:17:48,680 --> 00:17:51,440
What happened?

279
00:17:51,440 --> 00:17:55,020
So first you're going to brainstorm about this for maybe 20 to 30 minutes.

280
00:17:55,020 --> 00:17:58,380
And hopefully you come up with ideas that are all over the place that are coming from

281
00:17:58,380 --> 00:18:00,100
lots of different domains.

282
00:18:00,100 --> 00:18:04,380
So our engineers were coming up with things like the app is really slow or it's difficult

283
00:18:04,380 --> 00:18:05,620
to deploy.

284
00:18:05,620 --> 00:18:10,440
The data scientists were worried about the ETL to get the data into the app and the models

285
00:18:10,440 --> 00:18:12,240
themselves being bad.

286
00:18:12,240 --> 00:18:16,560
And then the people who are client-facing and selling the tool were thinking, well,

287
00:18:16,560 --> 00:18:22,160
maybe we build a great tool, but no one wants to use it or understands it.

288
00:18:22,160 --> 00:18:27,960
So once you get lots of these ideas out there, you want to organize them into a few major

289
00:18:27,960 --> 00:18:31,960
categories, definitely less than 10, but maybe around five.

290
00:18:31,960 --> 00:18:37,240
And so some of the categories we came up with were performance of the app, security breaches,

291
00:18:37,240 --> 00:18:41,520
in-line slip, major feature gaps, and people not using it.

292
00:18:41,520 --> 00:18:49,280
And you want these to be pretty major risks and problems that could happen, not something

293
00:18:49,280 --> 00:18:53,960
that is fairly minor.

294
00:18:53,960 --> 00:18:56,680
And then you want to estimate how important they are.

295
00:18:56,680 --> 00:19:01,920
So to do this, everyone votes from one to three on how likely they think it is to occur

296
00:19:01,920 --> 00:19:04,280
and how high the impact is.

297
00:19:04,280 --> 00:19:06,600
And then you average those numbers.

298
00:19:06,600 --> 00:19:10,920
So you can see here that we thought that security wasn't a super high-risk issue because it

299
00:19:10,920 --> 00:19:13,480
was something we were already thinking about a lot.

300
00:19:13,480 --> 00:19:16,920
But obviously, if it happened, the impact would be huge.

301
00:19:16,920 --> 00:19:20,440
On the other hand, we thought a timeline slip was pretty likely because we knew there was

302
00:19:20,440 --> 00:19:22,360
a lot of uncertainty there.

303
00:19:22,360 --> 00:19:25,760
But the impact is not quite as high, right?

304
00:19:25,760 --> 00:19:27,640
These things happen.

305
00:19:27,640 --> 00:19:31,080
And then you multiply the probability and impact together to get an overall importance

306
00:19:31,080 --> 00:19:32,080
score.

307
00:19:32,080 --> 00:19:35,960
So in this case, we were kind of surprised at what came out of this.

308
00:19:35,960 --> 00:19:41,720
Security ended up being relatively unimportant relative to other things as a focus for this

309
00:19:41,720 --> 00:19:47,560
meeting because even though the impact was high, we didn't think it was so likely.

310
00:19:47,560 --> 00:19:52,560
But we thought that feature gaps were both pretty likely and pretty impactful.

311
00:19:52,560 --> 00:19:56,920
So then you want to go from most important to least important and spend some time talking

312
00:19:56,920 --> 00:20:01,200
about what you could have done to avoid or mitigate the failure.

313
00:20:01,200 --> 00:20:06,880
So in this case, we realized that there were a lot of concerns around people not using

314
00:20:06,880 --> 00:20:09,060
it and it not being quite the right tool.

315
00:20:09,060 --> 00:20:14,840
And so we decided to have ongoing user interviews and discussions with our stakeholder clients

316
00:20:14,840 --> 00:20:20,360
to make sure that we were building the right MVP.

317
00:20:20,360 --> 00:20:26,240
Then after the meeting, you need whoever took notes to compile those into a nice format

318
00:20:26,240 --> 00:20:30,200
and send them out so people can discuss a little bit more, add anything that they think

319
00:20:30,200 --> 00:20:31,960
is missing.

320
00:20:31,960 --> 00:20:36,000
And then you want this to be a living document that you reference regularly.

321
00:20:36,000 --> 00:20:40,040
And ideally, you want to check in on those risks and the action items to make sure you're

322
00:20:40,040 --> 00:20:41,640
following up.

323
00:20:41,640 --> 00:20:46,800
If you work in a sprint framework, maybe you can make your sprint retrospective include

324
00:20:46,800 --> 00:20:50,760
a little bit of time to look at those risks and action items.

325
00:20:50,760 --> 00:20:55,000
And of course, if you have any postmortems where there are actual incidents that happen,

326
00:20:55,000 --> 00:21:00,160
Bring your pre-mortem document and see, were these problems that we anticipated?

327
00:21:00,160 --> 00:21:02,040
Did we follow up on the action items?

328
00:21:02,040 --> 00:21:06,960
And was there anything that was missing?

329
00:21:06,960 --> 00:21:10,320
So I want to take a step back and think, why bother doing this?

330
00:21:10,320 --> 00:21:11,800
This seems pretty negative, right?

331
00:21:11,800 --> 00:21:16,020
Having a meeting for everyone to talk about how your project's going to fail.

332
00:21:16,020 --> 00:21:21,080
But it's pretty important because it's easy when leadership is really enthusiastic about

333
00:21:21,080 --> 00:21:22,120
a project.

334
00:21:22,120 --> 00:21:25,680
People can feel concerned about bringing up things that they think might fail, even if

335
00:21:25,680 --> 00:21:28,920
they think it's pretty likely to go wrong.

336
00:21:28,920 --> 00:21:33,480
And so having a meeting where you are supposed to talk about these things, and that is literally

337
00:21:33,480 --> 00:21:37,960
the point of the meeting, means that those concerns are now a valuable asset for the

338
00:21:37,960 --> 00:21:39,140
team.

339
00:21:39,140 --> 00:21:44,600
People feel a little bit less nervous about it and more empowered to bring up their worries.

340
00:21:44,600 --> 00:21:50,260
It also reveals issues that are kind of domain specific to the entire team.

341
00:21:50,260 --> 00:21:54,500
Those of us who are working on the technical side were less tuned in to the product and

342
00:21:54,500 --> 00:21:57,740
sales related concerns and vice versa.

343
00:21:57,740 --> 00:22:00,820
But we all were on the same page afterwards.

344
00:22:00,820 --> 00:22:04,340
And this is why it's really important to have a variety of stakeholders, both technical

345
00:22:04,340 --> 00:22:06,700
and non-technical.

346
00:22:06,700 --> 00:22:11,660
It also lets everyone reflect on the project and the processes before something fails.

347
00:22:11,660 --> 00:22:17,540
Make sure you're building the right thing and that you're set up for success.

348
00:22:17,540 --> 00:22:21,060
And because everyone gets to get their concerns out there and have them listened to and taken

349
00:22:21,060 --> 00:22:28,300
seriously, it's easier for people to get on board and be enthusiastic about the project.

350
00:22:28,300 --> 00:22:31,860
So I just have a few closing thoughts.

351
00:22:31,860 --> 00:22:35,620
So failure is really scary, but it's also important.

352
00:22:35,620 --> 00:22:39,460
And we need to use it as an opportunity to learn.

353
00:22:39,460 --> 00:22:44,500
But we can only do that by talking about it and bringing it out into the open.

354
00:22:44,500 --> 00:22:50,900
It can be scary to do that too, because it's easy to feel like you're going to get punished.

355
00:22:50,900 --> 00:22:52,500
And sometimes that's actually true.

356
00:22:52,500 --> 00:22:54,460
Sometimes those fears are well founded.

357
00:22:54,460 --> 00:22:57,380
And this is why we need things like pre-mortems and post-mortems.

358
00:22:57,380 --> 00:23:01,700
These are specific processes where you're supposed to talk about failure.

359
00:23:01,700 --> 00:23:06,200
And you get to bring these things out into the open, both before a project starts and

360
00:23:06,200 --> 00:23:09,540
after a specific incident occurs.

361
00:23:09,580 --> 00:23:15,380
And hopefully introducing these into a team creates a more general environment of openness,

362
00:23:15,380 --> 00:23:20,220
where people feel like they can talk about incidents and concerns that they have, even

363
00:23:20,220 --> 00:23:23,020
when they're not in these meetings.

364
00:23:23,020 --> 00:23:27,060
And overall, the most important thing here is that you're focusing on the team, on the

365
00:23:27,060 --> 00:23:31,060
systems and the processes, rather than blaming individuals.

366
00:23:31,060 --> 00:23:37,620
That's really what creates that culture of openness and lets people learn from failure.

367
00:23:37,700 --> 00:23:40,180
So with that, I want to leave you with a few resources.

368
00:23:40,180 --> 00:23:42,180
I'm going to post my slides on my website.

369
00:23:42,180 --> 00:23:45,900
They should also be available on PyCon.

370
00:23:45,900 --> 00:23:48,580
Google has a great book on site reliability engineering.

371
00:23:48,580 --> 00:23:52,140
Even if you aren't an SRE, I recommend you take a look at their chapter on post-mortem

372
00:23:52,140 --> 00:23:53,140
culture.

373
00:23:53,140 --> 00:23:55,740
It's available online for free.

374
00:23:55,740 --> 00:23:59,260
And I think it's a really useful way to think about it.

375
00:23:59,260 --> 00:24:03,180
They also have an example post-mortem template there that you can use if you're implementing

376
00:24:03,180 --> 00:24:05,980
post-mortems in your team.

377
00:24:06,340 --> 00:24:09,780
This pager duty link is helpful because there are lots of example post-mortems, so you can

378
00:24:09,780 --> 00:24:11,100
see what these look like.

379
00:24:11,100 --> 00:24:15,380
Again, that's going to be focused on the SRE context, but I encourage you to think broadly

380
00:24:15,380 --> 00:24:18,540
about how you can use them in your own team.

381
00:24:18,540 --> 00:24:21,460
And then I have a couple of articles here about pre-mortems.

382
00:24:21,460 --> 00:24:26,980
They're actually really different structures for running a pre-mortem, and it's just not

383
00:24:26,980 --> 00:24:28,340
one size fits all.

384
00:24:28,340 --> 00:24:32,180
So I encourage you to read a couple of different structures and think about what's going to

385
00:24:32,180 --> 00:24:35,180
work well for your team and for your project.

386
00:24:36,180 --> 00:24:40,180
So thank you for coming, and with that, I'm happy to take any questions.

387
00:24:40,180 --> 00:24:45,180
Thank you again, Liz.

388
00:24:45,180 --> 00:24:49,180
If there are questions, we have microphones in the aisles here.

389
00:24:51,180 --> 00:24:52,180
Hi.

390
00:24:52,180 --> 00:24:58,180
I was just wondering if you use any particular tools for recording your pre-mortems or post-mortems,

391
00:24:58,180 --> 00:25:00,180
or do you just use a document?

392
00:25:01,180 --> 00:25:04,180
So in my team, we just use a document.

393
00:25:04,180 --> 00:25:11,180
I know that there are tools out there, but especially because in this data science use

394
00:25:11,180 --> 00:25:15,180
case, it's kind of non-standard and there aren't tools that are really linked into the

395
00:25:15,180 --> 00:25:17,180
way that our workflow works.

396
00:25:17,180 --> 00:25:20,180
We mostly just structure it through the document.

397
00:25:20,180 --> 00:25:21,180
Thank you.

398
00:25:22,180 --> 00:25:23,180
Excellent talk.

399
00:25:23,180 --> 00:25:24,180
I enjoyed it quite a bit.

400
00:25:24,180 --> 00:25:28,180
My background is chemical engineering, and a lot of what you're describing, both the

401
00:25:28,180 --> 00:25:34,180
pre-mortem and the post-mortem, seems very similar to the process safety analyses done

402
00:25:34,180 --> 00:25:36,180
in the chemical process industry.

403
00:25:36,180 --> 00:25:42,180
Can you comment, do you know the best practices here, are they cross-fertilized with chemical

404
00:25:42,180 --> 00:25:46,180
process, and if not, that might be something to investigate?

405
00:25:47,180 --> 00:25:52,180
I'm actually not familiar with that, but it sounds like there's probably a lot of, maybe

406
00:25:52,180 --> 00:25:55,180
there's some convergent evolution there of those two ideas.

407
00:25:55,180 --> 00:25:59,180
So I think there's probably a lot that each of those processes could learn from each other.

408
00:25:59,180 --> 00:26:00,180
Agreed.

409
00:26:00,180 --> 00:26:01,180
Thank you.

410
00:26:01,180 --> 00:26:02,180
Thanks.

411
00:26:02,180 --> 00:26:06,180
I like your talk, especially the pre-mortem stuff seems really exciting.

412
00:26:06,180 --> 00:26:10,180
Lately, in my mind, I've been trying to figure out how to stop meetings from happening.

413
00:26:10,180 --> 00:26:12,180
I feel like there's too many meetings.

414
00:26:13,180 --> 00:26:18,180
On your pre-mortem, the part that feels exciting to be synchronous together is that brainstorm

415
00:26:18,180 --> 00:26:22,180
of what could go wrong and maybe that first collection of votes.

416
00:26:22,180 --> 00:26:27,180
But I'm worried about the follow-up where people are actually doing the rest of the work.

417
00:26:27,180 --> 00:26:30,180
It might feel slow and boring in some meetings.

418
00:26:30,180 --> 00:26:34,180
Could you break it into two pieces and do one part kind of asynchronously or live document style?

419
00:26:35,180 --> 00:26:36,180
So what part?

420
00:26:36,180 --> 00:26:38,180
You mean the organizing and voting?

421
00:26:38,180 --> 00:26:41,180
Yeah, what do you feel like is the most important part for the humans to do face-to-face?

422
00:26:41,180 --> 00:26:47,180
Yeah, I think that the brainstorming is the most important part, just getting all of those ideas on paper

423
00:26:47,180 --> 00:26:53,180
and everyone being ideally in one physical space, but all being in a meeting together to talk about those things.

424
00:26:53,180 --> 00:27:00,180
But in my experience, there also is value to people being there to talk through what we could do to mitigate them,

425
00:27:00,180 --> 00:27:09,180
just because I think there can be a combination of efforts from people on maybe the sales side and on the technical side

426
00:27:09,180 --> 00:27:11,180
that we wouldn't identify otherwise.

427
00:27:12,180 --> 00:27:19,180
And that's just because, at least in my experience, in most meetings you don't have those two pieces of the business together very often.

428
00:27:19,180 --> 00:27:25,180
And so it is nice to have a place where everyone is together and you can share ideas a little bit more.

429
00:27:25,180 --> 00:27:29,180
But I think it would be possible to do those asynchronously if you wanted.

430
00:27:32,180 --> 00:27:33,180
Great talk. Thank you.

431
00:27:34,180 --> 00:27:35,180
I just have a couple of questions.

432
00:27:35,180 --> 00:27:36,180
I just have a couple of questions.

433
00:27:36,180 --> 00:27:43,180
First, at what point in the life of a project do you typically start thinking about the pre-mortem meetings?

434
00:27:43,180 --> 00:27:46,180
And then how many times do you follow up on that first pre-mortem?

435
00:27:47,180 --> 00:27:49,180
So I'll answer that second question first.

436
00:27:49,180 --> 00:27:52,180
I think we should have followed up on it more than we actually did.

437
00:27:52,180 --> 00:27:59,180
I think we had one big check-in where we reflected on it, but I wish that we had made it part of our sprint retrospectives,

438
00:27:59,180 --> 00:28:01,180
and I think I would do that in the future.

439
00:28:01,180 --> 00:28:07,180
And so that would be every couple weeks just quickly scanning through those things and seeing if anything that's relevant comes up.

440
00:28:08,180 --> 00:28:09,180
What was the first question again?

441
00:28:09,180 --> 00:28:11,180
When do you typically start planning?

442
00:28:11,180 --> 00:28:18,180
Yeah. I think ideally you do it before you've written a lot of code, like when you're scoping out the project.

443
00:28:18,180 --> 00:28:22,180
And if it's something that you're working directly with one or two clients on,

444
00:28:22,180 --> 00:28:29,180
you want to be able to get in front of any scope creep related to those individual clients.

445
00:28:29,180 --> 00:28:34,180
So I think ideally during that scoping phase, but again that can depend a little bit on the project.

446
00:28:36,180 --> 00:28:38,180
We have time for one more question.

447
00:28:38,180 --> 00:28:40,180
Hi. Thank you for the great talk.

448
00:28:40,180 --> 00:28:43,180
My question is a little similar, but I'll try to make it distinct.

449
00:28:43,180 --> 00:28:49,180
So it seems like there's a bit of a kind of an exploration, exploitation trade-off with the timing of the pre-mortems.

450
00:28:49,180 --> 00:28:52,180
As you get closer and closer to the incident of potential failure,

451
00:28:52,180 --> 00:28:56,180
you might have more information about what could go wrong or the magnitude of it.

452
00:28:56,180 --> 00:29:02,180
So are there scenarios where you find yourself like delaying the pre-mortems due to acquiring more information,

453
00:29:02,180 --> 00:29:08,180
or do you think this kind of exploration, exploitation simile is a little off?

454
00:29:09,180 --> 00:29:14,180
Yeah, I think that can definitely be an issue because if the project isn't scoped enough yet,

455
00:29:14,180 --> 00:29:19,180
no one knows enough about it to really like say what could go wrong even.

456
00:29:19,180 --> 00:29:22,180
So it definitely is a balance.

457
00:29:23,180 --> 00:29:30,180
I think you probably would want to delay it until you at least have something on paper for what the scope is.

458
00:29:30,180 --> 00:29:34,180
You wouldn't want to talk about, well, those conversations are still really general

459
00:29:34,180 --> 00:29:37,180
because people need like one thing that they can reference and say,

460
00:29:37,180 --> 00:29:40,180
okay, I think here are specific things that could go wrong.

461
00:29:42,180 --> 00:29:43,180
Thank you again, Liz.

462
00:29:43,180 --> 00:29:44,180
Thanks.

