1
00:00:00,000 --> 00:00:02,000
.

2
00:00:30,000 --> 00:00:32,920
.

3
00:01:00,000 --> 00:01:05,640
Sciences, and Eric is a research scientist at Novatis in Cambridge.

4
00:01:05,640 --> 00:01:07,840
So let's start.

5
00:01:07,840 --> 00:01:12,200
Again, if there are still any issues with the setup, please use binder.

6
00:01:12,200 --> 00:01:16,000
Can we get a thumbs up?

7
00:01:16,000 --> 00:01:18,000
Everyone's ready?

8
00:01:18,000 --> 00:01:19,000
Yeah.

9
00:01:19,000 --> 00:01:20,920
Before we start, a bit of housekeeping.

10
00:01:20,920 --> 00:01:28,080
There would be a break at 10.15, a snacks break, and lunch is at 12.20, and we have

11
00:01:28,080 --> 00:01:33,280
power outlets all around, so use them.

12
00:01:33,280 --> 00:01:39,280
There would be a server link for the tutorial, which we'll post later through the tutorial

13
00:01:39,280 --> 00:01:41,000
email.

14
00:01:41,000 --> 00:01:52,160
So before we start, let's just get our gears running.

15
00:01:52,240 --> 00:01:55,240
This is...

16
00:01:55,240 --> 00:02:03,520
We have created a list of dictionaries, right?

17
00:02:03,520 --> 00:02:13,040
So can anyone tell me what would be this function if you want to find persons with the surname

18
00:02:13,040 --> 00:02:18,040
in this data structure?

19
00:02:18,120 --> 00:02:25,120
You don't have to write the code, you just have to tell the idea behind that.

20
00:02:25,120 --> 00:02:28,120
Yeah.

21
00:02:35,120 --> 00:02:36,120
Anyone?

22
00:02:36,200 --> 00:02:39,200
Yes.

23
00:02:39,200 --> 00:02:50,200
That's a perfect answer, yeah.

24
00:02:50,200 --> 00:02:54,960
So in this tutorial, we're going to work a lot with lists and dictionaries.

25
00:02:54,960 --> 00:03:01,200
So by the end of the tutorial, you would be pretty comfortable with working with that.

26
00:03:01,280 --> 00:03:08,280
So just to present how the tutorial is, the logistics of it.

27
00:03:08,280 --> 00:03:11,280
So you see every notebook would have two versions.

28
00:03:11,280 --> 00:03:13,280
One is instructor and one is student.

29
00:03:13,280 --> 00:03:16,280
In the student version, you have exercises.

30
00:03:16,280 --> 00:03:19,280
So if you want to...

31
00:03:19,280 --> 00:03:25,280
I would suggest you actually work on the student notebook version, so you can go and actually

32
00:03:25,360 --> 00:03:30,360
solve the exercises, which is much more fun than just looking what's there.

33
00:03:30,360 --> 00:03:36,360
And if you're stuck, feel free to move to an instructor notebook and see the solution.

34
00:03:36,360 --> 00:03:37,360
That's totally okay.

35
00:03:37,360 --> 00:03:39,360
It's not an exam.

36
00:03:39,360 --> 00:03:43,360
And if I am too slow for you, that is okay, too.

37
00:03:43,360 --> 00:03:46,360
And there is a lot of material in this repository.

38
00:03:46,360 --> 00:03:49,360
You can use this material for a seven or eight hour tutorial.

39
00:03:49,360 --> 00:03:51,360
So feel free to go ahead.

40
00:03:51,360 --> 00:03:53,360
So that's okay, too.

41
00:03:53,440 --> 00:03:56,440
So let's start with the introduction.

42
00:03:59,440 --> 00:04:02,440
So this is a list comprehension.

43
00:04:02,440 --> 00:04:09,440
Can someone tell me what are the plausible data structures for S and my favorite things in this?

44
00:04:17,440 --> 00:04:19,440
S is a string.

45
00:04:19,440 --> 00:04:20,440
Okay.

46
00:04:23,440 --> 00:04:24,440
Yes.

47
00:04:25,440 --> 00:04:26,440
What else?

48
00:04:26,440 --> 00:04:28,440
What are my favorite things?

49
00:04:35,440 --> 00:04:36,440
Yes.

50
00:04:36,440 --> 00:04:37,440
So yeah.

51
00:04:37,440 --> 00:04:44,440
So you could see in here, this one is basically, it's a string.

52
00:04:44,440 --> 00:04:47,440
It's an iterable of dictionaries.

53
00:04:47,440 --> 00:04:48,440
Yeah.

54
00:04:48,520 --> 00:04:53,520
It could be anything with the Dunder Git.

55
00:04:53,520 --> 00:04:55,520
Dunder Git.

56
00:04:55,520 --> 00:04:56,520
Yes.

57
00:04:56,520 --> 00:04:57,520
Yeah.

58
00:04:57,520 --> 00:04:58,520
That's all right.

59
00:04:58,520 --> 00:05:01,520
And in standard data structures, that would be a dictionary.

60
00:05:01,520 --> 00:05:09,520
So before we talk about networks, can someone tell me an example of a real world network

61
00:05:09,520 --> 00:05:12,520
they can think of?

62
00:05:12,520 --> 00:05:15,520
What is the network for you?

63
00:05:15,520 --> 00:05:16,520
Home Wi-Fi.

64
00:05:16,600 --> 00:05:18,600
Home Wi-Fi, yeah.

65
00:05:18,600 --> 00:05:24,600
And what are the nodes and edges in that network, according to you?

66
00:05:29,600 --> 00:05:32,600
Phones and tablets are the nodes in this.

67
00:05:32,600 --> 00:05:37,600
Any other examples of what is a network?

68
00:05:41,600 --> 00:05:43,600
Social networks.

69
00:05:43,680 --> 00:05:46,680
So you have Facebook, Twitter, LinkedIn.

70
00:05:46,680 --> 00:05:50,680
Can someone tell me what's the...

71
00:05:50,680 --> 00:05:55,680
Suppose there is a Facebook social graph and there's a Twitter social graph.

72
00:05:55,680 --> 00:06:01,680
Can you think of a structural difference between a Facebook social graph and a Twitter social

73
00:06:01,680 --> 00:06:02,680
graph?

74
00:06:03,680 --> 00:06:05,680
What's the difference between Facebook?

75
00:06:05,680 --> 00:06:08,680
Suppose I'm friends with you on Facebook.

76
00:06:08,760 --> 00:06:11,760
And suppose I follow you on Twitter.

77
00:06:11,760 --> 00:06:14,760
There is something different between the structure.

78
00:06:14,760 --> 00:06:16,760
Can anyone think of that?

79
00:06:16,760 --> 00:06:18,760
Twitter doesn't have a response to that.

80
00:06:18,760 --> 00:06:19,760
Yes.

81
00:06:19,760 --> 00:06:23,760
So in this case, for Facebook, if I'm friends with someone, they're friends with me back.

82
00:06:23,760 --> 00:06:27,760
So there's no direction in our relationship.

83
00:06:27,760 --> 00:06:32,760
But on Twitter, if I follow some person X, that does not necessarily mean that the person

84
00:06:32,760 --> 00:06:33,760
X follows me back.

85
00:06:33,760 --> 00:06:36,760
So there is a notion of direction in this.

86
00:06:36,840 --> 00:06:39,840
So these are two basic concepts.

87
00:06:39,840 --> 00:06:44,840
Twitter is called a directed graph because you have direction, and Facebook is called

88
00:06:44,840 --> 00:06:47,840
an undirected graph because there's no direction.

89
00:06:47,840 --> 00:07:00,840
And one thing to keep in mind is the information, the heart of a network or a graph is its edges.

90
00:07:00,920 --> 00:07:07,920
Because just by looking at the nodes, they don't give you any special information.

91
00:07:07,920 --> 00:07:12,920
But the way they are connected, that's the whole point of creating a network.

92
00:07:12,920 --> 00:07:17,920
So edges are the most important part of a network.

93
00:07:19,920 --> 00:07:22,920
So we have discussed the examples.

94
00:07:22,920 --> 00:07:28,920
So our hope is by the end of this tutorial, you would be comfortable with using the NetworkX

95
00:07:29,000 --> 00:07:36,000
API, how to manipulate data, how to create networks, how to model them, and how to analyze

96
00:07:37,000 --> 00:07:38,000
them.

97
00:07:38,000 --> 00:07:43,000
You should be able to visualize networks using some basic techniques.

98
00:07:43,000 --> 00:07:50,000
And you would be comfortable with writing some algorithms on using graphs and computing

99
00:07:51,000 --> 00:07:54,000
some network statistics.

100
00:07:54,080 --> 00:08:03,080
And on a more conceptual thing, it's about how to think about network problems and how

101
00:08:03,080 --> 00:08:10,080
to map those interactions and create a network out of it.

102
00:08:10,080 --> 00:08:14,080
In network science research, there's a funny saying that every problem in the world can

103
00:08:14,080 --> 00:08:16,080
be modeled as a network.

104
00:08:16,080 --> 00:08:21,080
I don't necessarily agree with that, but if you think hard enough, you can model everything

105
00:08:21,080 --> 00:08:22,080
as a network.

106
00:08:22,160 --> 00:08:25,160
So that's there.

107
00:08:25,160 --> 00:08:30,160
So reiterating on this, there are student notebooks and instructor notebooks.

108
00:08:30,160 --> 00:08:37,160
If you want to solve the exercises which I recommend, which would be more fun, always

109
00:08:37,160 --> 00:08:39,160
open the student notebooks.

110
00:08:39,160 --> 00:08:46,160
And if you're stuck and if you're too tired right now, if you're jet-lagged, feel free

111
00:08:46,160 --> 00:08:48,160
to follow the instructor notebook too.

112
00:08:48,160 --> 00:08:49,160
That's okay too.

113
00:08:49,160 --> 00:08:50,160
I won't be offended.

114
00:08:50,240 --> 00:08:57,240
And feel free to skip ahead and just go full steam ahead till the end of the tutorial.

115
00:09:01,240 --> 00:09:06,240
So this work has been inspired by a lot of previous different work.

116
00:09:06,240 --> 00:09:11,240
And much of this work is written by Eric in this repository.

117
00:09:11,240 --> 00:09:14,240
And now today he's TAing me.

118
00:09:14,240 --> 00:09:19,240
So the apprentice has become the master now, apparently.

119
00:09:19,320 --> 00:09:23,320
So let's start.

120
00:09:23,320 --> 00:09:24,320
Run at that.

121
00:09:28,320 --> 00:09:32,320
Just to interject a few points, midway through, if there are any issues, just raise your hand.

122
00:09:32,320 --> 00:09:34,320
If you have a question, raise your hand.

123
00:09:34,320 --> 00:09:35,320
I'll come by with a mic.

124
00:09:35,320 --> 00:09:39,320
And I'd really like to encourage people to ask questions for everybody.

125
00:09:39,320 --> 00:09:43,320
And the reason I have a mic is because we want to keep your questions recorded on video

126
00:09:43,320 --> 00:09:46,320
for the benefit of other people who might be watching the tutorial later.

127
00:09:46,320 --> 00:09:47,320
Okay?

128
00:09:47,320 --> 00:09:48,320
Also, this is a tutorial.

129
00:09:48,400 --> 00:09:49,400
This is not a talk.

130
00:09:49,400 --> 00:09:52,400
So please feel free to interject and ask questions.

131
00:09:52,400 --> 00:09:54,400
If you don't want to interject me, that's okay too.

132
00:09:54,400 --> 00:09:57,400
You can raise your hand and ask Eric.

133
00:09:57,400 --> 00:09:58,400
He can solve your problem.

134
00:09:58,400 --> 00:10:02,400
But make sure that this is not a one-way interaction.

135
00:10:05,400 --> 00:10:07,400
And also, that's not a one-way interaction.

136
00:10:07,400 --> 00:10:11,400
Feel free to talk with each other and create a network.

137
00:10:11,400 --> 00:10:15,400
You are the nodes and create new relationships.

138
00:10:15,400 --> 00:10:17,400
See what I did there?

139
00:10:17,480 --> 00:10:19,480
So let's start.

140
00:10:20,480 --> 00:10:25,480
So the basic building block of a network, in this case, are nodes and edges.

141
00:10:25,480 --> 00:10:37,480
Node represents some entity, some person, a train station, a computer.

142
00:10:37,480 --> 00:10:45,480
And edges are the relationship between those things, between those people.

143
00:10:45,560 --> 00:10:52,560
And to understand the API of NetworkX, we will use some data.

144
00:10:52,560 --> 00:10:57,560
This is a very controversial data set.

145
00:10:57,560 --> 00:10:59,560
And we'll get to that later.

146
00:10:59,560 --> 00:11:00,560
So don't kill me for that.

147
00:11:00,560 --> 00:11:02,560
But this is a very controversial data set.

148
00:11:02,560 --> 00:11:03,560
Disclaimer.

149
00:11:03,560 --> 00:11:10,560
But before we do that, let's talk about data representation, how it's represented in NetworkX.

150
00:11:10,640 --> 00:11:18,640
So if you're familiar with Python, if you're familiar enough with Python, you'll see that

151
00:11:18,640 --> 00:11:22,640
this is a dictionary of a dictionary of a dictionary of a dictionary.

152
00:11:22,640 --> 00:11:24,640
It goes all the way down.

153
00:11:24,640 --> 00:11:30,640
So if you have done computer science or mathematics before and you know how graphs are represented,

154
00:11:30,640 --> 00:11:32,640
so you will understand what I'm saying.

155
00:11:32,640 --> 00:11:34,640
But it's a dictionary of a dictionary of a dictionary.

156
00:11:34,640 --> 00:11:38,640
So you need to be comfortable with playing around with dictionary.

157
00:11:38,720 --> 00:11:41,720
And in this notebook, we do that.

158
00:11:41,720 --> 00:11:44,720
So let's load this controversial data set.

159
00:11:44,720 --> 00:11:48,720
So this data set is a friendship data set.

160
00:11:48,720 --> 00:11:55,720
So some researchers went to a seventh grade class and asked a person, who's your best friend?

161
00:11:55,720 --> 00:11:57,720
They said, ta-da.

162
00:11:57,720 --> 00:12:04,720
But what if that person doesn't say that, oh, I say person X is my best friend.

163
00:12:04,720 --> 00:12:07,720
But the person X is like, no, he's not.

164
00:12:07,800 --> 00:12:08,800
He's not.

165
00:12:08,800 --> 00:12:10,800
Person Y is my best friend.

166
00:12:10,800 --> 00:12:14,800
So this is a controversial data set.

167
00:12:14,800 --> 00:12:18,800
So let's see what we can look into this.

168
00:12:24,800 --> 00:12:29,800
So there are some custom loaders in here to load the data set into the graph.

169
00:12:29,800 --> 00:12:31,800
You don't need to worry about that right now.

170
00:12:31,800 --> 00:12:36,800
But if you are interested how they're working, there is a custom folder in the repository

171
00:12:36,880 --> 00:12:39,880
you can look at the code there.

172
00:12:39,880 --> 00:12:42,880
So let's start with some basic statistics.

173
00:12:42,880 --> 00:12:46,880
Like, how many people are there in the graph?

174
00:12:46,880 --> 00:12:56,880
So to access nodes, you use something like g.nodes.

175
00:12:56,880 --> 00:13:01,880
And the only reason we're using NetworkX in this tutorial is because the API is very,

176
00:13:01,880 --> 00:13:02,880
very intuitive.

177
00:13:02,880 --> 00:13:05,880
Like, OK, you need to find the number of nodes in a graph, right?

178
00:13:05,960 --> 00:13:08,960
So we have g, which is a graph object.

179
00:13:08,960 --> 00:13:11,960
We do g.nodes.

180
00:13:11,960 --> 00:13:12,960
You get the number of nodes.

181
00:13:12,960 --> 00:13:14,960
You get something called a node view.

182
00:13:14,960 --> 00:13:16,960
You don't need to worry about that right now.

183
00:13:16,960 --> 00:13:18,960
You just get a list of nodes.

184
00:13:18,960 --> 00:13:19,960
You don't get a list.

185
00:13:19,960 --> 00:13:20,960
You get a view of node.

186
00:13:20,960 --> 00:13:24,960
And you can typecast this to a list to get a list of this.

187
00:13:24,960 --> 00:13:30,960
And if you want to calculate the total number of nodes, you just use the inbuilt length.

188
00:13:30,960 --> 00:13:33,960
So there are 29 nodes in this network.

189
00:13:33,960 --> 00:13:34,960
So far, so good.

190
00:13:35,040 --> 00:13:46,040
So I talked about casting this view as a list because it's a bug or feature, as you may

191
00:13:46,040 --> 00:13:55,040
like, of the NetworkX API as it moves towards 2.0.

192
00:13:55,040 --> 00:13:58,040
Initially, it used to be g.nodes returned a list.

193
00:13:58,040 --> 00:14:00,040
But now it returns a view.

194
00:14:00,040 --> 00:14:02,040
But you can't slice a view.

195
00:14:02,120 --> 00:14:03,120
You can't do this thing.

196
00:14:03,120 --> 00:14:05,120
It will give you an error.

197
00:14:05,120 --> 00:14:11,120
So if you want to select five nodes, then you have to first cast it as a list and then

198
00:14:11,120 --> 00:14:12,120
do the slicing.

199
00:14:12,120 --> 00:14:15,120
010, you have the first 10 nodes.

200
00:14:15,120 --> 00:14:21,120
So this is one thing to keep in mind if you are working with an older version of NetworkX.

201
00:14:21,120 --> 00:14:23,120
So things may break.

202
00:14:23,120 --> 00:14:25,120
So this is one thing to keep in mind.

203
00:14:25,120 --> 00:14:27,120
So the first exercise.

204
00:14:27,120 --> 00:14:31,120
Can you write a single line of code that returns a list?

205
00:14:31,200 --> 00:14:35,200
Can you write a single line of code that returns a number of nodes in the graph?

206
00:14:35,200 --> 00:14:37,200
Well, that was already done.

207
00:14:41,200 --> 00:14:44,200
Once you are done, give me a thumbs up.

208
00:14:44,280 --> 00:14:45,280
Yep.

209
00:14:59,280 --> 00:15:00,280
Oh, thank you.

210
00:15:00,280 --> 00:15:06,280
When you cast nodes to a list and then slice it, are you guaranteed to always get the same

211
00:15:06,280 --> 00:15:07,280
nodes back?

212
00:15:07,280 --> 00:15:09,280
Like, is it ordered or can it be different?

213
00:15:09,360 --> 00:15:19,360
So according to Python, if you are using Python 3.8 or 3.7, order is guaranteed because the

214
00:15:19,360 --> 00:15:21,360
dictionary underneath is ordered by default.

215
00:15:21,360 --> 00:15:24,360
But if you are using an earlier Python 3, then no.

216
00:15:24,360 --> 00:15:27,360
You can't say it's guaranteed.

217
00:15:27,360 --> 00:15:30,360
But again, it depends on the order of insertion.

218
00:15:30,360 --> 00:15:35,360
So if we have the same order, like if you have the same notebook, we'll get the same results.

219
00:15:35,360 --> 00:15:37,360
If you have the same Python and NetworkX.

220
00:15:37,440 --> 00:15:40,440
Everyone done with this exercise?

221
00:15:40,440 --> 00:15:44,440
Finding the number of nodes?

222
00:15:54,440 --> 00:15:59,440
So one way would be just to calculate the length of g.nodes.

223
00:15:59,440 --> 00:16:02,440
And another way is to calculate the length of the graph.

224
00:16:02,520 --> 00:16:07,520
Which is like, these are some concepts from graph theory, which is like a length of a

225
00:16:07,520 --> 00:16:09,520
graph is known as the number of nodes.

226
00:16:09,520 --> 00:16:13,520
So if you do that too, you'll get 29 again.

227
00:16:13,520 --> 00:16:18,520
So now let's figure out the more fun part.

228
00:16:18,520 --> 00:16:19,520
Who is connected to who?

229
00:16:19,520 --> 00:16:21,520
Who thinks you are my best friend?

230
00:16:21,520 --> 00:16:25,520
Who thinks like someone else is my best friend?

231
00:16:25,520 --> 00:16:28,520
So again, just like nodes, very intuitive.

232
00:16:28,520 --> 00:16:30,520
You want to find edges.

233
00:16:30,600 --> 00:16:33,600
So you do g.edges.

234
00:16:36,600 --> 00:16:40,600
You'll get, again, something called an outage view.

235
00:16:40,600 --> 00:16:45,600
Again, don't worry about what outage view is right now.

236
00:16:45,600 --> 00:16:53,600
But you see that you get a series of two tuples in which you have like a starting node and

237
00:16:53,600 --> 00:16:54,600
an ending node.

238
00:16:54,680 --> 00:17:05,680
And suppose you want to just get a sample of nodes.

239
00:17:05,680 --> 00:17:10,680
So we see that one is connected to two, one is connected to three, and so on.

240
00:17:10,680 --> 00:17:15,680
And here one, two, and three, four are people in our seventh grade.

241
00:17:15,760 --> 00:17:18,760
So yeah.

242
00:17:20,760 --> 00:17:23,760
Does the directionality here or the order matter?

243
00:17:23,760 --> 00:17:28,760
Like is one, two, like one said two is my best friend, any other way around, or something

244
00:17:28,760 --> 00:17:29,760
like that, or does it not matter?

245
00:17:29,760 --> 00:17:33,760
In this data set, it matters because it's created as a directed graph, but we'll get

246
00:17:33,760 --> 00:17:35,760
to that later.

247
00:17:35,760 --> 00:17:37,760
In this, it matters.

248
00:17:37,760 --> 00:17:43,760
So exercise number two, can you write a single line of code that returns the number of

249
00:17:43,840 --> 00:17:48,840
relationships, which means the number of edges in this network?

250
00:17:48,840 --> 00:17:51,840
We know how to get g.edges.

251
00:17:51,840 --> 00:17:56,840
So you have to calculate the number of those relationships.

252
00:17:59,840 --> 00:18:02,840
Once you're done, thumbs up.

253
00:18:13,760 --> 00:18:20,840
So just like g.nodes, if you want to calculate the number of edges, we just pass it through

254
00:18:43,840 --> 00:18:48,840
and we'll get the total number of edges in this network.

255
00:18:48,840 --> 00:18:51,840
And everyone got 376.

256
00:18:51,840 --> 00:18:53,840
Yep, yep, yep.

257
00:18:53,840 --> 00:18:54,840
Perfect.

258
00:18:54,840 --> 00:19:01,840
So now we are understanding what's the basic concept here, a network or graph.

259
00:19:01,840 --> 00:19:06,840
So the fight between network and graph is if you're doing mathematics, you'll say graph

260
00:19:06,840 --> 00:19:08,840
because it comes from graph theory.

261
00:19:08,840 --> 00:19:12,840
And if you're doing data science, you'll use the word network because that's network

262
00:19:12,920 --> 00:19:13,920
science.

263
00:19:13,920 --> 00:19:14,920
So it's the same thing.

264
00:19:14,920 --> 00:19:16,920
It's not a different thing.

265
00:19:16,920 --> 00:19:22,920
And conceptually, it's a set of nodes which are joined by a set of edges.

266
00:19:22,920 --> 00:19:30,920
And for the representation, a node list can be represented as a two-tuple where the first

267
00:19:30,920 --> 00:19:37,920
element is the node itself and the second element contains metadata about the node.

268
00:19:37,920 --> 00:19:41,920
Can anyone think of metadata in this network?

269
00:19:42,000 --> 00:19:44,000
We know every node is a student.

270
00:19:44,000 --> 00:19:47,000
What could be a metadata about every student?

271
00:19:47,000 --> 00:19:49,000
Yep, we have name.

272
00:19:49,000 --> 00:19:52,000
Yep, we can have the name.

273
00:19:52,000 --> 00:19:53,000
What else?

274
00:19:53,000 --> 00:19:54,000
Physical address.

275
00:19:54,000 --> 00:19:55,000
Yeah, physical address.

276
00:19:55,000 --> 00:19:59,000
So we can have a lot of metadata about the node itself.

277
00:19:59,000 --> 00:20:03,000
And just like that, even with an edge, we can have metadata about that too.

278
00:20:03,000 --> 00:20:05,000
So an edge is a three-tuple.

279
00:20:05,000 --> 00:20:11,000
You have a start or an end, like where the edge starts, where the edge ends, and data

280
00:20:11,080 --> 00:20:15,080
about that edge, metadata about that edge.

281
00:20:15,080 --> 00:20:19,080
Can anyone think of the metadata about the edge?

282
00:20:19,080 --> 00:20:24,080
What could be an example metadata in this dataset?

283
00:20:28,080 --> 00:20:31,080
Yep, how strong the friendship is.

284
00:20:31,080 --> 00:20:37,080
So we do have something like that in this dataset.

285
00:20:37,080 --> 00:20:38,080
We'll look at that.

286
00:20:38,080 --> 00:20:39,080
You had a question?

287
00:20:39,160 --> 00:20:42,160
Question.

288
00:20:45,160 --> 00:20:50,160
Is the number of edges associated to a node always going to be included in the metadata

289
00:20:50,160 --> 00:20:52,160
of a node?

290
00:20:52,160 --> 00:20:58,160
Likewise, is the direction of an edge counted as metadata for that edge?

291
00:20:58,160 --> 00:21:04,160
That is data related to the node, but that's not exactly metadata because you can just

292
00:21:04,160 --> 00:21:06,160
count the number of neighbors.

293
00:21:06,240 --> 00:21:10,240
You can just count the number of neighbors and then you have that information.

294
00:21:10,240 --> 00:21:15,240
But that is kind of metadata about the node too.

295
00:21:15,240 --> 00:21:20,240
I think that's a good point in that there's computable properties of a node and then there's

296
00:21:20,240 --> 00:21:22,240
just intrinsic properties of a node.

297
00:21:22,240 --> 00:21:25,240
And the intrinsic ones are the ones we can't compute on the fly from the graph.

298
00:21:25,240 --> 00:21:29,240
So number of neighbors, yes, it's metadata, but it's the kind that you can just compute

299
00:21:29,240 --> 00:21:30,240
directly.

300
00:21:30,240 --> 00:21:34,240
Whereas in this case, what's the name of the student?

301
00:21:34,240 --> 00:21:35,240
That's intrinsic to the node.

302
00:21:35,320 --> 00:21:44,320
So the graph we loaded in, it had a lot of metadata too.

303
00:21:44,320 --> 00:21:49,320
So to look at that, you need to pass in this argument data equals true.

304
00:21:49,320 --> 00:21:53,320
So if you don't do this, we'll get something like this, just a list of nodes.

305
00:21:53,320 --> 00:22:04,320
But if we do pass in data equals true, we'll get the biological sex of the student in the

306
00:22:04,400 --> 00:22:05,400
class.

307
00:22:05,400 --> 00:22:09,400
So you have gender for every node.

308
00:22:09,400 --> 00:22:14,400
And if you look at the data structure, it's again, it's a two-tuple.

309
00:22:14,400 --> 00:22:21,400
You have the node and then you have a dictionary which has information about that node.

310
00:22:21,400 --> 00:22:23,400
You can have multiple attributes, right?

311
00:22:23,400 --> 00:22:24,400
So that's why it's a dictionary.

312
00:22:24,400 --> 00:22:32,400
So you can have gender, you can have their name, where do they live, and many other things.

313
00:22:32,480 --> 00:22:37,480
So let's do an exercise again.

314
00:22:37,480 --> 00:22:44,480
Can you count the number of males and females in this network using the things that we know

315
00:22:44,480 --> 00:22:47,480
right now and your Pythonic knowledge?

316
00:22:52,480 --> 00:22:55,480
Just to give you a bigger overview, this is our data set.

317
00:22:55,480 --> 00:22:58,480
So we have 1 to 29.

318
00:22:58,480 --> 00:23:00,480
Some are male, some are female.

319
00:23:00,560 --> 00:23:05,560
The exercise is to count the number of males and females in our data.

320
00:23:07,560 --> 00:23:13,560
You have three minutes for this and once you're done, give me a thumbs up.

321
00:23:16,560 --> 00:23:23,560
And again, if I'm slow for you, feel free to go ahead and there are a lot of exercises to do.

322
00:23:30,480 --> 00:23:31,560
Okay.

323
00:24:00,480 --> 00:24:01,560
Okay.

324
00:24:30,560 --> 00:24:31,560
Okay.

325
00:24:50,560 --> 00:24:51,560
Just wanted to check.

326
00:24:51,560 --> 00:24:54,560
No one is stuck with the setup, right?

327
00:24:54,560 --> 00:24:55,560
Yeah, you are.

328
00:24:55,560 --> 00:24:56,560
Can you?

329
00:25:00,480 --> 00:25:01,560
Okay.

330
00:25:30,560 --> 00:25:31,560
Okay.

331
00:25:32,560 --> 00:25:33,560
People done with the exercise?

332
00:25:33,560 --> 00:25:34,560
Thumbs up.

333
00:26:00,560 --> 00:26:15,560
So does everyone get 17 females and 12 males?

334
00:26:15,560 --> 00:26:16,560
Yep.

335
00:26:16,560 --> 00:26:17,560
This is what you should get.

336
00:26:17,560 --> 00:26:20,560
And this is my answer of doing it.

337
00:26:20,560 --> 00:26:21,560
I use a counter object.

338
00:26:21,560 --> 00:26:23,560
This is not the only way of doing it.

339
00:26:23,560 --> 00:26:25,560
There are a lot of other ways of doing it.

340
00:26:25,640 --> 00:26:30,640
But until you are getting the final answer, that's more than perfect.

341
00:26:32,640 --> 00:26:37,640
So just like nodes, edges too can have this attribute dictionary.

342
00:26:37,640 --> 00:26:43,640
And in this data set, every student was asked a series of questions.

343
00:26:43,640 --> 00:26:48,640
And they were asked to pick up who is your best friend in this case or something like that.

344
00:26:48,640 --> 00:26:51,640
Who is your best friend in this case, in that case?

345
00:26:51,640 --> 00:26:53,640
So you have this thing called count.

346
00:26:53,720 --> 00:26:57,720
The number of times one chose two is one.

347
00:26:57,720 --> 00:27:00,720
The number of times one chose six is three.

348
00:27:00,720 --> 00:27:03,720
And it's always between one and three for some reason.

349
00:27:03,720 --> 00:27:06,720
I'm not sure why, but that's the data.

350
00:27:10,720 --> 00:27:19,720
So can you figure out the maximum time any student has rated any other student as their favorite?

351
00:27:19,720 --> 00:27:21,720
The answer should be three.

352
00:27:23,720 --> 00:27:43,720
So again, to reiterate the exercise, you basically need to find the maximum of this dictionary

353
00:27:43,720 --> 00:27:47,720
all through the data set.

354
00:27:47,800 --> 00:27:54,800
If I check the full output of this thing, I have count dictionary in every edge.

355
00:27:54,800 --> 00:27:58,800
And I have to find the maximum of count in this list.

356
00:28:06,800 --> 00:28:08,800
Again, you have three minutes for that.

357
00:28:08,800 --> 00:28:11,800
And once you are done, please give me a thumbs up.

358
00:28:12,800 --> 00:28:15,800
For those of you who might be a little bit confused, if it's the first time you've seen

359
00:28:15,880 --> 00:28:18,880
assertions in a function, that's a test.

360
00:28:18,880 --> 00:28:20,880
Tests are good.

361
00:28:20,880 --> 00:28:22,880
We can talk about them for all day long.

362
00:28:22,880 --> 00:28:24,880
But basically, you won't see any output.

363
00:28:24,880 --> 00:28:27,880
If your function is correct, you won't see any output.

364
00:28:27,880 --> 00:28:31,880
Only if your function is wrong, then the assertion will fail and there will be a big error.

365
00:28:45,800 --> 00:28:46,880
Okay.

366
00:29:15,800 --> 00:29:16,880
Okay.

367
00:29:45,880 --> 00:30:10,880
Thumbs up if you're done with the exercise and you got three.

368
00:30:10,880 --> 00:30:11,880
Perfect.

369
00:30:11,960 --> 00:30:18,960
Again, in our answer, we use a lot of list comprehensions because, come on, it looks

370
00:30:18,960 --> 00:30:20,960
very nice and neat.

371
00:30:20,960 --> 00:30:23,960
It's the Pythonic way of doing these things.

372
00:30:23,960 --> 00:30:28,960
But even if you're doing it without using these fancy list comprehensions, that's okay

373
00:30:28,960 --> 00:30:29,960
too.

374
00:30:29,960 --> 00:30:36,960
But we hope by the end of the tutorial, you are convinced that list comprehensions are

375
00:30:36,960 --> 00:30:37,960
a good thing.

376
00:30:38,040 --> 00:30:39,040
Okay.

377
00:30:39,040 --> 00:30:51,040
So let's say if you're trying to replicate this in a production environment, network

378
00:30:51,040 --> 00:30:54,040
environment, like say data center or Internet Edge.

379
00:30:54,040 --> 00:30:59,040
So using this module or dictionary, we can call it how many devices we have in the node

380
00:30:59,040 --> 00:31:01,040
which are active and pulling back to us.

381
00:31:01,040 --> 00:31:06,040
I'm trying to correlate this to the real world scenario for network analysis.

382
00:31:06,120 --> 00:31:07,120
Let's say for network analysis.

383
00:31:07,120 --> 00:31:13,120
If you want to do some analysis for the data center, for XYZ, like an issue or whatever

384
00:31:13,120 --> 00:31:14,120
it may be.

385
00:31:14,120 --> 00:31:17,120
So how do we correlate this module or function to the real time?

386
00:31:17,200 --> 00:31:45,200
If you have like 100,000 nodes, you can work with this thing.

387
00:31:45,280 --> 00:31:54,280
But as soon as you go to a couple of million nodes, in that case, what matters a lot is

388
00:31:54,280 --> 00:31:56,280
how you model the network.

389
00:31:56,280 --> 00:32:03,280
Like what kind of metadata you are putting on the edges and the nodes.

390
00:32:03,280 --> 00:32:06,280
So once you have a network problem.

391
00:32:06,360 --> 00:32:19,360
So let's do another exercise.

392
00:32:19,360 --> 00:32:24,360
When people did this survey, they basically missed out two people.

393
00:32:24,360 --> 00:32:28,360
So let's add those people in this network.

394
00:32:28,440 --> 00:32:37,440
How to do that is basically you can go through the documentation of network X out here.

395
00:32:37,440 --> 00:32:40,440
The function is gaddNode, which basically adds a node.

396
00:32:40,440 --> 00:32:43,440
And gaddEdge adds an edge.

397
00:32:43,440 --> 00:32:52,440
So in this exercise, you have to add a new relationship between a male which is named

398
00:32:52,520 --> 00:32:59,520
30 and a female which is named 31 and the other individual 7.

399
00:32:59,520 --> 00:33:01,520
These three people are besties.

400
00:33:01,520 --> 00:33:06,520
So whenever you ask a question, who's your best friend, they'll be like, oh, 31.

401
00:33:06,520 --> 00:33:08,520
And 31 will be like, oh, no, 30.

402
00:33:08,520 --> 00:33:12,520
And if you ask the same question to 7, it's like a bestie triangle.

403
00:33:12,520 --> 00:33:16,520
And you have to model that.

404
00:33:16,520 --> 00:33:21,520
So basically, in this, you have to add nodes and add edges.

405
00:33:22,520 --> 00:33:29,520
And if you want to understand, if you have any doubt with the syntax, you can check out

406
00:33:29,520 --> 00:33:32,520
this thing here.

407
00:33:32,520 --> 00:33:41,520
You can check out the documentation of network X, which introduces everything perfectly.

408
00:33:41,520 --> 00:33:46,520
And once you are done with this thing, thumbs up.

409
00:33:52,520 --> 00:33:55,520
Yep.

410
00:33:59,520 --> 00:34:04,520
So if we didn't already have g instantiated, could we do this?

411
00:34:04,520 --> 00:34:07,520
Could we do g.addNodes from scratch to create a network?

412
00:34:07,520 --> 00:34:08,520
No, no, no.

413
00:34:08,520 --> 00:34:13,520
You need to instantiate the graph object.

414
00:34:13,520 --> 00:34:15,520
Then you can add whatever you want.

415
00:34:15,520 --> 00:34:21,520
But for example, you don't need to add nodes to add edges.

416
00:34:21,600 --> 00:34:26,600
Like suppose if you just did addEdge 30, 31 count 3, it would add 30 and 31 as nodes.

417
00:34:26,600 --> 00:34:31,600
But it won't add the metadata, gender.

418
00:34:31,600 --> 00:34:36,600
But you need to create a graph object first to manipulate that.

419
00:34:42,600 --> 00:34:47,600
So I noticed that when you're adding edges, it's unidirectional.

420
00:34:47,600 --> 00:34:50,600
Is there a bidirectional way to add edges?

421
00:34:50,680 --> 00:34:51,680
Yes, there is.

422
00:34:51,680 --> 00:35:00,680
So just to show you that, if we do something, if we take the type of g, you see it's a directed

423
00:35:00,680 --> 00:35:01,680
graph.

424
00:35:01,680 --> 00:35:03,680
So it's like a diagram is directed graph.

425
00:35:03,680 --> 00:35:08,680
And in this case, if you want to add edges which goes both directions, you need to add

426
00:35:08,680 --> 00:35:12,680
an edge which goes from 1 to 2 and 2 to 1.

427
00:35:12,680 --> 00:35:17,680
But if you want to add edges which are without direction, there is something else called

428
00:35:17,760 --> 00:35:18,760
just a graph.

429
00:35:18,760 --> 00:35:21,760
And we look at those later.

430
00:35:21,760 --> 00:35:24,760
But in this, because...

431
00:35:28,760 --> 00:35:35,760
A nice API addition to NetworkX might be, if you want to PR, would be to automatically

432
00:35:35,760 --> 00:35:36,760
add bidirectional edges.

433
00:35:36,760 --> 00:35:39,760
So add bidirectional edge or something.

434
00:35:39,840 --> 00:35:42,840
I have to wait on something called hybrid network.

435
00:35:42,840 --> 00:35:47,840
Because you have directional less edges and you have directional edges too.

436
00:35:47,840 --> 00:35:51,840
But no one could actually come to consensus how to implement this.

437
00:35:51,840 --> 00:35:53,840
So that is the problem right now.

438
00:35:53,840 --> 00:35:58,840
But if you want to go ahead, I think there's a PR open with hybrid.

439
00:36:09,840 --> 00:36:16,840
So basically you're asking questions to the...

440
00:36:16,920 --> 00:36:23,920
Last three questions, the student will reply three times that this is my best friend.

441
00:36:40,200 --> 00:36:42,680
One, two, three.

442
00:36:43,520 --> 00:36:48,520
So the count thing basically comes from the way that the data were generated.

443
00:36:50,520 --> 00:36:55,520
So I noticed you talked about it as like a keyword argument to the add edge method,

444
00:36:55,520 --> 00:36:56,520
right?

445
00:36:56,520 --> 00:36:57,520
And so that...

446
00:36:57,520 --> 00:37:02,520
What NetworkX does is it actually collects all of the keyword arguments that are passed

447
00:37:02,520 --> 00:37:07,520
into add edge and it adds them as dictionary keys for the metadata.

448
00:37:07,520 --> 00:37:11,520
So count is not by no means like a fixed keyword argument.

449
00:37:12,360 --> 00:37:13,360
You can add anything you want.

450
00:37:14,360 --> 00:37:19,360
So if you look at the signature of the function, it's like the starting edge, the end of edge

451
00:37:19,360 --> 00:37:20,360
and just...

452
00:37:20,360 --> 00:37:23,360
You can pass in any keyword you want.

453
00:37:33,360 --> 00:37:36,360
It's a weight on the edges.

454
00:37:36,360 --> 00:37:39,360
Just a reminder, if you want to ask a question, please raise your hand and I'll bring the

455
00:37:39,360 --> 00:37:40,360
mic over.

456
00:37:42,360 --> 00:37:47,360
Thumbs up if you are done with this thing.

457
00:37:47,360 --> 00:37:50,360
Add node, add edge.

458
00:37:56,360 --> 00:38:01,360
Once you're done with that, verify that whatever you have done is right.

459
00:38:01,360 --> 00:38:04,360
How do you do that?

460
00:38:04,360 --> 00:38:05,360
What?

461
00:38:05,360 --> 00:38:08,360
Because I didn't run this.

462
00:38:08,360 --> 00:38:09,360
Yep.

463
00:38:09,360 --> 00:38:13,200
People with the thumbs up, did you get all tests passed?

464
00:38:40,200 --> 00:38:59,200
So this is the answer flashing on the screen.

465
00:38:59,200 --> 00:39:02,200
So it's again, add node and add edges.

466
00:39:02,200 --> 00:39:05,200
And you can create a loop to do this too.

467
00:39:06,040 --> 00:39:13,040
You can create a permutation of three and shift routine them if you are feeling fancy

468
00:39:13,040 --> 00:39:14,040
today.

469
00:39:14,040 --> 00:39:15,040
But I just did this.

470
00:39:15,040 --> 00:39:22,040
And let's just take a detour and actually look at the graph structure.

471
00:39:22,040 --> 00:39:25,040
So suppose I pass in...

472
00:39:25,040 --> 00:39:27,040
Because it's a dictionary, right?

473
00:39:27,040 --> 00:39:29,040
If you access dictionary, how do you do that?

474
00:39:29,040 --> 00:39:31,040
Let's use square brackets.

475
00:39:31,880 --> 00:39:35,880
So if we do G1, you see you get this thing called Atlas view.

476
00:39:35,880 --> 00:39:38,880
Again, ignore view for the time being.

477
00:39:38,880 --> 00:39:45,880
You see that it's kind of a view of dictionaries, right?

478
00:39:45,880 --> 00:39:50,880
So once you pass in G1, too, you have one, right?

479
00:39:50,880 --> 00:39:59,880
Which gives us the metadata of the edge 1, 2.

480
00:40:00,720 --> 00:40:03,720
Suppose I pass in 2, 1.

481
00:40:03,720 --> 00:40:07,720
In this case, there is a bidirectional edge.

482
00:40:07,720 --> 00:40:15,720
But when you're talking about directed networks, suppose this thing exists, G1 to exist, that

483
00:40:15,720 --> 00:40:20,720
does not necessarily mean that G2, 1 will also exist.

484
00:40:20,720 --> 00:40:23,720
So in this case, it exists.

485
00:40:23,720 --> 00:40:26,720
But that's just by incident.

486
00:40:27,560 --> 00:40:30,560
Again, an API note.

487
00:40:30,560 --> 00:40:41,560
If you are using 2.0 and later, both of these ways of accessing the weight or the attribute

488
00:40:41,560 --> 00:40:42,560
will work.

489
00:40:42,560 --> 00:40:45,560
But this is the...

490
00:40:52,560 --> 00:40:55,560
Oh, yeah, sorry.

491
00:40:57,560 --> 00:41:03,560
But this is the more Pythonic way now.

492
00:41:03,560 --> 00:41:08,560
So if you're creating a new application which depends on NetworkX, so use this.

493
00:41:08,560 --> 00:41:13,560
Because I'm pretty sure this wouldn't be deprecated in the future anytime soon.

494
00:41:13,560 --> 00:41:21,560
But if you are writing new code, use something like this, which is the new way of writing

495
00:41:21,560 --> 00:41:24,560
NetworkX code.

496
00:41:25,400 --> 00:41:29,400
We won't do this exercise, but this is for break time.

497
00:41:29,400 --> 00:41:33,400
If you are done with your coffee fast, you can do this.

498
00:41:35,400 --> 00:41:38,400
The controversial part of this data set.

499
00:41:40,400 --> 00:41:45,400
Let's try to find out unrequited friendships.

500
00:41:45,400 --> 00:41:47,400
I always say, oh, you are my best friend.

501
00:41:47,400 --> 00:41:50,400
But that person is like, no, sorry.

502
00:41:51,240 --> 00:41:56,240
So basically, you need to find these friendships.

503
00:41:56,240 --> 00:41:59,240
And you can do this later in the break.

504
00:42:01,240 --> 00:42:07,240
There are solutions to this if you want to check out.

505
00:42:07,240 --> 00:42:14,240
And talking about tests, again, as Eric mentioned, tests are something which are used a lot in

506
00:42:14,240 --> 00:42:15,240
software engineering.

507
00:42:16,080 --> 00:42:23,080
You have test development and stuff, but there isn't enough momentum behind testing in data

508
00:42:23,080 --> 00:42:24,080
science.

509
00:42:24,080 --> 00:42:31,080
So it's always nice to have, like always test your data, not just your code.

510
00:42:31,080 --> 00:42:32,080
Just test your data.

511
00:42:32,080 --> 00:42:35,080
Like if someone gives you data, just actually check it.

512
00:42:35,080 --> 00:42:38,080
It has what it says.

513
00:42:38,080 --> 00:42:39,080
It can happen.

514
00:42:39,080 --> 00:42:40,080
You never know.

515
00:42:40,080 --> 00:42:41,080
Sorry?

516
00:42:41,080 --> 00:42:44,080
We'll have the break later.

517
00:42:44,920 --> 00:42:47,920
Once we'll have the break.

518
00:42:47,920 --> 00:42:52,920
It's at 10.15, so it's like 25 minutes from now.

519
00:42:52,920 --> 00:42:57,920
So, yeah, so this is iteration over list comprehensions.

520
00:42:57,920 --> 00:43:01,920
Like this is the way of, this is the Pythonic way of doing that.

521
00:43:01,920 --> 00:43:03,920
You can see this in your notebooks.

522
00:43:03,920 --> 00:43:08,920
So let's take a detour and talk about drawing graphs.

523
00:43:09,760 --> 00:43:16,760
So if we just try to plot our graph that we had, what do you see?

524
00:43:17,760 --> 00:43:20,760
Do you see this beautiful picture?

525
00:43:20,760 --> 00:43:23,760
What do you think of this beautiful picture?

526
00:43:23,760 --> 00:43:28,760
Yeah, chaos, spaghetti, or hairballs.

527
00:43:28,760 --> 00:43:35,760
So, I mean, again, like you don't get, or you get some information about these.

528
00:43:36,600 --> 00:43:41,600
These are probably the 30, 31, and 71, that triplet of besties.

529
00:43:41,600 --> 00:43:48,600
But you don't get a lot of information from this standard pictorial representation of

530
00:43:48,600 --> 00:43:49,600
a network.

531
00:43:49,600 --> 00:43:56,600
And so the rule of thumb is that if you have 20, 25 sparsely connected nodes, like if you

532
00:43:57,200 --> 00:44:01,400
don't have a lot of connections, then you can have a picture like this, which actually

533
00:44:01,400 --> 00:44:03,900
gives you information about the network.

534
00:44:04,040 --> 00:44:11,040
But if you have like 100 or even millions of nodes, you won't get a lot of information

535
00:44:12,600 --> 00:44:15,180
out of the visualization.

536
00:44:15,180 --> 00:44:18,640
So this just happened like last week.

537
00:44:18,640 --> 00:44:25,640
Someone tweeted that, oh, I need to visualize 20 million nodes and 80 million edges.

538
00:44:26,640 --> 00:44:29,360
I'm like, I mean, yeah, like, okay.

539
00:44:29,360 --> 00:44:31,640
So a lot of people are like, oh, cool, nice.

540
00:44:32,380 --> 00:44:35,820
But if you just count the number of pixels in your screen, they're less than the number

541
00:44:35,820 --> 00:44:37,140
of nodes.

542
00:44:37,140 --> 00:44:41,980
So you can't really visualize it just by plotting it like this.

543
00:44:41,980 --> 00:44:44,020
You need to do something more.

544
00:44:44,020 --> 00:44:48,540
You need to do something with the data first and then visualize it.

545
00:44:48,540 --> 00:44:54,460
So if you want to do that, if you have 20 or a billion nodes, a very standard way is

546
00:44:54,460 --> 00:45:01,460
actually to compress the nodes into clusters of nodes and then try to represent the results

547
00:45:02,460 --> 00:45:04,140
of the relationship between clusters.

548
00:45:04,140 --> 00:45:07,140
I think we will discuss that later in the tutorial.

549
00:45:13,140 --> 00:45:15,060
This doesn't give you information.

550
00:45:15,060 --> 00:45:18,740
So you would argue because you don't know anything about the nodes.

551
00:45:18,740 --> 00:45:21,340
Let's even add the name of the nodes.

552
00:45:21,340 --> 00:45:27,500
Still, it doesn't give you anything except the bestie relationship.

553
00:45:27,500 --> 00:45:28,660
This will always be there.

554
00:45:28,660 --> 00:45:31,620
It doesn't matter your plot.

555
00:45:32,600 --> 00:45:36,200
There are other ways of plotting a network.

556
00:45:36,200 --> 00:45:38,400
So one of them is the matrix plot.

557
00:45:38,400 --> 00:45:45,400
And this is my favorite plot because this comes from the representation of a network.

558
00:45:46,520 --> 00:45:50,520
A network can be represented by an adjacency matrix.

559
00:45:50,520 --> 00:45:54,720
People who have done computer science or maths, they'll know what I'm talking about.

560
00:45:54,720 --> 00:46:01,520
But if you don't know what an adjacency matrix is, it's like you create a matrix and you

561
00:46:02,420 --> 00:46:03,420
have a number.

562
00:46:03,420 --> 00:46:04,420
So this is our matrix.

563
00:46:04,420 --> 00:46:11,420
So if one is connected to two, these are number 1 to 29, 1 to 31 in our case, 1 to 31, 1,

564
00:46:13,420 --> 00:46:15,420
2, 3, 4, 5, 6, 7, 8, till 31.

565
00:46:15,420 --> 00:46:22,420
And if one and two are connected, you'll have a number here.

566
00:46:23,420 --> 00:46:24,420
So there is something in the matrix.

567
00:46:24,420 --> 00:46:27,020
And if they are not connected, you have zeros.

568
00:46:27,020 --> 00:46:31,420
So this is our matrix plot, which comes up from this.

569
00:46:32,320 --> 00:46:36,320
So can someone say anything about this matrix plot?

570
00:46:36,320 --> 00:46:39,320
Do you see anything interesting in this plot?

571
00:46:41,320 --> 00:46:42,320
No diagonal, yeah?

572
00:46:42,320 --> 00:46:44,320
What does that mean?

573
00:46:47,320 --> 00:46:49,320
So diagonal is what?

574
00:46:50,320 --> 00:46:52,320
Yeah, so that's a good thing, right?

575
00:46:52,320 --> 00:46:55,320
So no student said, oh, I'm my best friend.

576
00:46:56,320 --> 00:46:58,320
So that's good, I guess.

577
00:46:58,320 --> 00:47:01,320
Our society still has hope.

578
00:47:02,320 --> 00:47:05,320
And any other thing that we can see from this matrix?

579
00:47:07,320 --> 00:47:09,320
Yes, it's not symmetrical.

580
00:47:09,320 --> 00:47:14,320
Because this is a directed graph, you're not guaranteed symmetry in a directed graph.

581
00:47:14,320 --> 00:47:23,320
But if it were an indirect graph, you would see that this matrix is always symmetrical.

582
00:47:24,320 --> 00:47:29,320
Another thing that I like to do with this plot is, you can kind of create QR codes with

583
00:47:30,220 --> 00:47:33,220
this graphs, because this looks like something like a QR code, right?

584
00:47:34,220 --> 00:47:39,220
So you can create random graphs, and using those random graphs, you can create random QRs.

585
00:47:40,220 --> 00:47:45,220
So if you want to waste two hours of your life, try doing that.

586
00:47:45,220 --> 00:47:46,220
It's fun.

587
00:47:48,220 --> 00:47:51,220
So let's talk about something called an arc plot.

588
00:47:52,220 --> 00:47:56,220
I don't use these plots a lot, but Eric swears by them.

589
00:47:56,220 --> 00:47:58,220
They look very nice.

590
00:47:59,120 --> 00:48:00,120
They do look very nice.

591
00:48:01,120 --> 00:48:09,120
The idea is that instead of worrying about just plotting nodes and just trying to draw edges,

592
00:48:10,120 --> 00:48:15,120
worry more about the position of nodes, how nodes are positioned.

593
00:48:16,120 --> 00:48:20,120
And once you have that figured out, the edges will flow from that.

594
00:48:20,120 --> 00:48:24,120
So in this you can see that you have, first you have grouped nodes,

595
00:48:25,020 --> 00:48:29,020
like you have females and males grouped separately,

596
00:48:30,020 --> 00:48:34,020
and then they are also in a descending order of how connected the graph is.

597
00:48:35,020 --> 00:48:39,020
If you have a lot of different connections for a node, you are at the top of this chain.

598
00:48:40,020 --> 00:48:46,020
So it gives you more information, especially than this hairball, right?

599
00:48:47,020 --> 00:48:51,020
You have more information, and you can actually go show these to people,

600
00:48:51,920 --> 00:48:54,920
and say, this is our graph and this is what's happening here.

601
00:48:55,920 --> 00:48:59,920
Circus plot is arc plot, but joined.

602
00:49:01,920 --> 00:49:03,920
And again, this looks perfect, right?

603
00:49:04,920 --> 00:49:07,920
If you want to sell something, this is what you show.

604
00:49:12,920 --> 00:49:15,920
So all of these visualizations are not in NetworkX.

605
00:49:16,820 --> 00:49:21,820
NetworkX is not a visualization library.

606
00:49:22,820 --> 00:49:27,820
They have an Nx.draw, which does the work, but they are not a visualization library.

607
00:49:28,820 --> 00:49:29,820
There are other options.

608
00:49:30,820 --> 00:49:33,820
One of them is NxVis, which is written by Eric here.

609
00:49:36,820 --> 00:49:39,820
It's a nice library if you want plots like this.

610
00:49:40,720 --> 00:49:45,720
And then there are, I think in the Python ecosystem, you can use Bokeh.

611
00:49:47,720 --> 00:49:51,720
You can use, I think even Dask has something now to visualize.

612
00:49:53,720 --> 00:49:55,720
Oh yeah, they use Pygraph vis.

613
00:49:56,720 --> 00:49:58,720
So there's Pygraph vis, there's Bokeh.

614
00:49:59,720 --> 00:50:01,720
And if you are okay with moving out of the Python world,

615
00:50:02,720 --> 00:50:06,720
there's something called Geffi, which is used a lot by people, at least in academia,

616
00:50:07,720 --> 00:50:09,720
to make graphs.

617
00:50:10,720 --> 00:50:15,720
But again, like, oh yeah, this is one of my favorite plots.

618
00:50:16,720 --> 00:50:17,720
It's called a Hive plot.

619
00:50:18,720 --> 00:50:26,720
It's really nice because it gives you relationships between the nodes in a group

620
00:50:27,720 --> 00:50:30,720
and the relation between the group.

621
00:50:31,720 --> 00:50:34,720
So for example, these are male students.

622
00:50:35,720 --> 00:50:36,720
These are also male students.

623
00:50:37,720 --> 00:50:38,720
This is just a copy of those students.

624
00:50:39,620 --> 00:50:41,620
And this is how they are connected inside the group,

625
00:50:42,620 --> 00:50:43,620
how males are connected to males.

626
00:50:44,620 --> 00:50:45,620
And this is how males are connected to females.

627
00:50:46,620 --> 00:50:51,620
And you'll see you have a bunch of popular fellas with the females.

628
00:50:52,620 --> 00:50:54,620
And you don't see that in females.

629
00:50:55,620 --> 00:50:57,620
It seems like it's evenly distributed all across females.

630
00:50:58,620 --> 00:51:01,620
So that's an interesting observation too.

631
00:51:02,520 --> 00:51:09,520
So let's now move to notebook three.

632
00:51:12,520 --> 00:51:13,520
It's 9.56.

633
00:51:14,520 --> 00:51:15,520
It breaks at 10.15.

634
00:51:24,520 --> 00:51:29,520
If the snacks are not out, we'll just introduce this notebook and then we'll go for snacks.

635
00:51:30,420 --> 00:51:35,420
In this we'll use a dataset from socio-patterns.

636
00:51:48,420 --> 00:51:53,420
Add a chip to your lanyard or something.

637
00:51:54,420 --> 00:51:55,420
And you're just going, talking to people.

638
00:51:56,320 --> 00:52:01,320
If you're talking to people for 30 seconds, there's an edge connected between them.

639
00:52:02,320 --> 00:52:05,320
So this is how you created this network of people.

640
00:52:06,320 --> 00:52:07,320
How people talk to each other.

641
00:52:08,320 --> 00:52:09,320
How they interact in a room.

642
00:52:10,320 --> 00:52:11,320
How they interact in a conference or something.

643
00:52:12,320 --> 00:52:13,320
So that's how they created this dataset.

644
00:52:16,320 --> 00:52:19,320
So the idea is how infections can spread through people.

645
00:52:22,320 --> 00:52:23,320
These are just hypotheticals.

646
00:52:24,220 --> 00:52:29,220
Suppose you need 30 seconds for a virus from person A to spread to person B.

647
00:52:30,220 --> 00:52:33,220
So stay away and how to model that.

648
00:52:35,220 --> 00:52:36,220
So let's load in the dataset.

649
00:52:38,220 --> 00:52:40,220
And let's check what's there in the dataset.

650
00:52:41,220 --> 00:52:45,220
So we have around 400 nodes in the dataset and 2700 edges.

651
00:52:50,220 --> 00:52:51,220
Let's talk about analyzing the network.

652
00:52:52,120 --> 00:52:55,120
Till now we just had a look at the description of the network.

653
00:52:56,120 --> 00:52:58,120
How many nodes, how many edges, how do they look like.

654
00:52:59,120 --> 00:53:01,120
But this is where the fun begins now.

655
00:53:02,120 --> 00:53:05,120
How do we evaluate important nodes?

656
00:53:06,120 --> 00:53:07,120
For example in Twitter, right?

657
00:53:08,120 --> 00:53:09,120
Who do you think is important?

658
00:53:19,120 --> 00:53:20,120
Is John Musk important?

659
00:53:21,020 --> 00:53:22,020
Is he important?

660
00:53:23,020 --> 00:53:24,020
I don't know, maybe he is.

661
00:53:35,020 --> 00:53:38,020
Suppose we are just looking at the Twitter network itself.

662
00:53:39,020 --> 00:53:40,020
Followers.

663
00:53:41,020 --> 00:53:42,020
One way of looking at it is just calculate the number of followers.

664
00:53:44,020 --> 00:53:45,020
So this person has 20 million followers.

665
00:53:46,020 --> 00:53:47,020
This person must be an important person.

666
00:53:48,020 --> 00:53:49,020
It makes sense.

667
00:53:49,920 --> 00:53:52,920
So this is how any sane person would say.

668
00:53:56,920 --> 00:53:57,920
If you go to a person who doesn't know what network science is,

669
00:53:58,920 --> 00:53:59,920
and they are like, who is the most important person on Twitter?

670
00:54:00,920 --> 00:54:01,920
Just count the followers.

671
00:54:02,920 --> 00:54:03,920
That makes sense.

672
00:54:04,920 --> 00:54:05,920
There is nothing wrong with that.

673
00:54:06,920 --> 00:54:09,920
So instead of followers we count number of neighbors.

674
00:54:10,920 --> 00:54:15,920
So basically neighbors is like the number of nodes a node is connected to.

675
00:54:16,920 --> 00:54:17,920
That's the neighbors.

676
00:54:17,920 --> 00:54:21,820
So let's just...

677
00:54:48,820 --> 00:54:49,820
Let's just say that we have a number of neighbors.

678
00:54:50,820 --> 00:54:51,820
So let's just say that we have a number of neighbors.

679
00:54:52,820 --> 00:54:53,820
So let's just say that we have a number of neighbors.

680
00:54:54,820 --> 00:54:55,820
So let's just say that we have a number of neighbors.

681
00:54:56,820 --> 00:54:57,820
So let's just say that we have a number of neighbors.

682
00:54:58,820 --> 00:54:59,820
So let's just say that we have a number of neighbors.

683
00:55:00,820 --> 00:55:01,820
So let's just say that we have a number of neighbors.

684
00:55:02,820 --> 00:55:03,820
So let's just say that we have a number of neighbors.

685
00:55:04,820 --> 00:55:05,820
So let's just say that we have a number of neighbors.

686
00:55:06,820 --> 00:55:07,820
So let's just say that we have a number of neighbors.

687
00:55:08,820 --> 00:55:09,820
So let's just say that we have a number of neighbors.

688
00:55:10,820 --> 00:55:11,820
So let's just say that we have a number of neighbors.

689
00:55:12,820 --> 00:55:13,820
So let's just say that we have a number of neighbors.

690
00:55:14,820 --> 00:55:15,820
So let's just say that we have a number of neighbors.

691
00:55:16,720 --> 00:55:17,720
What is the number of neighbors?

692
00:55:19,720 --> 00:55:21,520
Here I go the timepiece.

693
00:55:24,520 --> 00:55:25,520
So what we can do is we can go to the manager my name is Shavir.

694
00:55:26,520 --> 00:55:27,520
Thank you!

695
00:55:28,520 --> 00:55:29,520
We've been trying to get more people involved with our videoided Zen methods,

696
00:55:30,520 --> 00:55:31,520
all through Japan.

697
00:55:32,520 --> 00:55:33,720
We have been trying to get more people involved with our videoided Zen methods,

698
00:55:34,920 --> 00:55:40,260
with the

699
00:55:41,260 --> 00:55:42,760
community of Japan.

700
00:55:43,760 --> 00:55:45,160
And I think we need to start slowly but surely

701
00:55:45,820 --> 00:55:47,520
of neighbors in our case.

702
00:55:47,520 --> 00:55:52,920
So let's create a ranked list of who is the most important node

703
00:55:52,920 --> 00:55:54,960
in this network.

704
00:55:54,960 --> 00:55:57,240
So we have this network G, which we know here.

705
00:56:00,700 --> 00:56:02,480
And we calculate the neighbors for,

706
00:56:02,480 --> 00:56:04,700
so basically the idea is to calculate the neighbors

707
00:56:04,700 --> 00:56:08,440
for every node and find the maximum of that.

708
00:56:08,940 --> 00:56:17,400
You do that, or the better way to get a ranked list,

709
00:56:17,400 --> 00:56:18,640
who is the most important one?

710
00:56:24,960 --> 00:56:27,320
And once you are done, please give me a thumbs up.

711
00:56:38,440 --> 00:56:38,940
Thank you.

712
00:57:08,440 --> 00:57:08,940
Thank you.

713
00:57:38,440 --> 00:57:38,940
Thank you.

714
00:58:08,440 --> 00:58:37,140
If someone's done, can someone tell me the answer?

715
00:58:37,140 --> 00:58:41,140
Who is the most important node in this network?

716
00:58:46,180 --> 00:58:48,980
51.

717
00:58:48,980 --> 00:58:52,660
So we know what the network is.

718
00:58:52,660 --> 00:58:55,500
It's how people interact in a conference.

719
00:58:55,500 --> 00:58:58,220
So what can we say about the node 51?

720
00:59:01,140 --> 00:59:05,500
What kind of person is node 51?

721
00:59:05,500 --> 00:59:06,780
Maybe, yeah, an extrovert.

722
00:59:12,820 --> 00:59:17,540
And in a case of a flu outbreak, what do you do with 51?

723
00:59:17,540 --> 00:59:19,260
You stay away from 51.

724
00:59:35,500 --> 00:59:36,500
Thumbs up if you're done.

725
01:00:05,500 --> 01:00:32,100
As you can see on the screen, I have the answers flashing up,

726
01:00:32,100 --> 01:00:34,620
because again, there is no one way of doing it.

727
01:00:34,620 --> 01:00:40,500
So you can create a data frame and then try to figure this out.

728
01:00:40,500 --> 01:00:46,620
Or you can use the sorted function to solve this.

729
01:00:46,620 --> 01:00:52,340
And you can just create a list and then sort it.

730
01:00:52,340 --> 01:00:54,140
You can use whatever you fancy.

731
01:00:54,140 --> 01:00:56,580
And again, there is no one right answer.

732
01:00:57,580 --> 01:01:05,500
So we used our basic approach of counting followers, right?

733
01:01:05,500 --> 01:01:07,700
Because that would make sense.

734
01:01:07,700 --> 01:01:10,020
Just count the total number of neighbors.

735
01:01:10,020 --> 01:01:13,700
Whichever has the highest one should be an important node

736
01:01:13,700 --> 01:01:18,540
or an important person in this network.

737
01:01:18,540 --> 01:01:21,460
So now let's talk something about degree centrality.

738
01:01:21,460 --> 01:01:29,820
Degree centrality is nothing but a fancier name for a number of neighbors.

739
01:01:29,820 --> 01:01:35,020
So what it gives you is it gives you a normalized version of number of neighbors.

740
01:01:35,020 --> 01:01:39,700
So degree centrality is the number of nodes you are connected to divided

741
01:01:39,700 --> 01:01:43,180
by the number of nodes you can connect to.

742
01:01:43,180 --> 01:01:46,860
So suppose you have 100 nodes in a network.

743
01:01:46,860 --> 01:01:49,580
How many nodes can I connect to?

744
01:01:49,580 --> 01:01:50,080
Anyone?

745
01:01:52,460 --> 01:01:52,960
Sorry?

746
01:01:55,900 --> 01:01:58,260
I have 100 nodes in the network.

747
01:01:58,260 --> 01:02:00,860
How many nodes can I connect to?

748
01:02:00,860 --> 01:02:02,540
99, yes.

749
01:02:02,540 --> 01:02:04,820
Assuming we don't allow for self loops, right?

750
01:02:04,820 --> 01:02:08,900
We don't have any narcissists in our thing that they'll just talk to themselves.

751
01:02:08,900 --> 01:02:10,180
They're like, oh, yeah.

752
01:02:10,180 --> 01:02:14,420
So we have that number n minus 1.

753
01:02:14,420 --> 01:02:15,540
That's the denominator.

754
01:02:15,540 --> 01:02:18,380
And we know the numerator is the number of nodes you're connected to,

755
01:02:18,380 --> 01:02:22,220
which is whatever the number of nodes you're connected to.

756
01:02:22,220 --> 01:02:25,900
So again, degree centrality is just a fancy way of saying count the total number

757
01:02:25,900 --> 01:02:27,180
of neighbors.

758
01:02:27,180 --> 01:02:29,060
And it will give you a normalized version.

759
01:02:29,060 --> 01:02:32,540
And if you sum everything, you'll get one.

760
01:02:32,540 --> 01:02:36,580
If you sum all the degree centralities, you'll get one.

761
01:02:36,580 --> 01:02:38,380
Yeah, you should, yeah.

762
01:02:38,380 --> 01:02:46,420
And so to do that, again, networkX gives us a nice little function called

763
01:02:46,420 --> 01:02:48,260
nx.degreeCentrality.

764
01:02:48,260 --> 01:02:49,900
You pass in a graph.

765
01:02:49,900 --> 01:02:55,020
It will give you a nice looking dictionary, which is keyed by the node,

766
01:02:55,020 --> 01:03:01,460
and a nice little float, which is the degree centrality.

767
01:03:01,460 --> 01:03:05,620
So if we just look at any five, we get this thing.

768
01:03:11,380 --> 01:03:16,700
I don't think we'll do this exercise after the break.

769
01:03:16,700 --> 01:03:19,340
But does anyone know what is ecdf?

770
01:03:22,300 --> 01:03:23,780
Anyone?

771
01:03:23,780 --> 01:03:25,260
You can tell me.

772
01:03:35,180 --> 01:03:36,500
Testing.

773
01:03:36,500 --> 01:03:39,940
My favorite chart, the empirical cumulative distribution function,

774
01:03:39,940 --> 01:03:41,500
I think, just shows you like.

775
01:03:41,500 --> 01:03:44,980
I think those are the best ones.

776
01:03:44,980 --> 01:03:45,980
I love that chart.

777
01:03:46,060 --> 01:03:47,540
I think I love that too.

778
01:03:47,540 --> 01:03:52,540
So instead of using this program, we can do something called an ecdf.

779
01:03:52,540 --> 01:03:58,020
It's a very, not a very obscure concept, but not a lot of people do it.

780
01:03:58,020 --> 01:04:01,500
And apparently, a lot of people should use it.

781
01:04:01,500 --> 01:04:04,980
So we will do that later.

782
01:04:04,980 --> 01:04:08,460
But in this exercise, you have to calculate the start right now.

783
01:04:08,460 --> 01:04:11,460
And then you can just go straight and come back.

784
01:04:11,460 --> 01:04:15,460
You have to create an ecdf of the distribution of the degree centrality.

785
01:04:15,460 --> 01:04:26,260
And then compare the plots of these two and make sure that it's an actual straight line.

786
01:04:26,260 --> 01:04:32,300
Because as I said, degree centrality is exactly what number of neighbors is.

787
01:04:32,300 --> 01:04:38,180
So you should end up with something like this, a plot for degree centrality

788
01:04:38,180 --> 01:04:41,300
versus number of neighbors.

789
01:04:41,300 --> 01:04:41,820
Yes.

790
01:04:45,460 --> 01:04:45,940
Yeah.

791
01:04:50,940 --> 01:04:54,660
Could you just real quick explain the whole it has to sum up to zero thing?

792
01:04:54,660 --> 01:04:56,300
Because it doesn't seem intuitive to me.

793
01:04:56,300 --> 01:05:00,660
Like if you and I are both best friends with 90% of people in the room,

794
01:05:00,660 --> 01:05:05,500
I don't understand how the degree centrality would sum to one, conceptually.

795
01:05:05,500 --> 01:05:08,340
OK, suppose n minus 1.

796
01:05:08,340 --> 01:05:11,220
n minus 1 is our base, right?

797
01:05:11,220 --> 01:05:15,900
If I'm friends with you, if everyone is friends with n minus 1.

798
01:05:21,940 --> 01:05:23,420
I think it wouldn't also.

799
01:05:23,420 --> 01:05:25,060
It wouldn't sum up to one.

800
01:05:25,060 --> 01:05:27,060
It shouldn't sum up to one.

801
01:05:27,060 --> 01:05:28,860
And wait.

802
01:05:28,860 --> 01:05:30,060
I need to think about this.

803
01:05:30,060 --> 01:05:32,660
So yeah, we can talk about this in the break.

804
01:05:32,660 --> 01:05:36,140
And I think we can take the break now.

805
01:05:36,140 --> 01:05:37,100
Yep, yep.

806
01:05:37,100 --> 01:05:39,540
So I think we can take the break now.

807
01:05:39,780 --> 01:05:45,100
So I think we meet at 10.20, 10.25.

808
01:05:45,100 --> 01:05:48,540
So let's be back by 10.25.

809
01:05:48,540 --> 01:05:53,380
And if you come back early, just start working on the exercise.

810
01:05:56,980 --> 01:06:00,060
There are snacks out there, so have fun.

811
01:22:39,540 --> 01:22:40,540
Back.

812
01:22:59,980 --> 01:23:03,620
I hope you had a good snack and coffee break.

813
01:23:03,620 --> 01:23:08,500
So you can start working on this exercise.

814
01:23:08,580 --> 01:23:13,220
And if you're not very familiar with matplotlib, it's OK.

815
01:23:13,220 --> 01:23:19,900
Just open the instructor notebook, and you can get what's happening here.

816
01:23:19,900 --> 01:23:23,340
You need to be familiar with matplotlib for this exercise.

817
01:23:33,100 --> 01:23:35,860
And once you're done, give me a thumbs up.

818
01:23:35,860 --> 01:23:40,700
And this is what you should end up with, a plot looking like this

819
01:23:40,700 --> 01:23:45,660
for degree centrality, a very similar plot for number of neighbors,

820
01:23:45,660 --> 01:23:48,620
and this straight line plot.

821
01:25:05,860 --> 01:25:08,900
Somebody mentioned that you use these instead of histograms.

822
01:25:08,900 --> 01:25:11,460
I vaguely remember this in college.

823
01:25:11,460 --> 01:25:15,820
If it's straighter, the line, the more normally distributed it is, or no?

824
01:25:15,820 --> 01:25:16,820
OK.

825
01:25:16,820 --> 01:25:18,740
How do you read this?

826
01:25:18,740 --> 01:25:20,820
I imagine you'll probably get it.

827
01:25:20,820 --> 01:25:24,140
OK, I'm going to do my spiel on ECDFs, OK?

828
01:25:24,140 --> 01:25:25,540
All right.

829
01:25:25,540 --> 01:25:31,140
ECDFs are really cool, because they tell you more information than a histogram.

830
01:25:31,140 --> 01:25:34,460
You can read off much, much more information than a histogram.

831
01:25:34,500 --> 01:25:36,860
The only thing is that people are not used to it.

832
01:25:36,860 --> 01:25:37,860
That's it, OK?

833
01:25:37,860 --> 01:25:40,100
So let me give a bit of a demo, OK?

834
01:25:40,100 --> 01:25:42,620
We got this ECDF up here.

835
01:25:42,620 --> 01:25:47,580
On the x-axis, you have values that your data points take on.

836
01:25:47,580 --> 01:25:52,300
And on the y-axis, we're showing the cumulative number of points

837
01:25:52,300 --> 01:25:57,180
that are smaller than any particular value inside the data set, OK?

838
01:25:57,180 --> 01:26:01,740
So a number of things are immediately, like, you can read it off.

839
01:26:01,780 --> 01:26:03,060
You can read off the median.

840
01:26:03,060 --> 01:26:10,140
If you draw a line from the 50th percentile over onto the curve, or the dots,

841
01:26:10,140 --> 01:26:15,540
and then you project back down, you can see what the median is straight away.

842
01:26:15,540 --> 01:26:18,460
And because you can read off percentiles so easily,

843
01:26:18,460 --> 01:26:21,020
you can read off interquartile ranges.

844
01:26:21,020 --> 01:26:25,420
You can read off the 25th to 75th percentile very easily.

845
01:26:25,420 --> 01:26:29,020
You can even read off, like, the minimum and maximum.

846
01:26:29,020 --> 01:26:33,700
So actually, Mriddle, can you change this to plt.hist?

847
01:26:37,660 --> 01:26:47,100
So, and I think it's just degree centralities,

848
01:26:47,100 --> 01:26:51,100
just plt.hist degree centralities.

849
01:26:51,100 --> 01:26:54,100
Misspelled degree.

850
01:26:55,100 --> 01:26:57,100
Misspelled degree.

851
01:26:57,100 --> 01:26:59,100
Whoopsie.

852
01:27:06,100 --> 01:27:08,100
It probably needs to be run first.

853
01:27:08,100 --> 01:27:10,100
Oh, yeah. Whoops.

854
01:27:17,100 --> 01:27:19,100
Try reading off the median from there.

855
01:27:21,100 --> 01:27:23,100
Try reading off the interquartile range from there.

856
01:27:23,100 --> 01:27:25,100
You can't.

857
01:27:25,100 --> 01:27:29,100
One of the big problems about histograms is you have binning bias.

858
01:27:29,100 --> 01:27:36,100
If you change bins to like that, oh, oh, suddenly, yeah, we got, like, three outliers,

859
01:27:36,100 --> 01:27:38,100
potentially three outliers.

860
01:27:38,100 --> 01:27:40,100
But did we know that if we used the default settings?

861
01:27:40,100 --> 01:27:42,100
No. Do people change default settings?

862
01:27:42,100 --> 01:27:44,100
No. Sometimes. No. Rarely.

863
01:27:44,100 --> 01:27:46,100
Yeah, yeah, you get something like this.

864
01:27:46,100 --> 01:27:48,100
Now, what's going on there, right?

865
01:27:48,100 --> 01:27:50,100
Use an eCDF, right?

866
01:27:50,100 --> 01:27:56,100
And bring it back to your institutions, like, eCDFs give you the same information as a histogram,

867
01:27:56,100 --> 01:27:59,100
just richer, just richer.

868
01:27:59,100 --> 01:28:05,100
And in fact, bimodality is what some people are used to looking at, two humps in the data set.

869
01:28:05,100 --> 01:28:10,100
If you've got strong bimodality, you'll see that inside the eCDF,

870
01:28:10,100 --> 01:28:13,100
in that you'll see a middle plateau and then a second plateau.

871
01:28:13,100 --> 01:28:15,100
If you have trimodality, you'll see three plateaus.

872
01:28:15,100 --> 01:28:20,100
If you can't see plateaus, you don't have bimodality no matter what your histogram says.

873
01:28:20,100 --> 01:28:23,100
Okay? Cool? All right.

874
01:28:23,100 --> 01:28:28,100
And coming back to the normal thing, if you have a normal distribution, you'll get a perfect S.

875
01:28:28,100 --> 01:28:34,100
A perfect S, which, and a perfect, like, bimodally you have, like, perfect S with a...

876
01:28:34,100 --> 01:28:49,100
If you do a lot of the degree centralities, is it the same deal where you should expect an S for normality or no?

877
01:28:49,100 --> 01:28:58,100
So if you simply log transform the X values, that still might not necessarily get you to,

878
01:28:58,100 --> 01:29:02,100
that might not necessarily get you to normality. We can try.

879
01:29:02,100 --> 01:29:07,100
For normality, like, if you have a normally distributed degree,

880
01:29:07,100 --> 01:29:11,100
the log-log plot will also be a normally distributed degree.

881
01:29:11,100 --> 01:29:15,100
And if you have an exponential decay, then you'll get a straight line.

882
01:29:15,100 --> 01:29:20,100
What are the purposes of doing the log of this?

883
01:29:20,100 --> 01:29:27,100
So at least, like, the log-log plot is, so basically, I think what the reason was is,

884
01:29:27,100 --> 01:29:32,100
so there was this theory of preference, of how networks grow,

885
01:29:32,100 --> 01:29:38,100
how the degree is distributed all around the network, and that followed a decaying power law,

886
01:29:38,100 --> 01:29:40,100
which is this decaying exponential function.

887
01:29:40,100 --> 01:29:45,100
And if you take the log-log plot of that, you get a straight line.

888
01:29:45,100 --> 01:29:49,100
So I think the idea comes up from, like, it's a test.

889
01:29:49,100 --> 01:29:54,100
If you get a straight line in a log-log plot, it's a scale-free network.

890
01:29:54,100 --> 01:29:59,100
So I think we'll discuss that, like, for a bit later.

891
01:30:08,100 --> 01:30:14,100
So this is what you should get in the plot. And let's just discuss this plot for a bit.

892
01:30:14,100 --> 01:30:22,100
Like, as Eric mentioned, like, the 50th percentile, so 50th percentile goes to, like, 0.03.

893
01:30:22,100 --> 01:30:28,100
So we can say that the degree of centrality of 50 percent of the nodes is less than 0.03.

894
01:30:28,100 --> 01:30:40,100
Like, then if we go up, like, the degree of centrality of 0.95, like, 95 percent of the nodes is less than 0.08.

895
01:30:40,100 --> 01:30:52,100
So we are getting something here. Like, you know, 95 percent of the nodes are very sparsely connected.

896
01:30:52,100 --> 01:30:56,100
They're not connected to a lot of other people because they have a very low degree centrality.

897
01:30:56,100 --> 01:31:02,100
And you have these three, not outliers, exactly, but you have these three people in this network

898
01:31:02,100 --> 01:31:05,100
which are connected to a lot of other people.

899
01:31:05,100 --> 01:31:14,100
So what does this tell us about the real world? Like, does this mirror your expectations?

900
01:31:18,100 --> 01:31:24,100
Like, for example, in Twitter, right, like, you don't have, not everyone has 20 or 30 million followers.

901
01:31:24,100 --> 01:31:30,100
Majority of the people would have 100 or 200 followers. But you will have these three, these three people are like, you know,

902
01:31:30,100 --> 01:31:35,100
I don't know. I think Shakira has the most followers. Who has the most followers? I don't know.

903
01:31:35,100 --> 01:31:42,100
I think, I know a female pop artist has the most number of followers on Twitter. So these are those artists.

904
01:31:42,100 --> 01:31:50,100
No, no, no. Kardashian is a US thing, thankfully.

905
01:31:50,100 --> 01:31:59,100
Yeah. So if you look at the degree centrality ECDF and the number of neighbors ECDF, it looks similar.

906
01:31:59,100 --> 01:32:08,100
But it's not just similar. It's the exact same plot because degree centrality is just a normalized version of number of neighbors.

907
01:32:08,100 --> 01:32:16,100
And if you would plot the XY plot, you'll get a straight line, the relationship between degree centrality and number of neighbors.

908
01:32:16,100 --> 01:32:22,100
This is as expected. So this is an exercise, but we won't do this.

909
01:32:22,100 --> 01:32:32,100
Let's just look at the circus plot of this. And now we'll see why having a plot like this makes sense.

910
01:32:32,100 --> 01:32:42,100
So the first thought of this picture, this looks like a nice pretty picture, right? Yeah. Everything works.

911
01:32:42,100 --> 01:32:48,100
And if you look at, like these are the nodes because this is a circle, circle plots.

912
01:32:48,100 --> 01:32:52,100
And this represents the incoming time because this is an event, right?

913
01:32:52,100 --> 01:32:58,100
And we have information about when every node or every person enters into this conference.

914
01:32:58,100 --> 01:33:07,100
So like it goes in an anti-clockwise direction. This is increasing time. This bar is increasing time.

915
01:33:07,100 --> 01:33:15,100
So what can we infer from this? Anyone? This is a plot between interactions.

916
01:33:15,100 --> 01:33:28,100
These are the nodes with an increasing time order. Can we infer anything?

917
01:33:28,100 --> 01:33:34,100
Look at this space in the middle. What can we infer from this?

918
01:33:34,100 --> 01:33:39,100
It looks like people like lunchtime because you get a lot of activity. I mean, I assume this is one day.

919
01:33:39,100 --> 01:33:45,100
So what I see is that at the beginning, there's not as many. At the very end, there's not as many because that's like the left hand side.

920
01:33:45,100 --> 01:33:53,100
Not as many. It's not as dark, which I assume is representative of the number of interactions. You see a lot more on the far right.

921
01:33:53,100 --> 01:34:01,100
But so like let me make that clear again. So this is node three, which enters at a certain time.

922
01:34:01,100 --> 01:34:08,100
This is suppose node 20, which enters at a certain time. If there is a link between them, it means they had an interaction.

923
01:34:08,100 --> 01:34:15,100
Like you're like that makes sense. You know, people, if it's if it's darker, people are interacting more. That's perfect.

924
01:34:15,100 --> 01:34:20,100
But there is another interesting thing that we can take out of this plot.

925
01:34:20,100 --> 01:34:28,100
So that people are mostly interacting with people who came in at a very similar time.

926
01:34:28,100 --> 01:34:35,100
Yes, as you can see, like if you come at 8 a.m., you're just interacting with the people who came in.

927
01:34:35,100 --> 01:34:39,100
I think this interaction goes up to maybe like 10 or 12.

928
01:34:39,100 --> 01:34:46,100
So you are interacting with the interacting with the people who came in at this at a similar time as you.

929
01:34:46,100 --> 01:34:54,100
So if that wasn't the case, you would see a lot of you see a lot of connections in this middle.

930
01:34:54,100 --> 01:35:01,100
So this is one of the reasons like, you know, choosing a correct visualization is important.

931
01:35:01,100 --> 01:35:06,100
Like if you if you just plotted this on our annexed or draw like, you know, yeah, good luck with that.

932
01:35:06,100 --> 01:35:10,100
Good luck with that. Try inferring that from a hairball. Good luck with that.

933
01:35:10,100 --> 01:35:18,100
So this is again one of the reasons why visualization is important and choosing the right visualization is important.

934
01:35:18,100 --> 01:35:25,100
So let's move on to another concept in network science of graph theory is parts.

935
01:35:25,100 --> 01:35:35,100
And in my opinion, this is one of the one of the most useful and one of the most important part of networks is graph.

936
01:35:35,100 --> 01:35:47,100
Graph, graph traversal, like suppose I suppose talking about this social pattern network, suppose I tell a person X something.

937
01:35:47,100 --> 01:35:53,100
How much time will it take to like how does things spread in this network?

938
01:35:53,100 --> 01:36:01,100
Right. If I know the path from this person to every other person in the network, I can I can try to model these things.

939
01:36:01,100 --> 01:36:05,100
This is one of the reasons graph graph traversal is important.

940
01:36:05,100 --> 01:36:13,100
I mean, even Google Maps that I assume a lot of people use here is is basic problem graph traversal.

941
01:36:13,100 --> 01:36:17,100
And you can actually create your own Google Maps or Jupyter Notebook.

942
01:36:17,100 --> 01:36:22,100
If you want to know that, meet me after the after the tutorial.

943
01:36:22,100 --> 01:36:29,100
I was kind of working on that. So let's let's talk about shortest path.

944
01:36:29,100 --> 01:36:35,100
Like they're like going from point A to point B, there are multiple paths possible.

945
01:36:35,100 --> 01:36:43,100
Right. But one thing that we are very interested in is finding the shortest path because that's sometimes a good thing.

946
01:36:43,100 --> 01:36:49,100
And sometimes you're not. But sometimes that is what we're interested in.

947
01:36:49,100 --> 01:36:57,100
And if you remember from your college days or assuming if you have done computer science or math,

948
01:36:57,100 --> 01:37:01,100
there is something called Brett BFS, Brett for search and depth for search.

949
01:37:01,100 --> 01:37:09,100
These are standard algorithms to find the shortest path in a in a network.

950
01:37:09,100 --> 01:37:20,100
So the basic idea is that suppose I want to find the shortest path between me and let's suppose we are in the Facebook social network, right?

951
01:37:20,100 --> 01:37:23,100
Where every node is a user like I'm a user of Facebook.

952
01:37:23,100 --> 01:37:28,100
So I'm a node in the Facebook social network and every friendship is an edge.

953
01:37:28,100 --> 01:37:33,100
So suppose I want to find the shortest path from me to Mark Zuckerberg.

954
01:37:33,100 --> 01:37:39,100
Right. So basically I'll start jumping. So I look into my neighborhood.

955
01:37:39,100 --> 01:37:44,100
I look to my friends. I go to every neighborhood and then ask, are you friends with Mark Zuckerberg?

956
01:37:44,100 --> 01:37:48,100
Are you friends with Mark Zuckerberg? Are you friends? I do this for all of my friends.

957
01:37:48,100 --> 01:37:56,100
If I don't get an answer, yes, then I'll jump in my friends of friends, assuming I have access to all that data.

958
01:37:56,100 --> 01:38:03,100
Then I'll ask everyone. So basically you keep on expanding your neighborhood search with degree one, degree two.

959
01:38:03,100 --> 01:38:08,100
But in this case, I mean how far I'm going from my initial set.

960
01:38:08,100 --> 01:38:16,100
And this is how you find your like this is how I find the shortest path between me and Zuckerberg on Facebook.

961
01:38:16,100 --> 01:38:21,100
So talking about this, does anyone know about six degrees of separation?

962
01:38:21,100 --> 01:38:24,100
Can someone tell me that?

963
01:38:33,100 --> 01:38:42,100
It's the concept that if you have any two people, they should be connected by at least like through a path of sex.

964
01:38:42,100 --> 01:39:01,100
So I think it was some like some sociologists came up with this in like 80s or 90s that it's called a small world theory that we live in a very small world that I can jump from one person to any other person in this world in less than six steps on average and on average being the keyword term here.

965
01:39:02,100 --> 01:39:08,100
So I think so Facebook is the largest known social network of the world, right?

966
01:39:08,100 --> 01:39:11,100
Well, there is one sort of friendship and knowing each other.

967
01:39:11,100 --> 01:39:21,100
So I think they ran this couple of years back when they had one point three one point six billion people and they found out the average shortest path.

968
01:39:21,100 --> 01:39:26,100
The degrees of separation is three point eight on Facebook.

969
01:39:26,100 --> 01:39:30,100
So and that's a very interesting fact, right?

970
01:39:30,100 --> 01:39:36,100
That within four jumps within three point eight jumps, I can reach anyone on Facebook.

971
01:39:36,100 --> 01:39:42,100
Like like if I'm friends with you, you are friends with someone else in this like Dustin, like four jumps.

972
01:39:42,100 --> 01:39:48,100
I can reach to anyone in the in Facebook and Facebook has one point six billion people at that time.

973
01:39:48,100 --> 01:39:58,100
And when they did this, they actually release a tool where you could see your personal listing, not just average your personal shortest path length.

974
01:39:58,100 --> 01:40:02,100
That if I am here, like how many jumps will I take?

975
01:40:02,100 --> 01:40:06,100
And I think for me it was three point nine and for Zuckerberg it was three point one.

976
01:40:06,100 --> 01:40:10,100
So I mean, I'm pretty it's not three point one for him.

977
01:40:10,100 --> 01:40:13,100
It's one. But that's a different story.

978
01:40:14,100 --> 01:40:16,100
But but they have removed that tool now.

979
01:40:16,100 --> 01:40:19,100
So oops, oops, you can't you can't use that anymore.

980
01:40:19,100 --> 01:40:23,100
So coming back to shortest path.

981
01:40:23,100 --> 01:40:28,100
So this is a basic idea behind BFS to and BFS.

982
01:40:28,100 --> 01:40:30,100
It's called breadth first search.

983
01:40:30,100 --> 01:40:36,100
So in this you suppose you are a node, you start looking at the neighbors of the node.

984
01:40:36,100 --> 01:40:40,100
Does my destination exist in the neighborhood?

985
01:40:40,100 --> 01:40:45,100
If no, then I look at the neighborhood of every node in my neighborhood.

986
01:40:45,100 --> 01:40:47,100
You just keep on doing that.

987
01:40:47,100 --> 01:40:52,100
If you implement this, you can implement this in a recursive way.

988
01:40:52,100 --> 01:40:58,100
And like it's an exercise in the notebook, but we won't do it because it can take a lot of time.

989
01:40:58,100 --> 01:41:02,100
So let's just go through that.

990
01:41:02,100 --> 01:41:09,100
And the funny thing is the thing that we asked you to implement in the notebook is already present in NetworkX.

991
01:41:09,100 --> 01:41:14,100
So you don't actually need to do that.

992
01:41:18,100 --> 01:41:25,100
So suppose you want to find that does is there a path between node 400 and node one?

993
01:41:25,100 --> 01:41:27,100
It gives you true.

994
01:41:28,100 --> 01:41:29,100
It gives you true.

995
01:41:29,100 --> 01:41:33,100
This does not necessarily mean that 400 is connected to one.

996
01:41:33,100 --> 01:41:37,100
This means that there is a way of going from 400 to one.

997
01:41:37,100 --> 01:41:42,100
Somehow by jumping around the network, you can reach one from 400.

998
01:41:42,100 --> 01:41:45,100
And suppose you want to find that path.

999
01:41:45,100 --> 01:41:47,100
How do I reach from 400?

1000
01:41:47,100 --> 01:41:49,100
How do I reach to one from 400?

1001
01:41:49,100 --> 01:41:54,100
You just do just run this little algorithm.

1002
01:41:54,100 --> 01:41:55,100
Not an algorithm.

1003
01:41:55,100 --> 01:41:58,100
You just call this function shortest path.

1004
01:41:58,100 --> 01:42:06,100
And if you're familiar with graph theory and like graph algorithms, you would know that there are not tens,

1005
01:42:06,100 --> 01:42:11,100
but there are a lot of different algorithms to choose how to find the shortest path.

1006
01:42:11,100 --> 01:42:15,100
There is BFS, DFS, Dijkstra, A star, a lot of algorithms.

1007
01:42:15,100 --> 01:42:23,100
And if you call shortest path, NetworkX will take care of finding the most efficient algorithm for your graph.

1008
01:42:23,100 --> 01:42:25,100
And for your use case.

1009
01:42:25,100 --> 01:42:28,100
And there's nothing fancy going on behind these.

1010
01:42:28,100 --> 01:42:31,100
There are a bunch of heuristics that just always work.

1011
01:42:31,100 --> 01:42:33,100
So you don't need to worry about that.

1012
01:42:33,100 --> 01:42:38,100
If you don't really care about the implementation, just use shortest path.

1013
01:42:38,100 --> 01:42:43,100
And you'll get the shortest path from node one to 400 in this case.

1014
01:42:43,100 --> 01:42:45,100
Yes.

1015
01:42:45,100 --> 01:42:54,100
How would you figure out what algorithm it's using to get the shortest path?

1016
01:42:54,100 --> 01:43:01,100
I think, for example, the heuristic is that if it's a simple graph, which you have no weights, no nothing,

1017
01:43:01,100 --> 01:43:05,100
like just nodes and this thing, you use BFS or DFS.

1018
01:43:05,100 --> 01:43:08,100
And if you have weights, you start using Dijkstra.

1019
01:43:08,100 --> 01:43:10,100
If you have negative weights, you have A star.

1020
01:43:10,100 --> 01:43:17,100
So it's just like it will use the simplest algorithm for your graph.

1021
01:43:17,100 --> 01:43:25,100
If you don't, as soon as you start complicating your graph, it will use a more complicated algorithm.

1022
01:43:25,100 --> 01:43:26,100
What is DFS?

1023
01:43:26,100 --> 01:43:32,100
DFS is so breadth first search is like looking into your neighborhood.

1024
01:43:32,100 --> 01:43:34,100
In DFS, you go into one way.

1025
01:43:34,100 --> 01:43:39,100
I look at one of my friends and then I look at his or her friends.

1026
01:43:39,100 --> 01:43:42,100
And I just keep on going in one direction until I reach an end.

1027
01:43:42,100 --> 01:43:46,100
And if that end is not my destination, then I retract back.

1028
01:43:46,100 --> 01:43:47,100
So that's the idea of DFS.

1029
01:43:47,100 --> 01:43:53,100
You go depth first and then breadth you just swim around your neighborhood.

1030
01:43:53,100 --> 01:44:04,100
I mean, if you want to, you can implement this exercise after the tutorial to get a better understanding of BFS.

1031
01:44:04,100 --> 01:44:07,100
So but let's do this exercise instead.

1032
01:44:07,100 --> 01:44:12,100
So in this you have to write a function that extracts the shortest path.

1033
01:44:12,100 --> 01:44:16,100
So we know that this function and it's not shortest path gives us the graph rate.

1034
01:44:16,100 --> 01:44:18,100
It gives us the part.

1035
01:44:18,100 --> 01:44:23,100
It gives us the part that going from one to four hundred and need to take this route.

1036
01:44:23,100 --> 01:44:27,100
I jump from one to fifty fifty to one eighty eight to two thirty to three thirty five.

1037
01:44:27,100 --> 01:44:31,100
And I reach my destination four hundred.

1038
01:44:31,100 --> 01:44:36,100
Now you need to create a new graph which has just this part.

1039
01:44:36,100 --> 01:44:38,100
And how to do that?

1040
01:44:38,100 --> 01:44:41,100
Use this command cheater subgraph.

1041
01:44:41,100 --> 01:44:58,100
If you if you pass in a number of if you pass in a set of nodes cheater subgraph will extract those nodes and its relationship and give you a new graph.

1042
01:44:58,100 --> 01:45:01,100
And once you're done, just give me a thumbs up.

1043
01:45:28,100 --> 01:45:41,100
And if you're done, try to plot it to like you should get something like this.

1044
01:45:41,100 --> 01:45:44,100
Try to plot that graph.

1045
01:48:41,100 --> 01:48:51,100
Thumbs up if you're done.

1046
01:49:11,100 --> 01:49:31,100
Okay.

1047
01:49:31,100 --> 01:49:54,100
Yep.

1048
01:49:54,100 --> 01:49:55,100
Thanks.

1049
01:49:55,100 --> 01:50:02,100
Is there a reason that running this multiple times gives you different looking graphs each time you run it?

1050
01:50:02,100 --> 01:50:04,100
No, it's supposed to do that.

1051
01:50:04,100 --> 01:50:10,100
So whenever you call annexed on draw, it will give you a randomly drawn picture.

1052
01:50:10,100 --> 01:50:15,100
If you want to fix it, you need to like there are other arguments in the function that you can give in.

1053
01:50:15,100 --> 01:50:18,100
So which gives you a fixed answer every time.

1054
01:50:18,100 --> 01:50:21,100
But the but the picture is drawn randomly.

1055
01:50:21,100 --> 01:50:26,100
So you should get you should get different pictures.

1056
01:50:26,100 --> 01:50:34,100
So if you look at this, like if you look at the solution, which is flashing on the screen, we have this check here.

1057
01:50:34,100 --> 01:50:42,100
Is it possible to have like is it possible that there is no path in the graph?

1058
01:50:42,100 --> 01:50:48,100
If yes, then when?

1059
01:50:48,100 --> 01:50:54,100
When is it possible to not have any any part in the graph?

1060
01:50:54,100 --> 01:50:59,100
When does that happen?

1061
01:50:59,100 --> 01:51:05,100
If your graph is disconnected and you can do different sections.

1062
01:51:05,100 --> 01:51:09,100
So it's it's very much possible that your graph is not connected.

1063
01:51:09,100 --> 01:51:11,100
We will talk about this later, too.

1064
01:51:11,100 --> 01:51:14,100
And so that's why we have this check.

1065
01:51:14,100 --> 01:51:17,100
So if there is a path, then create a new graph.

1066
01:51:17,100 --> 01:51:20,100
Otherwise, let's say there's an exception.

1067
01:51:20,100 --> 01:51:25,100
And if you look at this is our plot, it looks like a straight line.

1068
01:51:25,100 --> 01:51:30,100
Is it possible to have a different plot for the subgraph?

1069
01:51:30,100 --> 01:51:38,100
Is it possible to have is it possible to have something like you have this line graph and then there is a connection between 90 to 230?

1070
01:51:38,100 --> 01:51:47,100
Is it possible?

1071
01:51:47,100 --> 01:51:49,100
Not when you're grabbing the shortest path.

1072
01:51:49,100 --> 01:52:01,100
Yes, if you're grabbing the shortest path, then as soon as if you have a connection between 90 and 230, it will it will end up taking for 90 to 30 rather than going all the way.

1073
01:52:01,100 --> 01:52:05,100
So this is the only possible answer for this subgraph.

1074
01:52:05,100 --> 01:52:11,100
And this is if you want to give a name of this, it's called a line graph, which is basically a line.

1075
01:52:11,100 --> 01:52:13,100
It's called a line graph.

1076
01:52:13,100 --> 01:52:19,100
So again, there are more exercises that you can do at home.

1077
01:52:19,100 --> 01:52:29,100
So in this, we basically this is we create a star graph in which we basically look at the neighbors of the graph.

1078
01:52:29,100 --> 01:52:33,100
And there are more exercises for home.

1079
01:52:33,100 --> 01:52:39,100
So let's go back to hubs and the notion of what is important, what is not important.

1080
01:52:39,100 --> 01:52:44,100
We just mentioned one thing like degrees and 30 on neighbors.

1081
01:52:44,100 --> 01:52:46,100
Just look at the number of neighbors.

1082
01:52:46,100 --> 01:52:54,100
And if if the highest number of neighbors is the most important node, that is what we concluded.

1083
01:52:54,100 --> 01:53:01,100
But it's very much possible that that is not the right way of measuring importance.

1084
01:53:01,100 --> 01:53:16,100
So can someone think of a way where just by looking at the number of neighbors, it's not the it's not the best way of measuring importance.

1085
01:53:16,100 --> 01:53:21,100
What could be any other way of measuring importance in a network?

1086
01:53:24,100 --> 01:53:30,100
Yeah.

1087
01:53:30,100 --> 01:53:40,100
Like if you have distinct groups and you had people that connect those groups, so they serve as bridging the gap between two otherwise pretty segmented communities, I'd imagine that be an important person.

1088
01:53:40,100 --> 01:53:41,100
Exactly.

1089
01:53:41,100 --> 01:53:58,100
Exactly. So it's like if there are bottlenecks in the graph, like suppose there are three different groups in a network and you have only one node in the network, which actually like connects to all these groups, even though that node is connected to only three different nodes.

1090
01:53:58,100 --> 01:54:01,100
But it connects the whole graph together.

1091
01:54:01,100 --> 01:54:03,100
In that case, it's an important node.

1092
01:54:03,100 --> 01:54:06,100
You can count it as an important node.

1093
01:54:06,100 --> 01:54:13,100
And the funny thing is that there is no whenever someone asks me, how do you measure importance, there is no right answer for that.

1094
01:54:13,100 --> 01:54:16,100
It depends what you are trying to measure.

1095
01:54:16,100 --> 01:54:21,100
For example, if you're trying to measure the, like, you know, which is the bottleneck in the node, it has a different answer.

1096
01:54:21,100 --> 01:54:30,100
If you want to just measure how to spread things in a network, then degree centrality is one of the basic ways of measuring that importance.

1097
01:54:30,100 --> 01:54:34,100
So we look into something called betweenness centrality.

1098
01:54:34,100 --> 01:54:47,100
And the intuitive definition of betweenness centrality is that I start finding shortest path between all the pairs of nodes in a network.

1099
01:54:47,100 --> 01:54:52,100
So I find shortest path for every node, for every pair of node in a network.

1100
01:54:52,100 --> 01:54:58,100
And then I try to find the node through which most of these paths go through.

1101
01:54:59,100 --> 01:55:01,100
Does this make sense?

1102
01:55:01,100 --> 01:55:07,100
I try to find a node through which most of the shortest path in a network go through and which is basically the bottleneck.

1103
01:55:07,100 --> 01:55:11,100
Like, every shortest path in the network has to go through that node.

1104
01:55:11,100 --> 01:55:16,100
Not every, but most of the shortest path have to go through that node.

1105
01:55:16,100 --> 01:55:18,100
And basically, you try to find these nodes.

1106
01:55:18,100 --> 01:55:22,100
And as soon as you have these nodes, these are the most important nodes.

1107
01:55:22,100 --> 01:55:29,100
To give you a better picture, we'll look at that later.

1108
01:55:29,100 --> 01:55:35,100
But before that, let's see how degree centrality and betweenness centrality interplay.

1109
01:55:35,100 --> 01:55:38,100
Like, can we say anything about a network?

1110
01:55:38,100 --> 01:55:40,100
Suppose a node has high degree centrality.

1111
01:55:40,100 --> 01:55:46,100
Can we infer anything about the betweenness centrality using the degree centrality?

1112
01:55:46,100 --> 01:55:47,100
Any guesses?

1113
01:55:47,100 --> 01:55:52,100
Should we be able to infer degree centrality from betweenness centrality?

1114
01:55:52,100 --> 01:55:57,100
Any guesses?

1115
01:55:57,100 --> 01:55:59,100
Yes, no.

1116
01:55:59,100 --> 01:56:01,100
Let's see.

1117
01:56:01,100 --> 01:56:04,100
So in this exercise, you basically plot.

1118
01:56:17,100 --> 01:56:23,100
In this plot, we plot the degree centrality versus betweenness centrality plot.

1119
01:56:23,100 --> 01:56:29,100
And as you see, you can't really say anything about how they are related.

1120
01:56:29,100 --> 01:56:35,100
Like, for example, this node has very high degree centrality, but has very low betweenness centrality.

1121
01:56:35,100 --> 01:56:37,100
That's the whole point.

1122
01:56:37,100 --> 01:56:41,100
The way we are calculating these centrality measures, they are very, very different.

1123
01:56:41,100 --> 01:56:43,100
They're very different.

1124
01:56:43,100 --> 01:56:48,100
So we can't infer degree centrality from betweenness centrality or the other way around.

1125
01:56:48,100 --> 01:56:55,100
So I mean, I think you can, if you try to make a network, you can probably make a network which gives you a straight line.

1126
01:56:55,100 --> 01:57:02,100
It is like, degree centrality is always related to betweenness centrality, but you have to over-engineer that network to give you that result.

1127
01:57:02,100 --> 01:57:06,100
But in the real world examples, you won't find that.

1128
01:57:06,100 --> 01:57:08,100
You won't really find that.

1129
01:57:14,100 --> 01:57:36,100
So coming back to how you find bottlenecks, can you come up with an example where a node has very low degree centrality, but very high betweenness centrality?

1130
01:57:36,100 --> 01:57:38,100
What would that example look like?

1131
01:57:44,100 --> 01:57:45,100
Anyone?

1132
01:57:45,100 --> 01:57:47,100
How would that example look like?

1133
01:57:51,100 --> 01:58:01,100
I would imagine that it would be like a node that connects two clusters of nodes.

1134
01:58:01,100 --> 01:58:03,100
Exactly. Something like this, right?

1135
01:58:03,100 --> 01:58:04,100
Yeah.

1136
01:58:04,100 --> 01:58:13,100
So in this case, if you measure degree centrality and say, oh, you want to find the most important node, you find the degree centrality and that's our final order.

1137
01:58:13,100 --> 01:58:21,100
But according to degree centrality, these two nodes will be the most important nodes because they have the most number of connections.

1138
01:58:21,100 --> 01:58:29,100
But according to betweenness centrality, this node will be the most important node, even though it has only two neighbors.

1139
01:58:29,100 --> 01:58:35,100
But every path, if you want to go from this cluster to this cluster, you have to pass through this, right?

1140
01:58:35,100 --> 01:58:40,100
So if you remove this fella right here, you break apart the network.

1141
01:58:42,100 --> 01:58:50,100
But doesn't every one of those paths also have to go through the one on the edge of the top left and the one on the edge of the bottom right?

1142
01:58:50,100 --> 01:58:55,100
Like wouldn't those three middle ones all have the same betweenness centrality?

1143
01:58:55,100 --> 01:58:56,100
No.

1144
01:58:57,100 --> 01:59:02,100
Because, for example, if you start a network from here, it will have that network too, right?

1145
01:59:02,100 --> 01:59:05,100
If you want to go from here to here, then you have...

1146
01:59:05,100 --> 01:59:06,100
Oh, OK.

1147
01:59:06,100 --> 01:59:08,100
In the calculation, it will end up adding those paths too.

1148
01:59:08,100 --> 01:59:10,100
Oh, I gotcha. Cool. Thanks.

1149
01:59:12,100 --> 01:59:22,100
So, funnily enough, in the eighth notebook, that notebook is about US airports data set and how airports are connected.

1150
01:59:23,100 --> 01:59:36,100
So if you run the standard algorithms, which is the most important airport in this data set, if you run betweenness centrality, you get a very interesting result as the most important airport.

1151
01:59:36,100 --> 01:59:42,100
Can anyone take a guess which is the most important airport in the US airport directory?

1152
01:59:42,100 --> 01:59:43,100
New York?

1153
01:59:45,100 --> 01:59:46,100
New York?

1154
01:59:46,100 --> 01:59:51,100
Yeah, these are the usual guesses that you would make.

1155
01:59:51,100 --> 01:59:59,100
But now, according to betweenness centrality, if you look at just the structure of the network, again, I'm emphasizing on structure.

1156
01:59:59,100 --> 02:00:04,100
I'm not emphasizing on number of people, number of flights, anything.

1157
02:00:04,100 --> 02:00:12,100
If you just look at the structure of the network, Anchorage, Alaska, is the most important node in the network.

1158
02:00:12,100 --> 02:00:18,100
And if you want to find an answer for that, I don't think we will be able to cover that in this...

1159
02:00:18,100 --> 02:00:24,100
We don't have two parts this time, so you can talk to me later or you can just look at the eighth notebook.

1160
02:00:24,100 --> 02:00:29,100
You'll have your answers, what's happening there, why Anchorage is the most important airport.

1161
02:00:29,100 --> 02:00:33,100
So moving on to the...

1162
02:00:33,100 --> 02:00:38,100
Before we move on, any questions, any doubts, any comments?

1163
02:00:40,100 --> 02:00:42,100
Okay, let's...

1164
02:00:44,100 --> 02:00:46,100
Is there a question back there?

1165
02:00:52,100 --> 02:00:56,100
Sorry, I just wanted to make sure I understand. So this algorithm is based on shortest path?

1166
02:00:56,100 --> 02:00:57,100
Yes.

1167
02:00:57,100 --> 02:01:02,100
So if the graph was weighted, it's not the number of nodes, it's the shortest path?

1168
02:01:03,100 --> 02:01:04,100
Yes.

1169
02:01:07,100 --> 02:01:11,100
You bring in an interesting question. So again, now this depends.

1170
02:01:11,100 --> 02:01:16,100
When you're measuring shortest path, how do you define that weight?

1171
02:01:16,100 --> 02:01:24,100
Sometimes, for example, in the case of airports, when you recreate this network,

1172
02:01:24,100 --> 02:01:28,100
should the number of flights be equal to...

1173
02:01:28,100 --> 02:01:33,100
Suppose you have number of flights as a weight. Should we use the weights just like that?

1174
02:01:33,100 --> 02:01:41,100
Because suppose there are 100 flights from New York to Chicago, and there are 100 flights from Chicago to San Francisco.

1175
02:01:41,100 --> 02:01:45,100
You have 100 flights because these are important routes, right?

1176
02:01:45,100 --> 02:01:50,100
And you have only 20 flights from maybe New York to Anchorage or something.

1177
02:01:50,100 --> 02:02:01,100
So if we use standard shortest path algorithms, it will penalize routes like New York, Chicago, and Chicago, San Francisco,

1178
02:02:01,100 --> 02:02:07,100
because you're giving it high weights. So a way to counter that is to use...

1179
02:02:07,100 --> 02:02:16,100
You need to make sure that you're modeling your network correctly, otherwise you'll end up with very wrong results.

1180
02:02:16,100 --> 02:02:23,100
So when you're adding weights, things get tricky, so we need to keep a lot of other things in mind.

1181
02:02:23,100 --> 02:02:26,100
So thanks for pointing that out.

1182
02:02:28,100 --> 02:02:33,100
So let's move to notebook number four, I think.

1183
02:02:33,100 --> 02:02:40,100
So till now, we were talking about nodes individually.

1184
02:02:40,100 --> 02:02:43,100
Now in this notebook, we'll look at something else.

1185
02:02:43,100 --> 02:02:46,100
We'll look at the structure of a network.

1186
02:02:46,100 --> 02:02:49,100
We're not really talking about just one node.

1187
02:02:49,100 --> 02:02:51,100
We're trying to find local structures.

1188
02:02:51,100 --> 02:02:57,100
Is there any interesting thing happening if you look at a cluster of nodes or something like that?

1189
02:02:57,100 --> 02:02:59,100
We'll talk about that.

1190
02:02:59,100 --> 02:03:06,100
So in this, we work with a data set of the physician trust network.

1191
02:03:06,100 --> 02:03:12,100
So I think these are four or five different cities, four different towns in Illinois.

1192
02:03:12,100 --> 02:03:19,100
And this is a trust network between physicians, and it was taken in 1966.

1193
02:03:19,100 --> 02:03:25,100
So it's like if you go to a physician and they're like, oh, if you want some advice, or if you want to refer someone, who do you refer to?

1194
02:03:25,100 --> 02:03:28,100
So that's how this network is created.

1195
02:03:28,100 --> 02:03:32,100
And you have this result of four different cities.

1196
02:03:32,100 --> 02:03:36,100
And let's create a plot of that.

1197
02:03:36,100 --> 02:03:38,100
Can we, like, we have the data.

1198
02:03:38,100 --> 02:03:40,100
We made a plot.

1199
02:03:40,100 --> 02:03:44,100
What can we say about this plot?

1200
02:03:44,100 --> 02:03:48,100
We know that it's from four different cities.

1201
02:03:48,100 --> 02:03:51,100
Do we see anything happening here?

1202
02:03:53,100 --> 02:03:55,100
Oh, hold on, hold on.

1203
02:03:55,100 --> 02:03:57,100
Where's the comment from?

1204
02:03:58,100 --> 02:04:04,100
How do you tell which cities are present in the visual?

1205
02:04:04,100 --> 02:04:05,100
That's part of the game.

1206
02:04:05,100 --> 02:04:07,100
You don't need to know that.

1207
02:04:07,100 --> 02:04:09,100
You just need to infer what's happening.

1208
02:04:09,100 --> 02:04:17,100
Like, if you look at the structure of this, is there anything special in the structure of this plot?

1209
02:04:17,100 --> 02:04:26,100
So it looks like you can almost see the four distinct cities with a very large city being on the very bottom with the well interconnectedness.

1210
02:04:26,100 --> 02:04:30,100
And then you can see minor gaps between the other ones.

1211
02:04:30,100 --> 02:04:34,100
Yeah, I guess that's the correct inference on this.

1212
02:04:34,100 --> 02:04:39,100
Because you can see four different clusters of cities.

1213
02:04:39,100 --> 02:04:44,100
I guess because it was 1966, communication wasn't that easy.

1214
02:04:45,100 --> 02:04:51,100
I think a family doctor is a more intimate thing.

1215
02:04:51,100 --> 02:04:56,100
So you won't just randomly say, oh, no, go talk to that doctor in that town.

1216
02:04:56,100 --> 02:05:01,100
So you see that these physician networks are localized to cities.

1217
02:05:01,100 --> 02:05:06,100
So that is what we can infer just from putting it out there.

1218
02:05:06,100 --> 02:05:10,100
And again, if we plotted the hairball, you wouldn't see anything here.

1219
02:05:10,100 --> 02:05:14,100
But with the Circos plot, we can see a clear representation of that.

1220
02:05:16,100 --> 02:05:20,100
So let's talk about structures in a graph.

1221
02:05:20,100 --> 02:05:24,100
Before structures, let's talk about something called cliques.

1222
02:05:24,100 --> 02:05:30,100
I mean, so in a clique, everyone is connected to each other.

1223
02:05:30,100 --> 02:05:34,100
It's like an exclusive group or sort of thing.

1224
02:05:34,100 --> 02:05:39,100
What is the simplest clique you can think of in a network where everyone is connected to each other?

1225
02:05:39,100 --> 02:05:40,100
Everyone is connected to each other.

1226
02:05:40,100 --> 02:05:45,100
You just have to pick a set of nodes and everyone is connected to each other.

1227
02:05:45,100 --> 02:05:49,100
Which is the simplest clique?

1228
02:05:49,100 --> 02:05:51,100
Sorry?

1229
02:05:51,100 --> 02:05:54,100
Family?

1230
02:05:54,100 --> 02:05:56,100
Yeah, family.

1231
02:05:56,100 --> 02:05:57,100
Family is the right answer.

1232
02:05:57,100 --> 02:06:00,100
But I'm talking in the sense of networks.

1233
02:06:00,100 --> 02:06:05,100
Like you have nodes and edges, which is the most simple clique.

1234
02:06:05,100 --> 02:06:08,100
Just like two people that are connected to just each other?

1235
02:06:08,100 --> 02:06:10,100
Yes, like an edge.

1236
02:06:10,100 --> 02:06:14,100
Just an edge is a clique because there are two people and both are connected to each other.

1237
02:06:14,100 --> 02:06:19,100
What is the most simple complex clique?

1238
02:06:19,100 --> 02:06:26,100
Anyone?

1239
02:06:26,100 --> 02:06:27,100
Three people?

1240
02:06:27,100 --> 02:06:30,100
And how would that work out?

1241
02:06:30,100 --> 02:06:31,100
A triangle.

1242
02:06:31,100 --> 02:06:32,100
Yes.

1243
02:06:32,100 --> 02:06:34,100
I was looking for the word triangle.

1244
02:06:34,100 --> 02:06:39,100
So you would see that there are triangle formings.

1245
02:06:39,100 --> 02:06:43,100
And basically you can build every clique with triangles.

1246
02:06:43,100 --> 02:06:49,100
Like if you're looking at four people and all of them are connected to each other,

1247
02:06:49,100 --> 02:06:53,100
it's basically a set of one, two, three different triangles.

1248
02:06:53,100 --> 02:06:57,100
Four.

1249
02:06:57,100 --> 02:06:59,100
It's a set of four different triangles.

1250
02:06:59,100 --> 02:07:05,100
So you can build up like the nth clique with triangles.

1251
02:07:05,100 --> 02:07:08,100
So that's why we focus on triangles.

1252
02:07:08,100 --> 02:07:13,100
Because finding triangles is still a hard problem.

1253
02:07:13,100 --> 02:07:18,100
But I think finding maximal cliques is a NP hard problem.

1254
02:07:18,100 --> 02:07:22,100
So we won't talk about that.

1255
02:07:22,100 --> 02:07:30,100
In this piece of code, what we have implemented is that if given a graph and given a node,

1256
02:07:30,100 --> 02:07:35,100
it returns that is that node in a triangle.

1257
02:07:35,100 --> 02:07:36,100
What does that mean?

1258
02:07:36,100 --> 02:07:42,100
So basically I give you a node and I look at the neighbors of this node.

1259
02:07:42,100 --> 02:07:48,100
And once I look at the neighbors of the node and I look, do they have a connection?

1260
02:07:48,100 --> 02:07:53,100
If two of my neighbors have an edge between them, they're in a triangle relationship.

1261
02:07:53,100 --> 02:07:54,100
Right?

1262
02:07:54,100 --> 02:07:59,100
Make sense?

1263
02:07:59,100 --> 02:08:03,100
Network gives us a function to calculate the number of triangles.

1264
02:08:03,100 --> 02:08:09,100
So this means that node three is in three triangular relationships.

1265
02:08:09,100 --> 02:08:11,100
Node one is also in three.

1266
02:08:11,100 --> 02:08:12,100
Node two is also.

1267
02:08:12,100 --> 02:08:16,100
Apparently all the nodes are in a three triangular relationship.

1268
02:08:16,100 --> 02:08:18,100
So exercise time again.

1269
02:08:18,100 --> 02:08:26,100
So in this exercise, you have to write a function that takes in a node, that takes in the graph,

1270
02:08:26,100 --> 02:08:34,100
and it returns the list of all the other nodes it's in a triangular relationship with.

1271
02:08:46,100 --> 02:09:13,100
Just to give you a better intuition again, you start with a node.

1272
02:09:13,100 --> 02:09:19,100
You just look at all of its neighbors and you try to find if there are any two neighbors

1273
02:09:19,100 --> 02:09:21,100
which have an edge.

1274
02:09:21,100 --> 02:09:25,100
As soon as you have that, you have a triangle.

1275
02:11:21,100 --> 02:11:49,100
Thumbs up if you're done.

1276
02:12:19,100 --> 02:12:24,100
Okay.

1277
02:12:49,100 --> 02:13:11,100
So if you look at the answer flashing on the screen, it's again, we check for every neighbor.

1278
02:13:11,100 --> 02:13:15,100
We run through a combination and we get a combination of two pairs of all the neighbors

1279
02:13:15,100 --> 02:13:23,100
and we check if that pair has an edge between them and if yes, then we add it to our triangular set,

1280
02:13:23,100 --> 02:13:25,100
these triangular nodes.

1281
02:13:25,100 --> 02:13:32,100
Just to show it pictorially how it works, in this case, three is in a triangular relationship,

1282
02:13:32,100 --> 02:13:38,100
42, 67, 41, 9, and 11.

1283
02:13:38,100 --> 02:13:46,100
Just to make sure that our answer is right, we also plot all the neighbors.

1284
02:13:46,100 --> 02:13:52,100
If you see that these are all the neighbors of node 3 and only these are the triangular relationships

1285
02:13:52,100 --> 02:13:55,100
and we get those relationships.

1286
02:13:55,100 --> 02:14:01,100
That means our code was right.

1287
02:14:01,100 --> 02:14:06,100
Let's talk about a nice important application of these triangles.

1288
02:14:06,100 --> 02:14:09,100
It's friend recommendation.

1289
02:14:09,100 --> 02:14:14,100
I'm pretty sure it's much more involved than just solving open triangles.

1290
02:14:14,100 --> 02:14:24,100
This was the first implementation of recommendations in LinkedIn.

1291
02:14:24,100 --> 02:14:27,100
I think that we know.

1292
02:14:27,100 --> 02:14:34,100
I'm not sure about Facebook, how they do it, but this is a way of understanding how recommendations work.

1293
02:14:34,100 --> 02:14:36,100
Suppose you have an open triangle.

1294
02:14:36,100 --> 02:14:38,100
What do I mean by open triangle?

1295
02:14:38,100 --> 02:14:43,100
Suppose I have two neighbors and they're not connected to each other.

1296
02:14:43,100 --> 02:14:45,100
Maybe they should be.

1297
02:14:45,100 --> 02:14:47,100
That's the recommendation we're talking about.

1298
02:14:47,100 --> 02:14:54,100
Suppose I have three friends and they're not friends with each other, but they're friends with me.

1299
02:14:54,100 --> 02:14:57,100
There is a slight chance that they know each other.

1300
02:14:57,100 --> 02:15:02,100
That's the recommendation that maybe these three people also know each other.

1301
02:15:02,100 --> 02:15:10,100
That's a very basic recommendation algorithm that you can come up with of how to recommend people in a network.

1302
02:15:10,100 --> 02:15:23,100
In this exercise, you have to write a function that identifies the other two nodes which are in an open triangle relationship.

1303
02:15:23,100 --> 02:15:29,100
In this exercise, you just have to consider the one in which you are the central node.

1304
02:15:29,100 --> 02:15:34,100
Suppose I'm friends with X and X is friends with Y.

1305
02:15:34,100 --> 02:15:36,100
You don't have to return that.

1306
02:15:36,100 --> 02:15:38,100
I can be friends with Y.

1307
02:15:38,100 --> 02:15:40,100
You don't have to return that.

1308
02:15:40,100 --> 02:15:44,100
In which you are the central node and there are two friends.

1309
02:15:44,100 --> 02:15:54,100
You have to find these open triangles.

1310
02:15:54,100 --> 02:16:00,100
The implementation is very similar to the one in which we are finding triangles.

1311
02:16:00,100 --> 02:16:05,100
In the triangle zone, we were finding which two nodes are connected.

1312
02:16:05,100 --> 02:16:11,100
In this, we have to find which two nodes are not connected because they should be possibly connected.

1313
02:16:11,100 --> 02:16:21,100
That's our recommendation algorithm.

1314
02:16:21,100 --> 02:16:23,100
Once you're done, thumbs up.

1315
02:16:51,100 --> 02:17:11,100
Okay.

1316
02:17:11,100 --> 02:17:33,100
Okay.

1317
02:17:33,100 --> 02:17:55,100
Okay.

1318
02:17:55,100 --> 02:18:22,100
Thumbs up if you're done.

1319
02:18:22,100 --> 02:18:25,100
Thumbs up if you're done.

1320
02:18:52,100 --> 02:18:57,100
Okay.

1321
02:19:22,100 --> 02:19:49,100
So if you look at the code flashing on the screen, instead of looking for nodes which have an edge between them,

1322
02:19:49,100 --> 02:19:55,100
we look for nodes which don't have an edge between them and then we add it to our recommendation pile.

1323
02:19:55,100 --> 02:20:01,100
So if you look at this thing, so like going back to the data itself,

1324
02:20:01,100 --> 02:20:07,100
it means that node three interacted with one and nine, right?

1325
02:20:07,100 --> 02:20:09,100
And node three interacted with all these other nodes.

1326
02:20:09,100 --> 02:20:16,100
So if node three interacted with node one and nine, so maybe there would be, you can go to node one and say, go talk to node nine.

1327
02:20:16,100 --> 02:20:21,100
Maybe you'll have something in common.

1328
02:20:21,100 --> 02:20:24,100
Not a sophisticated way, but it may work.

1329
02:20:24,100 --> 02:20:26,100
You never know.

1330
02:20:26,100 --> 02:20:29,100
So let's quickly talk about cliques.

1331
02:20:29,100 --> 02:20:33,100
So again, finding cliques is a very hard problem.

1332
02:20:33,100 --> 02:20:38,100
So in this, like when you use this function, we'll find cliques.

1333
02:20:38,100 --> 02:20:41,100
It will give you all the cliques in a graph.

1334
02:20:41,100 --> 02:20:45,100
It will give you two cliques which are basically like, you know, every edge.

1335
02:20:45,100 --> 02:20:49,100
And it will give you, like if you have four nodes in a clique,

1336
02:20:49,100 --> 02:20:54,100
which that means that every node is connected to every other node in the graph.

1337
02:20:54,100 --> 02:21:04,100
So just to give you a better picture of that, if you look at, this is a clique.

1338
02:21:04,100 --> 02:21:07,100
This is a four clique.

1339
02:21:07,100 --> 02:21:11,100
This is a six clique where every node is connected to each other.

1340
02:21:11,100 --> 02:21:16,100
And it's called a complete graph in graph theory.

1341
02:21:16,100 --> 02:21:19,100
So we won't do this exercise.

1342
02:21:19,100 --> 02:21:24,100
But in this exercise, we basically write a function to find the maximal clique.

1343
02:21:24,100 --> 02:21:31,100
You pass in a size, and I want cliques of only that size.

1344
02:21:31,100 --> 02:21:35,100
Now let's talk about connected.

1345
02:21:35,100 --> 02:21:39,100
I think there's one really neat point about cliques.

1346
02:21:39,100 --> 02:21:46,100
If you have a five clique, it is exactly decomposable into all of its constituent four cliques,

1347
02:21:46,100 --> 02:21:51,100
which are exactly decomposable into their constituent triangles,

1348
02:21:51,100 --> 02:21:56,100
which are exactly decomposable into their constituent edges.

1349
02:21:56,100 --> 02:22:01,100
So all triangles can be described as a set of edges.

1350
02:22:01,100 --> 02:22:06,100
All four cliques can be decomposed into three cliques.

1351
02:22:06,100 --> 02:22:12,100
And so all k cliques can be decomposed into their k minus 1 cliques down to k equals 3,

1352
02:22:12,100 --> 02:22:16,100
where the k minus 1 clique is 2.

1353
02:22:16,100 --> 02:22:22,100
And building upon on top of that, this is one of the ways of aggregating information in a network.

1354
02:22:22,100 --> 02:22:26,100
Suppose you have a very big network and you want to visualize that.

1355
02:22:26,100 --> 02:22:31,100
Instead of printing out every node, you try to find these.

1356
02:22:31,100 --> 02:22:34,100
Suppose there are cliques. There are a lot of cliques in the network.

1357
02:22:34,100 --> 02:22:40,100
You take that clique, create a meta node of that clique, and then you plot out the network.

1358
02:22:40,100 --> 02:22:44,100
So it's one of the ways of aggregating data to find cliques.

1359
02:22:44,100 --> 02:22:53,100
And talking about different aggregations, going back to the case where it's not possible to find a path.

1360
02:22:53,100 --> 02:22:58,100
You cannot go from node A to node B.

1361
02:22:58,100 --> 02:23:02,100
And that's where connected components come into the picture.

1362
02:23:02,100 --> 02:23:12,100
So components are these different clusters in a graph in which you cannot go from one cluster to another because they're not connected.

1363
02:23:12,100 --> 02:23:20,100
And let's try to find connected components in our graph G.

1364
02:23:20,100 --> 02:23:24,100
Oops. This is the physician network.

1365
02:23:24,100 --> 02:23:30,100
I was still thinking about the conference network.

1366
02:23:30,100 --> 02:23:32,100
So this is our physician network.

1367
02:23:32,100 --> 02:23:35,100
And we see that there are four different components.

1368
02:23:35,100 --> 02:23:37,100
And this is what we expected.

1369
02:23:37,100 --> 02:23:41,100
There are four different cities in the network, in the data set.

1370
02:23:41,100 --> 02:23:44,100
And every city is a network in itself.

1371
02:23:44,100 --> 02:23:47,100
They don't communicate between cities.

1372
02:23:47,100 --> 02:23:56,100
So if you try to plot this out, as you saw in the Circos plot, you have four different parts of the network.

1373
02:23:56,100 --> 02:24:07,100
So again, in this, we do the same Circos plot, but we add the notion of what the city is.

1374
02:24:07,100 --> 02:24:13,100
And once we have that city, we basically see that the bottom half was our one city.

1375
02:24:13,100 --> 02:24:17,100
And we have different colors to signify that.

1376
02:24:17,100 --> 02:24:21,100
So this is a prettier Circos plot of the same data.

1377
02:24:21,100 --> 02:24:30,100
And yes, and this is the interaction between Democrats and Republicans through the years.

1378
02:24:30,100 --> 02:24:35,100
So 1949, 1951.

1379
02:24:35,100 --> 02:24:37,100
So let's go to 2011.

1380
02:24:37,100 --> 02:24:41,100
So what can we say about the betweenness and variety of these people?

1381
02:24:41,100 --> 02:24:45,100
Remember?

1382
02:24:45,100 --> 02:24:47,100
Yes.

1383
02:24:47,100 --> 02:24:52,100
So who is the most important member of parliament?

1384
02:24:52,100 --> 02:24:54,100
That's a British thing.

1385
02:24:54,100 --> 02:24:59,100
Member of House of, Senate, Senate, Senator, US Senator.

1386
02:24:59,100 --> 02:25:06,100
Who is the most important US Senator according to this network and what we know about network science?

1387
02:25:06,100 --> 02:25:07,100
Anyone?

1388
02:25:07,100 --> 02:25:09,100
Who is the most US Senator?

1389
02:25:09,100 --> 02:25:10,100
Yep.

1390
02:25:10,100 --> 02:25:13,100
But again, it depends how you define importance.

1391
02:25:13,100 --> 02:25:18,100
In this case, suppose we define importance who can get things done.

1392
02:25:18,100 --> 02:25:22,100
Maybe someone who has connections in both sides of the house.

1393
02:25:22,100 --> 02:25:25,100
So you would need someone who is somewhere in the middle.

1394
02:25:25,100 --> 02:25:29,100
And that person will have a very high betweenness and variety.

1395
02:25:29,100 --> 02:25:32,100
So this is one of the real ones.

1396
02:25:32,100 --> 02:25:34,100
How to get politics working.

1397
02:25:34,100 --> 02:25:38,100
Eric, he has a question.

1398
02:25:38,100 --> 02:25:47,100
If you look at some of the charts further up, like 1973, there are a couple Republicans that are so far left that they're, what does that mean?

1399
02:25:47,100 --> 02:25:53,100
Does that mean they're more connected with all them than they are with the rest of the world?

1400
02:25:53,100 --> 02:26:01,100
Like how do we interpret some red that's penetrating super far to the left or some blue that's penetrating really far to the right in the network?

1401
02:26:01,100 --> 02:26:02,100
I'm not sure.

1402
02:26:02,100 --> 02:26:04,100
Do you know the answer for that?

1403
02:26:04,100 --> 02:26:05,100
Yeah.

1404
02:26:05,100 --> 02:26:11,100
So part of this is how we've chosen to visualize the network.

1405
02:26:11,100 --> 02:26:14,100
Or not we, but more like New York Times.

1406
02:26:14,100 --> 02:26:15,100
Okay.

1407
02:26:15,100 --> 02:26:20,100
So this is one of those classic hairballs.

1408
02:26:20,100 --> 02:26:31,100
And if I'm intuiting it correctly, this hairball is drawn by a force directed layout so that if you have a very high level of influence,

1409
02:26:31,100 --> 02:26:44,100
and if I'm intuiting it correctly, this hairball is drawn by a force directed layout so that if you have an edge between two nodes, there is an attractive force.

1410
02:26:44,100 --> 02:26:47,100
And if you're not connected, there's a repulsive force.

1411
02:26:47,100 --> 02:26:59,100
And the effect that the effect that force directed layout has is things like this and things like that can be visualized very clearly.

1412
02:26:59,100 --> 02:27:11,100
So and also the other part is just so that this is clear, the XY positioning of nodes in a force directed layout carries no meaning.

1413
02:27:11,100 --> 02:27:13,100
There is no meaning here.

1414
02:27:13,100 --> 02:27:21,100
So it is by convention that red is put to the right and blue is to the left in US politics that might be flipped in another country.

1415
02:27:22,100 --> 02:27:30,100
And that is just an artifact of how you just drag the nodes over, the red nodes over, and the rest of it will follow.

1416
02:27:30,100 --> 02:27:32,100
And you drag some blue ones over to the left and the rest will follow.

1417
02:27:32,100 --> 02:27:41,100
And then okay, now we roughly have them in some orientation that an ordinary person would be familiar with.

1418
02:27:41,100 --> 02:27:43,100
So that I want to make very clear.

1419
02:27:43,100 --> 02:27:57,100
The XY positioning in this chart inherently only carries meaning because someone decided that red and republicanism and right are put together and left and Democrats and left are put together.

1420
02:27:57,100 --> 02:27:58,100
Okay.

1421
02:27:58,100 --> 02:27:59,100
Blue.

1422
02:27:59,100 --> 02:28:10,100
So now you'll notice that yes, you've got some of those red nodes that are right in the middle and of the divide between the two and the same goes for the blue nodes.

1423
02:28:10,100 --> 02:28:22,100
Now, if we were to look at it graph theoretically, thankfully, in a force directed layout, they will match up with our intuition.

1424
02:28:22,100 --> 02:28:32,100
So we will have some of these more bipartisan all kind of senators or House of some representatives if this was the House of Reps instead.

1425
02:28:32,100 --> 02:28:35,100
Or if we're in the British Parliament, then members of Parliament, right?

1426
02:28:35,100 --> 02:28:43,100
People who bridge different political parties as covered as colored by the color that's attached to their nodes.

1427
02:28:43,100 --> 02:28:47,100
The force directed layout can help us discover it.

1428
02:28:47,100 --> 02:29:01,100
I still, though, would have a preference for making sure that we quantify explicitly how many same group connections I have versus other group connections I have as a node.

1429
02:29:01,100 --> 02:29:12,100
And that is the clearest way of visualize of like computing how many by that's the clearest way of computing the by a bipartisan or multi-partisan metric.

1430
02:29:12,100 --> 02:29:15,100
And yeah, it's good to visualize it this way.

1431
02:29:15,100 --> 02:29:21,100
But I think there might be better ways to do it right like you can do things that you can put all of the you can do this.

1432
02:29:21,100 --> 02:29:27,100
The arc plot as an option where you have the or rather.

1433
02:29:27,100 --> 02:29:29,100
Sorry, it's not the high plot.

1434
02:29:29,100 --> 02:29:31,100
The high plot. Yes, you have the high plots.

1435
02:29:31,100 --> 02:29:36,100
And let's say you have three political parties like Canada should write like three.

1436
02:29:36,100 --> 02:29:40,100
I'm Canadian. So you have three major political parties.

1437
02:29:40,100 --> 02:29:44,100
You put them each on the axis. You clone the axis for inter intra group.

1438
02:29:44,100 --> 02:29:47,100
And then you plot the inter group between the two.

1439
02:29:47,100 --> 02:29:53,100
Right. And so then that's a much more rational way, I think, of visualizing this.

1440
02:29:53,100 --> 02:30:04,100
And then you can compute the metric, the by or multi-partisanal metric and order nodes according to how many times they vote together with a member of another party.

1441
02:30:04,100 --> 02:30:07,100
Right. You can order it that way. And that's another great like.

1442
02:30:07,100 --> 02:30:13,100
Yeah. So it's a better way, I think, of visualizing than a hairball.

1443
02:30:13,100 --> 02:30:22,100
So we have we have 50 more minutes.

1444
02:30:22,100 --> 02:30:28,100
And so we have been talking a lot about like, you know, what our networks, what our cliques, what our paths.

1445
02:30:28,100 --> 02:30:31,100
So basically we're talking a lot about the theory. Right.

1446
02:30:31,100 --> 02:30:35,100
So let's see a real world example of that.

1447
02:30:35,100 --> 02:30:37,100
Let's talk about, you know, why this is useful.

1448
02:30:37,100 --> 02:30:40,100
And I'm going to give you a very nice reason for that.

1449
02:30:40,100 --> 02:30:46,100
The reason network sensors are useful is because we can understand Game of Thrones better.

1450
02:30:46,100 --> 02:30:51,100
And so how many of you like Game of Thrones?

1451
02:30:51,100 --> 02:30:55,100
OK. OK. Disappointing number. That's OK.

1452
02:30:55,100 --> 02:31:00,100
How many of you don't care about Game of Thrones?

1453
02:31:00,100 --> 02:31:06,100
That's OK, too. But you have to sit through this.

1454
02:31:06,100 --> 02:31:12,100
So. So Game of Thrones is the seventh notebook.

1455
02:31:12,100 --> 02:31:15,100
Again, if you want to do the exercise, you open the student one.

1456
02:31:15,100 --> 02:31:19,100
If you want to do the you don't want to access, you open the instructor one.

1457
02:31:19,100 --> 02:31:28,100
So even if you even if you're not a fan of Game of Thrones, has anyone ever seen this picture before?

1458
02:31:28,100 --> 02:31:35,100
So in this picture, again, and so people who are not familiar with Game of Thrones, what Game of Thrones is,

1459
02:31:35,100 --> 02:31:43,100
it's a TV show which is based on a set of books and it goes through a fictional fantasy world

1460
02:31:43,100 --> 02:31:53,100
where people are fighting each other for, like, you know, for the ultimate, like, you know, who becomes the king or the queen or I don't know.

1461
02:31:53,100 --> 02:31:56,100
Yeah, yeah, it's cool. Yeah, maybe.

1462
02:31:56,100 --> 02:32:09,100
So so so in this network, this is the interaction network between characters like every all these names of characters on the TV show and in the book.

1463
02:32:09,100 --> 02:32:20,100
And so the bigger the font of a net of a node, like, for example, John, Daenerys, Tyrion, it means the more important that node is.

1464
02:32:20,100 --> 02:32:26,100
And in this case, they have calculated importance, not by degree, not by between us, but something called PageRank.

1465
02:32:26,100 --> 02:32:33,100
Does anyone know what is PageRank? Has anyone heard about PageRank before? Yes.

1466
02:32:33,100 --> 02:32:36,100
So PageRank is known as the billion dollar algorithm.

1467
02:32:36,100 --> 02:32:45,100
It's behind Google's like it was behind the first Google search search index and it's named after Larry Page and Web Page.

1468
02:32:45,100 --> 02:32:48,100
See everything worked out there.

1469
02:32:48,100 --> 02:32:52,100
And so so so bigger the font, higher the PageRank.

1470
02:32:52,100 --> 02:32:57,100
And the colors you see in this are communities in the network.

1471
02:32:57,100 --> 02:32:59,100
We haven't talked about what are communities.

1472
02:32:59,100 --> 02:33:08,100
But just to give you a basic intuition is it's someone it's it's kind of like weak components, weak connected components.

1473
02:33:08,100 --> 02:33:13,100
It's like you don't have a clear cut difference between different components.

1474
02:33:13,100 --> 02:33:16,100
There could be some edges between component one to component two.

1475
02:33:16,100 --> 02:33:19,100
But this is a basic intuition behind communities.

1476
02:33:19,100 --> 02:33:23,100
It's like you can, you know, force them apart somehow.

1477
02:33:23,100 --> 02:33:33,100
And if you are familiar with Game of Thrones, you'll see that you have these communities like you have this purple looking community of people who are close to John.

1478
02:33:33,100 --> 02:33:37,100
John Snow, as others would know him.

1479
02:33:37,100 --> 02:33:40,100
And you have Daenerys and you have her community.

1480
02:33:40,100 --> 02:33:48,100
So you have these you have this nice pictorial representation of how things work in Game of Thrones.

1481
02:33:48,100 --> 02:33:50,100
And this is based on the books.

1482
02:33:50,100 --> 02:33:56,100
So apparently there are enough differences to make a difference in this final representation.

1483
02:33:56,100 --> 02:33:59,100
And I think this is from Book One.

1484
02:33:59,100 --> 02:34:08,100
Yeah. So in this in this notebook, we'll go through Book One, Book Two, Book Three, Book Four and Book Five, because we have only five books till now.

1485
02:34:08,100 --> 02:34:12,100
And we see that how the notion of importance has changed.

1486
02:34:12,100 --> 02:34:15,100
Like, you know, can we predict that?

1487
02:34:15,100 --> 02:34:19,100
Not predict, but can we say who's the most important character in Game of Thrones?

1488
02:34:19,100 --> 02:34:24,100
Like who should win this battle of battle?

1489
02:34:24,100 --> 02:34:30,100
And if you are behind Game of Thrones and you actually like Game of Thrones, I'll make sure that there are no spoilers.

1490
02:34:30,100 --> 02:34:32,100
But again, no guarantees.

1491
02:34:32,100 --> 02:34:36,100
But I tried hard enough to make sure that there are no spoilers.

1492
02:34:36,100 --> 02:34:38,100
So let's start.

1493
02:34:38,100 --> 02:34:41,100
So we read in.

1494
02:34:41,100 --> 02:34:43,100
Let's have a look at the data.

1495
02:34:43,100 --> 02:34:46,100
So in this, this is a Pandas data frame.

1496
02:34:46,100 --> 02:34:53,100
And we so you have a source, you have a target, you have this type thing and you have a weight and a book.

1497
02:34:53,100 --> 02:35:03,100
The type is the type is a pretty much useless column in this because all the networks are enacted in this in this in this network.

1498
02:35:03,100 --> 02:35:15,100
And even source and target does not make sense in an undirected network because it's not a source going towards the target because the connection goes both ways because it's an undirected network.

1499
02:35:15,100 --> 02:35:19,100
And the weight comes into the picture.

1500
02:35:19,100 --> 02:35:23,100
Weight is the number of interactions in that book.

1501
02:35:23,100 --> 02:35:39,100
So and the way they define interactions is is if if two characters are in a are in a neighborhood of 15 words, this is created from the book, not from the TV show.

1502
02:35:39,100 --> 02:35:45,100
If two characters are in a neighborhood of 15 words, like their name is mentioned, then there's an edge between them.

1503
02:35:45,100 --> 02:35:48,100
This is not the best way of making it this.

1504
02:35:48,100 --> 02:35:54,100
I'm not even saying this, but this is OK enough a way of making it to get some actual results.

1505
02:35:54,100 --> 02:36:01,100
And we'll see that, you know, this actually works of creating a character network.

1506
02:36:01,100 --> 02:36:06,100
So let's create five different graphs, one for each book.

1507
02:36:06,100 --> 02:36:07,100
So we have.

1508
02:36:07,100 --> 02:36:08,100
Yep.

1509
02:36:08,100 --> 02:36:14,100
Question.

1510
02:36:14,100 --> 02:36:17,100
Wanted to seize on this real quick because we're looking at the base data.

1511
02:36:17,100 --> 02:36:23,100
A lot of us are going to have super unclean data that's not already packaged in network formats.

1512
02:36:23,100 --> 02:36:29,100
Is there a best practice that you recommend when you're trying to just create a network from scratch?

1513
02:36:29,100 --> 02:36:33,100
And is it like if it's directed, then this is what the data structure should look like.

1514
02:36:33,100 --> 02:36:35,100
And if it's undirected, then this is what it should look like.

1515
02:36:35,100 --> 02:36:42,100
I mean, it depends on your it depends how you how you're modeling your system.

1516
02:36:42,100 --> 02:36:48,100
If you know that there is direction in the system, then you just created the object directed graph.

1517
02:36:48,100 --> 02:36:50,100
You use directed graph instead of using graph.

1518
02:36:50,100 --> 02:36:55,100
If you know that there is no there's no notion of directions in your system, then you create a normal graph.

1519
02:36:55,100 --> 02:36:58,100
And the and the topic of data cleaning, right?

1520
02:36:58,100 --> 02:37:02,100
And every data science problem, 90 percent of the work is data cleaning.

1521
02:37:02,100 --> 02:37:06,100
So I think I think there are some tutorials on data cleaning, too.

1522
02:37:06,100 --> 02:37:09,100
So that's another field altogether.

1523
02:37:10,100 --> 02:37:19,100
But once you have your data clean and you have a clear picture of a system you want to design, you know, how how nodes are defined and how interactions are working.

1524
02:37:19,100 --> 02:37:29,100
Once you have that picture and you have cleaned enough data, what are nodes and what are the edges, then I guess it goes just straightforward.

1525
02:37:30,100 --> 02:37:47,100
So like in this case, because like because someone if someone just gives you a book and says make a network out of it, there are there are certain a lot of like a lot of decisions that you had to make to end up with a with a network.

1526
02:37:47,100 --> 02:37:52,100
Right. So what those decisions is like, you know, those are pretty subjective.

1527
02:37:52,100 --> 02:37:58,100
I think I'll add like Paul, you had asked a little bit about best practices.

1528
02:37:58,100 --> 02:38:03,100
Notice how middle has a network actually stored in the form of a panda's data frame.

1529
02:38:03,100 --> 02:38:06,100
And that's a really, really useful starting point.

1530
02:38:06,100 --> 02:38:12,100
Network X has built in functions that let you import a panda's data frame as a graph.

1531
02:38:12,100 --> 02:38:16,100
You will need to data frames to store every graph.

1532
02:38:16,100 --> 02:38:19,100
You will need a node data frame and an edge data frame.

1533
02:38:19,100 --> 02:38:22,100
It's like having a node list and an edge list.

1534
02:38:22,100 --> 02:38:31,100
The node data frame stores the list of nodes, plus all of their keyword arguments attributes and the edge stories stores the edge list.

1535
02:38:31,100 --> 02:38:38,100
So you have two columns, one for the node at first node ID one for the second node ID, and then you have all the edge properties there.

1536
02:38:38,100 --> 02:38:50,100
Notebook five shows that and middle in this notebook also shows like an example of a real example of how we take a panda's data frame and convert it into a network X graph object.

1537
02:38:50,100 --> 02:39:02,100
So like like like in the fourth cell, we create new graphs and to populate this graph, we basically I trade through the to the pandas data frame.

1538
02:39:02,100 --> 02:39:05,100
I mean, I'm doing in this way, but there is a direct way of reading it too.

1539
02:39:05,100 --> 02:39:07,100
But like it's it's it's an extort.

1540
02:39:12,100 --> 02:39:17,100
If you go and extort from like you have a lot of ways you can read data into this.

1541
02:39:17,100 --> 02:39:25,100
And so basically, yeah, so you can have a you can have a adjacency matrix and cells that you can read.

1542
02:39:25,100 --> 02:39:27,100
You have you can have a panda's edge list.

1543
02:39:27,100 --> 02:39:37,100
And this is this is what is called an edge list in which you have a like you have a source, you have a target, you have a and you have attributes about that data.

1544
02:39:37,100 --> 02:39:40,100
You can you can you can run this code like this too.

1545
02:39:40,100 --> 02:39:45,100
But like to make it more explicit, I'm I'm I'm using a for loop.

1546
02:39:45,100 --> 02:39:46,100
And this is a bad way of doing it.

1547
02:39:46,100 --> 02:39:47,100
So you don't do it.

1548
02:39:47,100 --> 02:39:51,100
Use from pandas from pandas edge list.

1549
02:39:51,100 --> 02:39:57,100
But just to make it explicit, like so I have I add a source, which is my first node.

1550
02:39:57,100 --> 02:39:59,100
I add a second node, which is my target.

1551
02:39:59,100 --> 02:40:03,100
And then I add two attributes, the weight and the book.

1552
02:40:04,100 --> 02:40:09,100
And by doing that, I create these five different networks.

1553
02:40:09,100 --> 02:40:14,100
And let's just look at this network.

1554
02:40:14,100 --> 02:40:20,100
So in book one, there is an edge between Jamie Lannister and Laura Sterill.

1555
02:40:20,100 --> 02:40:22,100
And there is a weight of three.

1556
02:40:22,100 --> 02:40:26,100
So there are three interactions between Jamie and Laura in book one.

1557
02:40:26,100 --> 02:40:30,100
So this is this is our descriptive study.

1558
02:40:30,100 --> 02:40:33,100
Not said this is the description of our of our network.

1559
02:40:33,100 --> 02:40:35,100
And that's like that.

1560
02:40:35,100 --> 02:40:39,100
If you have edges in all the networks.

1561
02:40:39,100 --> 02:40:45,100
So now comes the most important part of this tutorial, finding the most important character.

1562
02:40:45,100 --> 02:40:48,100
Like how do we do that?

1563
02:40:48,100 --> 02:40:51,100
Any any ideas?

1564
02:40:51,100 --> 02:40:56,100
We already know what is like we already have discussed, you know, what is important.

1565
02:40:56,100 --> 02:40:58,100
We know what is degree, what is between us.

1566
02:40:58,100 --> 02:40:59,100
Any ideas?

1567
02:40:59,100 --> 02:41:02,100
How do we find the most important character?

1568
02:41:02,100 --> 02:41:06,100
First, we have to come to a consensus on what we mean by important.

1569
02:41:06,100 --> 02:41:08,100
Isn't that the million dollar question?

1570
02:41:08,100 --> 02:41:09,100
Yes.

1571
02:41:09,100 --> 02:41:12,100
We first need to define what importance is.

1572
02:41:12,100 --> 02:41:17,100
But then we reach a consensus and we won't.

1573
02:41:17,100 --> 02:41:24,100
So instead of doing that, like suppose you're giving you are given a you're given a network data.

1574
02:41:24,100 --> 02:41:27,100
And someone asks you what's the most important node in this network.

1575
02:41:27,100 --> 02:41:32,100
So this is how like at least for me, this is how I progress.

1576
02:41:32,100 --> 02:41:36,100
Like I first started, you know, the standard ones, degree between us or page rank.

1577
02:41:36,100 --> 02:41:39,100
And there are a ton of other centrality measures.

1578
02:41:39,100 --> 02:41:43,100
There's load, there is closeness, there's flow centrality.

1579
02:41:43,100 --> 02:41:49,100
So there are a lot of other things that we can do to make sure that we have the same

1580
02:41:49,100 --> 02:41:52,100
So there are a lot of other measures.

1581
02:41:52,100 --> 02:41:57,100
And but once you know enough about the data, then you can like, you know, then you can argue that this is more important.

1582
02:41:57,100 --> 02:42:01,100
In this case, we care more about this rather than more about that.

1583
02:42:01,100 --> 02:42:08,100
So, for example, suppose suppose in the suppose in the airport network, right.

1584
02:42:08,100 --> 02:42:11,100
I do care about something like the data.

1585
02:42:11,100 --> 02:42:16,100
I do care about something like the number of number of flight number of connections.

1586
02:42:16,100 --> 02:42:20,100
The airport has a number of places I can fly from from this airport.

1587
02:42:20,100 --> 02:42:26,100
But I also care about making the network connected.

1588
02:42:26,100 --> 02:42:32,100
For example, I should be able to fly from any city in the US to any other not directly.

1589
02:42:32,100 --> 02:42:34,100
But there should be a way.

1590
02:42:34,100 --> 02:42:37,100
Like the US airport network should not be disconnected.

1591
02:42:37,100 --> 02:42:43,100
But fun fact, if you look in the eighth notebook, there is there are some issues with that.

1592
02:42:43,100 --> 02:42:46,100
The US airport network is apparently not connected.

1593
02:42:46,100 --> 02:42:52,100
There are airports that you cannot fly to or fly from if you are if you're in New York.

1594
02:42:52,100 --> 02:42:55,100
But it's not a major it's not a major issue.

1595
02:42:55,100 --> 02:42:57,100
I don't want to give any spoilers.

1596
02:42:57,100 --> 02:42:59,100
But I do care about the data.

1597
02:42:59,100 --> 02:43:02,100
But it's not a major it's not a major issue.

1598
02:43:02,100 --> 02:43:04,100
I don't want to give any spoilers.

1599
02:43:04,100 --> 02:43:07,100
But if you're interested, you can check notebook eight.

1600
02:43:07,100 --> 02:43:10,100
And yep.

1601
02:43:10,100 --> 02:43:12,100
So again, that's how you define importance.

1602
02:43:12,100 --> 02:43:15,100
And in some cases, you want bottlenecks.

1603
02:43:15,100 --> 02:43:24,100
And in some cases, you like suppose you want to suppose you have a supply chain problem, which you have modeled as a network.

1604
02:43:24,100 --> 02:43:29,100
Like you go from warehouse A to warehouse B to warehouse C, and you try to find bottlenecks.

1605
02:43:29,100 --> 02:43:32,100
In this case, you care about between the centrality.

1606
02:43:32,100 --> 02:43:37,100
You don't care about how many like how good the warehouse can distribute.

1607
02:43:37,100 --> 02:43:39,100
But where is the bottleneck?

1608
02:43:39,100 --> 02:43:41,100
And that you care about that.

1609
02:43:41,100 --> 02:43:47,100
So let's let's just start with our standard measures.

1610
02:43:47,100 --> 02:43:50,100
Let's calculate degree centrality.

1611
02:43:50,100 --> 02:43:58,100
And if we see in book one, according to degree centrality, Eddard Stark is the most important character.

1612
02:43:58,100 --> 02:44:04,100
And people who are familiar with Game of Thrones, this kind of makes sense, right?

1613
02:44:04,100 --> 02:44:06,100
Yes. Can we can I get a yes?

1614
02:44:06,100 --> 02:44:11,100
If you if you if you know what I'm talking about.

1615
02:44:11,100 --> 02:44:12,100
I'm sorry if you're lost.

1616
02:44:12,100 --> 02:44:13,100
What's happening?

1617
02:44:13,100 --> 02:44:15,100
What what these names are?

1618
02:44:15,100 --> 02:44:20,100
But trust me, I thought Stark was an important character in book one.

1619
02:44:20,100 --> 02:44:22,100
Oh, I'm sorry.

1620
02:44:22,100 --> 02:44:23,100
Sorry.

1621
02:44:23,100 --> 02:44:28,100
But and as you see in book five, you cannot see that stuck anywhere.

1622
02:44:28,100 --> 02:44:29,100
Does that mean anything?

1623
02:44:29,100 --> 02:44:30,100
I don't know.

1624
02:44:30,100 --> 02:44:31,100
That's it.

1625
02:44:31,100 --> 02:44:37,100
So and in book five, we see that, you know, Jon Snow, then Daenerys Targaryen, Stannis.

1626
02:44:37,100 --> 02:44:40,100
These are important characters according to degree centrality.

1627
02:44:40,100 --> 02:44:44,100
And these like just by looking at these rankings, it kind of makes sense.

1628
02:44:44,100 --> 02:44:48,100
You know, these are known characters that we like, you know, that we predict.

1629
02:44:48,100 --> 02:44:51,100
You know, these these are characters that would be important.

1630
02:44:51,100 --> 02:44:53,100
So till now, so far, so good.

1631
02:44:53,100 --> 02:44:59,100
Like, you know, the way we model our network, maybe it wasn't the best way, but it was good enough way.

1632
02:44:59,100 --> 02:45:05,100
So like, here comes the sad histogram.

1633
02:45:05,100 --> 02:45:13,100
But it's an important way of looking at this is like because I want to show you the decay thing in a real world network.

1634
02:45:13,100 --> 02:45:17,100
It's like there's a theory of scale free networks.

1635
02:45:17,100 --> 02:45:26,100
And what scale free means is that in a real in all real world networks, the number of the number of connections,

1636
02:45:26,100 --> 02:45:29,100
the degree will always have an exponential decay.

1637
02:45:29,100 --> 02:45:34,100
That means like, you know, you'll have some nodes which will have a lot of connections,

1638
02:45:34,100 --> 02:45:37,100
but majority of the nodes will have less connections.

1639
02:45:37,100 --> 02:45:38,100
Just like Twitter.

1640
02:45:39,100 --> 02:45:45,100
If you try to plot the degrees centrality of Twitter, a histogram, you'll get something like this.

1641
02:45:45,100 --> 02:45:48,100
You'll find an exponential decay.

1642
02:45:48,100 --> 02:45:50,100
That's the theory behind that.

1643
02:45:50,100 --> 02:45:56,100
And here is that log log plot, the fancy log log plot that a lot of academic people love.

1644
02:45:56,100 --> 02:46:03,100
I don't know why, but because if if this was a if this was a proper network, like not a proper network,

1645
02:46:03,100 --> 02:46:09,100
if this was an exact network which was following exponential decay, you would have gotten a straight line.

1646
02:46:09,100 --> 02:46:12,100
But we get something like a straight line.

1647
02:46:12,100 --> 02:46:16,100
So we say, oh, yeah, maybe this network follows the scale free property.

1648
02:46:16,100 --> 02:46:25,100
So in this exercise, we create a new centrality measure because we say that we are not happy with.

1649
02:46:25,100 --> 02:46:27,100
Oh, yes. Yeah, go ahead.

1650
02:46:28,100 --> 02:46:30,100
I was just wondering.

1651
02:46:30,100 --> 02:46:39,100
So is there a is there a metric to describe the amount of people that so let's just use Twitter for an example.

1652
02:46:39,100 --> 02:46:43,100
The amount of people you follow to the ratio of followers.

1653
02:46:43,100 --> 02:46:46,100
Is there a metric to describe that?

1654
02:46:46,100 --> 02:46:55,100
Yes. So like in in network terms, you say that, you know, this is in degree divided by out degree.

1655
02:46:55,100 --> 02:47:02,100
So like, for example, when we when we are calculating degree till now, we're assuming there is no direction to the number of neighbors.

1656
02:47:02,100 --> 02:47:06,100
Right. As soon as you have a directed network, you have something called an in degree.

1657
02:47:06,100 --> 02:47:09,100
Like, you know, how many nodes are pointing towards me?

1658
02:47:09,100 --> 02:47:12,100
And then there's out degree. How many nodes am I pointing towards to?

1659
02:47:12,100 --> 02:47:21,100
And this like again, like follower follower folly following ratio is an important ratio in Twitter analysis.

1660
02:47:21,100 --> 02:47:23,100
So coming back to the exercise.

1661
02:47:23,100 --> 02:47:29,100
So so I say that, you know, I'm not happy with these measures that, you know, I don't like the results.

1662
02:47:29,100 --> 02:47:33,100
I need a I need a measure that captures more information.

1663
02:47:33,100 --> 02:47:36,100
So we create this new measure called weighted degree.

1664
02:47:36,100 --> 02:47:49,100
And instead of just counting the number of neighbors I have, I'm counting the number of I'm counting the summation of the weight on the edges.

1665
02:47:49,100 --> 02:47:55,100
So suppose instead of like if I had an N neighbors in the first case, my degree is N.

1666
02:47:55,100 --> 02:48:02,100
But suppose I have N neighbors, but every neighbor has some weight on its on its edge.

1667
02:48:02,100 --> 02:48:08,100
Then my new is my new weighted degree is the sum of all those weights on the edges.

1668
02:48:12,100 --> 02:48:13,100
Make sense?

1669
02:48:19,100 --> 02:48:35,100
If I'm following you, so what you're saying with the weighted degree, it's how many other important nodes are directly related to me?

1670
02:48:35,100 --> 02:48:45,100
Not exactly. No, I'm just saying that I'm just I'm not I'm not even saying this is a good measure, but I'm not even saying it's a good measure.

1671
02:48:45,100 --> 02:48:54,100
I'm just saying that I'm just creating a new measure in which I'm counting the number of I'm just counting the weight that is pointing towards me.

1672
02:48:54,100 --> 02:49:00,100
Like I'm just counting how close are my connections?

1673
02:49:00,100 --> 02:49:08,100
Like suppose suppose as a node, I'm connected to 10 different nodes, but everyone every connection has a weight of one.

1674
02:49:08,100 --> 02:49:14,100
And suppose I'm not now I'm connected to four people, but every connection has a weight 10.

1675
02:49:14,100 --> 02:49:23,100
So I have very strong connections like I'm not I'm not a I'm like I'm not a loosey that you know I'm just I'm not just an extrovert.

1676
02:49:23,100 --> 02:49:25,100
I'm an extrovert and an introvert.

1677
02:49:25,100 --> 02:49:29,100
Like I'm connected to a lot of people and I have those my connections are strong.

1678
02:49:29,100 --> 02:49:33,100
That's the concept of weighted degree.

1679
02:49:33,100 --> 02:49:43,100
Let me know once you're done.

1680
02:49:43,100 --> 02:49:49,100
And just as a hint in the in the exercise this end here, this end here would be a three tuple.

1681
02:49:49,100 --> 02:50:02,100
If you remember from our first notebook, it would have the first would be our the start node, the end node, and the third would be a dictionary, which has attributes.

1682
02:50:32,100 --> 02:50:50,100
Thumbs up if you're done.

1683
02:50:50,100 --> 02:51:17,100
You should get a similar plot like this.

1684
02:51:17,100 --> 02:51:45,100
As you look at look at look on the screen, we have this new histogram of weighted degree and distribution of that.

1685
02:51:45,100 --> 02:51:55,100
And again, it doesn't give us a lot of information, but we see a very similar plot that that find there is some exponential decay in this network.

1686
02:51:55,100 --> 02:52:00,100
And but let's see if it made any changes to our rankings.

1687
02:52:00,100 --> 02:52:04,100
So we still have a dot tag is the most important node.

1688
02:52:04,100 --> 02:52:06,100
So not a lot of change.

1689
02:52:06,100 --> 02:52:10,100
But if we concentrate on this character called Jon Snow.

1690
02:52:10,100 --> 02:52:15,100
So in an according to weighted degree, Jon Snow is the third most important.

1691
02:52:15,100 --> 02:52:21,100
And according to just degree centrality, he is at fifth.

1692
02:52:21,100 --> 02:52:24,100
So this measure bumped up Jon Snow to three.

1693
02:52:24,100 --> 02:52:27,100
So maybe it is a good measure.

1694
02:52:27,100 --> 02:52:28,100
That was a joke.

1695
02:52:28,100 --> 02:52:33,100
So you shouldn't choose your measures according to your results.

1696
02:52:33,100 --> 02:52:36,100
So so let's do let's do this for between a centrality.

1697
02:52:36,100 --> 02:52:41,100
And remember between a centrality is the one which always gives you interesting results.

1698
02:52:41,100 --> 02:52:46,100
Doesn't matter which data set it will always give you a nice particular result.

1699
02:52:46,100 --> 02:52:49,100
So let's see if that happens here too.

1700
02:52:49,100 --> 02:52:55,100
So if we do between a centrality for the first book, it starts again.

1701
02:52:55,100 --> 02:52:59,100
Maybe this Adar Stark fellow fellow is an important character in first book.

1702
02:52:59,100 --> 02:53:02,100
Maybe like we have two very different measures.

1703
02:53:02,100 --> 02:53:05,100
One is degree centrality and one is between us.

1704
02:53:05,100 --> 02:53:11,100
And if you remember that plot, they are not correlated at all because the way they're calculated are very different.

1705
02:53:11,100 --> 02:53:17,100
And both of them say that this fellow named here, Adar Stark, is an important person in book one.

1706
02:53:17,100 --> 02:53:21,100
So maybe just maybe we say that fine.

1707
02:53:21,100 --> 02:53:24,100
That Stark is important in book one.

1708
02:53:24,100 --> 02:53:29,100
Let's see in book one.

1709
02:53:29,100 --> 02:53:34,100
And in this case, in this case, we use the term of weights.

1710
02:53:34,100 --> 02:53:47,100
So if you look at this, you can calculate between a centrality because it's the shortest path between a weighted version and an unweighted version.

1711
02:53:47,100 --> 02:53:51,100
And this when we take weight in this, we are not taking any weight.

1712
02:53:51,100 --> 02:53:52,100
We're just doing the structure.

1713
02:53:52,100 --> 02:53:53,100
We have Adar Stark.

1714
02:53:53,100 --> 02:54:03,100
And when we look at the weight, which is a number of interactions, we see that it's still like he goes to the second position, but he's still important.

1715
02:54:03,100 --> 02:54:06,100
So not that different.

1716
02:54:06,100 --> 02:54:09,100
And we'll quickly talk about page rank.

1717
02:54:09,100 --> 02:54:13,100
So you don't need to worry about the implementation per se.

1718
02:54:13,100 --> 02:54:22,100
But the intuition behind page rank is if an important node points towards me, then I'm important.

1719
02:54:22,100 --> 02:54:29,100
It's not about the number of neighbors, number of shortest paths going through me.

1720
02:54:29,100 --> 02:54:35,100
But it just depends if an important node points towards me, I'm an important.

1721
02:54:35,100 --> 02:54:41,100
And in turn, if I point towards someone else because I am important, that node is important.

1722
02:54:41,100 --> 02:54:44,100
So it's a very neat equation.

1723
02:54:44,100 --> 02:54:49,100
If you want to go into the mathematical details of that, it's a very neat short and sweet equation.

1724
02:54:49,100 --> 02:54:51,100
And it works perfectly.

1725
02:54:51,100 --> 02:54:56,100
So if we calculate a page rank to again, I got stuck.

1726
02:54:56,100 --> 02:54:58,100
So maybe, maybe.

1727
02:54:58,100 --> 02:55:02,100
And that's the most important character in Book One.

1728
02:55:02,100 --> 02:55:09,100
But.

1729
02:55:09,100 --> 02:55:16,100
Earlier on, you said in both in the notebook, it says as well that we were doing an undirected network though.

1730
02:55:16,100 --> 02:55:19,100
So how does that work with?

1731
02:55:19,100 --> 02:55:28,100
Yes. So the thing with page rank is page rank was when it was initially defined, it was defined only for directed networks.

1732
02:55:28,100 --> 02:55:30,100
But it works both.

1733
02:55:30,100 --> 02:55:33,100
It won't give you the best results for undirected network.

1734
02:55:33,100 --> 02:55:40,100
And like I would still trust page rank, but it won't give you the best results for undirected networks.

1735
02:55:40,100 --> 02:55:46,100
But it still works because it's basically it's a it's a edge between an undirected edge is two edges.

1736
02:55:46,100 --> 02:55:49,100
It's one in this direction, one in that direction.

1737
02:55:49,100 --> 02:55:59,100
It still works. But when it was defined, it was defined for directed networks.

1738
02:55:59,100 --> 02:56:04,100
So you said that the page rank thing had it looked at the number of links and the quality of links.

1739
02:56:04,100 --> 02:56:12,100
So when you're doing an unweighted form of page rank, is that really similar to degree centrality?

1740
02:56:12,100 --> 02:56:19,100
And in Paging, it also looks at the path of the link, like how that link is coming towards me.

1741
02:56:19,100 --> 02:56:28,100
It's not like it's not just looking at the absolute surrounding, but also, you know, how it converges.

1742
02:56:28,100 --> 02:56:34,100
Let me check if I don't have the picture here, but we can talk about this.

1743
02:56:34,100 --> 02:56:42,100
So and in this, we see that if there is any correlation between these instead of plotting them out,

1744
02:56:42,100 --> 02:56:46,100
let's see if there is a correlation between these matrix that we just calculated.

1745
02:56:46,100 --> 02:56:56,100
So we see that there is a very high correlation for some reason between page rank and weighted degree.

1746
02:56:56,100 --> 02:57:01,100
So if you see you have a point nine nine. This is the Pearson correlation.

1747
02:57:01,100 --> 02:57:04,100
There's a very high correlation between page rank and weighted degree.

1748
02:57:04,100 --> 02:57:08,100
I don't have an answer for that. Why there is a correlation.

1749
02:57:08,100 --> 02:57:12,100
And it does not say anything about, you know, these measures.

1750
02:57:12,100 --> 02:57:18,100
It's just it's just coincidental that you have this very high correlation.

1751
02:57:18,100 --> 02:57:23,100
Now, let's talk about how these how these measures change.

1752
02:57:23,100 --> 02:57:32,100
Because as the story evolves, like, you know, things happen, you know, so like how the character develops.

1753
02:57:32,100 --> 02:57:35,100
Like, you know, this is how you can study.

1754
02:57:35,100 --> 02:57:38,100
You can pretty much put this to any other.

1755
02:57:38,100 --> 02:57:41,100
You can put this to Harry Potter or Lord of the Rings.

1756
02:57:41,100 --> 02:57:43,100
And I'm pretty sure people have done that.

1757
02:57:43,100 --> 02:57:52,100
So you can study how character develops, you know, how like does an important character stays always important or do they die off or something like that happens?

1758
02:57:52,100 --> 02:57:58,100
So let's just plot it for like, you know, three different characters.

1759
02:57:58,100 --> 02:58:03,100
So these are we have a dark stock, Tyrion and Jon Snow, people who don't know.

1760
02:58:03,100 --> 02:58:11,100
These are, you know, well known important characters in the show.

1761
02:58:11,100 --> 02:58:15,100
So in this plot, we see that.

1762
02:58:16,100 --> 02:58:19,100
I got stuck. This is the first book.

1763
02:58:19,100 --> 02:58:21,100
That stock is very important.

1764
02:58:21,100 --> 02:58:27,100
And then something happens and he slowly like his graph slowly dies off.

1765
02:58:27,100 --> 02:58:31,100
And like that stock is no more important for some reason.

1766
02:58:31,100 --> 02:58:34,100
I don't know what happens, but something happens.

1767
02:58:34,100 --> 02:58:43,100
And and you see that there is a in the third book after the third book, something happens to Jon Snow.

1768
02:58:43,100 --> 02:58:47,100
And apparently in the fourth book, Jon Snow is not that important.

1769
02:58:47,100 --> 02:58:49,100
But and here he is.

1770
02:58:49,100 --> 02:58:55,100
Here is, you know, important again in the fifth book, you know, character evolves.

1771
02:58:55,100 --> 02:58:57,100
Something happens.

1772
02:58:57,100 --> 02:58:59,100
Story changes.

1773
02:58:59,100 --> 02:59:03,100
So you can you can try to.

1774
02:59:03,100 --> 02:59:08,100
This is how you can use data science and network science to better understand your TV shows.

1775
02:59:08,100 --> 02:59:13,100
So let's just work with these set of characters.

1776
02:59:13,100 --> 02:59:25,100
And in this exercise, we basically look at the evolution of weighted degree centrality and how like, you know, how it evolves for these characters.

1777
02:59:25,100 --> 02:59:33,100
And so basically this this set of characters is is the intersection is the union of top five from every book.

1778
02:59:34,100 --> 02:59:41,100
So you have like enough important characters from all the books and we see how these characters evolve.

1779
02:59:41,100 --> 02:59:47,100
And you have this nice, pretty looking graph, not so pretty, but nice.

1780
02:59:47,100 --> 02:59:56,100
And we see that according to according to weighted degree centrality, we have.

1781
02:59:57,100 --> 03:00:04,100
We have Jamie Lannister as the most important in book five and then there is the second most important.

1782
03:00:04,100 --> 03:00:11,100
And this is this was a dark stock and whoops, not so important anymore.

1783
03:00:11,100 --> 03:00:18,100
So so again, like, you know, you can see that, you know, the story is evolving book by book.

1784
03:00:18,100 --> 03:00:27,100
And the notion of important, not the importance of character is changing as you progress through the as you progress through the storyline.

1785
03:00:27,100 --> 03:00:32,100
And let's see if we get a different.

1786
03:00:36,100 --> 03:00:38,100
Does someone dip below zero there?

1787
03:00:40,100 --> 03:00:44,100
I'm not sure. I mean, I think this goes to zero.

1788
03:00:44,100 --> 03:00:48,100
Brain of that goes to zero.

1789
03:00:48,100 --> 03:00:52,100
Maybe there is no mention of her in book four.

1790
03:00:52,100 --> 03:00:58,100
I'm not sure. Let's do the same thing.

1791
03:00:58,100 --> 03:01:05,100
But for between us and charity and see, because between us and charity will always give you nice, peculiar results.

1792
03:01:05,100 --> 03:01:13,100
We have this fellow right here, which basically goes, which you can see this is this is this is amazing.

1793
03:01:13,100 --> 03:01:17,100
This is a major outlier. And this is not Jon Snow.

1794
03:01:17,100 --> 03:01:20,100
This is not Denaris. This is not any stock.

1795
03:01:20,100 --> 03:01:25,100
This is any guesses for people who like to watch.

1796
03:01:25,100 --> 03:01:31,100
This is Stanis Baratian and people who don't watch or don't like like.

1797
03:01:31,100 --> 03:01:41,100
So what the answer for so what is this is not this is not you would something expect like, OK, so he's an important enough character.

1798
03:01:41,100 --> 03:01:46,100
But you won't say, oh, like, you know, this is the most important character in the network.

1799
03:01:46,100 --> 03:01:53,100
So this is why the result is surprising. And and so this is the between us and charity.

1800
03:01:53,100 --> 03:01:57,100
So what can we say about Stanis Baratian?

1801
03:01:57,100 --> 03:02:04,100
Any guesses? Stanis Baratian is important according to between us and charity.

1802
03:02:04,100 --> 03:02:09,100
What's happening there? Can anyone try to predict what's the storyline here?

1803
03:02:09,100 --> 03:02:11,100
Why is Stanis Baratian important?

1804
03:02:12,100 --> 03:02:20,100
I'm not telling you to actually tell the story, but like he has a high between us and charity.

1805
03:02:20,100 --> 03:02:24,100
What does that translate to? Yes.

1806
03:02:24,100 --> 03:02:32,100
So so it basically means that this like, you know, Stanis Baratian is some maybe something like this.

1807
03:02:33,100 --> 03:02:41,100
So if you if you have read the books or was the TV shows at the end of Book 4 and at the end of season six, I guess,

1808
03:02:41,100 --> 03:02:49,100
you have these you have certain events that happen and those certain events,

1809
03:02:49,100 --> 03:02:56,100
those certain events end up bridging multiple communities in these networks.

1810
03:02:56,100 --> 03:03:01,100
And and all those events have one person in common, and that is Stanis Baratian.

1811
03:03:01,100 --> 03:03:10,100
And because of that, those events, certain events, we have Stanis Baratian as node five here.

1812
03:03:10,100 --> 03:03:15,100
Does that make sense? Is that a good enough explanation for Game of Thrones fans?

1813
03:03:15,100 --> 03:03:25,100
Just like that, if you see for a bit degree centrality in Book 5, see, even even with degree centrality, Stanis Baratian is important.

1814
03:03:25,100 --> 03:03:27,100
It's not like he's not an important character.

1815
03:03:27,100 --> 03:03:35,100
But when you check it for between us and charity, the if you just look at the ratio of how high the score goes,

1816
03:03:35,100 --> 03:03:40,100
it's much, much more in between us and charity as compared to degree centrality.

1817
03:03:40,100 --> 03:03:45,100
This is why I always whenever I get a new data set, I'm like between us and charity.

1818
03:03:45,100 --> 03:03:47,100
Let's see what happens with that.

1819
03:03:47,100 --> 03:03:52,100
But surprisingly, I did this for the Indian Airport Network to there are no surprises there.

1820
03:03:52,100 --> 03:03:54,100
So I was disappointed.

1821
03:03:54,100 --> 03:03:57,100
I wasn't able to find a surprising little airport in India,

1822
03:03:57,100 --> 03:04:00,100
which is important for the integrity of the structure.

1823
03:04:00,100 --> 03:04:04,100
It's not. So let's let's look at the data set.

1824
03:04:04,100 --> 03:04:14,100
And this is one of the most hotly debated area because I think in the I think network sciences as a field is like 20 years old.

1825
03:04:14,100 --> 03:04:23,100
And still no one has come up with a definition of what is a community like apparently there are 39 different not 39,

1826
03:04:23,100 --> 03:04:26,100
but there are 39 different areas of the network.

1827
03:04:26,100 --> 03:04:29,100
But no one has come up with a there is no consensus.

1828
03:04:29,100 --> 03:04:31,100
You know, what is the definition of community?

1829
03:04:31,100 --> 03:04:43,100
But in this we use the most famous one, which is called Lua Community Detection and which is the same one which is used in the picture that we saw to find those communities.

1830
03:04:43,100 --> 03:04:46,100
And and that picture was drawn using Geffi.

1831
03:04:46,100 --> 03:04:54,100
So that's if you if you like visualization, it's if you're OK with moving out of the Python world, Geffi is an option.

1832
03:04:54,100 --> 03:04:58,100
And I do this. I try to do the same thing, but with Python.

1833
03:04:58,100 --> 03:05:00,100
So you have this.

1834
03:05:00,100 --> 03:05:02,100
So you have this.

1835
03:05:02,100 --> 03:05:04,100
So you have this.

1836
03:05:04,100 --> 03:05:06,100
So you have this.

1837
03:05:06,100 --> 03:05:08,100
So you have this.

1838
03:05:08,100 --> 03:05:12,100
And I do this, I try to do the same thing, but with Python.

1839
03:05:12,100 --> 03:05:16,100
So you have this not so pretty looking community.

1840
03:05:16,100 --> 03:05:22,100
I mean, if I do a circus plot of this, I'll get a much better visualization.

1841
03:05:22,100 --> 03:05:32,100
But if you want just want to have a look of, you know, how things are going ahead, you can plot it like this.

1842
03:05:32,100 --> 03:05:44,100
And we create and these are our communities like it's it's keyed in by zero and it's keyed in by an integer and you have list of characters in all those communities.

1843
03:05:44,100 --> 03:06:01,100
And so I'm not going to explain what is Lua Community Detection, but the intuition behind that is like the intuition that I really like is you basically try to find clusters of nodes which have high density.

1844
03:06:01,100 --> 03:06:03,100
And how do you define density?

1845
03:06:03,100 --> 03:06:18,100
It's like there's an actual definition is number of nodes, number of edges in a network divided by the total possible number of edges in the network, which is suppose you have m edges and which is divided by nc2.

1846
03:06:18,100 --> 03:06:27,100
Like because like if you have n nodes, you can and if you pick two nodes at random, that's the total number of possible combinations of edges.

1847
03:06:27,100 --> 03:06:29,100
So it's m divided by nc2.

1848
03:06:29,100 --> 03:06:31,100
That is the density of a network.

1849
03:06:31,100 --> 03:06:37,100
And you basically try to find clusters of nodes where the where this density is very high.

1850
03:06:37,100 --> 03:06:48,100
So in which basically the intuition is that you try to find clusters in which nodes are interconnected to each other a lot as compared to other nodes in the network.

1851
03:06:48,100 --> 03:06:51,100
So to to see that pictorially.

1852
03:06:51,100 --> 03:06:57,100
So if I if I plot a community here, so this is the plot of that community.

1853
03:06:57,100 --> 03:07:00,100
You see that there are a lot of interconnections.

1854
03:07:00,100 --> 03:07:02,100
You see this is very, very dense.

1855
03:07:02,100 --> 03:07:05,100
The structure right here is very dense.

1856
03:07:05,100 --> 03:07:07,100
So that's a community.

1857
03:07:07,100 --> 03:07:18,100
And again, if I if I plot it for any other community, again, you see a very dense structure like characters in characters in this community are all of them are connected to each other.

1858
03:07:18,100 --> 03:07:26,100
And just to have a look at the actual numbers, if I calculate the total density of the network, it's around zero point zero four.

1859
03:07:26,100 --> 03:07:32,100
And if I calculate density of these communities that I found, it's like it's point zero point two.

1860
03:07:32,100 --> 03:07:38,100
So you have like, you know, these communities are, you know, five times as dense as the network itself.

1861
03:07:38,100 --> 03:07:42,100
So this is how you find communities.

1862
03:07:42,100 --> 03:07:45,100
So we won't do this exercise.

1863
03:07:45,100 --> 03:07:51,100
So talking about a bit of network science theory, I like to end on this.

1864
03:07:51,100 --> 03:07:56,100
We talked a lot about Python or talk a lot about working with real networks.

1865
03:07:56,100 --> 03:08:03,100
So again, you see this beautiful, magnificent plot, right?

1866
03:08:03,100 --> 03:08:12,100
And let's let's go back to nineteen sixties when, you know, graph theory was all the rage.

1867
03:08:12,100 --> 03:08:15,100
All the cool kids in mathematics were doing graph theory.

1868
03:08:15,100 --> 03:08:18,100
And there was this guy known as Paul Aldous.

1869
03:08:18,100 --> 03:08:22,100
And does anyone know what Aldous number?

1870
03:08:22,100 --> 03:08:25,100
So, yeah, one guy knows.

1871
03:08:25,100 --> 03:08:29,100
So apparently, so Paul Aldous was a mathematician.

1872
03:08:29,100 --> 03:08:34,100
And if you have written a paper with Paul Aldous, you get the number one.

1873
03:08:34,100 --> 03:08:39,100
If you have written a paper who has written a paper with Paul Aldous, you get the number two and so on.

1874
03:08:39,100 --> 03:08:44,100
If you have written a paper with someone who has written a paper who had someone written a paper with Paul Aldous, you get the number three.

1875
03:08:44,100 --> 03:08:49,100
And in the same in the same idea, there is something called as a Kevin Bacon number.

1876
03:08:49,100 --> 03:08:50,100
Has anyone heard about that?

1877
03:08:50,100 --> 03:08:52,100
So it's the same idea.

1878
03:08:52,100 --> 03:08:56,100
If you have worked in a movie with Kevin Bacon, you get the number one.

1879
03:08:56,100 --> 03:09:01,100
If you have worked with someone who has worked in the movie, you get number two and so on.

1880
03:09:01,100 --> 03:09:06,100
So and then there's a Paul, then there's an Aldous Bacon number, which is a summation of both of them.

1881
03:09:06,100 --> 03:09:15,100
So if you have a very low Aldous Bacon number, that means you are you are a mathematician plus a movie star.

1882
03:09:15,100 --> 03:09:18,100
So that's an interesting combination to have.

1883
03:09:18,100 --> 03:09:21,100
So coming back to Aldous graphs.

1884
03:09:21,100 --> 03:09:26,100
So suppose I don't give you data like right now we have a lot of data.

1885
03:09:26,100 --> 03:09:35,100
Suppose there's an algorithm that you came up with and you want to test this on some data and you you come up with some you have to come up with synthetic data.

1886
03:09:35,100 --> 03:09:39,100
Then the first question is how do I generate this?

1887
03:09:39,100 --> 03:09:42,100
The first answer that pops up randomly.

1888
03:09:42,100 --> 03:09:45,100
Randomly, yes, you can generate randomly data.

1889
03:09:45,100 --> 03:09:52,100
But even even even how you know, which you so you you you you generate normally distributed data.

1890
03:09:52,100 --> 03:09:55,100
But how does that translate to networks?

1891
03:09:55,100 --> 03:09:57,100
Right. So that was the first question.

1892
03:09:57,100 --> 03:10:02,100
So I think Paul Aldous came up with any this model.

1893
03:10:02,100 --> 03:10:09,100
It's called Aldous-Renny model in which you give you suppose I give you a probability of zero point five.

1894
03:10:09,100 --> 03:10:16,100
So you you basically go to every two nodes that you pick two nodes and with a probability of zero point five you add an edge.

1895
03:10:16,100 --> 03:10:19,100
So this is how you end up with a random graph.

1896
03:10:19,100 --> 03:10:29,100
This this was in the 1960s and in late 90s another model was proposed, which was called Barabasi-Albert graph.

1897
03:10:29,100 --> 03:10:37,100
And in this model, the idea is that most of them like this is what our real world network looks like.

1898
03:10:37,100 --> 03:10:42,100
Most of the nodes are connected to a small number of nodes.

1899
03:10:42,100 --> 03:10:45,100
But there would be one node who's connected to a lot of nodes.

1900
03:10:45,100 --> 03:10:53,100
So like if you look at the histogram plot, I'm sorry, but histogram plot.

1901
03:10:57,100 --> 03:10:59,100
This is the difference.

1902
03:10:59,100 --> 03:11:05,100
If you look at like because see because histograms are not nice, you don't see a nice plot.

1903
03:11:05,100 --> 03:11:11,100
But if we increase the number of nodes, we'll get a much smoother plot.

1904
03:11:11,100 --> 03:11:19,100
So yeah, this is the plot of Aldous-Renny graph and the degree distribution of that graph.

1905
03:11:19,100 --> 03:11:21,100
It's a normal distribution.

1906
03:11:21,100 --> 03:11:23,100
It's not it's not a normal distribution.

1907
03:11:23,100 --> 03:11:32,100
It's not a normal distribution, but it peaks at zero point one as you see, because I put in the probability as zero point one of having an edge.

1908
03:11:32,100 --> 03:11:33,100
So it peaks at zero point one.

1909
03:11:33,100 --> 03:11:34,100
So it peaks at zero point one.

1910
03:11:34,100 --> 03:11:36,100
So you have this nice looking random graph.

1911
03:11:36,100 --> 03:11:38,100
And then you have something like this.

1912
03:11:38,100 --> 03:11:40,100
This is the Barabasi-Albert graph.

1913
03:11:40,100 --> 03:11:47,100
And if you remember, this was our degree distribution for our Game of Thrones networks, right?

1914
03:11:47,100 --> 03:11:56,100
So which is much closer to a real world as compared to something like this, because these two are very, very different networks, right?

1915
03:11:56,100 --> 03:11:58,100
Like structurally very different.

1916
03:11:58,100 --> 03:12:02,100
How this is how the degrees are distributed here and the degrees are distributed here.

1917
03:12:02,100 --> 03:12:06,100
If you plot the ECDF of this, you'll get a smooth S curve.

1918
03:12:06,100 --> 03:12:14,100
And if you plot ECDF of this, you'll get a cliff, which is which is what most real world networks will give you.

1919
03:12:14,100 --> 03:12:18,100
So and this is our log log plot.

1920
03:12:18,100 --> 03:12:23,100
If you were interested in this, this is the log log plot of Aldous-Renny graph.

1921
03:12:24,100 --> 03:12:30,100
And this is the log log plot, which is our straight line of Barabasi-Albert graph.

1922
03:12:30,100 --> 03:12:35,100
So this was this was my detour to a bit of network science theory.

1923
03:12:35,100 --> 03:12:39,100
And if you want to talk more about this, I'm here for the next eight days.

1924
03:12:39,100 --> 03:12:44,100
So and there is still a lot of material left in the repository.

1925
03:12:44,100 --> 03:12:47,100
There is book five, six, eight, three bonus notebooks.

1926
03:12:47,100 --> 03:12:51,100
So if you are more interested, there is a lot of more material.

1927
03:12:51,100 --> 03:12:53,100
Feel free to go through it.

1928
03:12:53,100 --> 03:12:56,100
Feel free to talk to Eric on me during PyCon.

1929
03:12:56,100 --> 03:12:57,100
So thank you.

1930
03:13:03,100 --> 03:13:05,100
We got a few minutes.

1931
03:13:05,100 --> 03:13:06,100
We got a few minutes.

1932
03:13:06,100 --> 03:13:07,100
Mirza's got some announcements.

1933
03:13:07,100 --> 03:13:13,100
And then if there are questions that people want to ask right now and leave for posterity on YouTube, we're happy to entertain them as well.

1934
03:13:13,100 --> 03:13:16,100
So lunch is at twelve twenty.

1935
03:13:16,100 --> 03:13:20,100
So that's in two minutes in Grand Ballroom A and B.

1936
03:13:25,100 --> 03:13:29,100
So any questions from people that are burning questions?

1937
03:13:29,100 --> 03:13:31,100
Right. So Paul, you've asked a lot.

1938
03:13:31,100 --> 03:13:33,100
I'm going to go to the back first.

1939
03:13:40,100 --> 03:13:43,100
Sorry, I misunderstood.

1940
03:13:43,100 --> 03:13:45,100
All right. So Paul, you get the first one.

1941
03:13:46,100 --> 03:13:51,100
What are the most interesting areas where you could apply this in prediction and data science?

1942
03:13:51,100 --> 03:13:53,100
So the open triangles is obviously one.

1943
03:13:53,100 --> 03:13:57,100
But what are the other ones that we might want to take back to our respective institutions?

1944
03:13:59,100 --> 03:14:01,100
I guess that's a very particular question.

1945
03:14:01,100 --> 03:14:03,100
It depends where you work.

1946
03:14:03,100 --> 03:14:07,100
I could probably. So we can talk later about that.

1947
03:14:07,100 --> 03:14:10,100
It's quite highly context specific.

1948
03:14:10,100 --> 03:14:20,100
What are some interesting networks you've seen that maybe didn't seem like it makes sense as a network at first until you start looking at some of these plots?

1949
03:14:27,100 --> 03:14:32,100
I'm not the best person to ask this question because I've been doing networks for the last four years.

1950
03:14:32,100 --> 03:14:35,100
And whenever I look at some data, I'm like, oh, that's a network.

1951
03:14:35,100 --> 03:14:38,100
But last week I was working on, I started working on some spatial networks.

1952
03:14:38,100 --> 03:14:47,100
It's like how you, I mean, it's a very, it's a very, like, if you try hard enough, you can make spatial points as networks.

1953
03:14:47,100 --> 03:14:50,100
So like last week I was working on that.

1954
03:14:50,100 --> 03:14:55,100
But for me, I have a bad habit of like, you know, that could be more or less a network.

1955
03:14:55,100 --> 03:15:00,100
I think that speaks to like once you get used to this, you know, you're not going to be able to do it.

1956
03:15:00,100 --> 03:15:13,100
It becomes very natural to take a row like to take your data table, which we for in which each row is basically a node and start asking the question, how are the nodes, how are the rows related to one another?

1957
03:15:13,100 --> 03:15:19,100
And then once we find a good definition for a relation, suddenly we have a graph.

1958
03:15:19,100 --> 03:15:22,100
And now we can ask questions about how we can do that.

1959
03:15:22,100 --> 03:15:28,100
And then once we find a good definition for a relation, suddenly we have a graph.

1960
03:15:28,100 --> 03:15:32,100
And now we can ask questions about the relationships between the nodes.

1961
03:15:32,100 --> 03:15:35,100
That's a quote that I have in notebook two.

1962
03:15:35,100 --> 03:15:38,100
The heart of a graph is not in its nodes, it's in its edges.

1963
03:15:38,100 --> 03:15:40,100
The edges are what make a graph interesting.

1964
03:15:40,100 --> 03:15:46,100
The relationships between the nodes are what make a graph interesting.

1965
03:15:46,100 --> 03:15:50,100
Now, there have been questions before about scalability.

1966
03:15:50,100 --> 03:15:52,100
Before we go to the last question at the back.

1967
03:15:52,100 --> 03:15:53,100
Is that unscalability?

1968
03:15:53,100 --> 03:15:54,100
No.

1969
03:15:54,100 --> 03:15:58,100
Okay. But before we go to that question on the back, I just want to put this out there for everybody.

1970
03:15:58,100 --> 03:16:02,100
NVIDIA is working on Cougraph.

1971
03:16:02,100 --> 03:16:13,100
And I've been on GitHub talking with the NVIDIA developers to make sure that Cougraph's API accelerates graph algorithms and matches NetworkX.

1972
03:16:13,100 --> 03:16:23,100
So hopefully within the near future on some undefined timeframe, we'll be able to have NetworkX APIs on the GPU.

1973
03:16:23,100 --> 03:16:26,100
They recently had a very big project, this thing, right?

1974
03:16:26,100 --> 03:16:28,100
With a lot of researchers and...

1975
03:16:28,100 --> 03:16:30,100
Yes.

1976
03:16:30,100 --> 03:16:32,100
Final question at the back.

1977
03:16:32,100 --> 03:16:40,100
So obviously the math is fantastic.

1978
03:16:40,100 --> 03:16:45,100
But do you find that you actually use the plots to kind of investigate?

1979
03:16:45,100 --> 03:16:56,100
I mean, they're great to look at the visual graphs, but are they useful for investigating kind of, I don't know, your ideas about how the network is working or how it behaves?

1980
03:16:56,100 --> 03:16:59,100
Do you find that it's more than just...

1981
03:16:59,100 --> 03:17:06,100
You start seeing patterns that can repeat that you're like, oh, I see where there's a problem in this graph or network.

1982
03:17:06,100 --> 03:17:15,100
For example, if I look at a plot like this, I know that the graph has a scale-free property.

1983
03:17:15,100 --> 03:17:23,100
And once I know that, I know that the scale-free property defines that there are less nodes with a lot of neighbors.

1984
03:17:23,100 --> 03:17:25,100
So I can start thinking towards that direction.

1985
03:17:25,100 --> 03:17:31,100
And for example, with an ACDF plot, I know exactly what's the percentile distribution, right?

1986
03:17:31,100 --> 03:17:35,100
And I'll just know a lot more about the data.

1987
03:17:35,100 --> 03:17:39,100
And then I can start thinking from that way forward.

1988
03:17:39,100 --> 03:17:41,100
So it does come with experience.

1989
03:17:41,100 --> 03:17:44,100
The more you do it, the more familiar you are.

1990
03:17:44,100 --> 03:17:50,100
That said, visualization is one of the biggest tools that we need in any type of data analysis, right?

1991
03:17:50,100 --> 03:17:51,100
So that's why we have them.

1992
03:17:51,100 --> 03:17:56,100
And these graph-specific ones hopefully are useful, right?

1993
03:17:56,100 --> 03:18:02,100
So for example, we had that...the exhibition one.

1994
03:18:02,100 --> 03:18:15,100
Like we would not have...if we didn't choose the right visualization, we would not have been able to immediately intuit that inference that, oh, yeah, people are just local in time connecting with one another, right?

1995
03:18:15,100 --> 03:18:19,100
So visual inferences and your visual toolkit, very important.

1996
03:18:19,100 --> 03:18:20,100
Cool.

1997
03:18:20,100 --> 03:18:22,100
Well, thanks for coming.

1998
03:18:22,100 --> 03:18:24,100
Thanks, Mriddle. Let's give a hand for Mriddle.

1999
03:18:24,100 --> 03:18:26,100
The apprentice is really the master now.

