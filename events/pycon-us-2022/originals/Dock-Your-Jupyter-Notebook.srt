1
00:00:00,000 --> 00:00:07,960
All right, everyone, thanks for your patience.

2
00:00:07,960 --> 00:00:12,920
So please join me in welcoming Nir from DAGS Hub, who's going to talk about docking Jupyter

3
00:00:12,920 --> 00:00:13,920
Notebooks.

4
00:00:13,920 --> 00:00:14,920
Thank you.

5
00:00:14,920 --> 00:00:18,320
And thank you so much, everyone, for waiting.

6
00:00:18,320 --> 00:00:21,640
I'm sorry for the technical issue.

7
00:00:21,640 --> 00:00:25,040
And I must say that this is awesome to see everyone here.

8
00:00:25,040 --> 00:00:31,640
It's been two wild years doing virtual conferences and finally seeing all of your faces and even

9
00:00:31,640 --> 00:00:35,320
some familiar faces that I already met during the conference.

10
00:00:35,320 --> 00:00:36,320
This is absolutely awesome.

11
00:00:36,320 --> 00:00:39,600
And I want to thank you for joining me today.

12
00:00:39,600 --> 00:00:45,140
And I'd like to start our session today by asking you a few questions.

13
00:00:45,140 --> 00:00:52,400
So we'll be more data driven, the reason why we want to use Docker for Jupyter Notebook.

14
00:00:52,400 --> 00:00:57,520
So I'll start by asking, what type of operation system are you using?

15
00:00:57,520 --> 00:01:00,880
So with a show of hands, who is using here Mac OS?

16
00:01:00,880 --> 00:01:01,880
Whoa.

17
00:01:01,880 --> 00:01:02,880
Okay.

18
00:01:02,880 --> 00:01:03,880
Quite a lot.

19
00:01:03,880 --> 00:01:04,880
Nice.

20
00:01:04,880 --> 00:01:10,120
I love it, though it gave me a few issues just now.

21
00:01:10,120 --> 00:01:11,120
What about Linux?

22
00:01:11,120 --> 00:01:12,120
Nice.

23
00:01:12,120 --> 00:01:13,120
Wow.

24
00:01:13,120 --> 00:01:14,120
Quite a few.

25
00:01:14,120 --> 00:01:15,120
Windows?

26
00:01:15,120 --> 00:01:16,120
Ooh.

27
00:01:16,120 --> 00:01:18,120
Coding with Windows?

28
00:01:18,120 --> 00:01:20,040
How that's working for you.

29
00:01:20,040 --> 00:01:21,040
No, I'm kidding.

30
00:01:21,280 --> 00:01:27,040
I used to work with Windows, but then I discovered Mac and coding with Mac, it's the best.

31
00:01:27,040 --> 00:01:30,800
So are you using any type of special hardware?

32
00:01:30,800 --> 00:01:35,680
Any specific like powerful GPUs, very powerful clusters?

33
00:01:35,680 --> 00:01:39,560
Anyone are using special hardware here for training in their machine learning models?

34
00:01:39,560 --> 00:01:40,560
Okay.

35
00:01:40,560 --> 00:01:42,040
I see quite a few.

36
00:01:42,040 --> 00:01:43,040
Nice.

37
00:01:43,040 --> 00:01:44,080
Awesome.

38
00:01:44,080 --> 00:01:48,720
So I'd like to ask all the people in this room, what do you think if I'm going to ask

39
00:01:48,800 --> 00:01:54,120
you to collaborate on the same machine learning project altogether?

40
00:01:54,120 --> 00:01:56,200
Do you think it's going to be even possible?

41
00:01:56,200 --> 00:01:59,240
Well, probably it's going to be very challenging.

42
00:01:59,240 --> 00:02:04,240
You're going to have a lot of different dependencies, operation system that you're using.

43
00:02:04,240 --> 00:02:09,960
You're going to have problems like it works on my machine, but it won't work on your machine.

44
00:02:09,960 --> 00:02:15,720
And those are a lot of challenges that are hard to overcome.

45
00:02:15,720 --> 00:02:22,080
And by the end of this talk, we'll make it possible for all the people in this room to

46
00:02:22,080 --> 00:02:28,220
collaborate together on the same machine learning project together, regardless of their operation

47
00:02:28,220 --> 00:02:33,440
system or the tools that they're using, only by using Docker.

48
00:02:33,440 --> 00:02:39,060
So you're going to become a super woman or man of Docker.

49
00:02:39,060 --> 00:02:43,920
And this talk is going to focus on the very basic concepts of Docker.

50
00:02:43,920 --> 00:02:45,560
So what is Docker?

51
00:02:45,560 --> 00:02:46,560
Why do we actually need it?

52
00:02:46,560 --> 00:02:49,000
And what are the different components that it has?

53
00:02:49,000 --> 00:02:53,400
So if you are not familiar with it, by the end of this session, you will be.

54
00:02:53,400 --> 00:02:57,000
And if you are familiar with Docker and you know how to use it, this is going to be a

55
00:02:57,000 --> 00:03:00,480
very good refreshment for you.

56
00:03:00,480 --> 00:03:01,720
And my name is Nir Balazida.

57
00:03:01,720 --> 00:03:06,880
I'm an MLOps researcher at DAGZUB, which is the GitHub for machine learning that does

58
00:03:06,880 --> 00:03:09,600
the DevOps heavy lifting for you.

59
00:03:09,600 --> 00:03:15,440
And in my research, I focus on machine learning workflows, which in my opinion has the perfect

60
00:03:15,440 --> 00:03:21,280
balance between machine learning, DevOps, and people.

61
00:03:21,280 --> 00:03:25,320
And when I'm off the clock, I do a different kind of heavy lifting.

62
00:03:25,320 --> 00:03:28,120
And with that, I think we're ready to start.

63
00:03:28,120 --> 00:03:30,800
So what is Docker?

64
00:03:30,800 --> 00:03:36,280
Docker is an open source software packaging tool for building isolated environment and

65
00:03:36,280 --> 00:03:39,420
running applications with their dependencies.

66
00:03:39,420 --> 00:03:46,940
So we're able to wrap our application, our project, to the OS level and run it on different

67
00:03:46,940 --> 00:03:51,020
machines without worrying on the dependencies that it has.

68
00:03:51,020 --> 00:03:55,760
It's one of the most widely adopted tools in the industry, and it's used throughout

69
00:03:55,760 --> 00:04:02,280
the development and production lifecycle of a project.

70
00:04:02,280 --> 00:04:06,120
And why do we really need Docker for machine learning?

71
00:04:06,140 --> 00:04:12,020
So generally, the main advantage that Docker provides is standardization.

72
00:04:12,020 --> 00:04:18,980
And this gives us, first and foremost, reproducibility, which is very valuable for data scientists.

73
00:04:18,980 --> 00:04:24,720
So everyone are using the same operation system, the same tools, the same dependencies, which

74
00:04:24,720 --> 00:04:29,780
means that if we want to reproduce previous results, we can do it very easily.

75
00:04:29,780 --> 00:04:35,380
We can simply use our Docker container to run it on a local machine and start building

76
00:04:35,380 --> 00:04:36,820
our model.

77
00:04:36,820 --> 00:04:44,200
And it also provides us the ability to move our application or our training of our model

78
00:04:44,200 --> 00:04:46,300
from one machine to the other.

79
00:04:46,300 --> 00:04:50,700
And if you can think about it, most of the people who are using or are training machine

80
00:04:50,700 --> 00:04:55,100
learning models use heavy computing power, so they do need to move their project from

81
00:04:55,100 --> 00:05:01,640
their local machine to their remote cluster or to a powerful GPU machine.

82
00:05:01,640 --> 00:05:04,280
So this is very important.

83
00:05:04,680 --> 00:05:10,120
Some of you might ask, why not simply use Collab for that task?

84
00:05:10,120 --> 00:05:15,480
Well, Collab does provide an isolated environment that has all the dependencies that you need

85
00:05:15,480 --> 00:05:17,480
for the rest of your team.

86
00:05:17,480 --> 00:05:22,860
And that might be a bit of a harsh slide, so I'm sorry for that, because Docker is good,

87
00:05:22,860 --> 00:05:26,760
and it does provide some valuable capabilities.

88
00:05:26,760 --> 00:05:31,560
But when you're going to try to productionize your work and move to production, it's going

89
00:05:31,560 --> 00:05:38,240
to be harder because you don't know which operation system that machine use.

90
00:05:38,240 --> 00:05:42,700
If you and your teammate use the same machine, what tools you use.

91
00:05:42,700 --> 00:05:48,200
So it's going to take much longer to move from your research state to your production

92
00:05:48,200 --> 00:05:49,240
state.

93
00:05:49,240 --> 00:05:54,560
So that's why I wouldn't recommend using Collab when thinking about deploying to production.

94
00:05:54,560 --> 00:05:58,660
OK, so we're ready to talk about Docker.

95
00:05:59,540 --> 00:06:07,700
And Docker has three main components that eventually create that isolated environment.

96
00:06:07,700 --> 00:06:14,040
And I read a very good blog post, written by our CEO, so I might be biased.

97
00:06:14,040 --> 00:06:21,280
And he compared building that Docker container, so that isolated environment, to the process

98
00:06:21,280 --> 00:06:23,200
of baking a cookie.

99
00:06:23,200 --> 00:06:29,640
It might sound funny, but I promise you that it will make a lot of sense in the next two

100
00:06:29,640 --> 00:06:30,640
minutes.

101
00:06:30,640 --> 00:06:35,400
So the first component that Docker has, it's the Docker file.

102
00:06:35,400 --> 00:06:41,720
And the Docker file is basically a file that contains all the commands that we want to

103
00:06:41,720 --> 00:06:47,640
call when we generate the Docker image, which is the next component.

104
00:06:47,640 --> 00:06:56,080
And it basically has all the commands such as copy or move files or run some sort of

105
00:06:56,080 --> 00:06:57,620
installations.

106
00:06:57,620 --> 00:07:00,480
So that file is going to hold all of those commands.

107
00:07:00,480 --> 00:07:05,960
And in our analogy, the Docker file is the engineer's instructions on how to create our

108
00:07:05,960 --> 00:07:09,680
cookie cutter for baking our cookie.

109
00:07:09,680 --> 00:07:13,960
So which height it should be, how strong it should be, et cetera.

110
00:07:13,960 --> 00:07:17,560
Next, we have our Docker image.

111
00:07:17,560 --> 00:07:22,860
And our Docker image acts like, and this is a very, very big like, so don't use it outside

112
00:07:22,860 --> 00:07:26,540
of this room, including the people watching back home.

113
00:07:26,540 --> 00:07:32,600
So the Docker image is like a zip file that holds all of the components of our project

114
00:07:32,600 --> 00:07:35,280
or all of our dependencies in it.

115
00:07:35,280 --> 00:07:41,020
So if you want to copy files that you have from your local machine to that Docker image,

116
00:07:41,020 --> 00:07:49,000
if you want to install the operation system that you want to use, Linux, Ubuntu, and more.

117
00:07:49,000 --> 00:07:56,700
And in our analogy, our Docker image is basically our cookie cutter that will create our Docker

118
00:07:56,700 --> 00:07:57,700
container.

119
00:07:57,700 --> 00:08:03,740
So basically, it has everything that we need in order to run our application with all of

120
00:08:03,740 --> 00:08:05,980
our dependencies.

121
00:08:05,980 --> 00:08:12,100
And last, we have our Docker container, which probably a lot of you heard about it.

122
00:08:12,100 --> 00:08:17,760
And Docker container is basically a single instance of our application that is live and

123
00:08:17,760 --> 00:08:19,260
running.

124
00:08:19,260 --> 00:08:24,660
And in our analogy, our Docker container is actually our cookie, so what we try to build

125
00:08:24,660 --> 00:08:28,100
through that entire process.

126
00:08:28,100 --> 00:08:30,520
And where does those containers live?

127
00:08:30,560 --> 00:08:37,640
So container lives in a container registry, which is a special type of storage.

128
00:08:37,640 --> 00:08:45,280
And companies use different types of storages like AWS ECR, Azure Container Registry, and

129
00:08:45,280 --> 00:08:46,280
more.

130
00:08:46,280 --> 00:08:50,480
But there is another registry, which is the Docker Hub.

131
00:08:50,480 --> 00:08:54,480
And this is, you can think of it like the GitHub for Docker.

132
00:08:54,480 --> 00:08:58,360
And it has a lot of Docker images, so this is important.

133
00:08:58,360 --> 00:09:01,680
All of those registries are holding Docker images.

134
00:09:01,680 --> 00:09:11,000
And those images are available for the public use on Docker Hub that are for various types

135
00:09:11,000 --> 00:09:12,760
of tasks.

136
00:09:12,760 --> 00:09:17,140
So if you want one for machine learning or for running a Flask application, if you want

137
00:09:17,140 --> 00:09:22,280
to use Windows, Mac OS, different operation system, so you're going to find them all on

138
00:09:22,280 --> 00:09:25,160
Docker Hub.

139
00:09:25,680 --> 00:09:31,080
And now I think we're ready to get our hands dirty and start building our new Docker container

140
00:09:31,080 --> 00:09:34,120
from scratch for our machine learning project.

141
00:09:34,120 --> 00:09:39,400
And for that I'm going to use my pneumonia classification project, where I try to classify

142
00:09:39,400 --> 00:09:43,840
x-ray chest images if they have pneumonia or not.

143
00:09:43,840 --> 00:09:48,400
So my DAGZAP repository holds both my code and my data.

144
00:09:48,400 --> 00:09:51,680
My code is versioned by Git and my data is versioned by DVC.

145
00:09:51,680 --> 00:09:55,280
And I'm going to pull all of it to my Docker container.

146
00:09:55,280 --> 00:09:59,760
And at this point, let's say that I'd like to test a new hypothesis.

147
00:09:59,760 --> 00:10:03,520
So I want to use a different type of backbone model.

148
00:10:03,520 --> 00:10:06,200
Instead of using ResNet, I'm going to use VGG19.

149
00:10:06,200 --> 00:10:08,560
So this is my new hypothesis.

150
00:10:08,560 --> 00:10:10,840
And for that I'm going to create a new Docker.

151
00:10:10,840 --> 00:10:14,640
And I'm going to have all the dependencies I need to run that experiment on.

152
00:10:14,640 --> 00:10:16,440
So this is our goal here.

153
00:10:16,440 --> 00:10:21,920
I'm going to create a Docker container that I'm going to run my experiment on, which has

154
00:10:21,920 --> 00:10:25,240
all the dependencies that my team is using.

155
00:10:25,240 --> 00:10:28,240
So what will be the first part that we're going to do?

156
00:10:28,240 --> 00:10:32,420
We're going to start writing our Docker file.

157
00:10:32,420 --> 00:10:35,880
And due to time constraints, I'm not going to cover how to install Docker.

158
00:10:35,880 --> 00:10:39,040
This is a fairly easy process.

159
00:10:39,040 --> 00:10:42,600
This is the only process that varies between operation systems.

160
00:10:42,600 --> 00:10:47,200
So there are different installations on Mac, Windows, and more.

161
00:10:47,200 --> 00:10:51,760
But this should be a very easy task.

162
00:10:51,760 --> 00:10:57,580
And I'm going to add a link at the last slide with a reference on how to install it.

163
00:10:57,580 --> 00:11:06,100
So by starting to work on our Docker file, we'll usually base it on a previous image

164
00:11:06,100 --> 00:11:12,140
that already has some of the base dependencies that we're going to need for our project,

165
00:11:12,140 --> 00:11:16,600
like the operation system that we'd like to use, the language that we'd want to use,

166
00:11:16,600 --> 00:11:23,860
which is obviously Python, some frameworks, so Keras, TensorFlow, PyTorch, et cetera.

167
00:11:23,860 --> 00:11:28,540
And if we're not going to base it on a previous image, we're going to have to write everything

168
00:11:28,540 --> 00:11:31,740
from scratch, which is going to be very hard to do.

169
00:11:31,740 --> 00:11:35,020
Or it's going to be a very long process.

170
00:11:35,020 --> 00:11:39,380
So I highly recommend basing your image on previously defined images.

171
00:11:39,380 --> 00:11:42,940
So for my project, I will need the following dependencies.

172
00:11:42,940 --> 00:11:44,940
So I need Python 3 and above.

173
00:11:44,940 --> 00:11:50,900
I'm going to need Git because I want to clone my project to that Docker container.

174
00:11:50,900 --> 00:11:56,980
I'd like to have a Jupyter Notebook and TensorFlow as the framework to use.

175
00:11:56,980 --> 00:12:00,620
So a quick search on Docker Hub, and voila.

176
00:12:00,620 --> 00:12:05,100
I have a Docker image that is maintained by Project Jupyter that probably a lot of you

177
00:12:05,100 --> 00:12:12,220
are familiar with, which are maintaining that image for TensorFlow with Jupyter Notebook

178
00:12:12,220 --> 00:12:19,220
and a lot of other dependencies that are relevant for data science, like pandas, numpy, et cetera.

179
00:12:19,220 --> 00:12:21,520
And what do we actually see here?

180
00:12:21,520 --> 00:12:27,820
So first of all, we see the name of the maintainer and then the backslash and then the name of

181
00:12:27,820 --> 00:12:30,060
the image that we have here.

182
00:12:30,060 --> 00:12:32,500
So the name of the image here is actually TensorFlow-Notebook.

183
00:12:32,500 --> 00:12:35,060
And this is important.

184
00:12:35,060 --> 00:12:38,020
Next we can see how reliable that Docker image is.

185
00:12:38,020 --> 00:12:45,540
So we can see that it has 50 million downloads, which is fairly reliable.

186
00:12:45,540 --> 00:12:48,460
We can also see how we can pull it to our local machine.

187
00:12:48,460 --> 00:12:55,860
So let's say we don't want to reinvent the wheel and we want to use the exact image that

188
00:12:55,860 --> 00:12:57,140
already exists.

189
00:12:57,140 --> 00:13:01,820
So all we need to do is pull it to our machine and we can start using it.

190
00:13:01,820 --> 00:13:04,240
Next we're going to see here the tag.

191
00:13:04,240 --> 00:13:08,800
So the tags are basically the version of that Docker image.

192
00:13:08,800 --> 00:13:13,000
It will be updated as the dependencies are updated.

193
00:13:13,000 --> 00:13:17,520
So let's say TensorFlow releases a new version, then probably Jupyter Notebook or the Project

194
00:13:17,520 --> 00:13:20,240
Jupyter are going to create a new version.

195
00:13:20,240 --> 00:13:24,080
And you can see that there is a special type of tag here, which is the latest.

196
00:13:24,080 --> 00:13:29,000
And latest means the newest version of that image.

197
00:13:29,000 --> 00:13:31,040
Next we can see the operation system that it uses.

198
00:13:31,040 --> 00:13:40,280
So here it uses Linux and it has its 3.1 gigabyte weight.

199
00:13:40,280 --> 00:13:44,960
So let's take this information and put it in our Docker file.

200
00:13:44,960 --> 00:13:49,760
So for that we're going to use the from command, which is going to state the base image that

201
00:13:49,760 --> 00:13:50,760
we're going to use.

202
00:13:50,760 --> 00:13:54,800
Next, we're going to state the maintainer backslash, the name of the image that we'd

203
00:13:54,800 --> 00:13:56,200
like to use.

204
00:13:56,200 --> 00:13:58,800
And last, we're going to state the tag name.

205
00:13:58,800 --> 00:14:04,960
So here I used latest, but if you want previous versions of that image, you can simply specify

206
00:14:04,960 --> 00:14:07,320
them, specify it here.

207
00:14:07,320 --> 00:14:11,280
And by running that command, when I'm going to build the image, it's going to simply run

208
00:14:11,280 --> 00:14:15,680
the install command and it's going to use the tag latest.

209
00:14:15,680 --> 00:14:21,520
And at this point, I would like to go ahead and go to my DAGZAP repo and see what is my

210
00:14:21,520 --> 00:14:25,360
Git remote, my DVC remote, which is basically my remote storage.

211
00:14:25,360 --> 00:14:27,520
So I'll be able to pull off my data.

212
00:14:27,520 --> 00:14:29,520
And where do I store my requirements?

213
00:14:29,520 --> 00:14:35,600
So I would like to also install all the relevant requirements for my project.

214
00:14:35,600 --> 00:14:40,600
So I'm going to take all of this information and I'm going to put it in my Docker file.

215
00:14:40,600 --> 00:14:44,920
And here you see that I'm using the run command, which is basically going to run the following

216
00:14:44,920 --> 00:14:46,600
pipeline.

217
00:14:46,600 --> 00:14:49,320
And next, I'm going to clone my repo.

218
00:14:49,320 --> 00:14:51,720
I'm going to change directory to the project.

219
00:14:51,720 --> 00:14:57,560
I'm a true believer in using branches for testing new hypothesis.

220
00:14:57,560 --> 00:15:01,000
So I'm switching to VGG19 branch.

221
00:15:01,000 --> 00:15:05,200
Then I'm installing my requirements and I'm going to pull all of my data.

222
00:15:05,200 --> 00:15:09,440
So this is going to be translated into this.

223
00:15:09,440 --> 00:15:13,760
And a few more commands that I think are going to be valuable for you.

224
00:15:13,760 --> 00:15:19,080
So we have the env command, which is simply going to set the environment variables.

225
00:15:19,080 --> 00:15:24,000
We have the copy, which is going to copy the files from our local machine to that image.

226
00:15:24,000 --> 00:15:27,940
So to that imaginary zip file, if you can think of it.

227
00:15:27,940 --> 00:15:29,040
We have the maintainers.

228
00:15:29,040 --> 00:15:31,480
So the name of the maintainer of the Docker image.

229
00:15:31,480 --> 00:15:38,040
And the cmd command, which is the default command to run after building the image.

230
00:15:38,040 --> 00:15:44,420
Next we're going to want to run that Docker file and build our Docker image.

231
00:15:44,420 --> 00:15:48,360
So for that, we're going to use the Docker build command.

232
00:15:48,360 --> 00:15:53,200
We're going to use the pull flag, which is simply going to pull all the latest updates

233
00:15:53,200 --> 00:15:56,520
from the remote Docker hub.

234
00:15:56,520 --> 00:15:57,840
Next we're going to tag it.

235
00:15:57,840 --> 00:16:02,720
So I tagged it as pneumonia classification, which is the repository name.

236
00:16:02,720 --> 00:16:07,720
And the VGG19, which is the hypothesis that I'd like to test.

237
00:16:07,720 --> 00:16:13,080
And next I'm going to specify the path to my Docker file.

238
00:16:13,080 --> 00:16:15,560
And by running this command from your terminal,

239
00:16:15,560 --> 00:16:18,720
it's going to build a new Docker image.

240
00:16:18,720 --> 00:16:22,800
If it's the first time that you're using that base image, so

241
00:16:22,800 --> 00:16:28,000
the TensorFlow notebook image, it's going to download it to your local machine.

242
00:16:28,000 --> 00:16:30,160
Then it's going to run all the relevant commands, and

243
00:16:30,160 --> 00:16:34,200
it's going to wrap it up in that Docker image file.

244
00:16:35,280 --> 00:16:38,520
And now let's see all the files, all the images that I have locally.

245
00:16:38,520 --> 00:16:43,160
So by running Docker images, you're going to see all the images that you have.

246
00:16:43,160 --> 00:16:46,480
And here I can see that I have the pneumonia classification and

247
00:16:46,480 --> 00:16:49,680
then the VGG19 with that Docker image.

248
00:16:51,600 --> 00:16:58,680
And now we'd like to run our Docker container and start working on our project.

249
00:16:58,680 --> 00:17:01,480
So for that I'm going to use the Docker run command.

250
00:17:01,480 --> 00:17:06,240
I'm going to give it a name, so near my name, the port I want to use, and

251
00:17:06,240 --> 00:17:11,800
the image that I want to base the Docker container on.

252
00:17:11,800 --> 00:17:15,400
So it's going to use the pneumonia classification VGG19.

253
00:17:15,400 --> 00:17:19,760
You can also specify here the Docker image ID, and it will also work.

254
00:17:21,160 --> 00:17:26,120
And by running that command, I'm going to see in my terminal

255
00:17:26,120 --> 00:17:30,240
the same thing that I see when I run Jupyter Notebook from my terminal.

256
00:17:30,240 --> 00:17:34,840
So it's going to simply run the Docker container, and it's going to provide me

257
00:17:34,840 --> 00:17:39,480
with the URLs that I'm going to need to copy to my browser in order to get

258
00:17:39,480 --> 00:17:42,120
the Jupyter Notebook environment.

259
00:17:42,120 --> 00:17:48,520
And by copying one of those URLs, I'm going to get a fully configured

260
00:17:48,520 --> 00:17:55,640
Jupyter Notebook environment with all my project dependencies and files.

261
00:17:55,640 --> 00:17:59,280
So this includes both my code files and my data files.

262
00:17:59,280 --> 00:18:04,760
So basically everything that I need in order to start testing that new hypothesis.

263
00:18:04,760 --> 00:18:10,360
And let's say that at this point I change a few lines of code,

264
00:18:10,360 --> 00:18:14,680
I ran the experiment, and now I'm ready to version it and

265
00:18:14,680 --> 00:18:17,640
push it to my git and DVC remote.

266
00:18:17,640 --> 00:18:22,160
So I want to push both my git tract files and my DVC tract files.

267
00:18:22,160 --> 00:18:27,640
So for that, I'd like to connect with an SSH to that Docker container.

268
00:18:27,640 --> 00:18:29,200
And how can we do that?

269
00:18:29,200 --> 00:18:33,200
So we're going to use the Docker x command,

270
00:18:33,200 --> 00:18:36,080
which is going to execute that command.

271
00:18:36,080 --> 00:18:38,320
We're going to get an interactive terminal.

272
00:18:38,320 --> 00:18:43,400
And then we're going to take the Docker container ID that we'd like to connect to.

273
00:18:43,400 --> 00:18:46,200
And then the command that we'd like to run.

274
00:18:46,200 --> 00:18:47,400
And how it's going to look like?

275
00:18:49,120 --> 00:18:55,720
Then I'm going to start by looking for all the containers that I have live.

276
00:18:55,720 --> 00:18:59,600
And from that, I'm going to take the container ID that I'd like to connect to.

277
00:19:00,600 --> 00:19:05,840
Next, I'm going to run the command, the Docker execute IT.

278
00:19:05,840 --> 00:19:09,360
And then I'm providing it the container name.

279
00:19:09,360 --> 00:19:15,040
And last, I'm going to open a shell script in that container.

280
00:19:15,040 --> 00:19:19,240
And as you can see, I'm inside my running container.

281
00:19:20,360 --> 00:19:26,040
Next, we can simply run or change directories, run git status,

282
00:19:26,080 --> 00:19:29,880
version our code, and push it to our remotes.

283
00:19:29,880 --> 00:19:33,960
And as simple as that, you can start building your machine learning project on

284
00:19:33,960 --> 00:19:37,000
an isolated environment with your colleagues,

285
00:19:37,000 --> 00:19:42,160
without worrying about issues with dependencies or using different types of tools.

286
00:19:42,160 --> 00:19:47,280
And by pushing all of those files, I can see that experiment on DAGZub and

287
00:19:47,280 --> 00:19:49,280
compare it to different experiments.

288
00:19:49,280 --> 00:19:54,800
I can diff my Jupyter notebook and see which cells I modified,

289
00:19:54,800 --> 00:19:57,000
what was the output when I modified it.

290
00:19:57,000 --> 00:20:01,720
So if I process my data differently, and now what was its output, etc.

291
00:20:03,360 --> 00:20:08,120
So reaching to the end of our time together today,

292
00:20:08,120 --> 00:20:12,320
I'd like to have a quick recap on what we covered.

293
00:20:12,320 --> 00:20:17,840
So we started by talking about why do we actually need Docker for machine learning.

294
00:20:17,840 --> 00:20:20,080
And we understand that this is very valuable for

295
00:20:20,080 --> 00:20:23,880
us to collaborate and reproduce results with our colleagues.

296
00:20:23,880 --> 00:20:27,320
Then we talked about the different components that Docker has.

297
00:20:27,320 --> 00:20:31,000
So we have the Docker file, the Docker image, and

298
00:20:31,000 --> 00:20:36,840
eventually we have the Docker container, which is a live app that is fully

299
00:20:36,840 --> 00:20:42,160
configured and running, and that's how we can build our Docker container from scratch.

300
00:20:43,840 --> 00:20:46,680
I'd like to ask you if you have any questions.

301
00:20:46,680 --> 00:20:48,600
And before you are going to infer it,

302
00:20:48,600 --> 00:20:53,320
I'm going to state one question that I didn't cover.

303
00:20:53,320 --> 00:20:58,680
So how you can share that image that we just created with your colleagues.

304
00:20:58,680 --> 00:21:02,040
So because of time constraint, we can't cover it today.

305
00:21:02,040 --> 00:21:07,440
But it's a fairly straightforward task,

306
00:21:07,440 --> 00:21:10,040
which is kind of like Docker push.

307
00:21:10,040 --> 00:21:11,200
It sums to Docker push.

308
00:21:11,200 --> 00:21:15,240
You simply need to set your credentials with Docker Hub and

309
00:21:15,240 --> 00:21:18,120
push it to your Docker registry.

310
00:21:18,120 --> 00:21:22,520
Once again, I added a link on how to do it in the last slide, so

311
00:21:22,520 --> 00:21:24,880
you can easily do it.

312
00:21:24,880 --> 00:21:27,800
And if you have any questions, I'd love to take them.

313
00:21:27,800 --> 00:21:31,720
I think we have a minute, or you want to take it offline?

314
00:21:31,720 --> 00:21:33,120
Actually, everyone, sorry for the confusion.

315
00:21:33,120 --> 00:21:36,520
We can't take questions in the room due to COVID restrictions, but

316
00:21:36,520 --> 00:21:38,320
feel free to come to the front and ask them directly.

317
00:21:38,320 --> 00:21:40,720
Awesome, so we're going to take it offline.

318
00:21:41,840 --> 00:21:44,520
So I'd like to thank you all for joining me today.

319
00:21:44,520 --> 00:21:45,960
It was awesome.

320
00:21:45,960 --> 00:21:51,200
It's so great to finally do live presentations and live talks and

321
00:21:51,240 --> 00:21:53,320
seeing all of your faces here.

322
00:21:53,320 --> 00:21:55,960
It actually warms my heart, so I'm very excited.

323
00:21:55,960 --> 00:21:57,400
And thank you so much for joining.

324
00:21:57,400 --> 00:21:58,020
Thank you very much.

