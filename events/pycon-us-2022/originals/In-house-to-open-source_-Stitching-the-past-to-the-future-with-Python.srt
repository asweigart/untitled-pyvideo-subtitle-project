1
00:00:00,000 --> 00:00:06,560
Welcome, everyone.

2
00:00:06,560 --> 00:00:09,600
You're in room 355ABC.

3
00:00:09,600 --> 00:00:13,640
And we have Nandita Viswanath and Sagar Ariel.

4
00:00:13,640 --> 00:00:17,640
And they're going to talk about in-house to open source, stitching the past to the future

5
00:00:17,640 --> 00:00:18,640
with Python.

6
00:00:18,640 --> 00:00:19,640
Hi, everyone.

7
00:00:19,640 --> 00:00:20,640
I'm Nandita.

8
00:00:20,640 --> 00:00:21,640
I'm a software engineer at Bloomberg.

9
00:00:21,640 --> 00:00:22,640
And I'm Sagar.

10
00:00:22,640 --> 00:00:23,640
I'm also a software engineer at Bloomberg.

11
00:00:23,640 --> 00:00:24,640
And I'm also a software engineer at Bloomberg.

12
00:00:25,640 --> 00:00:34,400
And we're going to be presenting our talk, in-house to open source, stitching the past

13
00:00:34,400 --> 00:00:36,920
to the future with Python.

14
00:00:36,920 --> 00:00:40,560
So today we're going to be discussing how you can leverage open source software when

15
00:00:40,560 --> 00:00:43,520
thinking about migrating away from legacy code.

16
00:00:43,520 --> 00:00:46,480
Our talk is loosely broken up into four sections.

17
00:00:46,480 --> 00:00:48,600
We're going to start with an introduction.

18
00:00:48,600 --> 00:00:52,560
We'll then move on to identifying our right open source candidate.

19
00:00:52,560 --> 00:00:56,800
We'll touch up on how you can integrate your open source candidate into your existing

20
00:00:56,800 --> 00:00:57,840
tech stack.

21
00:00:57,840 --> 00:01:01,040
And then we'll wrap up with some conclusions.

22
00:01:01,040 --> 00:01:05,640
So before we jump into why you should think about open source for migrations from legacy

23
00:01:05,640 --> 00:01:09,440
code, let's first understand what legacy code even is.

24
00:01:09,440 --> 00:01:15,040
Legacy code is typically code that's no longer engineered but is just patched for fixes.

25
00:01:15,040 --> 00:01:19,800
So it becomes nearly impossible to add new features, which makes them great candidates

26
00:01:19,800 --> 00:01:22,080
for migrations.

27
00:01:22,080 --> 00:01:26,760
So when you're thinking about migrating software, I think open source should be one of the first

28
00:01:26,760 --> 00:01:28,440
things that come to mind.

29
00:01:28,440 --> 00:01:33,680
And the first reason why is because you already have access to high quality pre-built software.

30
00:01:33,680 --> 00:01:38,320
Chances are there's already software within the open source community that can address

31
00:01:38,320 --> 00:01:42,640
your needs, even if not entirely, to an extent large enough that it would take minimal effort

32
00:01:42,640 --> 00:01:45,800
for you to go in and tailor it to your specific needs.

33
00:01:45,800 --> 00:01:49,120
Which brings me to the second big advantage, customization.

34
00:01:49,160 --> 00:01:51,920
Now, since the code is open source, you know what's going on.

35
00:01:51,920 --> 00:01:55,320
You can maybe just add a plugin to tailor it to your requirement or go in and modify

36
00:01:55,320 --> 00:01:57,840
the code base yourself.

37
00:01:57,840 --> 00:02:02,120
Another advantage is that in some way you have access to latest innovation.

38
00:02:02,120 --> 00:02:07,840
As more and more people start adopting that open source software, more people become invested

39
00:02:07,840 --> 00:02:09,740
in its growth and development.

40
00:02:09,740 --> 00:02:14,360
So in a way, you're always on top of the cutting edge technology.

41
00:02:14,360 --> 00:02:17,200
And it's not just me saying this, we're all at PyCon.

42
00:02:17,280 --> 00:02:21,360
And some of you guys have also found that IT leaders think the usage of open source

43
00:02:21,360 --> 00:02:24,960
is going to boom over the next couple years.

44
00:02:24,960 --> 00:02:29,360
But even while open source is great, there are some things to still keep in mind.

45
00:02:29,360 --> 00:02:33,800
The first is that support and maintenance may not always be available.

46
00:02:33,800 --> 00:02:38,520
But there are some companies and enterprises that offer maintenance at an additional fee.

47
00:02:38,520 --> 00:02:41,060
So that's something to keep in mind.

48
00:02:41,060 --> 00:02:44,400
The other thing to keep in mind, especially when you're building critical applications,

49
00:02:44,600 --> 00:02:47,200
is the maturity and the stability of the software.

50
00:02:47,200 --> 00:02:51,720
If there is an issue, you might end up relying on someone to fix it, or you might have to

51
00:02:51,720 --> 00:02:53,380
step up and fix it yourself.

52
00:02:53,380 --> 00:02:55,180
So that's an added consideration.

53
00:02:55,180 --> 00:02:59,320
And the last is that usage of open source does not eliminate hardware costs.

54
00:02:59,320 --> 00:03:05,400
You have to budget for hardware if you want to adopt open source at scale.

55
00:03:05,400 --> 00:03:09,400
At this point, I want to introduce a case study that we're going to be walking through

56
00:03:09,400 --> 00:03:11,300
as the talk progresses.

57
00:03:11,300 --> 00:03:14,580
We're going to be trying to migrate an orchestration framework.

58
00:03:14,580 --> 00:03:21,020
So let's think of a really complex framework that has to use some metadata to decide to

59
00:03:21,020 --> 00:03:25,980
schedule some processes, and then has to account for process dependencies, monitor events,

60
00:03:25,980 --> 00:03:29,700
and then finally write some data to a database.

61
00:03:29,700 --> 00:03:31,860
Let's build a little more clarity around that.

62
00:03:31,860 --> 00:03:37,420
So say we have some metadata based on which we decide we need to schedule a process.

63
00:03:37,420 --> 00:03:41,020
Our process is that little red circle you see there.

64
00:03:41,020 --> 00:03:45,180
Figuring that one red circle can actually set off a bunch of other processes, our purple

65
00:03:45,180 --> 00:03:49,820
circles, which can in turn set off another set of processes, our orange circles.

66
00:03:49,820 --> 00:03:53,940
So our red circle is not really done until all of the purple and the orange processes

67
00:03:53,940 --> 00:03:55,140
complete.

68
00:03:55,140 --> 00:03:59,240
And like I said earlier, what these processes are doing is just writing data.

69
00:03:59,240 --> 00:04:03,840
And we're looking at data in the range of about 50 million data points.

70
00:04:03,840 --> 00:04:06,140
But this is when the complexity really kicks in.

71
00:04:06,140 --> 00:04:09,460
We don't want to just schedule and orchestrate one of these red circles.

72
00:04:09,460 --> 00:04:14,260
We want to do hundreds of such processes and in turn write billions of data points with

73
00:04:14,260 --> 00:04:17,900
no room for error.

74
00:04:17,900 --> 00:04:22,700
Now next I'd like to talk to you about how it is that you can actually go about identifying

75
00:04:22,700 --> 00:04:26,180
the software that you want to migrate towards.

76
00:04:26,180 --> 00:04:28,700
We're going to go through this in a three-phase approach.

77
00:04:28,700 --> 00:04:32,740
The first being understanding your requirements, identifying what it is that you're actually

78
00:04:32,740 --> 00:04:38,800
looking to replace, and then researching for a solution that would address these requirements.

79
00:04:38,800 --> 00:04:44,160
And finally, you want to narrow down the potential solutions that you've come up with to one

80
00:04:44,160 --> 00:04:46,760
final system.

81
00:04:46,760 --> 00:04:52,040
So in terms of understanding your requirements, in our use case, we had to first get rid of

82
00:04:52,040 --> 00:04:55,920
all the business logic as well as the specific intricacies that were unique to our problem

83
00:04:55,920 --> 00:04:59,660
and try to boil it down to the highest level.

84
00:04:59,660 --> 00:05:05,120
We came up with one sentence that we believe perfectly describes our use case, and that

85
00:05:05,120 --> 00:05:10,400
is the automated coordination of events and data streams leveraging domain-specific metadata

86
00:05:10,400 --> 00:05:12,520
to intelligently schedule and trigger processes.

87
00:05:12,520 --> 00:05:17,720
It's a bit of a mouthful, but from this we can derive these three keywords that describe

88
00:05:17,720 --> 00:05:22,080
the system, and that is scheduler, orchestration, and dependencies.

89
00:05:22,080 --> 00:05:25,760
Now we came up with a list of must-haves as well as nice-to-haves.

90
00:05:25,760 --> 00:05:29,800
In terms of the must-haves, obviously modeling dependencies, that's the first and primary

91
00:05:29,800 --> 00:05:30,800
goal.

92
00:05:30,800 --> 00:05:33,420
We want processes to be able to trigger other processes.

93
00:05:33,420 --> 00:05:37,700
We also want to be able to do this for historical runs, and obviously we want permissioning

94
00:05:37,700 --> 00:05:39,580
since this is going into production.

95
00:05:39,580 --> 00:05:42,660
We want to make sure there's no vulnerabilities.

96
00:05:42,660 --> 00:05:44,220
Performance is also another consideration.

97
00:05:44,220 --> 00:05:48,260
Like I mentioned, on a production cluster, we don't want it to take up all the resources.

98
00:05:48,260 --> 00:05:51,980
In terms of nice-to-haves, we did say that a user interface as well as the ability to

99
00:05:51,980 --> 00:05:56,220
monitor all these processes would be nice to have, not necessary though.

100
00:05:56,220 --> 00:06:03,140
And parallelization, these processes are being run on off-peak hours, so it wasn't a necessity.

101
00:06:04,140 --> 00:06:08,020
Now, when it came time to research, obviously the first thing everyone does is go to the

102
00:06:08,020 --> 00:06:09,020
internet.

103
00:06:09,020 --> 00:06:13,780
You take your keywords and you post them into search engines, and you try to come up with

104
00:06:13,780 --> 00:06:15,760
potential options.

105
00:06:15,760 --> 00:06:21,700
Going about this, we eventually landed on Apache's website, where most open-source systems are.

106
00:06:21,700 --> 00:06:28,100
We found two systems which closely match what we're looking for, namely Apache NiFi as well

107
00:06:28,100 --> 00:06:30,300
as Apache Airflow.

108
00:06:30,500 --> 00:06:34,460
Another way that we were going about doing research was word of mouth.

109
00:06:34,460 --> 00:06:39,180
Obviously conferences like PyCon can give you potential solutions that might fit your

110
00:06:39,180 --> 00:06:44,580
use case, as well as networking, from which internally at Bloomberg we support Argo.

111
00:06:44,580 --> 00:06:47,940
That's another solution that we came across.

112
00:06:47,940 --> 00:06:50,220
We have these three potential options.

113
00:06:50,220 --> 00:06:53,020
We want to first figure out the evaluation criteria.

114
00:06:53,020 --> 00:06:58,060
How can we narrow it down to a specific system?

115
00:06:58,060 --> 00:07:03,100
We broadly categorize it into these four different metrics, first being adoption.

116
00:07:03,100 --> 00:07:07,940
Systems that have more GitHub activity are bound to have more support.

117
00:07:07,940 --> 00:07:09,380
Your questions will be answered quicker.

118
00:07:09,380 --> 00:07:12,180
Any bugs that come up will be fixed sooner.

119
00:07:12,180 --> 00:07:13,900
That's a very important one.

120
00:07:13,900 --> 00:07:15,340
Then compatibility.

121
00:07:15,340 --> 00:07:17,700
Does this system meet your technical requirements?

122
00:07:17,700 --> 00:07:20,820
Does it address the problem that you're trying to solve?

123
00:07:20,820 --> 00:07:22,580
And then of course extendability.

124
00:07:22,580 --> 00:07:26,500
Once you do integrate an open-source system, it'd be nice for it to eventually evolve into

125
00:07:26,500 --> 00:07:27,500
something more.

126
00:07:27,700 --> 00:07:31,700
Can it address other problems that you haven't particularly foreseen until you start using it?

127
00:07:31,700 --> 00:07:34,220
And then finally ease of customization.

128
00:07:34,220 --> 00:07:39,020
No system is a perfect match, but if something is flexible and is easy to customize for your

129
00:07:39,020 --> 00:07:42,380
specific use case, then that's obviously better.

130
00:07:42,380 --> 00:07:47,220
This is what we ended up categorizing these three systems into.

131
00:07:47,220 --> 00:07:50,460
Airflow was a very popular Apache project.

132
00:07:50,460 --> 00:07:55,060
It's very actively maintained, very extensible, lots of plugins and lots of support for them.

133
00:07:55,060 --> 00:07:58,820
It's very flexible with permission control and very easy to adapt.

134
00:07:58,820 --> 00:08:01,340
It's actually pure Python.

135
00:08:01,340 --> 00:08:06,500
Apache NiFi, also a great solution, but it didn't match our use case specifically because

136
00:08:06,500 --> 00:08:08,500
it's very data pipeline focused.

137
00:08:08,500 --> 00:08:10,420
Now we do already have the ETL infrastructure.

138
00:08:10,420 --> 00:08:11,940
That's not the part we're trying to replace.

139
00:08:11,940 --> 00:08:14,620
So it didn't exactly match what we were looking for.

140
00:08:14,620 --> 00:08:19,540
Argo, again, it was supported internally at Bloomberg, so that communication link is even

141
00:08:19,540 --> 00:08:20,540
more direct.

142
00:08:20,540 --> 00:08:22,580
That's why it had such a high rating on adoption.

143
00:08:22,620 --> 00:08:27,860
It's focused on containerized applications, whereas we're looking for more of a bare metal

144
00:08:27,860 --> 00:08:29,100
Linux solution.

145
00:08:29,100 --> 00:08:34,140
Again, this is very subjective evaluation criteria for our specific use case, not necessarily

146
00:08:34,140 --> 00:08:37,260
going to be true everywhere.

147
00:08:37,260 --> 00:08:42,620
Now Apache Airflow, like I mentioned, it's based around the directed acyclic graph, DAG

148
00:08:42,620 --> 00:08:44,220
for short.

149
00:08:44,220 --> 00:08:46,300
It's pure Python, like I mentioned.

150
00:08:46,300 --> 00:08:51,060
It didn't support every particular use case that we had, but it had a lot of support for

151
00:08:51,100 --> 00:08:55,020
plugins, and we did find plugins that were very useful.

152
00:08:55,020 --> 00:08:58,660
And of course, a very nice and easy to navigate web UI.

153
00:08:58,660 --> 00:09:01,340
Now with that, I'd like to hand it off to my colleague, Nandita.

154
00:09:01,340 --> 00:09:02,340
Okay, great.

155
00:09:02,340 --> 00:09:05,580
So now Sagar has helped us pick Airflow, and we know Airflow is what we want to migrate

156
00:09:05,580 --> 00:09:06,580
to.

157
00:09:06,580 --> 00:09:07,980
But where do we even start?

158
00:09:07,980 --> 00:09:12,060
We have this huge complex framework that's been working just fine.

159
00:09:12,060 --> 00:09:17,740
The only issue is that we're not able to iterate and add new features to it.

160
00:09:17,740 --> 00:09:19,300
And it's doing a lot of things.

161
00:09:19,300 --> 00:09:21,020
It's monitoring for dependencies.

162
00:09:21,020 --> 00:09:22,420
It's writing billions of data points.

163
00:09:22,420 --> 00:09:24,340
There's so much scope for error.

164
00:09:24,340 --> 00:09:29,540
So before we even move further, let's break this down into independent but connected components.

165
00:09:29,540 --> 00:09:31,400
What are we really dealing with here?

166
00:09:31,400 --> 00:09:36,220
We have a scheduler that uses some metadata to decide which process to kick off.

167
00:09:36,220 --> 00:09:41,220
We have an orchestration engine, possibly, that kicks off that first process and monitors

168
00:09:41,220 --> 00:09:42,460
it for completion.

169
00:09:42,460 --> 00:09:48,360
And we have, let's say, a job management system that monitors the dependent processes

170
00:09:48,440 --> 00:09:51,000
that were kicked off.

171
00:09:51,000 --> 00:09:54,760
These are the three independent chunks of this huge framework that we're trying to migrate

172
00:09:54,760 --> 00:09:55,760
from.

173
00:09:55,760 --> 00:09:59,920
If we want to move away from all of these three in one big bang, there's just a lot

174
00:09:59,920 --> 00:10:02,520
more risk and the scope for failure balloons.

175
00:10:02,520 --> 00:10:07,160
Instead, we could just start by replacing the easily replaceable components.

176
00:10:07,160 --> 00:10:10,960
To me, that looks like the scheduler and the orchestration engine.

177
00:10:10,960 --> 00:10:15,360
So we can just try removing the scheduler and the orchestration engine out of that framework

178
00:10:15,360 --> 00:10:18,560
and replacing that with Airflow.

179
00:10:18,560 --> 00:10:19,560
But how?

180
00:10:19,560 --> 00:10:24,120
The scheduler, orchestration engine, job management system all work perfectly together because

181
00:10:24,120 --> 00:10:26,480
they were all natively integrated.

182
00:10:26,480 --> 00:10:29,120
And they were probably built around the same time.

183
00:10:29,120 --> 00:10:31,240
They were built to be compatible with each other.

184
00:10:31,240 --> 00:10:35,080
But then when we integrate with an open source solution like Airflow, it's not been built

185
00:10:35,080 --> 00:10:39,060
for our specific use case, but it still works really great.

186
00:10:39,060 --> 00:10:44,240
So we need a way to really make Airflow and our job management system kind of speak the

187
00:10:44,280 --> 00:10:45,560
same language.

188
00:10:45,560 --> 00:10:47,800
And I think we all know where I'm getting at with this.

189
00:10:47,800 --> 00:10:48,800
We're at PyCon.

190
00:10:48,800 --> 00:10:53,440
So this is where we want to introduce PyHero, our Python component that's going to help

191
00:10:53,440 --> 00:10:58,480
stitch together Airflow and our legacy job management system.

192
00:10:58,480 --> 00:11:00,600
And we have a lot of superheroes out there.

193
00:11:00,600 --> 00:11:02,400
So why should we think of PyHero?

194
00:11:02,400 --> 00:11:07,240
There are essentially three superpowers that we're really looking for.

195
00:11:07,240 --> 00:11:11,940
We want to be able to integrate easily with our existing code base.

196
00:11:11,940 --> 00:11:16,220
So it should be easy for us to integrate with something that's not necessarily Python

197
00:11:16,220 --> 00:11:17,540
based.

198
00:11:17,540 --> 00:11:22,140
The second superpower that we want is we need to be able to write this component really

199
00:11:22,140 --> 00:11:23,140
quickly.

200
00:11:23,140 --> 00:11:26,500
Eventually, in the future, our job management system is going to go away too.

201
00:11:26,500 --> 00:11:28,640
And Airflow is going to take over everything.

202
00:11:28,640 --> 00:11:32,200
So at that point of time, PyHero will unfortunately have to step down.

203
00:11:32,200 --> 00:11:35,140
So we don't want to invest too much time building out PyHero.

204
00:11:35,140 --> 00:11:37,840
He's eventually just going to go away.

205
00:11:37,840 --> 00:11:42,240
And the third thing that we're looking for is production quality PyHero.

206
00:11:42,240 --> 00:11:46,240
Even though PyHero is temporary, it still has to be production quality.

207
00:11:46,240 --> 00:11:51,380
Because we want it to run in production, we cannot cut corners in terms of its performance.

208
00:11:51,380 --> 00:11:56,440
So let's now jump into discussing how Python possesses all of these three superpowers, starting

209
00:11:56,440 --> 00:12:00,520
with how we can use it to integrate with an existing stack.

210
00:12:00,520 --> 00:12:02,400
So let's assume the worst case scenario.

211
00:12:02,400 --> 00:12:05,040
Our job management system is not Python at all.

212
00:12:05,040 --> 00:12:07,320
It's built in a completely new language.

213
00:12:07,320 --> 00:12:10,520
Now we need Python to kind of interface with it.

214
00:12:10,520 --> 00:12:13,200
What are the different ways that we can go about this?

215
00:12:13,200 --> 00:12:18,400
The first is, like I said, an interfaced approach, where we want to directly use our non-Python

216
00:12:18,400 --> 00:12:21,240
components within our Python module.

217
00:12:21,240 --> 00:12:25,760
In this case, we have, honestly, multiple options.

218
00:12:25,760 --> 00:12:32,720
If you had a C or C++ library that you wanted to use, you can compile it into a .so or

219
00:12:32,720 --> 00:12:36,520
.dll file and then import that within your Python code.

220
00:12:36,520 --> 00:12:42,520
An alternative would be to use the Python API to expose our C, C++ libraries by our

221
00:12:42,520 --> 00:12:44,220
Python interface.

222
00:12:44,220 --> 00:12:49,720
But both of this will require you to kind of go in and modify your libraries themselves.

223
00:12:49,720 --> 00:12:54,480
There is another easier, non-intrusive approach that you can take, wherein your non-Python

224
00:12:54,480 --> 00:12:58,380
components are treated as independent entities in themselves.

225
00:12:58,380 --> 00:13:03,240
You modularize them and package them as executables, and you just invoke them as subprocesses from

226
00:13:03,240 --> 00:13:06,060
within your Python script.

227
00:13:06,060 --> 00:13:10,620
So this is where you really have to kind of balance your requirements, and you have to

228
00:13:10,620 --> 00:13:12,020
make a trade-off.

229
00:13:12,020 --> 00:13:15,700
If you have things within, let's say, our job management system that we want to reuse

230
00:13:15,700 --> 00:13:17,520
even after our migration is complete.

231
00:13:17,520 --> 00:13:22,700
So let's say we had a C++ library that was super powerful that we intend on using even

232
00:13:22,700 --> 00:13:27,780
after we fully move to airflow, it might make sense to just go with the first approach,

233
00:13:27,780 --> 00:13:30,420
even if it's going to require more development time.

234
00:13:30,420 --> 00:13:34,560
But in our case, we were really looking at completely replacing our job management system,

235
00:13:34,560 --> 00:13:39,600
in which case it was just easier for us to modularize it and package it as an executable

236
00:13:39,600 --> 00:13:42,680
and invoke it as a subprocess.

237
00:13:42,680 --> 00:13:47,120
So now that we've discussed how we can integrate Python with an existing stack, let's move

238
00:13:47,120 --> 00:13:53,560
on to discussing how Python can help us write production quality code quickly.

239
00:13:53,560 --> 00:13:58,280
So we've talked about how we want this PyHero component to be running in production.

240
00:13:58,280 --> 00:14:01,940
And one of the most important things that that comes with is awareness when something

241
00:14:01,940 --> 00:14:03,300
goes wrong.

242
00:14:03,300 --> 00:14:07,100
When something goes wrong, you don't want to find out, let's say, hours later or days

243
00:14:07,100 --> 00:14:08,100
later.

244
00:14:08,100 --> 00:14:11,300
You want to know as soon as PyHero went down in production.

245
00:14:11,300 --> 00:14:15,440
And to do this, we actually found ourselves using a feature of Python that most of us

246
00:14:15,440 --> 00:14:16,440
are already aware of.

247
00:14:16,440 --> 00:14:18,360
I learned about it in theory, too.

248
00:14:18,360 --> 00:14:24,120
But this is how we could really see it being used while writing production quality code.

249
00:14:24,120 --> 00:14:29,200
So we have a decorator that we use within our group that takes in three arguments.

250
00:14:29,200 --> 00:14:33,180
It takes in a severity, a group, and the name of the component.

251
00:14:33,180 --> 00:14:38,960
And based on these three arguments, it creates a ticket with the appropriate severity level

252
00:14:38,960 --> 00:14:40,640
and routes it to the correct group.

253
00:14:40,640 --> 00:14:47,120
So all it does is really just wrap the function code in a try-catch block and create a ticket

254
00:14:47,120 --> 00:14:52,760
based on the input parameters and route it when something goes wrong and execution fails.

255
00:14:52,760 --> 00:14:56,940
But this was great when I was trying to come up with this component quickly because I could

256
00:14:56,940 --> 00:15:01,240
just focus on writing the core functionality of my module without worrying about the bells

257
00:15:01,300 --> 00:15:05,340
and whistles around alarming because it really just came for free.

258
00:15:05,340 --> 00:15:08,860
But it's not just sufficient for us to be able to write our code quickly.

259
00:15:08,860 --> 00:15:13,460
It's also important that we're able to debug this code quickly, especially when we're interfacing

260
00:15:13,460 --> 00:15:16,700
with a legacy component.

261
00:15:16,700 --> 00:15:20,780
With that, I'd like to walk you through an example of a bug that we faced when trying

262
00:15:20,780 --> 00:15:26,940
to implement Airflow and how the PDB as a superpower of PyHero really came in to help

263
00:15:26,940 --> 00:15:28,140
and save us.

264
00:15:28,140 --> 00:15:31,480
So here we have a screen, the login screen for Airflow.

265
00:15:31,480 --> 00:15:33,800
And as you can see, there's an error message at the top.

266
00:15:33,800 --> 00:15:37,560
So the way that we generated this was we tried to sign in using SSO, which redirects us to

267
00:15:37,560 --> 00:15:39,160
the SSO page.

268
00:15:39,160 --> 00:15:41,640
And we log in and it redirects us back here.

269
00:15:41,640 --> 00:15:46,960
Now we knew the credentials were correct, so that wasn't the issue at hand.

270
00:15:46,960 --> 00:15:51,120
But we didn't really have much other information on this page about what's causing this.

271
00:15:51,120 --> 00:15:56,600
Now the first place anyone really starts to debug is by checking the logs.

272
00:15:56,600 --> 00:16:00,820
And when we did check the logs, this is the only message that really came in with any

273
00:16:00,820 --> 00:16:01,820
relevance.

274
00:16:01,820 --> 00:16:03,880
It was this error message right here.

275
00:16:03,880 --> 00:16:06,040
Now we see that there's some issue with OAuth.

276
00:16:06,040 --> 00:16:09,360
We see something about an invalid audience, but it's still fairly abstract.

277
00:16:09,360 --> 00:16:10,940
It doesn't give us much information.

278
00:16:10,940 --> 00:16:15,520
However, we do know exactly what line and what file this error is being raised.

279
00:16:15,520 --> 00:16:19,360
So with PDB, let's step into that file and try to figure out what's going on.

280
00:16:19,360 --> 00:16:23,700
So we went to that file and these are the lines that the error was being thrown from,

281
00:16:23,700 --> 00:16:27,580
as you can see the log message right there on that fourth line there.

282
00:16:27,580 --> 00:16:30,260
And we put a breakpoint.

283
00:16:30,260 --> 00:16:35,100
Now with this breakpoint, we are able to halt execution of the program while trying to log

284
00:16:35,100 --> 00:16:37,180
in on the web server itself.

285
00:16:37,180 --> 00:16:40,780
And we pause execution and from there we're able to observe the variables, including these

286
00:16:40,780 --> 00:16:43,880
abstract variables like app builder or .sm.

287
00:16:43,880 --> 00:16:49,380
Now what we realized by observing these variables live is that these were actually instances

288
00:16:49,380 --> 00:16:53,460
of classes that we had defined in the web server config.py.

289
00:16:53,460 --> 00:16:58,140
So let's dig into this rabbit hole a bit further and see where it leads us.

290
00:16:58,140 --> 00:17:02,020
After that, we put another breakpoint in web server config.py and while the rest of the

291
00:17:02,020 --> 00:17:05,620
code isn't too important, we step through line by line to get to this line.

292
00:17:05,620 --> 00:17:07,460
This is where the error was really being raised.

293
00:17:07,460 --> 00:17:11,300
And so that invalid audience makes a bit more sense as you can see the issue is in that

294
00:17:11,300 --> 00:17:13,380
key error flow right there.

295
00:17:13,380 --> 00:17:18,100
Now the great thing about PDB is that while the execution has been paused, you can retry

296
00:17:18,100 --> 00:17:21,480
code lines of code with that environment.

297
00:17:21,520 --> 00:17:25,720
And so you could retry other keys until you find the correct one.

298
00:17:25,720 --> 00:17:28,920
Needless to say, that is what we did and it helped us solve this issue.

299
00:17:28,920 --> 00:17:32,480
An issue that was rather abstract to begin with could be solved in a matter of a couple

300
00:17:32,480 --> 00:17:34,600
of minutes using PDB.

301
00:17:34,600 --> 00:17:39,120
So this really goes to highlight some of the advantages of PDB and first and foremost is

302
00:17:39,120 --> 00:17:44,280
that you don't have to rebuild your software every time you put in a new breakpoint.

303
00:17:44,280 --> 00:17:45,880
You simply have to restart.

304
00:17:45,880 --> 00:17:52,760
And so that's one of the great powers of Python is that it's much quicker to put in a breakpoint

305
00:17:52,760 --> 00:17:55,000
and to then start debugging.

306
00:17:55,000 --> 00:17:58,920
There's also command line interface which allows for remote debugging.

307
00:17:58,920 --> 00:18:03,760
The issue that we showed earlier was debugged on a server.

308
00:18:03,760 --> 00:18:08,060
And then it also comes default with the Python language so you don't have to install it separately

309
00:18:08,060 --> 00:18:09,200
or anything like that.

310
00:18:09,200 --> 00:18:10,720
There's two ways that you can invoke it.

311
00:18:10,720 --> 00:18:14,440
The first one we already showed you in our example is just by adding it into the script

312
00:18:14,920 --> 00:18:18,800
directly and the second one is calling it via the command line which is very similar

313
00:18:18,800 --> 00:18:22,960
to other debuggers you might have encountered in the past.

314
00:18:22,960 --> 00:18:28,560
Another aspect of Python that really enables rapid development is how easy it is to customize

315
00:18:28,560 --> 00:18:29,560
it.

316
00:18:29,560 --> 00:18:33,240
And so I'm going to walk you through one specific use case that we had with Airflow to really

317
00:18:33,240 --> 00:18:34,640
highlight this point.

318
00:18:34,640 --> 00:18:38,920
And so by default Airflow uses SMTP for email.

319
00:18:38,920 --> 00:18:44,200
And as you can see in the email.py file it's using some SMTP lib which under the hood uses

320
00:18:44,960 --> 00:18:45,960
SMTP.

321
00:18:45,960 --> 00:18:48,720
Now SMTP wasn't ideal for our use case.

322
00:18:48,720 --> 00:18:53,120
It's not important why but there is an alternative and that's what we're going to try to implement

323
00:18:53,120 --> 00:18:55,960
as a plugin in Airflow.

324
00:18:55,960 --> 00:19:00,760
So what we did was we copied this email.py file and we modified it to use the mailx command

325
00:19:00,760 --> 00:19:05,720
which is something we already had code for written somewhere else in our tech stack.

326
00:19:05,720 --> 00:19:09,560
And all it required on Airflow side was a simple configuration modification as you can

327
00:19:09,560 --> 00:19:10,560
see here.

328
00:19:10,560 --> 00:19:11,560
So we're going to use the same configuration as we did with Airflow.

329
00:19:11,560 --> 00:19:12,560
We're going to use the same configuration as we did with Airflow.

330
00:19:12,560 --> 00:19:17,360
And this is actually a file path to the actual plugin that we've defined.

331
00:19:17,360 --> 00:19:21,600
And with Python since you can use dynamic importing of libraries Airflow doesn't need

332
00:19:21,600 --> 00:19:25,800
anything else than this configuration change as well as this file being copied into the

333
00:19:25,800 --> 00:19:30,160
correct directory from which it's able to pick it up and on restart seamlessly integrate

334
00:19:30,160 --> 00:19:32,680
and use it for emails going forward.

335
00:19:32,680 --> 00:19:35,160
Now that's the function definition that you see there.

336
00:19:35,160 --> 00:19:38,760
This was simply copied from the other email.py file.

337
00:19:38,760 --> 00:19:40,480
But that was essentially it.

338
00:19:40,480 --> 00:19:44,560
And that really goes to highlight how easy it is to integrate your own code into Python

339
00:19:44,560 --> 00:19:45,560
code bases.

340
00:19:45,560 --> 00:19:51,120
And that's why another major advantage of a pure Python system like Airflow for open

341
00:19:51,120 --> 00:19:52,120
source migrations.

342
00:19:52,120 --> 00:19:53,120
Great.

343
00:19:53,120 --> 00:19:56,580
So now we've spoke to you about some of the things about Python that make it really easy

344
00:19:56,580 --> 00:19:59,080
for rapid development.

345
00:19:59,080 --> 00:20:05,240
But let's go on to how Python makes it easy to create production quality software.

346
00:20:05,240 --> 00:20:08,880
In the case of any open source system you don't really know the extent to which it's

347
00:20:08,960 --> 00:20:11,440
valuable to you until you actually start using it.

348
00:20:11,440 --> 00:20:14,400
So the best way to actually learn about an open source system is to use it.

349
00:20:14,400 --> 00:20:18,320
And to do that you have to be able to deploy it into your production system quick.

350
00:20:18,320 --> 00:20:22,640
In our case we were able to deploy Airflow into our production system in an isolated

351
00:20:22,640 --> 00:20:25,120
manner using virtual environments.

352
00:20:25,120 --> 00:20:29,080
And therefore we didn't have to modify any configurations or touch any other part of

353
00:20:29,080 --> 00:20:30,560
our production cluster.

354
00:20:30,560 --> 00:20:35,280
All you really need is one isolated file path where all your dependencies even the language

355
00:20:35,280 --> 00:20:37,520
itself are going to be stored.

356
00:20:37,520 --> 00:20:40,960
And tomorrow if you don't want to use the system anymore you simply delete that directory

357
00:20:40,960 --> 00:20:43,840
and it's gone without leaving a trace.

358
00:20:43,840 --> 00:20:48,360
Now in the case of Airflow it's fairly simple since the only overhead was really creating

359
00:20:48,360 --> 00:20:52,500
this requirements file which as you can see doesn't have too much extra.

360
00:20:52,500 --> 00:20:58,360
After that you create an isolated build and it runs on your production cluster.

361
00:20:58,360 --> 00:20:59,680
And that's it.

362
00:20:59,680 --> 00:21:04,440
Another thing that I'd like to highlight is PyTest is what we use for creating unit tests.

363
00:21:04,480 --> 00:21:07,480
And so in production environment you want to make sure that code changes don't break

364
00:21:07,480 --> 00:21:08,480
it.

365
00:21:08,480 --> 00:21:12,920
And so before any release we're able to use PyTest to determine that previously working

366
00:21:12,920 --> 00:21:15,200
behavior hasn't been affected.

367
00:21:15,200 --> 00:21:16,460
Great.

368
00:21:16,460 --> 00:21:21,360
So now we have a half new system and an half old system and we have Python stitching them

369
00:21:21,360 --> 00:21:22,800
together.

370
00:21:22,800 --> 00:21:26,140
But we still want to make sure that this half new system hasn't broken anything.

371
00:21:26,140 --> 00:21:29,720
So we want to go about we want to figure out how we can reconcile it.

372
00:21:29,720 --> 00:21:32,440
With that I'd like to hand it back to my colleague.

373
00:21:32,440 --> 00:21:33,600
Okay great.

374
00:21:33,600 --> 00:21:37,900
So now we have like Sagar said a half old and half new system up and running.

375
00:21:37,900 --> 00:21:39,860
It's churning out some data.

376
00:21:39,860 --> 00:21:44,640
But how do we make sure that our old system and our new system are really doing the same

377
00:21:44,640 --> 00:21:46,120
thing.

378
00:21:46,120 --> 00:21:50,400
One level of a sanity check could be to just check what processes are kicked off by the

379
00:21:50,400 --> 00:21:54,400
old system and the new system and then compare it and see if they tie out.

380
00:21:54,400 --> 00:21:59,520
But this does leave room for error because if we don't capture a failure correctly or

381
00:21:59,720 --> 00:22:04,160
stall process correctly in the new system we won't ever catch it.

382
00:22:04,160 --> 00:22:07,720
And that's when you really have to ask the question what is really the output of your

383
00:22:07,720 --> 00:22:08,720
system.

384
00:22:08,720 --> 00:22:14,320
And like we discussed earlier the output of our system was data and it was columnar data

385
00:22:14,320 --> 00:22:15,900
to be more specific.

386
00:22:15,900 --> 00:22:20,360
So the best way for us to ensure that our migration has gone through correctly and that

387
00:22:20,360 --> 00:22:25,120
our old system and new system are doing the same thing is to compare the data that was

388
00:22:25,120 --> 00:22:29,560
generated from the old system and the new system and make sure that they tie out.

389
00:22:29,560 --> 00:22:34,220
But we're again looking at the scale of millions of data points here and it can be very intensive

390
00:22:34,220 --> 00:22:38,760
to make sure that every one of these million data points tie out correctly.

391
00:22:38,760 --> 00:22:43,160
But to help with that we have a data reconciliation framework that we use within our team which

392
00:22:43,160 --> 00:22:45,000
is built on top of pandas.

393
00:22:45,000 --> 00:22:49,060
And if you want to learn more about that definitely stop by our booth we'd be happy to chat.

394
00:22:49,060 --> 00:22:55,220
So we used that tool to compare the data that was being produced by our old system

395
00:22:55,220 --> 00:22:59,300
and our new system to ensure that there were no differences in terms of the output that

396
00:22:59,300 --> 00:23:01,660
was being generated.

397
00:23:01,660 --> 00:23:06,300
So quickly wrapping up on everything that we discussed so far let's do a quick recap.

398
00:23:06,300 --> 00:23:11,440
So we started with this complex orchestration framework that we wanted to migrate from.

399
00:23:11,440 --> 00:23:17,180
We identified keywords and then identified our three options that we could potentially

400
00:23:17,620 --> 00:23:19,900
integrate with three open source options.

401
00:23:19,900 --> 00:23:26,100
We brainstormed came up with an evaluation criteria based on which airflow one.

402
00:23:26,100 --> 00:23:31,140
And then we broke down our existing architecture into independent but connected components

403
00:23:31,140 --> 00:23:33,060
to start integrating with airflow.

404
00:23:33,060 --> 00:23:38,620
And instead of integrating everything big bang we first replaced the easily replaceable

405
00:23:38,620 --> 00:23:42,200
components which in our case were the scheduler and the orchestration engine.

406
00:23:42,200 --> 00:23:46,980
But we still needed a way to connect airflow to our job management system and that's where

407
00:23:46,980 --> 00:23:48,980
by hero stepped in.

408
00:23:48,980 --> 00:23:54,060
And while integrating with existing code with our existing code base we had two options.

409
00:23:54,060 --> 00:23:58,420
We could either interface directly with the code components and use them within our Python

410
00:23:58,420 --> 00:24:02,340
module or we could just invoke them as sub processes.

411
00:24:02,340 --> 00:24:07,700
And we went with the second approach and then added some test cases like Sagar said using

412
00:24:07,700 --> 00:24:12,960
pi test packaged it with a virtual environment and then came up with this half old half new

413
00:24:12,960 --> 00:24:15,700
system that was churning out some data.

414
00:24:15,740 --> 00:24:19,100
But at this point it was important for us to ensure that the data that we were churning

415
00:24:19,100 --> 00:24:20,980
out was in fact correct.

416
00:24:20,980 --> 00:24:27,340
And we used a data reconciliation framework built on top of pandas to ensure that correctness.

417
00:24:27,340 --> 00:24:32,460
OK so in conclusion open source is a great option for software migrations.

418
00:24:32,460 --> 00:24:35,680
But remember integration doesn't have to be a big bang.

419
00:24:35,680 --> 00:24:37,900
Small steps are usually better.

420
00:24:37,900 --> 00:24:42,860
Now once you have integrated your system don't forget you want to customize enhance and extend

421
00:24:42,860 --> 00:24:44,100
it.

422
00:24:44,140 --> 00:24:48,700
And once once all of that is said and done don't forget to contribute and give back to

423
00:24:48,700 --> 00:24:50,540
the community.

424
00:24:50,540 --> 00:24:57,100
On that note Bloomberg has recently open source I think as early as two days ago a new memory

425
00:24:57,100 --> 00:24:59,620
profiler for Python on Linux.

426
00:24:59,620 --> 00:25:03,780
And this can also help you debug the memory usage of your C extensions as well.

427
00:25:03,780 --> 00:25:10,340
So if you decide to ever integrate with your code base by exposing your C libraries by

428
00:25:10,340 --> 00:25:13,100
a Python interfaces this could even help with that.

429
00:25:14,780 --> 00:25:20,260
We'd like to thank everyone here for helping us with our talk and helping with all the

430
00:25:20,260 --> 00:25:22,540
work that went into this presentation.

431
00:25:22,540 --> 00:25:26,860
A special shout out to our manager here who is with us here today.

432
00:25:26,860 --> 00:25:30,580
These are their references and thank you so much for attending our talk.

433
00:25:30,580 --> 00:25:33,340
We are hiring and please do stop by our booth later.

434
00:25:33,340 --> 00:25:34,340
Thank you.

