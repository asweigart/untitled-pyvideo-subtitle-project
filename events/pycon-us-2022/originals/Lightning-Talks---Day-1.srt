1
00:00:00,000 --> 00:00:02,000
And we'll start with the

2
00:00:03,020 --> 00:00:05,020
first speaker.

3
00:00:07,060 --> 00:00:09,060
Welcome to lightning talks.

4
00:00:12,420 --> 00:00:14,420
Real quick, we're going to go over how lightning talks work.

5
00:00:15,220 --> 00:00:17,220
We're going to have a series of speakers.

6
00:00:18,400 --> 00:00:20,300
They're each going to talk for five minutes or less. No more

7
00:00:20,300 --> 00:00:22,300
than five minutes.

8
00:00:23,620 --> 00:00:25,620
They're going to talk on any topic that they suggested.

9
00:00:27,340 --> 00:00:28,800
And real quick, this is what we're going to do as they get

10
00:00:28,860 --> 00:00:30,860
started.

11
00:00:32,540 --> 00:00:34,540
We're going to have a little one-finger clap.

12
00:00:36,560 --> 00:00:38,560
Let's practice everyone one finger clap quietly.

13
00:00:39,620 --> 00:00:41,620
You can barely hear it.

14
00:00:42,920 --> 00:00:44,920
And then as they get closer, we'll do a two-finger clap.

15
00:00:46,200 --> 00:00:48,200
Make a little more noise and they'll say, I have to wrap up.

16
00:00:49,320 --> 00:00:51,320
And then once they get to five, we'll do a full-on applause.

17
00:00:52,620 --> 00:00:54,620
Thank you, get off the stage. Next speaker, please.

18
00:00:56,720 --> 00:00:58,720
All right. Cool.

19
00:00:59,800 --> 00:01:01,800
Thank you, Justin.

20
00:01:04,000 --> 00:01:06,800
Okay. Good life. Hi, I'm Samir. I'm the head of privacy at

21
00:01:06,800 --> 00:01:09,800
Devron. Let's take a moment to think about what is data

22
00:01:09,800 --> 00:01:11,800
science without data?

23
00:01:13,100 --> 00:01:15,100
Can we actually do anything when we don't have data?

24
00:01:16,300 --> 00:01:18,300
The answer is generally speaking, no.

25
00:01:19,400 --> 00:01:21,400
That's the start of data science.

26
00:01:22,500 --> 00:01:24,500
Then what does data science without data mean?

27
00:01:25,600 --> 00:01:27,600
Does it mean just science?

28
00:01:29,100 --> 00:01:31,100
Does it mean data privacy?

29
00:01:33,120 --> 00:01:35,120
Does it mean data privacy?

30
00:01:36,820 --> 00:01:38,820
What does data privacy mean?

31
00:01:40,020 --> 00:01:42,020
If you have data access problems because of the emerging data

32
00:01:43,120 --> 00:01:45,120
privacy regulations and laws or if your data is split into

33
00:01:46,240 --> 00:01:48,240
multiple different trust domains or if you would like to retain

34
00:01:49,360 --> 00:01:51,360
ownership of your data but still like to make use of this data,

35
00:01:52,480 --> 00:01:54,480
you would be interested in what we're doing at Devron.

36
00:01:56,280 --> 00:01:58,280
If you're interested in knowing more what we do, please come

37
00:01:59,120 --> 00:02:01,120
and get it.

38
00:02:02,680 --> 00:02:04,680
I'll buy them archives, 말이- маски,

39
00:02:05,680 --> 00:02:07,680
what Kelly said like we're interested in you.

40
00:02:08,880 --> 00:02:10,880
Thank you.

41
00:02:13,200 --> 00:02:26,280
Simpson if you're interested in

42
00:02:26,280 --> 00:02:28,200
Steam today, I read the chat.

43
00:02:28,200 --> 00:02:29,960
Yes, absolutely.

44
00:02:29,960 --> 00:02:30,800
Cultural shock.

45
00:02:30,800 --> 00:02:33,960
I'm already shocked because this room is so big.

46
00:02:33,960 --> 00:02:37,720
It's my first time physically attending PyCon US,

47
00:02:37,720 --> 00:02:42,520
which is, so, spoiler, I was lost in the venue.

48
00:02:42,520 --> 00:02:44,960
The first day I went to lunch and I got lost.

49
00:02:46,360 --> 00:02:47,440
So I'm check.

50
00:02:47,440 --> 00:02:49,840
Hit me up on Twitter if you want to.

51
00:02:49,840 --> 00:02:54,840
I am living in London, UK, so this is what it,

52
00:02:54,840 --> 00:02:56,120
well, it's not what it looks like,

53
00:02:56,120 --> 00:02:58,680
but it's what people think it looks like.

54
00:02:58,680 --> 00:03:02,520
And also, I, so my company is based in Dublin,

55
00:03:02,520 --> 00:03:04,280
so I visit Dublin quite a lot as well,

56
00:03:04,280 --> 00:03:08,520
so I also have some tip about Dublin for you later.

57
00:03:08,520 --> 00:03:13,520
So what I think here in the US is everything is so big.

58
00:03:13,600 --> 00:03:15,920
It's very big, like this room is so big.

59
00:03:15,920 --> 00:03:17,640
The venue is so big.

60
00:03:17,640 --> 00:03:18,960
The rows are so big.

61
00:03:18,960 --> 00:03:20,880
When I cross the row, I always have to run

62
00:03:20,880 --> 00:03:22,760
because I feel like I don't have enough time

63
00:03:22,760 --> 00:03:23,720
to cross the row.

64
00:03:23,720 --> 00:03:24,720
It's so big.

65
00:03:25,720 --> 00:03:27,360
The bed is so big in my hotel room.

66
00:03:27,360 --> 00:03:29,320
This is my hotel room, by the way.

67
00:03:29,320 --> 00:03:31,600
You can see that that's my teddy bear there.

68
00:03:31,600 --> 00:03:33,200
It's very small.

69
00:03:33,200 --> 00:03:37,840
So, yeah, but the teddy bear here are so big as well.

70
00:03:37,840 --> 00:03:41,560
So, yeah, and anybody see this in the airport?

71
00:03:41,560 --> 00:03:44,560
Like, that really shocked me, right?

72
00:03:44,560 --> 00:03:46,600
Wow, the teddy bear is so big.

73
00:03:46,600 --> 00:03:50,040
Yeah, like, it really shocked me.

74
00:03:50,040 --> 00:03:53,400
Another thing, hotel rooms, they have no kettles.

75
00:03:53,560 --> 00:03:57,120
So, you know, well, I would say that I'm kind of British.

76
00:03:57,120 --> 00:03:58,800
I live in UK for a while, you know,

77
00:03:58,800 --> 00:04:01,080
and then, like, we love tea.

78
00:04:01,080 --> 00:04:02,760
We need to have a cup of tea.

79
00:04:02,760 --> 00:04:04,920
So there's no tea.

80
00:04:04,920 --> 00:04:07,320
No, there's tea in the hotel room, but there's no kettle.

81
00:04:07,320 --> 00:04:09,280
I was like, but I was prepared

82
00:04:09,280 --> 00:04:11,320
because I was told that there's no kettle here,

83
00:04:11,320 --> 00:04:13,800
so I bring my own kettle.

84
00:04:13,800 --> 00:04:15,080
I forgot to take a picture of it,

85
00:04:15,080 --> 00:04:17,480
but I do have a travel kettle that can collapse,

86
00:04:17,480 --> 00:04:18,800
which is very good.

87
00:04:18,800 --> 00:04:21,280
For any of those of you who would love to buy one,

88
00:04:21,320 --> 00:04:23,960
talk to me, I can give you a tip.

89
00:04:23,960 --> 00:04:28,720
But anyway, so, also, I was scared.

90
00:04:28,720 --> 00:04:32,360
Luckily, in this city, you don't necessarily need to drive

91
00:04:32,360 --> 00:04:34,600
because there's a tram, there are buses,

92
00:04:34,600 --> 00:04:36,920
but I was so scared because before I came here,

93
00:04:36,920 --> 00:04:39,000
I was like, oh my God, do I have to drive?

94
00:04:39,000 --> 00:04:40,800
Because I'm horrible at driving.

95
00:04:40,800 --> 00:04:42,800
I only drive maybe once or twice in my life.

96
00:04:42,800 --> 00:04:46,520
I'm a city girl, so am I super scared?

97
00:04:46,520 --> 00:04:50,520
So also, there's something that's called Ice Cream Sprint

98
00:04:50,560 --> 00:04:53,200
that I do in all the PyCons in Europe

99
00:04:53,200 --> 00:04:56,040
that will run for ice cream during lunchtime.

100
00:04:56,040 --> 00:04:57,560
So I was worried that it would become

101
00:04:57,560 --> 00:05:01,280
an ice cream speeding ticket instead of ice cream sprint.

102
00:05:01,280 --> 00:05:03,920
So yeah, but luckily, it didn't happen.

103
00:05:05,000 --> 00:05:09,160
So I was shocked, but I don't want you to be shocked

104
00:05:09,160 --> 00:05:12,200
in case you are going to these following conferences,

105
00:05:12,200 --> 00:05:15,520
PyTator London in June, EuroPython in July,

106
00:05:15,520 --> 00:05:17,600
and PyCon UK in September.

107
00:05:17,600 --> 00:05:18,840
I really want to see you there.

108
00:05:18,880 --> 00:05:23,000
I really love seeing people coming to my country,

109
00:05:23,000 --> 00:05:26,360
yeah, my place, so that would be great.

110
00:05:26,360 --> 00:05:28,120
So I want to give you some tips

111
00:05:28,120 --> 00:05:29,920
so you won't have cultural shock like me.

112
00:05:29,920 --> 00:05:33,200
So the weather, it's gotta be a bit wet, you know,

113
00:05:33,200 --> 00:05:35,120
London, a bit wet.

114
00:05:35,120 --> 00:05:38,840
Bring some clothes that is waterproof or water-resistant.

115
00:05:38,840 --> 00:05:40,720
Also getting around, you don't need to drive, don't worry.

116
00:05:40,720 --> 00:05:42,840
You can take trains, you can take buses.

117
00:05:42,840 --> 00:05:44,480
They're very convenient.

118
00:05:44,480 --> 00:05:47,720
The underground train in London is called Tube,

119
00:05:47,720 --> 00:05:50,480
so if anybody telling you to take the Tube,

120
00:05:50,480 --> 00:05:54,960
that's what you mean, it's the underground transport system.

121
00:05:54,960 --> 00:05:59,440
So eating out, definitely try fish and chips.

122
00:05:59,440 --> 00:06:00,720
There's something called Sunday Roast.

123
00:06:00,720 --> 00:06:02,800
They're only available on Sunday in pubs,

124
00:06:02,800 --> 00:06:05,720
but usually they are yummy, so try that.

125
00:06:05,720 --> 00:06:08,960
Also, tips are optional in Europe,

126
00:06:08,960 --> 00:06:10,480
so don't worry about the tips.

127
00:06:10,480 --> 00:06:12,960
If you don't want the tips, that's fine.

128
00:06:12,960 --> 00:06:17,640
Also, show, show, the Brits, they love drink.

129
00:06:18,560 --> 00:06:19,480
They could be a bit shy in the conference,

130
00:06:19,480 --> 00:06:21,480
but after a few drinks in the pub,

131
00:06:21,480 --> 00:06:22,720
they can talk anything with you.

132
00:06:22,720 --> 00:06:24,480
They can introduce their family to you

133
00:06:24,480 --> 00:06:25,760
or something like that.

134
00:06:25,760 --> 00:06:29,440
Also, Guinness, if you go to Ireland, go to Dublin,

135
00:06:29,440 --> 00:06:31,520
Guinness is a must drink.

136
00:06:31,520 --> 00:06:33,480
It tastes different there, so trust me.

137
00:06:34,480 --> 00:06:36,240
Accommodation could be expensive,

138
00:06:36,240 --> 00:06:38,840
but look for something like Airbnb,

139
00:06:38,840 --> 00:06:40,880
but be careful of the scammers.

140
00:06:40,880 --> 00:06:43,640
Also, student accommodation could be an option

141
00:06:43,640 --> 00:06:46,000
because summer, nobody's gotta be in the student

142
00:06:46,040 --> 00:06:49,320
accommodation, or I have a small room,

143
00:06:50,160 --> 00:06:53,720
so be my friend, that I could maybe host you.

144
00:06:53,720 --> 00:06:54,960
I don't know.

145
00:06:54,960 --> 00:06:58,680
So people are there, just very nice, like people here,

146
00:06:58,680 --> 00:07:00,320
so don't worry about it.

147
00:07:00,320 --> 00:07:02,920
Come to visit me.

148
00:07:02,920 --> 00:07:07,280
Come to PyData London in June, Europe Python in July,

149
00:07:07,280 --> 00:07:09,360
or PyCon UK in September.

150
00:07:09,360 --> 00:07:12,320
So that's it, thank you so much.

151
00:07:12,760 --> 00:07:13,600
Thank you.

152
00:07:13,600 --> 00:07:14,440
Thank you.

153
00:07:14,440 --> 00:07:15,280
Thank you.

154
00:07:15,280 --> 00:07:16,120
Thank you.

155
00:07:16,120 --> 00:07:16,960
Thank you.

156
00:07:16,960 --> 00:07:17,800
Thank you.

157
00:07:17,800 --> 00:07:18,640
Thank you.

158
00:07:18,640 --> 00:07:19,480
Thank you.

159
00:07:19,480 --> 00:07:21,440
Thank you so much, Chuk.

160
00:07:21,440 --> 00:07:24,520
Up next is a gentleman who I don't think many of us

161
00:07:24,520 --> 00:07:27,720
need an introduction for, Lukas.

162
00:07:27,720 --> 00:07:28,720
Hi there.

163
00:07:28,720 --> 00:07:31,360
We've seen each other already in the morning,

164
00:07:31,360 --> 00:07:34,280
so I'm just gonna quickly make you a typing expert.

165
00:07:34,280 --> 00:07:37,120
This is a concept that many of us struggle with

166
00:07:37,120 --> 00:07:38,800
because we don't have nice examples,

167
00:07:38,800 --> 00:07:41,960
and the property of nice examples is obviously

168
00:07:42,000 --> 00:07:44,680
to have cutesy animals explaining them.

169
00:07:44,680 --> 00:07:46,840
With that, everything is easier.

170
00:07:46,840 --> 00:07:49,720
So imagine some abstract animal,

171
00:07:50,680 --> 00:07:54,480
and we have some subtypes of that abstract animal,

172
00:07:54,480 --> 00:07:57,400
namely a dog, a cow, a cat, this sort of thing.

173
00:07:57,400 --> 00:08:01,560
So covariance, contravariance, and invariance

174
00:08:01,560 --> 00:08:06,080
are concepts that explain us whether we can replace

175
00:08:06,080 --> 00:08:07,800
one of those with another,

176
00:08:07,800 --> 00:08:09,920
and what will happen in that case.

177
00:08:09,920 --> 00:08:14,920
So covariance, the most kind of natural intuitive of those,

178
00:08:15,080 --> 00:08:19,320
means that whenever we have an animal accepted,

179
00:08:19,320 --> 00:08:22,320
we could put cow and it should work.

180
00:08:22,320 --> 00:08:25,880
Like one example in Python is that if you have a function

181
00:08:25,880 --> 00:08:28,720
that prints an animal, if you have a function

182
00:08:28,720 --> 00:08:32,560
that prints many animals by calling print animal,

183
00:08:32,560 --> 00:08:34,760
what you can do is you can define a function

184
00:08:34,760 --> 00:08:39,160
called print cats that just uses print animals

185
00:08:39,160 --> 00:08:41,320
and everything works fine.

186
00:08:41,320 --> 00:08:44,160
So this is in fact something that does work.

187
00:08:44,160 --> 00:08:45,120
You can do that.

188
00:08:45,120 --> 00:08:48,360
So the property of the covariance here

189
00:08:48,360 --> 00:08:50,800
happens in the sequence of animal

190
00:08:50,800 --> 00:08:54,480
that can be replaced with sequence of cats.

191
00:08:54,480 --> 00:08:56,920
The opposite happens for contravariance,

192
00:08:56,920 --> 00:08:58,560
which means in some context,

193
00:08:58,560 --> 00:09:01,960
you can replace a cow with a generic animal.

194
00:09:01,960 --> 00:09:03,120
How does that work?

195
00:09:03,120 --> 00:09:05,360
Well, this is the weirdest of the examples,

196
00:09:05,360 --> 00:09:08,960
but in fact, it deals with callables.

197
00:09:08,960 --> 00:09:12,320
So if you have some print with implementation

198
00:09:12,320 --> 00:09:15,040
where we want to print a cat,

199
00:09:15,040 --> 00:09:17,400
I don't know, as JSON or whatever else,

200
00:09:17,400 --> 00:09:19,840
and we wanna provide an implementation for it,

201
00:09:19,840 --> 00:09:22,560
so we by default want prints cat

202
00:09:22,560 --> 00:09:25,840
because we know that this is something that can print cats.

203
00:09:26,720 --> 00:09:31,680
Can we put a function that can print any animal there?

204
00:09:31,680 --> 00:09:34,880
Well, we can because it can print any animal.

205
00:09:34,880 --> 00:09:37,800
So this relationship between those callables

206
00:09:37,800 --> 00:09:40,800
prints cat and prints animal is reverse

207
00:09:40,800 --> 00:09:43,680
to what you would think about with inheritance

208
00:09:43,680 --> 00:09:48,360
because you can in fact replace the more concrete thing

209
00:09:48,360 --> 00:09:50,000
with a more generic one.

210
00:09:50,000 --> 00:09:53,080
And finally, we have invariance where you cannot

211
00:09:53,080 --> 00:09:56,480
replace the cow with a generic animal and vice versa.

212
00:09:56,480 --> 00:09:58,120
It's just impossible.

213
00:09:58,120 --> 00:10:01,240
And in fact, this is something that very, very many users

214
00:10:01,240 --> 00:10:05,060
of typing fall into faster or later

215
00:10:05,060 --> 00:10:06,840
because of an example like this.

216
00:10:06,840 --> 00:10:10,300
If you have a function that allows us to add animals

217
00:10:10,300 --> 00:10:14,700
to an existing list and we have a function that adds a cat,

218
00:10:14,700 --> 00:10:17,840
we would think that we should be able

219
00:10:17,840 --> 00:10:20,200
to just use this add animal function

220
00:10:20,200 --> 00:10:23,520
in the implementation of add cat, right?

221
00:10:23,520 --> 00:10:28,520
Because it's natural, it doesn't do really much weirdness.

222
00:10:29,600 --> 00:10:30,940
It should work.

223
00:10:30,940 --> 00:10:33,460
But it doesn't because in general,

224
00:10:33,460 --> 00:10:37,380
if in the add animal function, we did something funky,

225
00:10:37,380 --> 00:10:40,580
this is just an example, but the point being,

226
00:10:40,580 --> 00:10:43,900
we would add an animal which is not a cat,

227
00:10:43,900 --> 00:10:48,900
then the function below add cat that takes a list of cats

228
00:10:50,020 --> 00:10:53,860
would suddenly change the type of those cats

229
00:10:53,860 --> 00:10:57,220
into cats plus some other animal.

230
00:10:57,220 --> 00:10:58,800
And what type is that?

231
00:10:58,800 --> 00:11:00,980
Well, we don't really know.

232
00:11:00,980 --> 00:11:04,460
This is something that you might break in Python

233
00:11:04,460 --> 00:11:07,500
all the time because containers don't really limit you

234
00:11:07,500 --> 00:11:11,220
from putting incompatible types next to each other.

235
00:11:11,220 --> 00:11:15,940
But with non-py types or with other programming languages,

236
00:11:15,940 --> 00:11:18,220
the memory layout between different types

237
00:11:18,220 --> 00:11:19,380
might be different.

238
00:11:19,380 --> 00:11:21,960
So this becomes more important then.

239
00:11:22,860 --> 00:11:24,340
So in this particular case,

240
00:11:24,340 --> 00:11:26,860
that would not be possible to be done.

241
00:11:26,860 --> 00:11:29,020
And now you understand covariance,

242
00:11:29,020 --> 00:11:30,920
contravariance, and invariance.

243
00:11:30,920 --> 00:11:32,400
And cutesy animals, thank you.

244
00:11:32,400 --> 00:11:35,400
пАдăц, и падъц

245
00:11:38,740 --> 00:11:40,360
Awesome, thanks, Lukas.

246
00:11:40,360 --> 00:11:41,900
All right, next we have Seth,

247
00:11:41,900 --> 00:11:45,040
who told me earlier he'd never met another Python-ista

248
00:11:45,040 --> 00:11:46,300
until he came to this conference.

249
00:11:46,300 --> 00:11:47,320
I met all the Python-istas.

250
00:11:47,320 --> 00:11:49,320
So welcome, Seth.

251
00:11:49,320 --> 00:11:50,220
Seth's gonna give us a talk

252
00:11:50,220 --> 00:11:52,160
on the future of trust stores in Python.

253
00:11:52,160 --> 00:11:53,720
Give it away for Seth.

254
00:11:53,720 --> 00:12:08,760
So, I'm Seth Larson, I'm maintainer of Uralib 3 requests and some other packages, and a

255
00:12:08,760 --> 00:12:13,560
lot of the work that's done here is also done by David Glick, who's in the audience.

256
00:12:13,560 --> 00:12:16,320
Okay, show of hands.

257
00:12:16,320 --> 00:12:17,320
Have you seen this error?

258
00:12:17,320 --> 00:12:19,060
I've seen this error so many times.

259
00:12:19,060 --> 00:12:23,200
If you've worked at a corporate proxy environment, you've seen this error.

260
00:12:23,200 --> 00:12:26,240
Usually you see this when there's no root certificate and you can't verify your cert

261
00:12:26,240 --> 00:12:28,280
chain and you're trying to use TLS.

262
00:12:28,280 --> 00:12:32,320
Okay, so first off, what is a trust store?

263
00:12:32,320 --> 00:12:36,760
Trust store is a collection of certificates that your system uses when you're doing a

264
00:12:36,760 --> 00:12:37,760
TLS handshake.

265
00:12:37,760 --> 00:12:41,560
The server gives you certificates back, you verify them against that trust store.

266
00:12:41,560 --> 00:12:47,140
And so in Python, because we're strongly tied to OpenSSL with our SSL APIs, usually takes

267
00:12:47,140 --> 00:12:51,240
the form of a file or a directory of certs.

268
00:12:51,240 --> 00:12:54,520
So today in Python, trust stores look kind of like this.

269
00:12:54,520 --> 00:13:00,480
Linux distros, they ship things that are compatible for OpenSSL, but macOS and Windows don't do

270
00:13:00,480 --> 00:13:04,060
that and Python is strongly tied to OpenSSL.

271
00:13:04,060 --> 00:13:08,160
So what do we do on macOS and Windows?

272
00:13:08,160 --> 00:13:09,840
We use certify.

273
00:13:09,840 --> 00:13:14,920
So certify is a Python package that basically takes the certificates that Mozilla bundles

274
00:13:14,920 --> 00:13:19,280
in their CA bundle and then repackages it, uploads it to the Python package index and

275
00:13:19,320 --> 00:13:22,360
then you can use them.

276
00:13:22,360 --> 00:13:27,120
But there are a couple of problems with using OpenSSL and certify, especially on macOS and

277
00:13:27,120 --> 00:13:28,720
Windows systems.

278
00:13:28,720 --> 00:13:32,880
So certify, you only get the certs that are bundled with certify.

279
00:13:32,880 --> 00:13:36,680
You don't get to follow some central policy on your system.

280
00:13:36,680 --> 00:13:41,080
For example, in a corporate environment, if your system administrator installs an additional

281
00:13:41,080 --> 00:13:45,440
certificate into your system trust store, certify has no idea what that even is.

282
00:13:45,440 --> 00:13:48,480
And so that means you're going to end up with one trust store per application.

283
00:13:48,480 --> 00:13:49,480
It's really tough to maintain.

284
00:13:49,480 --> 00:13:54,960
You don't get any auto updates and now the Python package index is a CA certificate distribution

285
00:13:54,960 --> 00:13:57,680
channel, which is not what it's for.

286
00:13:57,680 --> 00:14:00,600
And so here's why system trust stores are a lot better.

287
00:14:00,600 --> 00:14:04,080
You get one per system instead of per application, so that means there's one place where all

288
00:14:04,080 --> 00:14:05,840
the certificates get updated.

289
00:14:05,840 --> 00:14:09,560
The system itself manages and updates everything and you get a whole bunch of fancy features

290
00:14:09,560 --> 00:14:13,480
that the operating system usually gives you that OpenSSL wouldn't necessarily give you

291
00:14:13,480 --> 00:14:16,700
or you'd have to configure additionally.

292
00:14:16,700 --> 00:14:18,780
So this is kind of that future that we're envisioning.

293
00:14:18,780 --> 00:14:21,980
So there's this new experimental package that me and David have put together called trust

294
00:14:21,980 --> 00:14:23,180
store.

295
00:14:23,180 --> 00:14:25,700
This code is very new, so it's experimental.

296
00:14:25,700 --> 00:14:27,500
Don't deploy it.

297
00:14:27,500 --> 00:14:29,180
It's only been alive for about four months now.

298
00:14:29,180 --> 00:14:30,580
You can get it on GitHub.

299
00:14:30,580 --> 00:14:31,860
There's a URL there.

300
00:14:31,860 --> 00:14:36,100
But essentially what it is, is it provides an SSL context API.

301
00:14:36,100 --> 00:14:41,520
It works on all of the major platforms and does the native system trust store thing to

302
00:14:41,520 --> 00:14:43,300
make sure everything works.

303
00:14:43,300 --> 00:14:45,820
And we tested against a whole bunch of libraries.

304
00:14:45,820 --> 00:14:51,180
The only kicker is it requires Python 3.10 because it uses some special private APIs

305
00:14:51,180 --> 00:14:54,780
that if you really are super interested, I wrote an entire article about it.

306
00:14:54,780 --> 00:14:55,780
So go to the GitHub.

307
00:14:55,780 --> 00:14:58,780
You'll find it.

308
00:14:58,780 --> 00:15:00,640
And so then this exists.

309
00:15:00,640 --> 00:15:02,100
What happens now?

310
00:15:02,100 --> 00:15:03,100
Look at the project.

311
00:15:03,100 --> 00:15:04,100
Be interested by it.

312
00:15:04,100 --> 00:15:05,100
Like learn about it.

313
00:15:05,100 --> 00:15:07,460
But do not deploy it yet, please.

314
00:15:07,460 --> 00:15:11,760
It's very, very young code to be doing something that's super, super important.

315
00:15:11,760 --> 00:15:14,460
So just wait for a little bit in that case.

316
00:15:14,500 --> 00:15:18,220
But I think one of the future directions that this is going to go in is we would like to

317
00:15:18,220 --> 00:15:21,940
get this functionality added to Python so that all applications that use Python can

318
00:15:21,940 --> 00:15:23,900
immediately take advantage of it.

319
00:15:23,900 --> 00:15:29,460
And I think that there is an avenue for more incremental adoption by some libraries and

320
00:15:29,460 --> 00:15:31,900
tools of the specific library.

321
00:15:31,900 --> 00:15:34,900
So that's kind of it.

322
00:15:34,900 --> 00:15:35,900
Thank you.

323
00:15:35,900 --> 00:15:36,900
Fantastic.

324
00:15:36,900 --> 00:15:48,980
Love hearing that there is a space for you to collaborate, but do not yet deploy to prod.

325
00:15:48,980 --> 00:15:50,340
Huge emphasis there.

326
00:15:50,340 --> 00:15:53,340
Up next, we have Pablo.

327
00:15:53,340 --> 00:15:56,180
Hey, hello, PyCon.

328
00:15:56,180 --> 00:15:58,080
So I'm Pablo Galindo.

329
00:15:58,080 --> 00:16:03,060
You may know me from my work on CPython, but I'm here today to talk about something that

330
00:16:03,060 --> 00:16:07,340
we have released from the company that I work for, that is Bloomberg, and this is MemRay.

331
00:16:07,340 --> 00:16:13,660
So MemRay is a memory profiler that we have open source two weeks ago.

332
00:16:13,660 --> 00:16:17,340
Many of you may know it because apparently it was quite popular on Twitter during a couple

333
00:16:17,340 --> 00:16:22,380
of days, but I hope to give you an overview over what it does and why it could be useful

334
00:16:22,380 --> 00:16:23,380
for you.

335
00:16:23,380 --> 00:16:29,260
So the escape of memory profilers and profilers in Python is a fantastic landscape because

336
00:16:29,260 --> 00:16:30,780
there's a lot of cool tools.

337
00:16:31,260 --> 00:16:36,460
But let me help you cover what MemRay does that other profilers may not do or may do

338
00:16:36,460 --> 00:16:37,560
a bit worse.

339
00:16:37,560 --> 00:16:41,180
So one of the things that happen is that, for example, in the standard library, we see

340
00:16:41,180 --> 00:16:42,180
with some memory profilers.

341
00:16:42,180 --> 00:16:43,860
It's called TraceMalloc.

342
00:16:43,860 --> 00:16:47,500
The problem with, for example, TraceMalloc and many other profilers is that they can

343
00:16:47,500 --> 00:16:52,660
see allocations that the Python interpreter does, but not allocations that other things

344
00:16:52,660 --> 00:16:53,780
underneath do.

345
00:16:53,780 --> 00:16:57,260
For instance, in this case, we are allocating a huge amount of memory.

346
00:16:57,260 --> 00:17:01,660
This is like 90-something megabytes using MemMap, but this could also be done in a C

347
00:17:01,660 --> 00:17:06,180
extension or NumPy or things that are not communicating with the Python interpreter.

348
00:17:06,180 --> 00:17:08,980
And the problem is that, for instance, in this case, if you ask TraceMalloc how much

349
00:17:08,980 --> 00:17:13,020
memory was allocated, it tells you that it's only 80 bytes, which is not great because

350
00:17:13,020 --> 00:17:15,260
there is a huge amount of memory here.

351
00:17:15,260 --> 00:17:18,860
But if you do the same with MemRay, this is one of the example outputs that you will see.

352
00:17:18,860 --> 00:17:22,900
In this case, it will tell you that, oh, we detected one allocation is 9 megabytes and

353
00:17:22,900 --> 00:17:25,340
it's because one allocator happened.

354
00:17:25,340 --> 00:17:29,260
So MemRay can see not only allocations that happen in Python, but also a lot of allocations

355
00:17:29,260 --> 00:17:31,300
that happen in C extensions.

356
00:17:31,300 --> 00:17:34,820
Other profilers can do this, but something that many other profilers cannot do is that

357
00:17:34,820 --> 00:17:38,580
if you have one of the outputs of MemRay, which is this flying graph, for instance,

358
00:17:38,580 --> 00:17:42,700
in this case, some memory is allocated in this Python code, MemRay can also tell you

359
00:17:42,700 --> 00:17:46,540
what happens underneath that Python code, and it can tell you all the C code that is

360
00:17:46,540 --> 00:17:48,820
executed underneath and what happened.

361
00:17:48,820 --> 00:17:52,820
And as you can see, you can go here and see that actually there is some NumPy cache that

362
00:17:53,060 --> 00:17:57,380
the actual responsibility to allocate the memory for that instruction, which is super

363
00:17:57,380 --> 00:18:01,860
cool, especially if you are using data science libraries that use the extension or Cython.

364
00:18:01,860 --> 00:18:03,260
But we have many other things.

365
00:18:03,260 --> 00:18:08,380
For example, we dump all the information that we collect to a binary file, and then you

366
00:18:08,380 --> 00:18:10,820
can produce a ton of reports, depending on what you want.

367
00:18:10,820 --> 00:18:14,820
You can get the statistical reports, you can build tree reports, flying graphs, tables,

368
00:18:14,820 --> 00:18:19,340
and for instance, you can even get live reports when you can see what your application is

369
00:18:19,340 --> 00:18:20,900
doing as it's running.

370
00:18:20,940 --> 00:18:24,500
You don't need to generate one, you can see what's happening, which is very cool.

371
00:18:24,500 --> 00:18:28,780
I know people like moving things, so here you go.

372
00:18:28,780 --> 00:18:32,940
But yeah, the idea is that we also have an API, so you can use the API to track just

373
00:18:32,940 --> 00:18:36,900
parts of your code, you don't need to track the entire program, because you may be using

374
00:18:36,900 --> 00:18:40,900
Unicorn or other things that make tracking the whole thing very difficult, so you can

375
00:18:40,900 --> 00:18:43,300
just say, okay, track only what happens here.

376
00:18:43,300 --> 00:18:48,220
And the cool thing about MemRay is that, as opposed to other memory profilers, is that

377
00:18:48,260 --> 00:18:52,340
anything that happens outside this context manager has zero overhead, because MemRay

378
00:18:52,340 --> 00:18:56,980
activates everything in a very special way that makes sure that any code that is not

379
00:18:56,980 --> 00:19:01,300
under this context manager has zero overhead, so it runs at full speed.

380
00:19:01,300 --> 00:19:06,060
We have also a Python explain, which you can use immediately by installing, adding dash

381
00:19:06,060 --> 00:19:11,900
dash MemRay to your invocation of Python, that after the test suite passes, it will

382
00:19:11,900 --> 00:19:12,900
show you a bunch of statistics.

383
00:19:12,900 --> 00:19:16,940
So for instance, it will tell you how much memory was allocated, how many allocations

384
00:19:16,940 --> 00:19:22,180
happened, meaning Instagram of the allocations that happened, and the places in your code

385
00:19:22,180 --> 00:19:26,700
and your test when there were more allocations, which is quite cool.

386
00:19:26,700 --> 00:19:31,300
But you can use also despite this plugin to say, okay, I have this test, but I don't want

387
00:19:31,300 --> 00:19:35,540
anything under this test to use more than 25 megabytes, and MemRay will make sure that

388
00:19:35,540 --> 00:19:40,140
this test will fail, even if the test itself passes, if it uses more than 25 megabytes.

389
00:19:40,140 --> 00:19:44,340
So you can use that your functions are limited by whatever you want.

390
00:19:44,340 --> 00:19:45,340
So yeah, this is the profiler.

391
00:19:45,740 --> 00:19:46,740
It's just one among many.

392
00:19:46,740 --> 00:19:51,060
There is many, many other good profilers, and this is just complementary to them.

393
00:19:51,060 --> 00:19:52,460
But we think it's quite cool.

394
00:19:52,460 --> 00:19:56,940
We put a lot of effort into developing this thing and open sourcing it, and we hope that

395
00:19:56,940 --> 00:19:57,940
you like it.

396
00:19:57,940 --> 00:20:02,980
You can check it in that URL, so github.com BloombergMemRay, and I hope that you use it

397
00:20:02,980 --> 00:20:06,460
for finding why your programs are getting so big.

398
00:20:06,460 --> 00:20:07,460
Thank you very much.

399
00:20:07,460 --> 00:20:08,460
Super cool.

400
00:20:08,460 --> 00:20:09,460
Very excited about that.

401
00:20:09,460 --> 00:20:14,460
Okay, next we have Graham, who has no slides, but is going to talk to us about the grief

402
00:20:14,460 --> 00:20:19,460
cycle, data security breaches, and how we could code the future of America and the world.

403
00:20:19,460 --> 00:20:22,460
Let's give it away for Graham.

404
00:20:26,460 --> 00:20:31,460
First of all, I think that title is a little bit grandiose because coding the future of

405
00:20:31,460 --> 00:20:34,460
America and the world is a little bit of a challenge.

406
00:20:34,460 --> 00:20:39,460
It's a little bit grandiose because coding the future of the world is a big topic.

407
00:20:39,460 --> 00:20:41,460
Can I get a show of hands?

408
00:20:41,460 --> 00:20:44,460
Who here knows someone that has been hacked?

409
00:20:47,460 --> 00:20:50,460
Now, who here has been hacked?

410
00:20:52,460 --> 00:20:56,460
Now, raise your hand if you are proud that you got hacked.

411
00:20:58,460 --> 00:21:00,460
I didn't think so.

412
00:21:01,460 --> 00:21:07,460
One of the big things that I encountered when I was doing research in my master's program

413
00:21:07,460 --> 00:21:13,460
was a real issue with shame that came with being hacked.

414
00:21:13,460 --> 00:21:19,460
And it kind of built onto this grief cycle concept where you start, people actually are

415
00:21:19,460 --> 00:21:24,460
going through a grief cycle because of the shame of the fact that, oh, I'm compromised,

416
00:21:24,460 --> 00:21:28,460
my data, myself, it's my fault.

417
00:21:28,460 --> 00:21:38,460
And it made me reconsider how we as, I mean, Python, this is PyCon, we should be the

418
00:21:38,460 --> 00:21:42,460
people to be helping people with this sort of thing.

419
00:21:42,460 --> 00:21:48,460
And in the future, we're going to be building things that will shape the minds of everyone

420
00:21:48,460 --> 00:21:51,460
that uses the internet.

421
00:21:51,460 --> 00:21:53,460
That was loud.

422
00:21:53,460 --> 00:22:01,460
And for that reason, I think it's really important that we look at it from a holistic

423
00:22:01,460 --> 00:22:06,460
perspective because I think there's some parts of this grief cycle that people are going

424
00:22:06,460 --> 00:22:13,460
through, like in the workplace, even on our teams or our friends or even our clients,

425
00:22:13,460 --> 00:22:17,460
that there's lots of people that we don't know they're in the anger phase, and we try

426
00:22:17,460 --> 00:22:18,460
to sell them something.

427
00:22:18,460 --> 00:22:22,460
And while in the anger phase, they're just not going to buy something because who would?

428
00:22:22,460 --> 00:22:27,460
And I think that there's a lot of potential.

429
00:22:27,460 --> 00:22:33,460
There's a, I don't think it, I know there's a lot of potential in machine learning and

430
00:22:33,460 --> 00:22:41,460
specifically, I think, in reinforcement learning for the advancement of even our understanding

431
00:22:41,460 --> 00:22:43,460
of the way social dynamics work.

432
00:22:43,460 --> 00:22:51,460
I'm kind of excited to see what the next couple years hold in terms of modeling social change,

433
00:22:51,460 --> 00:22:58,460
like figuring out how we can create models to maybe do conflict resolution with people

434
00:22:58,460 --> 00:23:04,460
that are in a grief cycle, with maybe a chat bot that helps people to calm down before

435
00:23:04,460 --> 00:23:10,460
they talk to a human so that the poor customer service people don't have to deal with that.

436
00:23:10,460 --> 00:23:17,460
And this really came to my attention whenever I had to do cold calling.

437
00:23:17,460 --> 00:23:22,460
And that was one of the hardest jobs I ever did.

438
00:23:22,460 --> 00:23:28,460
It changed my perspective of that whole industry, and it really made me appreciate those people

439
00:23:28,460 --> 00:23:30,460
and what they go through.

440
00:23:30,460 --> 00:23:37,460
And I think that's the kind of people that we serve with open source software.

441
00:23:37,460 --> 00:23:43,460
And that's the kind of thing I'm excited to work on with all of you is this working on

442
00:23:43,460 --> 00:23:49,460
making machine learning without bias, working on building things that work and that can

443
00:23:49,460 --> 00:23:51,460
actually enact change.

444
00:23:51,460 --> 00:23:57,460
And I really, really appreciate being here this year and for everything that PyCon offers.

445
00:23:57,460 --> 00:24:02,460
On that note, we appreciate all of you being here at the end of a long day or for many of you

446
00:24:02,460 --> 00:24:04,460
who have been here many days.

447
00:24:04,460 --> 00:24:09,460
But up next we have Mason, who is going to be talking to us about what is synthetic data.

448
00:24:09,460 --> 00:24:11,460
There it is.

449
00:24:11,460 --> 00:24:13,460
There we go.

450
00:24:13,460 --> 00:24:15,460
Okay.

451
00:24:15,460 --> 00:24:17,460
We'll try that again.

452
00:24:17,460 --> 00:24:19,460
Hello.

453
00:24:19,460 --> 00:24:21,460
My name is Mason.

454
00:24:21,460 --> 00:24:23,460
I will be talking about synthetic data today.

455
00:24:23,460 --> 00:24:28,460
Usually whenever I try to do a talk, what I'm trying to do is I'm trying to do a presentation.

456
00:24:28,460 --> 00:24:31,460
I'm trying to do a presentation on how to do that.

457
00:24:31,460 --> 00:24:33,460
And I'm trying to do that.

458
00:24:33,460 --> 00:24:35,460
So I'm going to be talking about synthetic data today.

459
00:24:35,460 --> 00:24:39,460
Usually whenever I try to do a new topic, what I'm trying to do...

460
00:24:39,460 --> 00:24:41,460
Keep going with this.

461
00:24:41,460 --> 00:24:43,460
Yeah, we'll do that.

462
00:24:43,460 --> 00:24:45,460
You know I speak with my hands.

463
00:24:45,460 --> 00:24:47,460
Okay.

464
00:24:47,460 --> 00:24:49,460
We'll try this for the third time.

465
00:24:49,460 --> 00:24:51,460
Synthetic data.

466
00:24:51,460 --> 00:24:53,460
My name is Mason.

467
00:24:53,460 --> 00:24:55,460
One of the first things that I do whenever I learn about a new topic is I usually try to find some sort of

468
00:24:55,460 --> 00:24:57,460
definition on the Internet that gives it some sort of explanation.

469
00:24:57,460 --> 00:25:01,460
So the definition that I've found is that synthetic data is artificially annotated information that is

470
00:25:01,460 --> 00:25:07,460
generated by a computer using algorithms or simulations and it's commonly used as an alternative to real world data.

471
00:25:07,460 --> 00:25:11,460
After I read that definition, I was just as confused as I bet some of you are.

472
00:25:11,460 --> 00:25:17,460
Let's look at a couple of examples and some of the problems that synthetic data solves.

473
00:25:17,460 --> 00:25:23,460
So data is one of the biggest problems that developers face today.

474
00:25:23,460 --> 00:25:27,460
Getting access to usable testing data is usually pretty difficult.

475
00:25:27,460 --> 00:25:33,460
The data could be in a production database or you don't have some sort of access to it, you're not on the right team.

476
00:25:33,460 --> 00:25:39,460
The data may contain private information such as social security numbers, credit card numbers, all of these kind of things

477
00:25:39,460 --> 00:25:45,460
where it's not safe for a company to allow every developer within the company to have access to this data.

478
00:25:45,460 --> 00:25:49,460
Another problem that developers have with data is the limited data sets.

479
00:25:49,460 --> 00:25:55,460
35% of the time that goes into building a new ML model is spent just in the data gathering phase and it is the

480
00:25:55,460 --> 00:25:59,460
largest phase that happens in the ML thing.

481
00:25:59,460 --> 00:26:03,460
Trying to find relevant data that helps us is very difficult.

482
00:26:03,460 --> 00:26:09,460
And also our data is biased. We very often don't have a complete data set.

483
00:26:09,460 --> 00:26:15,460
This can be intentional or unintentional, but very often the data has a really slanted view in one way or the other

484
00:26:15,460 --> 00:26:18,460
and it's a problem that we have to deal with.

485
00:26:18,460 --> 00:26:22,460
Synthetic data comes to the rescue in almost all of these situations.

486
00:26:22,460 --> 00:26:27,460
One thing synthetic data can do is it can make private data accessible and shareable.

487
00:26:27,460 --> 00:26:33,460
What you can do with your production data is you can take this production data and run it through a synthetic data generator

488
00:26:33,460 --> 00:26:39,460
and then generate an entirely new data set that is statistically equivalent to the production data set,

489
00:26:39,460 --> 00:26:44,460
would give you the same things through any sort of testing, any sort of machine learning algorithm,

490
00:26:44,460 --> 00:26:51,460
but it has now been completely anonymized and you would not be able to know that this came from a production data set.

491
00:26:51,460 --> 00:26:56,460
You could then in turn share this data and use it wherever you want it.

492
00:26:56,460 --> 00:27:00,460
It also allows us to generate more samples if we have a limited data set.

493
00:27:00,460 --> 00:27:07,460
Say we have a data set of only 5,000 elements and we need a much larger data set because our model will perform better

494
00:27:07,460 --> 00:27:13,460
if we have more data to train it on. We can generate as much of this synthetic data as possible as we want.

495
00:27:13,460 --> 00:27:17,460
We can generate a million records, a trillion records, however much you want,

496
00:27:17,460 --> 00:27:24,460
and we can with pretty good accuracy tell you that this data is still statistically equivalent to the original data set.

497
00:27:24,460 --> 00:27:30,460
We can even reduce bias in machine learning data sets through a combination of some of these techniques.

498
00:27:30,460 --> 00:27:38,460
So a really good example that is in this slide, and I'll give these slides and all these links after the presentation,

499
00:27:38,460 --> 00:27:41,460
is reducing AI bias in predicting heart disease with synthetic data.

500
00:27:41,460 --> 00:27:46,460
This slide talks about a case study where they were looking at heart disease data from patients.

501
00:27:46,460 --> 00:27:52,460
70% of the data which came from men, because that was the data that they had, 30%, was from women,

502
00:27:52,460 --> 00:27:57,460
and it was very biased towards the men's side and it didn't perform very well.

503
00:27:57,460 --> 00:28:02,460
We were able to then take this data set, shrink down the men's size to a 50%,

504
00:28:02,460 --> 00:28:08,460
and then take the 30% that we have for the women's set and expand upon it using synthetic data, generate it,

505
00:28:08,460 --> 00:28:15,460
and then the model actually improved in accuracy from 88% to 96% because we were able to de-bias the data.

506
00:28:15,460 --> 00:28:20,460
But a lot of you may be going, well, isn't synthetic data just fake data?

507
00:28:20,460 --> 00:28:28,460
And the answer is no. There's actually a very big difference between synthetic data and fake data, or mock data, if you will.

508
00:28:28,460 --> 00:28:31,460
When a lot of people think of fake data, they think of faker.

509
00:28:31,460 --> 00:28:37,460
And one of the problems that I've had people tell me is that faker sometimes gives too perfect of results.

510
00:28:37,460 --> 00:28:40,460
Like all the data sets are always filled, they're always meaningful.

511
00:28:40,460 --> 00:28:43,460
That's not how data comes in the real world, and we all know that.

512
00:28:43,460 --> 00:28:48,460
So fake or mock data has no accuracy. It's purely random.

513
00:28:48,460 --> 00:28:54,460
Synthetic data, on the other hand, is nearly as accurate or in some cases, as represented by this paper as well,

514
00:28:54,460 --> 00:28:58,460
can be more accurate than the original data set when trained on a specific model.

515
00:28:58,460 --> 00:29:03,460
So where can you use synthetic data? The answer is everywhere.

516
00:29:03,460 --> 00:29:09,460
Automotives, financial services, cybersecurity, health care, and life sciences with genomics, all sorts of things.

517
00:29:09,460 --> 00:29:13,460
How can you, as the audience member, start using synthetic data?

518
00:29:13,460 --> 00:29:17,460
Gretel, the company that I work for, has open sourced our synthetic data model.

519
00:29:17,460 --> 00:29:19,460
We have one right now. There are more coming.

520
00:29:19,460 --> 00:29:25,460
So if you have a really good GPU or are using Google Collab, you are more than welcome to try to use it.

521
00:29:25,460 --> 00:29:28,460
Or you can use our cloud offering. It has a free tier.

522
00:29:28,460 --> 00:29:35,460
It also gives you all the synthetic data scores to tell you how far your data has drifted, differential privacy, a whole bunch of things.

523
00:29:35,460 --> 00:29:42,460
You can check out this blog. I'm doing an open space, 250 AB tomorrow at 4 on Saturday.

524
00:29:42,460 --> 00:29:44,460
And that's all the time I have.

525
00:29:48,460 --> 00:29:52,460
Thank you, Mason. Love synthetic data.

526
00:29:52,460 --> 00:29:56,460
All right. Next up, we have Sophia who's going to talk to us about HoloViz.

527
00:29:56,460 --> 00:29:58,460
Take it away.

528
00:30:13,460 --> 00:30:15,460
Hello, everyone.

529
00:30:15,460 --> 00:30:21,460
Hi. My name is Sophia. I'm a data scientist from Anaconda.

530
00:30:21,460 --> 00:30:23,460
Today I would like to talk about HoloViz.

531
00:30:23,460 --> 00:30:30,460
HoloViz is my favorite Python visualization ecosystem, which comprises seven libraries,

532
00:30:30,460 --> 00:30:35,460
panel, HVPlot, HoloViews, GeoViews, DataShader, Param, and Colorset.

533
00:30:35,460 --> 00:30:41,460
With more than hundreds of thousands of downloads per month, it is one of the most popular Python libraries.

534
00:30:43,460 --> 00:30:48,460
So my data visualization workflow really starts with HVPlot.

535
00:30:48,460 --> 00:30:55,460
I use HVPlot with panel to build dashboards, and I use HVPlot with DataShader to visualize big data.

536
00:30:57,460 --> 00:31:01,460
HVPlot, you might be familiar with pandas.plot API.

537
00:31:01,460 --> 00:31:06,460
HVPlot just works and looks and feels just like pandas.plot.

538
00:31:06,460 --> 00:31:13,460
To the left here, we have pandas.plot API plotting x, x, and y-axis with matplotlib as the backend.

539
00:31:13,460 --> 00:31:17,460
To the right, we replace dotplot to dothvplot.

540
00:31:17,460 --> 00:31:20,460
So you can see this is HVPlot plotting.

541
00:31:20,460 --> 00:31:24,460
This is the same plot with bokeh as the backend.

542
00:31:24,460 --> 00:31:34,460
In the HoloViz ecosystem, you can actually use different backends from your preferred library like matplotlib, bokeh, plolly, and et cetera.

543
00:31:35,460 --> 00:31:41,460
Next, I want to show you an example of how to build a dashboard using HVPlot and panel.

544
00:31:42,460 --> 00:31:46,460
So you might be familiar with pandas.pepline.

545
00:31:46,460 --> 00:31:49,460
To the left here, we have a pandas.pepline.

546
00:31:49,460 --> 00:31:53,460
We define, this is a pandas.chain method.

547
00:31:53,460 --> 00:31:55,460
This is with a car data set.

548
00:31:55,460 --> 00:32:03,460
We define the cylinder and manufacturer, and we group by some variables and calculate the meaning of the horsepower.

549
00:32:03,460 --> 00:32:09,460
What if we want to interactively select the cylinder, manufacturer, and all that?

550
00:32:09,460 --> 00:32:14,460
Instead of using those defined values, we can actually use panel widgets.

551
00:32:14,460 --> 00:32:21,460
Here I define three panel widgets, cylinders, manufacturer, and x-axis to define the variables we want to take the mean of.

552
00:32:21,460 --> 00:32:30,460
And then the result is an interactive table or interactive data frame, which you can plot interactive plots on.

553
00:32:30,460 --> 00:32:34,460
So here is the final result with a few more lines of code.

554
00:32:34,460 --> 00:32:42,460
If you want to see full example of this, full code of this example, please go check out my GitHub page.

555
00:32:42,460 --> 00:32:44,460
It is this link here.

556
00:32:44,460 --> 00:32:51,460
And then finally, I want to show you a simple example of how to visualize big data using HVPlot and data shader.

557
00:32:51,460 --> 00:32:59,460
To the left here, again, we have pandas.plotapi plotting 11 million data points of NYC taxi drop-off locations.

558
00:32:59,460 --> 00:33:05,460
As you can see in this plot, it is a blob, and it's very hard to extract meaningful information from this.

559
00:33:05,460 --> 00:33:17,460
With HVPlot, we can use the restorize equals true option, which uses data shader under the hood to plot this data meaningfully and interactively really fast.

560
00:33:17,460 --> 00:33:28,460
If you want to learn more about HoloViz, please check out the documentation at holoviz.org and also the documentation of HVPlot panel and data shader.

561
00:33:28,460 --> 00:33:35,460
I have also written several blog posts on data visualizations at Anaconda Nucleus, Anaconda Cloud.

562
00:33:35,460 --> 00:33:42,460
Anaconda Nucleus is a data science engagement content and community platform.

563
00:33:42,460 --> 00:33:44,460
Please go check it out. It's pretty cool.

564
00:33:44,460 --> 00:33:49,460
Thank you. Please feel free to connect me at Twitter and LinkedIn.

565
00:33:49,460 --> 00:33:54,460
Thanks, Sophia.

566
00:33:54,460 --> 00:33:57,460
Excellent. Thank you so much, Sophia.

567
00:33:57,460 --> 00:34:01,460
Up next, we have Shabai, and I'm really excited about this.

568
00:34:01,460 --> 00:34:05,460
Go ahead, without further ado.

569
00:34:05,460 --> 00:34:08,460
With a little ado, because we need to put the dongle on the computer.

570
00:34:08,460 --> 00:34:10,460
A small ado.

571
00:34:10,460 --> 00:34:12,460
A dongle-sized ado.

572
00:34:12,460 --> 00:34:14,460
Oh, no. We're going to do a comedies get up here.

573
00:34:14,460 --> 00:34:16,460
No, I don't think so. We should.

574
00:34:27,460 --> 00:34:32,460
All right. Let's give them another round of applause.

575
00:34:32,460 --> 00:34:42,460
One moment.

576
00:34:42,460 --> 00:34:46,460
Hello.

577
00:34:46,460 --> 00:34:51,460
First of all, welcome everyone to the lightning talks.

578
00:34:51,460 --> 00:34:54,460
I'm Shabai. I'm a contributor and sponsor for Robin.

579
00:34:54,460 --> 00:34:58,460
Robin is an async Python web framework with a Rust runtime.

580
00:34:58,460 --> 00:35:00,460
Today I'm going to be telling you all about it.

581
00:35:00,460 --> 00:35:04,460
First of all, let's get to know about how Robin actually started.

582
00:35:04,460 --> 00:35:10,460
It's a project from one of my really close friends, who is one of the original creators of this project.

583
00:35:10,460 --> 00:35:15,460
Basically, back in April of 2021, he was in his final year of college.

584
00:35:15,460 --> 00:35:18,460
He was basically preparing for his final thesis.

585
00:35:18,460 --> 00:35:26,460
Along that same time, there was a huge build with Rust or basically rewrite in Rust.

586
00:35:26,460 --> 00:35:32,460
A lot of different software were being rewritten using Rust because Rust is such a popular language.

587
00:35:32,460 --> 00:35:34,460
Because of its performance.

588
00:35:34,460 --> 00:35:40,460
At that point of time, he was also working on a side project that was being built with Flask.

589
00:35:40,460 --> 00:35:44,460
He also was working a lot with Node.js.

590
00:35:44,460 --> 00:35:50,460
He wished that Flask could actually get async support, which it lacked at that point of time.

591
00:35:50,460 --> 00:35:58,460
He decided that why not just create another framework that could actually become the next async Flask.

592
00:35:58,460 --> 00:36:04,460
He was aware of Fast API, but he just wanted to create his own Rust-based framework.

593
00:36:04,460 --> 00:36:07,460
That's how Robin actually came into play.

594
00:36:07,460 --> 00:36:20,460
One of the biggest benefits of Robin over other Python frameworks is that everyone should be knowing about the notoriousness of the global interpreter log that is there in Python.

595
00:36:20,460 --> 00:36:23,460
Which does not allow it for being truly concurrent.

596
00:36:23,460 --> 00:36:35,460
That's where Rust, because it natively implements multi-threading, is much more faster as compared to other Python frameworks that might have been built using Python or CPython.

597
00:36:35,460 --> 00:36:38,460
Robin also comes with a coupled server.

598
00:36:38,460 --> 00:36:44,460
That means that it does not have to depend on an actual or an external ASGI.

599
00:36:44,460 --> 00:36:52,460
If we just compare it against all the major frameworks as compared to, such as your Flask, Fast API, Django.

600
00:36:52,460 --> 00:37:00,460
This test that you see in this table was done over 10,000 different requests for a simple HTTP request, get request.

601
00:37:00,460 --> 00:37:07,460
You can see that Robin is actually the fastest as compared to all of them across different kind of stream workloads.

602
00:37:07,460 --> 00:37:10,460
Quickly coming to the architecture.

603
00:37:10,460 --> 00:37:18,460
Essentially, since it's a Rust-based runtime, we are basically compiling the code of Python into Rust, so it's getting converted.

604
00:37:18,460 --> 00:37:32,460
Now, if you can see the worker event cycle, this is sending requests to the router, which basically contains various Python-based code objects, which basically are there for each and every separate route that is being generated.

605
00:37:32,460 --> 00:37:42,460
Now, once this basically, the router sends this code directly to a thread pool, which then distributes it along the different threads based on the workload of the CPU.

606
00:37:42,460 --> 00:37:51,460
And this sort of becomes really great if you want to truly scale it, because each of these worker events can be distributed amongst various CPU cores.

607
00:37:51,460 --> 00:38:04,460
And if you truly want to scale it further, you can distribute this workload across various CPU cores, and that makes it super impressive, as you can see from the results that we saw from the comparison.

608
00:38:04,460 --> 00:38:17,460
And of course, if you want to get used to it, you can simply install the Python packets for Robin, and you will be able to use it very simply, as you might actually use something like Flask, of course, with the added benefit of being async.

609
00:38:17,460 --> 00:38:31,460
And well, if you want to get involved, if you like the project, you can give it a star by going to github.com, and you can also join the Gitter community for the Robin project, and you can also follow the Robin project on Twitter.

610
00:38:31,460 --> 00:38:36,460
And of course, if you want to connect with me, you can connect with me on Twitter at the rate HODL up.

611
00:38:36,460 --> 00:38:39,460
But thank you so much for attending today's lightning talk.

612
00:38:44,460 --> 00:38:49,460
All right. Yet another web framework, just what we need.

613
00:38:49,460 --> 00:38:52,460
I'm just joking.

614
00:38:52,460 --> 00:38:56,460
We can always make them faster, right?

615
00:38:56,460 --> 00:38:58,460
I think you need a Donald?

616
00:38:58,460 --> 00:39:02,460
You got one. Oh, sorry. I'm vamping because I thought we were moving on.

617
00:39:02,460 --> 00:39:04,460
All right. So this is Chris.

618
00:39:04,460 --> 00:39:07,460
Chris is going to give us a talk on elegant code in three steps.

619
00:39:07,460 --> 00:39:09,460
Is the first step just use Python?

620
00:39:09,460 --> 00:39:10,460
Maybe. Yeah, maybe. So, okay.

621
00:39:10,460 --> 00:39:19,460
Give it away for Chris.

622
00:39:19,460 --> 00:39:23,460
I'm told in America they make things bigger.

623
00:39:23,460 --> 00:39:25,460
Anyway, my name is Chris May.

624
00:39:25,460 --> 00:39:28,460
I'm excited about talking to you how to make code elegant.

625
00:39:28,460 --> 00:39:31,460
To make code elegant, we need to refactor.

626
00:39:31,460 --> 00:39:35,460
And that is because it is practically impossible to make elegant code,

627
00:39:35,460 --> 00:39:38,460
code that is well documented, code that you can understand,

628
00:39:38,460 --> 00:39:41,460
code that you can maintain the first go around.

629
00:39:41,460 --> 00:39:44,460
And thankfully, since people have been writing code for decades,

630
00:39:44,460 --> 00:39:50,460
we have decades worth of tools that you can use to refactor, such as code smells.

631
00:39:50,460 --> 00:39:54,460
People have categorized specific things they call code smells,

632
00:39:54,460 --> 00:39:58,460
which are things that suggest opportunities for improvement.

633
00:39:58,460 --> 00:40:03,460
In addition, there are specific methods you can use to refactor your code.

634
00:40:03,460 --> 00:40:08,460
Each of these have a list of specific steps you can follow to make sure that

635
00:40:08,460 --> 00:40:12,460
your code is always going to run and it's going to be more elegant when you're finished.

636
00:40:12,460 --> 00:40:14,460
But there are a lot of them, right?

637
00:40:14,460 --> 00:40:18,460
How are you going to keep them straight, especially when we don't have this list there, you know,

638
00:40:19,460 --> 00:40:21,460
or you don't know which one you need to follow?

639
00:40:21,460 --> 00:40:26,460
Wouldn't it be great if there was a way that you could just follow something simple

640
00:40:26,460 --> 00:40:28,460
to make your code more elegant?

641
00:40:28,460 --> 00:40:32,460
Well, thanks to Heineck telling me about this book, 99 Bottles of OOP,

642
00:40:32,460 --> 00:40:36,460
I've been really impressed with Sandy Metz and Katrina Owen.

643
00:40:36,460 --> 00:40:40,460
They spent two years trying to figure out how do you tell people,

644
00:40:40,460 --> 00:40:42,460
how do you explain how to refactor?

645
00:40:42,460 --> 00:40:45,460
And they created this thing called the flocking rules.

646
00:40:45,460 --> 00:40:47,460
So these are the three rules.

647
00:40:47,460 --> 00:40:50,460
But if I were to read them to you right now, I mean, you're not going to get it.

648
00:40:50,460 --> 00:40:52,460
So we need a little code to kind of walk through, right?

649
00:40:52,460 --> 00:40:56,460
So in trying to learn the flocking rules, I started creating code

650
00:40:56,460 --> 00:41:00,460
that would recite the 12 Days of Christmas song.

651
00:41:00,460 --> 00:41:03,460
So here are two verses that I started working.

652
00:41:03,460 --> 00:41:07,460
So first thing we need to do is identify the things that are most alike.

653
00:41:07,460 --> 00:41:10,460
In this case, there are two verses. That's easy.

654
00:41:10,460 --> 00:41:13,460
We need to find the smallest difference between them.

655
00:41:13,460 --> 00:41:17,460
I'm going to focus on the first lines of each of these cases, right?

656
00:41:17,460 --> 00:41:21,460
The only difference is the word first or the word second.

657
00:41:21,460 --> 00:41:27,460
And next, we need to make simple changes that will remove the differences.

658
00:41:27,460 --> 00:41:35,460
So the first and second, we need to come up with a concept that encapsulates this idea.

659
00:41:35,460 --> 00:41:39,460
When verse is one, this thing will be first.

660
00:41:39,460 --> 00:41:41,460
I'm going to use the word day.

661
00:41:41,460 --> 00:41:43,460
It makes sense to me. We don't have to stick on this.

662
00:41:43,460 --> 00:41:46,460
We can always refactor it later. So day.

663
00:41:46,460 --> 00:41:51,460
So what we need to do is create new code that represents day.

664
00:41:51,460 --> 00:41:54,460
With Python, we just make a function.

665
00:41:54,460 --> 00:41:58,460
Next, we need to make this code ready to return the data that we want.

666
00:41:58,460 --> 00:42:01,460
And I should say, I made tests for this. We should be running tests.

667
00:42:01,460 --> 00:42:03,460
I ran the test. The test passed.

668
00:42:03,460 --> 00:42:06,460
And that is good because we know we have valid code.

669
00:42:06,460 --> 00:42:09,460
We now add what we need to return, run our tests.

670
00:42:09,460 --> 00:42:12,460
It passes again. We know we're ready to incorporate it in.

671
00:42:12,460 --> 00:42:13,460
So let's do that.

672
00:42:13,460 --> 00:42:16,460
Parse, execute, and use the results.

673
00:42:16,460 --> 00:42:20,460
So we insert that in, right into this first opportunity.

674
00:42:20,460 --> 00:42:23,460
Run our tests. They pass. We're doing good.

675
00:42:23,460 --> 00:42:27,460
So technically, you can say we can go to the next one, delete unused code,

676
00:42:27,460 --> 00:42:32,460
but we've got all code that's being used, so we could go back through the flocking rules.

677
00:42:32,460 --> 00:42:37,460
Or you can kind of focus in and say, let's just stick here and refactor this whole thing through.

678
00:42:37,460 --> 00:42:41,460
So the next thing we need to do is incorporate the second.

679
00:42:41,460 --> 00:42:44,460
So it can return second. So Day needs more information.

680
00:42:44,460 --> 00:42:46,460
Let's give it to it.

681
00:42:46,460 --> 00:42:48,460
We pass in something that we know we can delete later,

682
00:42:48,460 --> 00:42:52,460
because we want to make sure the tests pass at this point, which they do.

683
00:42:52,460 --> 00:42:56,460
So let's do that. Let's add the code to return second.

684
00:42:56,460 --> 00:42:59,460
Let's incorporate it into the code.

685
00:42:59,460 --> 00:43:02,460
Now let's make the two pieces of code the same.

686
00:43:02,460 --> 00:43:04,460
Just like that.

687
00:43:04,460 --> 00:43:06,460
And hey, look at that. They're identical now.

688
00:43:06,460 --> 00:43:11,460
So we can delete unused code, which is this little extra code that I put in here.

689
00:43:11,460 --> 00:43:15,460
And we now have code that's more elegant.

690
00:43:15,460 --> 00:43:17,460
And at this point, you can go back through the flocking rules again.

691
00:43:17,460 --> 00:43:21,460
And the thing I love about the flocking rules is that it's always kind of fractal in nature.

692
00:43:21,460 --> 00:43:25,460
So no matter where you are, you can just jump back into them, make your code better.

693
00:43:25,460 --> 00:43:30,460
And if you get pulled away while you're in the middle of refactoring and you don't know where you are,

694
00:43:30,460 --> 00:43:32,460
you're going to have working code that works, obviously.

695
00:43:32,460 --> 00:43:35,460
And you can always jump back in and make it better.

696
00:43:35,460 --> 00:43:39,460
Well, thank you. If you want more tips like this, check me out at everydaysuperpowers.dev,

697
00:43:39,460 --> 00:43:45,460
where I want to give you the superpowers you can use every day, and on Twitter at underscore Chris May.

698
00:43:45,460 --> 00:43:51,460
Thank you very much.

699
00:43:51,460 --> 00:43:53,460
Thank you so much, Chris.

700
00:43:53,460 --> 00:44:01,460
And up next, we have Chris, who's going to be talking to us about getting to 100% coverage

701
00:44:01,460 --> 00:44:09,460
and why it matters.

702
00:44:09,460 --> 00:44:11,460
Check one, check two. Thank you.

703
00:44:11,460 --> 00:44:14,460
Thank you all for staying for the last lightning talk of the day.

704
00:44:14,460 --> 00:44:17,460
So I'm going to talk to you about 100% test coverage.

705
00:44:17,460 --> 00:44:22,460
100% test coverage is when we have all lines of our code covered by test.

706
00:44:22,460 --> 00:44:27,460
I want to talk about, is it worth it? Is it worth getting to 100%? And how can we get there?

707
00:44:27,460 --> 00:44:33,460
So this comes out of my two-year journey to achieve 100% test coverage on an open source project called Static Frame.

708
00:44:33,460 --> 00:44:37,460
I achieved that goal, and I got that 100% banner there.

709
00:44:37,460 --> 00:44:41,460
It was really hard, but I made it, and it's very satisfying.

710
00:44:41,460 --> 00:44:48,460
Initially, I was very skeptical about this goal, because 100% test coverage does not mean 100% behavior coverage.

711
00:44:48,460 --> 00:44:53,460
And aren't all those new features you want more important than 100% test coverage?

712
00:44:53,460 --> 00:44:56,460
I believe 100% test coverage is worth the effort.

713
00:44:56,460 --> 00:45:00,460
At least we have exercised all lines of our code when we have 100% test coverage,

714
00:45:00,460 --> 00:45:05,460
and this is critical in Python where unexercised codes will not be evaluated.

715
00:45:05,460 --> 00:45:09,460
It does not guarantee correctness, but it does offer many additional benefits.

716
00:45:09,460 --> 00:45:14,460
So this is my journey through the CodeCov timeline of my coverage.

717
00:45:14,460 --> 00:45:17,460
And you can see in January of 2020, I set out to get to 100%.

718
00:45:17,460 --> 00:45:20,460
I didn't make it. I got to about 98%.

719
00:45:20,460 --> 00:45:23,460
And then you can see my coverage wander and start to slip away.

720
00:45:23,460 --> 00:45:25,460
And then I realized one day my coverage was slipping.

721
00:45:25,460 --> 00:45:29,460
So I tried again, and then I got distracted, and my coverage drifted, drifted.

722
00:45:29,460 --> 00:45:34,460
And you see this pattern repeat over and over again until finally in January of 2022, I got to 100%.

723
00:45:34,460 --> 00:45:39,460
And it's much easier to stay at 100% once you're at 100%.

724
00:45:39,460 --> 00:45:42,460
So that's really one of the important takeaways here.

725
00:45:42,460 --> 00:45:46,460
So what is it in that last 2% that was so hard?

726
00:45:46,460 --> 00:45:49,460
Well, one of the things is non-trivial, unreachable code.

727
00:45:49,460 --> 00:45:52,460
This is not the unreachable code that Pilent tells you about.

728
00:45:52,460 --> 00:45:57,460
This is the unreachable code that is due to a logic problem that you haven't evaluated correctly.

729
00:45:57,460 --> 00:45:59,460
So that's one of the things that I found.

730
00:45:59,460 --> 00:46:02,460
But overwhelmingly, what you find is hard to test code.

731
00:46:02,460 --> 00:46:05,460
There's a reason that's the last 2% is because it's hard.

732
00:46:05,460 --> 00:46:10,460
And that often leads to valuable refactoring of your code and improving your designs.

733
00:46:10,460 --> 00:46:16,460
But is less than 100% good enough? If you have like 93, can you say, well, I tried?

734
00:46:16,460 --> 00:46:21,460
Well, many popular open source packages do not make it to 100%.

735
00:46:21,460 --> 00:46:23,460
And we can see one example here.

736
00:46:23,460 --> 00:46:27,460
So I argue that less than 100% is not good enough.

737
00:46:27,460 --> 00:46:29,460
And there's a number of reasons.

738
00:46:29,460 --> 00:46:33,460
So the first is, as I said, the last 2% of lines is the hardest to test code.

739
00:46:33,460 --> 00:46:37,460
And there are probably real bugs in that code.

740
00:46:37,460 --> 00:46:42,460
It's also, while you're working on your code, hard to tell if you are growing or reducing coverage if you're not at 100%.

741
00:46:42,460 --> 00:46:47,460
I mean, you can check your coverage every day, but it's going to be harder to follow if you're not at 100%.

742
00:46:47,460 --> 00:46:53,460
Furthermore, without 100% coverage, you have less confidence that any refactoring you do is not going to break things.

743
00:46:53,460 --> 00:47:00,460
Without 100% coverage, it's hard to tell if pull requests are adding enough coverage.

744
00:47:00,460 --> 00:47:04,460
And this helps make test expectations really explicit for your contributors.

745
00:47:04,460 --> 00:47:09,460
So, for example, here in a GitHub PR using the CodeCover Report tool,

746
00:47:09,460 --> 00:47:14,460
we can see that I added 10 lines of code in this PR and I added 10 lines of tests.

747
00:47:14,460 --> 00:47:19,460
And if you merge all your code through your PRs and you have code coverage looking at your coverage with each of these PR,

748
00:47:19,460 --> 00:47:23,460
you can maintain 100% coverage in your project.

749
00:47:23,460 --> 00:47:25,460
So how do we get to 100% coverage?

750
00:47:25,460 --> 00:47:29,460
Well, the first step is building coverage into your continuous integration.

751
00:47:29,460 --> 00:47:32,460
And I've used CodeCov.io for a number of years. I've been very happy with it.

752
00:47:32,460 --> 00:47:37,460
There's probably alternatives out there, but it's worked very well for me, and it's free for open source projects.

753
00:47:37,460 --> 00:47:42,460
You'll need a couple of packages. The coverage package has been there for a long time and is a great utility.

754
00:47:42,460 --> 00:47:49,460
The PyTestCov plugin works with coverage to derive your coverage in your PyTest runs.

755
00:47:49,460 --> 00:47:51,460
Now, you need to get this in your continuous integration.

756
00:47:51,460 --> 00:47:55,460
So I use GitHub Actions, other continuous integrations. You can probably do the same thing.

757
00:47:55,460 --> 00:48:01,460
You can see here I just run PyTest with the Cove plugin, and I tell it to give me an XML report.

758
00:48:01,460 --> 00:48:06,460
And then I use the CodeCov action tool to upload that to CodeCov, and that's all we need to do.

759
00:48:06,460 --> 00:48:10,460
Set this up with your continuous integration, and you'll get constant coverage updates.

760
00:48:10,460 --> 00:48:15,460
So a couple of practical tips. So not every line needs coverage.

761
00:48:15,460 --> 00:48:20,460
You can use the pragma no-cover declaration to skip immaterial lines.

762
00:48:20,460 --> 00:48:23,460
Now, you don't want to just skip stuff because it's hard.

763
00:48:23,460 --> 00:48:26,460
You want to skip stuff that really doesn't need coverage.

764
00:48:26,460 --> 00:48:30,460
And a good example is unimplemented abstract base class methods.

765
00:48:30,460 --> 00:48:34,460
Like, that's code that should never be called. We don't want coverage on that.

766
00:48:34,460 --> 00:48:38,460
In addition, while you're studying your coverage, I recommend putting comments in your code.

767
00:48:38,460 --> 00:48:43,460
When you identify lines that do not have coverage, it's a good idea to put a comment in your code right away

768
00:48:43,460 --> 00:48:45,460
to tell you coverage is missing there.

769
00:48:45,460 --> 00:48:48,460
So later on, when you're not looking at your coverage and you're maybe working on your test,

770
00:48:48,460 --> 00:48:51,460
you can find what's missing and work on getting that coverage.

771
00:48:51,460 --> 00:48:55,460
Finally, you can debug when you're test writing tests to get coverage.

772
00:48:55,460 --> 00:49:00,460
It's useful to debug on that line because you might think you're getting coverage there, but you're not.

773
00:49:00,460 --> 00:49:06,460
So I implore all of you, stop adding new features and chase down that remaining coverage.

774
00:49:06,460 --> 00:49:08,460
Thank you.

775
00:49:11,460 --> 00:49:14,460
Right down to the wire. Nice job.

776
00:49:14,460 --> 00:49:18,460
All right. Next talk is by Indra.

777
00:49:18,460 --> 00:49:20,460
Is your mic working? I think it's probably on.

778
00:49:20,460 --> 00:49:21,460
Yep. Thank you.

779
00:49:21,460 --> 00:49:22,460
All right. Let's give it away for Indra.

780
00:49:22,460 --> 00:49:24,460
Hi, everyone.

781
00:49:26,460 --> 00:49:29,460
Thank you so much. Really excited to be here. My name is Indra.

782
00:49:29,460 --> 00:49:33,460
I'm a Python developer and I'm a big fan of frameworks.

783
00:49:33,460 --> 00:49:41,460
So I worked extensively with Django and GraphQL and SQLAlchemy and more recently with Keras and TensorFlow.

784
00:49:41,460 --> 00:49:46,460
I was part of Bankpipers in Bangalore and I attended PyCon in India,

785
00:49:46,460 --> 00:49:48,460
but this is my first time attending PyCon in the U.S.

786
00:49:48,460 --> 00:49:51,460
So really excited to be here and talking to you all.

787
00:49:52,460 --> 00:49:59,460
Today I wanted to talk to you about a medium article that I wrote called Pandas to Production.

788
00:49:59,460 --> 00:50:05,460
And as I said, I'm a fan of frameworks and I'm becoming a fan of frameworks that help data scientists

789
00:50:05,460 --> 00:50:11,460
very quickly take their models from a Jupyter Notebook and make an API service out of it.

790
00:50:11,460 --> 00:50:15,460
There are many sort of frameworks that do this today.

791
00:50:15,460 --> 00:50:18,460
There's FastAPI, there's Kubeflow, MLflow.

792
00:50:18,460 --> 00:50:24,460
And I have used BentoML, which is one of the open source projects that also aims to do this.

793
00:50:24,460 --> 00:50:26,460
So what's the problem it's solving?

794
00:50:26,460 --> 00:50:31,460
Machine learning models are easy to build and prototype iteratively on a Jupyter Notebook.

795
00:50:31,460 --> 00:50:38,460
But then we don't, like typically data scientists have to hand this off to a DevOps team or a MLOps team more likely these days

796
00:50:38,460 --> 00:50:44,460
because someone needs to understand the machine learning side of it, the DevOps side of it, writing APIs.

797
00:50:44,460 --> 00:50:49,460
And everyone can hire an API engineer and an infrastructure engineer to do these things.

798
00:50:49,460 --> 00:50:56,460
So here's a very quick tutorial on how you can do all of that if you sort of work with one of these frameworks.

799
00:50:56,460 --> 00:50:59,460
So step one is sort of the easy bit, which is the model.

800
00:50:59,460 --> 00:51:02,460
I guess not easy, it's the bit that's easy for the data scientists.

801
00:51:02,460 --> 00:51:04,460
So I'll skip over this.

802
00:51:04,460 --> 00:51:10,460
I'll just tell you that I'm using a pre-trained sentiment analysis model that I pulled from Kaggle.

803
00:51:12,460 --> 00:51:13,460
And so what's step two?

804
00:51:13,460 --> 00:51:15,460
Step two is defining the API service contract.

805
00:51:15,460 --> 00:51:18,460
So what does your endpoint take as input?

806
00:51:18,460 --> 00:51:20,460
What does it provide as output?

807
00:51:20,460 --> 00:51:22,460
How does it respond to queries?

808
00:51:22,460 --> 00:51:26,460
And in this example, I'm going to try and step through code live.

809
00:51:26,460 --> 00:51:28,460
And this may or may not work very well.

810
00:51:28,460 --> 00:51:36,460
But you can see that I have imported BentoML and the framework itself has ways of interacting with model artifacts.

811
00:51:36,460 --> 00:51:39,460
So in my case, my model is a SKLearn model.

812
00:51:39,460 --> 00:51:41,460
So I'm importing that kind of artifact.

813
00:51:41,460 --> 00:51:46,460
And also I'm telling Bento that I'm expecting a JSON input.

814
00:51:46,460 --> 00:51:51,460
And really all I'm doing is writing a very simple sort of Flask API endpoint.

815
00:51:51,460 --> 00:51:55,460
So you can see my class is a sentiment analysis class.

816
00:51:55,460 --> 00:51:59,460
It's a Bento service, which means this is going to be exposed at a certain endpoint.

817
00:51:59,460 --> 00:52:03,460
There's a couple of big packages that I'm declaring I need.

818
00:52:03,460 --> 00:52:07,460
And this is important because it gets packaged into the runtime environment.

819
00:52:07,460 --> 00:52:12,460
And I'm defining that I expect a model artifact which will be pickled.

820
00:52:12,460 --> 00:52:14,460
So it's going to be loading from a pickle file.

821
00:52:14,460 --> 00:52:17,460
And then I just have to implement a predict function.

822
00:52:17,460 --> 00:52:21,460
All this does is says, okay, I'm expecting some kind of JSON input.

823
00:52:21,460 --> 00:52:25,460
And then here's all the code that I have to write to make my model an API.

824
00:52:25,460 --> 00:52:27,460
I'm saying, let me parse the JSON.

825
00:52:27,460 --> 00:52:30,460
Let me load the model artifact and run predict on that.

826
00:52:30,460 --> 00:52:34,460
This is going to load the SKLearn model, run predict on my text.

827
00:52:34,460 --> 00:52:37,460
And then for each prediction, I'm just constructing a JSON response.

828
00:52:37,460 --> 00:52:39,460
I'm saying, here's the sentiment score.

829
00:52:39,460 --> 00:52:41,460
Here's the sentiment score name.

830
00:52:41,460 --> 00:52:43,460
And then here's the text that I predicted on.

831
00:52:43,460 --> 00:52:46,460
Seems simple enough.

832
00:52:46,460 --> 00:52:49,460
So from there, the next step is to package this model and serve it.

833
00:52:49,460 --> 00:52:55,460
So all I need to do is import that particular model, call Bento service, and say,

834
00:52:55,460 --> 00:52:57,460
hey, this is the service I defined.

835
00:52:57,460 --> 00:52:59,460
This is the model that you need to run on.

836
00:52:59,460 --> 00:53:03,460
And then all it's going to do is it's going to load those two together,

837
00:53:03,460 --> 00:53:06,460
load up a Docker environment, install the pip packages at the cloud,

838
00:53:06,460 --> 00:53:08,460
and ready to serve.

839
00:53:08,460 --> 00:53:12,460
So that exposes a Flask endpoint, which you can see right here.

840
00:53:12,460 --> 00:53:16,460
It comes with a bundled health metrics and other endpoints.

841
00:53:16,460 --> 00:53:21,460
And I'm able to execute and get responses from this API.

842
00:53:21,460 --> 00:53:25,460
With a couple of quick changes to that, and I'm coming up on a minute,

843
00:53:25,460 --> 00:53:27,460
so I'm going to run through this.

844
00:53:27,460 --> 00:53:30,460
With a couple of quick changes to that, we can instrument error tracking

845
00:53:30,460 --> 00:53:32,460
and performance metrics measurements.

846
00:53:32,460 --> 00:53:36,460
So I will skip down to the end and show you how I've done that.

847
00:53:36,460 --> 00:53:41,460
So relying on our good friend Sentry here, so import Sentry SDK,

848
00:53:41,460 --> 00:53:45,460
set up your Sentry config, and you're ready to go.

849
00:53:45,460 --> 00:53:49,460
Sentry will start tracking errors as long as there is a try except block

850
00:53:49,460 --> 00:53:51,460
and you're doing capture exception.

851
00:53:51,460 --> 00:53:55,460
Bento ML comes bundled with Prometheus for performance metrics tracking.

852
00:53:55,460 --> 00:53:57,460
So I have two metrics that I've defined here.

853
00:53:57,460 --> 00:54:01,460
There's a request time metric, which measures latency,

854
00:54:01,460 --> 00:54:04,460
and there is a text length, which is more of a custom metric.

855
00:54:04,460 --> 00:54:09,460
So I'm interested in how many queries am I being asked at any given time.

856
00:54:09,460 --> 00:54:14,460
And with that, you can see some zero division errors that I forced here

857
00:54:14,460 --> 00:54:17,460
and Prometheus logs out of the box.

858
00:54:17,460 --> 00:54:20,460
So this is part one, hoping to do part two with A-B testing and more.

859
00:54:20,460 --> 00:54:22,460
Thank you.

860
00:54:22,460 --> 00:54:25,460
All right. Thank you, Indra.

861
00:54:25,460 --> 00:54:28,460
And that does it for tonight's lightning talks.

862
00:54:28,460 --> 00:54:32,460
But if you enjoyed these lightning talks, you might also enjoy lightning talks

863
00:54:32,460 --> 00:54:36,460
tomorrow morning, tomorrow evening, and Sunday morning.

864
00:54:36,460 --> 00:54:40,460
If you want to give a lightning talk like these fine folks that just gave talks today,

865
00:54:40,460 --> 00:54:44,460
you can sign up for tomorrow evening and Sunday morning lightning talks

866
00:54:44,460 --> 00:54:48,460
in the boards directly out that back door right next to the registration booth.

867
00:54:48,460 --> 00:54:51,460
Anyone can sign up to give five minutes to talk about whatever they want.

868
00:54:51,460 --> 00:54:55,460
And as a point of clarification, if you are selected, you will be emailed.

869
00:54:55,460 --> 00:54:57,460
So look for an email.

870
00:54:57,460 --> 00:55:01,460
And write your email really nicely on the board, because if I can't read your email,

871
00:55:01,460 --> 00:55:04,460
I can't email you to tell you that your talk has been accepted.

872
00:55:04,460 --> 00:55:06,460
Exactly.

873
00:55:06,460 --> 00:55:09,460
All right. Thanks, everyone. Have a great night and see you all tomorrow.

