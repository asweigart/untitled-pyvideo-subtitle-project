1
00:00:00,000 --> 00:00:09,200
Okay, so this is the second to last talk, so enjoy it.

2
00:00:09,200 --> 00:00:10,640
It's going to be great.

3
00:00:10,640 --> 00:00:14,200
Our next talk is Managing the Test Data Nightmare by Pandy Knight.

4
00:00:14,200 --> 00:00:20,520
So go ahead and give him a round of applause.

5
00:00:20,520 --> 00:00:21,560
Thank you, Mason.

6
00:00:21,560 --> 00:00:22,560
Thank you.

7
00:00:22,560 --> 00:00:23,560
Also, Mason's pretty awesome.

8
00:00:23,560 --> 00:00:24,560
Go follow him on Twitter.

9
00:00:24,560 --> 00:00:25,760
He does amazing things.

10
00:00:25,760 --> 00:00:27,320
So hello, everyone.

11
00:00:27,320 --> 00:00:28,560
Thanks for joining my talk today.

12
00:00:28,600 --> 00:00:32,360
My name is Pandy Knight, and I am the automation panda.

13
00:00:32,360 --> 00:00:34,960
It's been three years since our last in-person PyCon.

14
00:00:34,960 --> 00:00:36,440
It's hard to believe.

15
00:00:36,440 --> 00:00:42,860
Since it's important to make human connections, I'd like to share a little bit about myself.

16
00:00:42,860 --> 00:00:46,280
So my wife and I have this adorable French bulldog puppy.

17
00:00:46,280 --> 00:00:47,880
Her name is Suki.

18
00:00:47,880 --> 00:00:52,260
She is super cute, and I miss her so very much.

19
00:00:52,260 --> 00:00:53,520
This is my car.

20
00:00:53,520 --> 00:00:56,440
I drive a 1970 Volkswagen Beetle.

21
00:00:56,440 --> 00:00:57,440
Yes.

22
00:00:57,440 --> 00:01:01,560
And when I say this is my car, I mean that this is my primary driver.

23
00:01:01,560 --> 00:01:02,640
This is not a toy.

24
00:01:02,640 --> 00:01:04,120
This is not something I pull out for shows.

25
00:01:04,120 --> 00:01:06,800
This is what I drive to get groceries and stuff.

26
00:01:06,800 --> 00:01:08,160
I'm restoring the inside.

27
00:01:08,160 --> 00:01:13,380
The exterior is already pretty baller, and I dropped a whole new engine in this bad boy.

28
00:01:13,380 --> 00:01:18,440
So about me, where I work, I work as a developer advocate at Apple tools, where I help people

29
00:01:18,440 --> 00:01:23,400
get the most value out of their test automation, hence automation panda.

30
00:01:23,400 --> 00:01:25,760
Apple tools provides automated visual testing tools.

31
00:01:26,160 --> 00:01:28,200
So what does automated visual testing mean?

32
00:01:28,200 --> 00:01:29,200
Take a look at this picture.

33
00:01:29,200 --> 00:01:30,760
Can you spot the differences?

34
00:01:30,760 --> 00:01:31,760
Apple tools can.

35
00:01:31,760 --> 00:01:33,640
There it goes.

36
00:01:33,640 --> 00:01:34,920
There are 10 differences in here.

37
00:01:34,920 --> 00:01:36,240
This is what visual AI does.

38
00:01:36,240 --> 00:01:38,440
You might think, well, that's cool, but how is it useful?

39
00:01:38,440 --> 00:01:41,540
This is a game changer for testing your web and mobile apps.

40
00:01:41,540 --> 00:01:42,640
Think about all the changes you make.

41
00:01:42,640 --> 00:01:43,640
Oh, did a button disappear?

42
00:01:43,640 --> 00:01:45,040
Did this label go bad?

43
00:01:45,040 --> 00:01:48,260
Boom, we can find it for you.

44
00:01:48,260 --> 00:01:52,800
At Apple tools, I'm also director of test automation university, which provides free

45
00:01:52,800 --> 00:01:55,480
courses on testing and automation topics.

46
00:01:55,480 --> 00:01:59,960
Personally, I've developed four courses for TAU even before I joined Apple tools, three

47
00:01:59,960 --> 00:02:02,160
of which cover Python.

48
00:02:02,160 --> 00:02:03,160
Woo!

49
00:02:03,160 --> 00:02:06,160
Python for testing is amazing.

50
00:02:06,160 --> 00:02:07,160
All righty.

51
00:02:07,160 --> 00:02:08,840
So let's get down to the nitty gritty.

52
00:02:08,840 --> 00:02:12,440
One of the toughest challenges in testing any software product is handling the test

53
00:02:12,440 --> 00:02:13,440
data.

54
00:02:13,440 --> 00:02:17,620
Now, when I say test data, quote unquote, I'm referring to multiple things.

55
00:02:17,620 --> 00:02:22,040
Test data includes both the actual data inside the product under test, as well as the data

56
00:02:22,040 --> 00:02:24,640
values used by test cases.

57
00:02:24,640 --> 00:02:29,080
As testers, we shouldn't underestimate the work to handle test data properly.

58
00:02:29,080 --> 00:02:34,320
Good data is just as important as good tests and good automation.

59
00:02:34,320 --> 00:02:38,340
So in this talk, we will dive deep into the connection between product data and test case

60
00:02:38,340 --> 00:02:39,340
data.

61
00:02:39,340 --> 00:02:43,200
We will learn how to pick the right strategies for handling both, including how to avoid

62
00:02:43,200 --> 00:02:45,260
data collisions when testing.

63
00:02:45,260 --> 00:02:49,560
By the end, you'll know how to manage the test data nightmare for your own test projects,

64
00:02:49,560 --> 00:02:54,440
whether you're testing a Django app, a Flask app, some other Python project, or something

65
00:02:54,440 --> 00:02:57,000
written in a completely different language.

66
00:02:57,000 --> 00:02:59,200
Let's learn.

67
00:02:59,200 --> 00:03:04,280
Let's say we have an application for a bank to provide loans.

68
00:03:04,280 --> 00:03:10,880
The bank could configure this application for many different types of loans, such as

69
00:03:10,880 --> 00:03:16,680
a home mortgage loan, a car purchase, or a student loan.

70
00:03:16,680 --> 00:03:24,360
All the information the bank needs to provide the loans is stored in data in the database.

71
00:03:25,240 --> 00:03:26,840
It's part of the system.

72
00:03:26,840 --> 00:03:29,440
Each loan product is different.

73
00:03:29,440 --> 00:03:34,220
It comes in with its own rate, maturity, and payment schedule.

74
00:03:34,220 --> 00:03:40,360
The bank must also store information about borrowers, funding curves, profitability targets,

75
00:03:40,360 --> 00:03:41,740
all that stuff.

76
00:03:41,740 --> 00:03:44,160
It's fairly complicated.

77
00:03:44,160 --> 00:03:49,880
Testing requires that all data already be present in the system as a prerequisite.

78
00:03:49,880 --> 00:03:54,440
We could write a simple test case to exercise the basic application behavior.

79
00:03:54,440 --> 00:04:02,280
A scenario for creating a new loan application starts with, given the Chrome browser is open

80
00:04:02,280 --> 00:04:10,080
and the page myloanapp.com is loaded, when the user creates a new loan for the home mortgage

81
00:04:10,080 --> 00:04:18,880
and the user enters all their personal identification information, and the user submits the application,

82
00:04:18,880 --> 00:04:22,760
and the page displays a success message with a reference number, and the application is

83
00:04:22,760 --> 00:04:26,240
sent to the bank, or so we hope.

84
00:04:26,240 --> 00:04:32,120
Bear in mind, a real loan application will probably have several pages of information,

85
00:04:32,120 --> 00:04:34,320
but let's keep our example simple for here today.

86
00:04:34,320 --> 00:04:38,360
I know it's a Sunday afternoon at PyCon.

87
00:04:38,360 --> 00:04:41,000
We're all here, which is awesome.

88
00:04:41,000 --> 00:04:45,000
This test creates and submits a new home mortgage loan application for the user.

89
00:04:45,000 --> 00:04:47,160
We can all agree on that.

90
00:04:47,160 --> 00:04:51,640
There are many test data points in this short scenario.

91
00:04:51,640 --> 00:04:55,520
Most apparently, there's the user's personal information.

92
00:04:55,520 --> 00:05:02,080
There's the type of loan, the record of the loan application sent to the bank, the reference

93
00:05:02,080 --> 00:05:09,160
number shown to the user, and furthermore, the URL is configuration info, and the browser

94
00:05:09,160 --> 00:05:12,320
is arguably a type of test input.

95
00:05:12,320 --> 00:05:16,720
Test data is everywhere in this short, simple scenario.

96
00:05:16,720 --> 00:05:21,480
The data is inextricable from the test.

97
00:05:21,480 --> 00:05:26,800
Without specific data, this test would be meaningless.

98
00:05:26,800 --> 00:05:27,800
Everybody with me?

99
00:05:27,800 --> 00:05:28,800
Yeah, good.

100
00:05:28,800 --> 00:05:34,480
Unfortunately, the term test data is ambiguous.

101
00:05:34,480 --> 00:05:38,040
We've applied it to both the product data in the loan web app, as well as to the various

102
00:05:38,040 --> 00:05:42,800
pieces of test case data that make even the most basic test work.

103
00:05:42,800 --> 00:05:47,360
Product data refers to real data living in the software system.

104
00:05:47,360 --> 00:05:51,920
For the loan web app, product data includes all the bank's product configurations and

105
00:05:51,920 --> 00:05:54,640
lending information.

106
00:05:54,640 --> 00:05:59,040
Test case data, however, refers to data used to define test cases.

107
00:05:59,040 --> 00:06:04,880
It may include values to enter into the product under test, inputs controlling how the testing

108
00:06:04,880 --> 00:06:09,200
is performed, or records to retrieve from the product.

109
00:06:09,200 --> 00:06:14,800
In the latter case, test case data is a reflection of product data.

110
00:06:14,800 --> 00:06:19,320
Its values refer to entities existing in the product data.

111
00:06:19,320 --> 00:06:22,880
The two types of test data are separate but connected.

112
00:06:22,880 --> 00:06:30,800
Distinguishing these two types of data is important to avoid confusion.

113
00:06:30,800 --> 00:06:34,320
The dependency of test case data on product data can be brittle.

114
00:06:34,320 --> 00:06:38,760
For example, consider our test case step to create a new loan application for a home

115
00:06:38,760 --> 00:06:40,060
mortgage.

116
00:06:40,060 --> 00:06:45,520
This step works as long as the bank's web app is configured for home mortgages.

117
00:06:45,520 --> 00:06:52,320
However, the product data could be changed at any time, just like product code.

118
00:06:52,320 --> 00:06:55,400
What if the specifics of a home mortgage loan change?

119
00:06:55,400 --> 00:06:59,920
What if the loan is no longer called a quote unquote home mortgage loan, but a quote unquote

120
00:06:59,920 --> 00:07:02,120
personal residential loan?

121
00:07:02,120 --> 00:07:05,800
That would make the test case break.

122
00:07:05,800 --> 00:07:11,960
Compounding breakages cause nightmares for test management.

123
00:07:11,960 --> 00:07:14,360
So how should we manage test data?

124
00:07:14,360 --> 00:07:19,440
For feature testing, test data is just as important as test cases and test code.

125
00:07:19,440 --> 00:07:23,120
How do we handle both product data and test case data appropriately?

126
00:07:23,120 --> 00:07:25,840
Are there strategies we can use to avoid brittle dependencies?

127
00:07:25,840 --> 00:07:31,280
In this talk, we'll explore multiple ways to handle both product data and test case data.

128
00:07:31,560 --> 00:07:36,880
Unfortunately, there's no universal or perfect solutions out there, but you can avoid nightmares

129
00:07:36,880 --> 00:07:40,560
by picking strategies that work well for your needs.

130
00:07:40,560 --> 00:07:44,080
Let's start with product data.

131
00:07:44,080 --> 00:07:50,480
As stated previously, product data is any live data in the product or system under test.

132
00:07:50,480 --> 00:07:54,920
In simplest terms, it's everything in the database.

133
00:07:54,960 --> 00:08:01,560
It can include user accounts, administration settings, product customizations, records

134
00:08:01,560 --> 00:08:06,960
created by users, files uploaded by users, so on and so forth.

135
00:08:06,960 --> 00:08:10,760
For that example, loan application we were talking about, product data would include

136
00:08:10,760 --> 00:08:15,960
things like the user accounts, the loan product settings, the loan applications, and the behind-the-scenes

137
00:08:15,960 --> 00:08:19,440
bank data.

138
00:08:19,440 --> 00:08:24,240
Data must be present in a product as a prerequisite for most testing.

139
00:08:24,240 --> 00:08:27,840
There are two primary ways to get that data in the system.

140
00:08:27,840 --> 00:08:31,640
On one hand, you can set up the data before running your tests.

141
00:08:31,640 --> 00:08:35,240
This would be static data creation.

142
00:08:35,240 --> 00:08:42,340
For example, a loan web app could be set up with a set of pre-registered users and a collection

143
00:08:42,340 --> 00:08:44,400
of loan types.

144
00:08:44,400 --> 00:08:51,520
Test cases, whether they are manual or automated, can presume that this static data is already

145
00:08:51,520 --> 00:08:55,440
in the system and simply refer to it.

146
00:08:55,440 --> 00:08:59,720
Static data preparation is a good strategy for complicated data or for data that is slow

147
00:08:59,720 --> 00:09:02,160
to create dynamically.

148
00:09:02,160 --> 00:09:06,580
For example, user accounts may need email verification, so it might be easier for automated

149
00:09:06,580 --> 00:09:11,640
tests to simply use a set of pre-registered users.

150
00:09:11,640 --> 00:09:16,240
Tests will run faster if they can simply reference existing data instead of creating new data

151
00:09:16,240 --> 00:09:17,920
each time.

152
00:09:18,320 --> 00:09:21,880
However, static data must be maintained.

153
00:09:21,880 --> 00:09:26,120
Any changes to static data could impact tests too.

154
00:09:26,120 --> 00:09:30,560
Static data may also become stale over time as data formats are updated or if data is

155
00:09:30,560 --> 00:09:35,240
time-sensitive, like a time series.

156
00:09:35,240 --> 00:09:39,680
On the other hand, you could set up data during test execution.

157
00:09:39,680 --> 00:09:45,840
This would be what we call dynamic data creation.

158
00:09:45,880 --> 00:09:51,280
In the example loan test case, the loan application document is dynamically created.

159
00:09:51,280 --> 00:09:55,240
The test does not reference an existing loan application.

160
00:09:55,240 --> 00:09:58,120
It creates a new one.

161
00:09:58,120 --> 00:10:03,120
Dynamically created records avoid the brittleness of hard references to static data.

162
00:10:03,120 --> 00:10:08,360
They can also be used exclusively by the current test case, protecting them from interruptions

163
00:10:08,360 --> 00:10:10,880
by other test cases.

164
00:10:10,880 --> 00:10:14,160
The main downside of dynamic data prep is the execution time.

165
00:10:14,160 --> 00:10:17,600
It does slow down your tests.

166
00:10:17,600 --> 00:10:24,480
Dynamically created data is essentially disposable too, so it should be cleaned up eventually.

167
00:10:24,480 --> 00:10:26,120
Which strategy is best?

168
00:10:26,120 --> 00:10:30,880
Typically, testing requires both strategies together.

169
00:10:30,880 --> 00:10:36,120
Data that is slow to set up or considered immutable should use static data preparation,

170
00:10:36,120 --> 00:10:42,480
while data that is quick and easy to set up should use dynamic data preparation.

171
00:10:42,480 --> 00:10:47,320
When I develop test solutions, I prefer to create as much data as possible dynamically

172
00:10:47,320 --> 00:10:51,560
per test case to try to preserve test case independence.

173
00:10:51,560 --> 00:10:56,200
When a test creates the data it needs dynamically, it will be the only one referring to it.

174
00:10:56,200 --> 00:11:00,120
And there is a much lower risk of collisions.

175
00:11:00,120 --> 00:11:04,520
These two data prep strategies are a bit complicated when implementing them.

176
00:11:04,520 --> 00:11:08,320
Dynamic data prep really depends upon the test case that you're doing.

177
00:11:08,320 --> 00:11:14,040
So for example, with that lone test case, we had to create a new record for that instance.

178
00:11:14,040 --> 00:11:19,000
However, static data prep has a few general strategies that are independent of the test

179
00:11:19,000 --> 00:11:22,660
cases that use them.

180
00:11:22,660 --> 00:11:26,160
The simplest data prep strategy is manual configuration.

181
00:11:26,160 --> 00:11:29,040
How many people have done this in their systems before?

182
00:11:29,040 --> 00:11:32,000
Yeah, yeah, I know.

183
00:11:32,000 --> 00:11:33,000
Yep.

184
00:11:33,000 --> 00:11:34,920
That's exactly what it sounds like.

185
00:11:34,920 --> 00:11:39,240
Users log into the system and manually create whatever records they need to be in the system.

186
00:11:39,240 --> 00:11:43,800
That can include creating users, configuring settings, and saving records.

187
00:11:43,800 --> 00:11:47,400
The nice thing about manual configuration is that it's low tech.

188
00:11:47,400 --> 00:11:48,580
Anyone can do it.

189
00:11:48,580 --> 00:11:51,400
You don't need fancy or complicated tools.

190
00:11:51,400 --> 00:11:54,600
However, manual configuration is slow.

191
00:11:54,600 --> 00:11:58,520
It does not scale well for large systems or large test environments.

192
00:11:58,520 --> 00:12:04,020
Furthermore, manually configured systems can easily fall into disrepair without any automated

193
00:12:04,020 --> 00:12:07,620
mechanisms for maintenance.

194
00:12:07,620 --> 00:12:11,420
Better strategy might be automated configuration.

195
00:12:11,420 --> 00:12:15,720
Rather than manually setting up everything, automated tools can create the desired data.

196
00:12:15,720 --> 00:12:17,300
This could be accomplished in many ways.

197
00:12:17,300 --> 00:12:23,600
We're using UI interactions from tests, calling REST APIs, or even possibly using tools like

198
00:12:23,600 --> 00:12:26,300
Puppet or Chef.

199
00:12:26,300 --> 00:12:29,500
Automation could generate data deterministically or randomly.

200
00:12:30,260 --> 00:12:37,340
The main benefit of automation is the ability to create fresh data at any time.

201
00:12:37,340 --> 00:12:43,260
Automation can also clean data, like scrubbing private fields or updating time-sensitive fields.

202
00:12:43,260 --> 00:12:46,940
Unfortunately, automated configuration is not a free lunch.

203
00:12:46,940 --> 00:12:50,780
It requires extra skills, and the automation code must be maintained.

204
00:12:50,780 --> 00:12:55,860
If you want a shortcut, you could try to clone the database.

205
00:12:55,860 --> 00:12:59,320
Cloning databases is easier than ever with cloud management tools.

206
00:12:59,320 --> 00:13:04,800
You can maintain one database in a golden state and create a copy before running tests.

207
00:13:04,800 --> 00:13:08,560
Once testing is complete, the copy could be destroyed.

208
00:13:08,560 --> 00:13:12,480
Granular cleanup would not be necessary.

209
00:13:12,480 --> 00:13:16,480
Database clones make it easy to copy all data at once without worrying about any damage

210
00:13:16,480 --> 00:13:18,960
that rogue testing could cause.

211
00:13:18,960 --> 00:13:26,000
However, databases can have a lot of data, so cloning large ones may not be practical.

212
00:13:26,000 --> 00:13:29,720
You may also need extra refinement to scrub special fields and hook them up properly into

213
00:13:29,720 --> 00:13:31,720
your systems.

214
00:13:31,720 --> 00:13:38,200
Finally, if managing real data is too much of a hassle, then you could mock your endpoints.

215
00:13:38,200 --> 00:13:42,600
This would completely remove dependencies on databases and even services.

216
00:13:42,600 --> 00:13:46,880
All data returned by the mocks will be deterministic, too, yielding consistent results for your

217
00:13:46,880 --> 00:13:48,680
functional tests.

218
00:13:48,680 --> 00:13:50,720
But mocks are not always a good solution.

219
00:13:50,720 --> 00:13:55,560
They often require a lot of extra effort to set up, and mock data can make tests overlook

220
00:13:55,560 --> 00:13:58,720
unpredicted real-world variations.

221
00:13:58,720 --> 00:14:05,280
Mocks also mean that tests will not truly be end-to-end in coverage.

222
00:14:05,280 --> 00:14:07,580
These strategies can also work together.

223
00:14:07,580 --> 00:14:12,040
For example, you could use automated scripts to configure product data in a golden database,

224
00:14:12,040 --> 00:14:14,800
and then you could make clones of that database.

225
00:14:14,800 --> 00:14:19,100
In another example, in a large testing environment, you could choose to mock some endpoints while

226
00:14:19,100 --> 00:14:22,720
using real data for others.

227
00:14:22,720 --> 00:14:26,840
Many times, we want to use production or production-like data in our systems to mirror

228
00:14:26,840 --> 00:14:28,440
the real world.

229
00:14:28,440 --> 00:14:32,760
Unfortunately, production data has things like personally identifiable information in

230
00:14:32,760 --> 00:14:36,100
it, and it's not always safe to share.

231
00:14:36,100 --> 00:14:40,320
Many things might be like credit card numbers or social security numbers that must be kept

232
00:14:40,320 --> 00:14:42,240
private.

233
00:14:42,240 --> 00:14:46,640
Generating data synthetically is a great way to avoid those roadblocks.

234
00:14:46,640 --> 00:14:51,360
For example, Redel AI is an awesome tool that generates synthetic data that is statistically

235
00:14:51,360 --> 00:14:54,800
accurate, privacy-protected, and safe to share.

236
00:14:54,800 --> 00:15:01,840
You can use Redel AI with any of these static data prep strategies.

237
00:15:01,840 --> 00:15:04,680
There are multiple factors that should be considered when deciding the best strategy

238
00:15:04,680 --> 00:15:06,800
for static data prep.

239
00:15:06,800 --> 00:15:07,800
How big is your data?

240
00:15:07,800 --> 00:15:14,680
If it's small, manual configuration can probably be sufficient.

241
00:15:14,680 --> 00:15:20,160
But if it's large, then automation may be required.

242
00:15:20,160 --> 00:15:22,680
How fresh does the data need to be?

243
00:15:22,680 --> 00:15:27,960
If data is time-sensitive, then automation will be needed to keep it up to date.

244
00:15:27,960 --> 00:15:30,760
How frequently will the data need to be updated?

245
00:15:30,760 --> 00:15:36,240
Again, automation can help for frequent updates, and synthetic data generation tools like Redel

246
00:15:36,240 --> 00:15:39,360
AI really shine here.

247
00:15:39,360 --> 00:15:45,040
How difficult will it be to try advanced tricks like mocking or cloning databases?

248
00:15:45,040 --> 00:15:49,200
This may be especially difficult for old or legacy systems.

249
00:15:49,200 --> 00:15:52,960
Is there any bureaucracy in the way of automated solutions?

250
00:15:52,960 --> 00:15:55,720
Hey, company red tape happens.

251
00:15:55,720 --> 00:15:59,840
Not every organization has efficient or even healthy culture.

252
00:15:59,840 --> 00:16:04,880
Bureaucracy can stonewall advanced solutions that need extra support.

253
00:16:04,880 --> 00:16:10,640
Do folks have the skills required for automation, database administration, or mocks?

254
00:16:10,640 --> 00:16:15,760
Skill level may be a barrier at first, but with training and learning, you can overcome

255
00:16:15,760 --> 00:16:19,180
any of those limitations.

256
00:16:19,180 --> 00:16:21,940
And finally, what about the cost?

257
00:16:21,940 --> 00:16:24,720
Each data prep strategy has a cost.

258
00:16:24,720 --> 00:16:31,500
There should be a cost-benefit analysis done when your team is deciding.

259
00:16:31,500 --> 00:16:34,380
So that's how to handle product data.

260
00:16:34,380 --> 00:16:35,380
Everybody still with me?

261
00:16:35,380 --> 00:16:36,380
Still awake?

262
00:16:36,380 --> 00:16:37,380
Yeah?

263
00:16:37,380 --> 00:16:38,380
Woo!

264
00:16:38,380 --> 00:16:39,380
Awesome.

265
00:16:39,380 --> 00:16:40,380
Awesome.

266
00:16:40,380 --> 00:16:41,380
I love seeing everybody here.

267
00:16:41,380 --> 00:16:42,380
This is so cool.

268
00:16:42,380 --> 00:16:43,660
So what about test case data?

269
00:16:43,660 --> 00:16:46,220
We're only halfway through.

270
00:16:46,220 --> 00:16:49,580
Let's look at test case data next.

271
00:16:49,580 --> 00:16:52,020
Test case data is inherently part of test cases.

272
00:16:52,020 --> 00:16:55,860
Let's revisit that example test case from earlier.

273
00:16:55,860 --> 00:16:59,420
As we saw before, there are multiple bits of test data throughout the steps of this

274
00:16:59,420 --> 00:17:00,980
short scenario.

275
00:17:00,980 --> 00:17:03,340
They represent different types of test case data.

276
00:17:03,340 --> 00:17:06,700
Let's look at the first step.

277
00:17:06,700 --> 00:17:12,480
Given the Chrome browser is open, Chrome browser is test data because it specifies the type

278
00:17:12,480 --> 00:17:15,260
of web browser in which to load the app.

279
00:17:15,260 --> 00:17:19,340
This is what we call a test control input.

280
00:17:19,340 --> 00:17:24,860
It directs how tests will run rather than specifying anything about feature behavior.

281
00:17:24,860 --> 00:17:29,740
Theoretically, this test should run the same on any browser, but the steps dictate that

282
00:17:29,740 --> 00:17:31,900
the test should run on Chrome.

283
00:17:31,900 --> 00:17:35,020
This is best practice.

284
00:17:35,020 --> 00:17:37,420
Don't do this.

285
00:17:37,420 --> 00:17:41,020
Test control inputs should not be hard-coded into test automation code.

286
00:17:41,020 --> 00:17:44,500
Instead, they should be passed into automation as inputs.

287
00:17:44,500 --> 00:17:46,420
That way, tests can easily be retargeted.

288
00:17:46,420 --> 00:17:48,980
There's a few ways to do this.

289
00:17:48,980 --> 00:17:52,740
The simplest way would be to create a flat file with input values.

290
00:17:52,740 --> 00:17:57,860
I recommend using a format like JSON or YAML because they're easy to write, easy to read,

291
00:17:57,860 --> 00:18:01,020
and easy for programming languages to parse.

292
00:18:01,020 --> 00:18:03,460
They can also have line-by-line diffs.

293
00:18:03,460 --> 00:18:10,140
Test automation code can read the file before any tests start, and it can inject input values

294
00:18:10,140 --> 00:18:12,580
as appropriate.

295
00:18:12,580 --> 00:18:16,980
For example, using this JSON file, automation could read the browser type and construct

296
00:18:16,980 --> 00:18:22,340
a WebDriver instance or Playwright page for Chrome for each test.

297
00:18:22,340 --> 00:18:25,980
The path for the input file would need to be hard-coded into the automation, but it

298
00:18:25,980 --> 00:18:31,740
could be as simple as standard file name in the current directory.

299
00:18:31,740 --> 00:18:35,620
Another way to handle input is using environment variables.

300
00:18:35,620 --> 00:18:39,820
Tests could set variables from a system shell or profile, and automation could read those

301
00:18:39,820 --> 00:18:42,000
variables by name.

302
00:18:42,000 --> 00:18:47,080
This can be useful for integrations with continuous integration servers or Docker containers.

303
00:18:47,080 --> 00:18:51,760
However, it can be a little more dangerous because anyone could change the variable values.

304
00:18:51,760 --> 00:18:58,560
Again, automation would read them in before any tests run and handle them appropriately.

305
00:18:58,560 --> 00:19:03,300
Let's remove that hard-coded step for browser type from the test scenario.

306
00:19:03,300 --> 00:19:06,520
This can be handled as an automation-level concern.

307
00:19:06,520 --> 00:19:11,360
Next, let's look at a second type of test case data.

308
00:19:11,360 --> 00:19:13,840
Notice how the URL here is hard-coded.

309
00:19:13,840 --> 00:19:15,200
This is also not a good practice.

310
00:19:15,200 --> 00:19:18,480
Don't do this in the real world.

311
00:19:18,480 --> 00:19:26,000
Typically, development teams host multiple instances of products under development, like

312
00:19:26,000 --> 00:19:32,000
a developer environment or a staging environment or a test environment.

313
00:19:32,000 --> 00:19:36,840
Hard-coding configuration information like this limits where tests can run.

314
00:19:36,840 --> 00:19:42,120
The information about a product's configuration is called configuration metadata.

315
00:19:42,120 --> 00:19:49,120
This can include things like URLs, usernames, passwords, and possibly other descriptors.

316
00:19:49,120 --> 00:19:52,060
There's a few ways to handle config metadata.

317
00:19:52,060 --> 00:19:56,320
You can use flat files or environment variables like for test control inputs.

318
00:19:56,320 --> 00:20:01,600
However, I do recommend using flat files, and I also recommend separating test control

319
00:20:01,600 --> 00:20:04,840
inputs from configuration metadata.

320
00:20:04,840 --> 00:20:11,240
Create an input to refer to the target configuration and store multiple configurations in the configuration

321
00:20:11,240 --> 00:20:13,000
metadata files.

322
00:20:13,000 --> 00:20:20,660
That way, testers can change those one or a few simple inputs to target any configuration,

323
00:20:20,660 --> 00:20:27,040
and they won't need to change multiple configuration fields regularly.

324
00:20:27,040 --> 00:20:32,240
If you want to be fancy, you could create a web service to provide config metadata,

325
00:20:32,240 --> 00:20:37,240
something like Azure Key Vault or whatever the AWS thing is.

326
00:20:37,240 --> 00:20:42,720
But you don't really need to do that unless you want to go big or you need to keep your

327
00:20:42,720 --> 00:20:44,840
passwords and secrets safe.

328
00:20:44,840 --> 00:20:48,000
So it may be overkill.

329
00:20:48,000 --> 00:20:54,760
Either way, the test case step can be rewritten to refer more generically to the web app.

330
00:20:54,760 --> 00:21:01,280
Automation can select the target environment using the inputs and config metadata.

331
00:21:01,320 --> 00:21:04,640
By the way, did anybody see that YAML shirt from CircleCI?

332
00:21:04,640 --> 00:21:08,080
That's pretty funny, wasn't it?

333
00:21:08,080 --> 00:21:10,360
All right.

334
00:21:10,360 --> 00:21:15,600
The remaining pieces of test case data all fall into the category called test case values.

335
00:21:15,600 --> 00:21:20,360
These values pertain directly to the behavior exercised by the test, not to any configuration

336
00:21:20,360 --> 00:21:21,640
factor.

337
00:21:21,640 --> 00:21:23,920
Even in this classification, guess what?

338
00:21:23,920 --> 00:21:26,760
There are subtypes.

339
00:21:26,760 --> 00:21:31,080
First kind of test case data is a literal value.

340
00:21:31,880 --> 00:21:33,880
These are values that are hard-coded in the test.

341
00:21:33,880 --> 00:21:39,400
In this example, the table of personal info contains literal values.

342
00:21:39,400 --> 00:21:44,360
Literals are simple to use and they provide specification by example.

343
00:21:44,360 --> 00:21:48,880
Literals should also be independent of any statically created product data.

344
00:21:48,880 --> 00:21:53,780
They should be values that can be safely originated by the test case.

345
00:21:53,780 --> 00:21:58,840
The literals in this info table will be entered as input values into the web app.

346
00:21:58,920 --> 00:22:03,800
Theoretically, they could be any values.

347
00:22:03,800 --> 00:22:07,760
The second kind of test case value is an output reference.

348
00:22:07,760 --> 00:22:12,360
These are values that are typically retrieved from the product under test.

349
00:22:12,360 --> 00:22:16,440
They are the outputs generated by exercising a behavior.

350
00:22:16,440 --> 00:22:21,440
In this example test, the reference number can be scraped from the success page and verified

351
00:22:21,440 --> 00:22:23,560
for correct format.

352
00:22:23,560 --> 00:22:28,080
The loan application can be retrieved from the web app's backend to verify that it was

353
00:22:28,080 --> 00:22:30,080
correctly submitted.

354
00:22:30,080 --> 00:22:36,680
These values cannot be literals because they originate from the product.

355
00:22:36,680 --> 00:22:41,880
Tests must refer to them by reference and retrieve their values from the product.

356
00:22:41,880 --> 00:22:47,240
As a side note, this test dynamically creates the loan application.

357
00:22:47,240 --> 00:22:51,840
Example of dynamic creation.

358
00:22:51,840 --> 00:22:55,460
The third and final kind of test case value is the trickiest.

359
00:22:55,460 --> 00:22:59,700
The input reference.

360
00:22:59,700 --> 00:23:03,340
At first, these values may look like literals.

361
00:23:03,340 --> 00:23:09,300
However, input references are values that directly refer to product data.

362
00:23:09,300 --> 00:23:14,860
While personal info like name and address are created dynamically by the test case,

363
00:23:14,860 --> 00:23:19,900
the name of the loan type refers to the loan configuration in your application.

364
00:23:19,900 --> 00:23:23,540
Thus, this test has an input dependency.

365
00:23:23,540 --> 00:23:28,260
It must specify the type of loan and that loan type must already exist in the product

366
00:23:28,260 --> 00:23:30,140
data.

367
00:23:30,140 --> 00:23:33,580
The simplest way to write this test is to simply hard code the reference.

368
00:23:33,580 --> 00:23:34,780
That's what's done here.

369
00:23:34,780 --> 00:23:40,160
The name home mortgage refers to the name of the loan type in the web app.

370
00:23:40,160 --> 00:23:43,620
Automation can use that name when selecting the loan type like from a button or a drop

371
00:23:43,620 --> 00:23:45,220
down.

372
00:23:45,220 --> 00:23:50,020
Hard coded references make it easy to write tests, but they require statically prep data

373
00:23:50,020 --> 00:23:52,620
to exist in the system.

374
00:23:52,620 --> 00:23:56,340
This has also become hard to maintain when the product data changes or when the same

375
00:23:56,340 --> 00:24:01,260
test must run against different configurations with different names.

376
00:24:01,260 --> 00:24:07,860
One way to avoid the pain of static data is to dynamically create these records or configurations.

377
00:24:07,860 --> 00:24:11,300
If the test calls the back end to create a new loan product named home mortgage for each

378
00:24:11,300 --> 00:24:14,980
test run, then static prep isn't needed.

379
00:24:14,980 --> 00:24:18,620
However, we already know the pain points of dynamic prep.

380
00:24:18,620 --> 00:24:23,820
So in this case, let's say dynamically creating a new loan type is just too slow.

381
00:24:23,820 --> 00:24:28,420
More robust solution could be what we call data discovery.

382
00:24:28,420 --> 00:24:33,220
Let's say the target web app is already configured with multiple acceptable loan types.

383
00:24:33,220 --> 00:24:39,780
Instead of hard coding the names of the desired loan type, the test could create, excuse me,

384
00:24:39,780 --> 00:24:44,100
the test could describe the loan type and then use automation to search the web app's

385
00:24:44,100 --> 00:24:48,540
configuration to find a loan type matching the desired criteria.

386
00:24:48,540 --> 00:24:52,220
For example, if different regions of a bank have different names for this type of loan,

387
00:24:52,220 --> 00:24:56,220
the discovery mechanism could look into the config for a satisfactory home mortgage loan

388
00:24:56,220 --> 00:25:01,260
type and return the specific name for whatever region you're in.

389
00:25:01,260 --> 00:25:05,620
Discovery enables tests to search existing product data for required records instead

390
00:25:05,620 --> 00:25:08,180
of hard coding those records.

391
00:25:08,180 --> 00:25:11,540
Discovery makes tests more resilient to changes in product data.

392
00:25:11,540 --> 00:25:16,260
It's great when testing multiple environments with ever so slight differences between them.

393
00:25:16,660 --> 00:25:21,380
However, it does require extra coding and it may be overkill for small projects.

394
00:25:24,300 --> 00:25:26,660
Whoo, who's still with me?

395
00:25:26,660 --> 00:25:27,660
I'm not sure I'm still with me.

396
00:25:27,660 --> 00:25:28,420
Where are you, Pikachu?

397
00:25:28,420 --> 00:25:29,900
Let's get him.

398
00:25:29,900 --> 00:25:35,300
That's a lot of information about test case data, right?

399
00:25:35,300 --> 00:25:36,940
Here's summary.

400
00:25:36,940 --> 00:25:43,340
Test control inputs direct how tests will be run, not what behavior is covered.

401
00:25:43,380 --> 00:25:48,420
They should be supplied via flat files or environment variables.

402
00:25:48,420 --> 00:25:52,700
Configuration metadata describe product configuration for the target environment.

403
00:25:52,700 --> 00:25:56,820
They should be supplied via config files or service API calls.

404
00:25:56,820 --> 00:26:00,700
And test case values direct the behavior covered by the test.

405
00:26:00,700 --> 00:26:04,860
They may be literals, output references, or input references.

406
00:26:04,860 --> 00:26:07,180
And input references may be hard coded or discovered.

407
00:26:07,180 --> 00:26:10,620
If you want to take a picture of a slide, take this one.

408
00:26:10,620 --> 00:26:11,620
Here's your chance.

409
00:26:12,460 --> 00:26:14,100
Whoo.

410
00:26:14,100 --> 00:26:17,860
So at this point, you're probably thinking, wow, that's a ton of information,

411
00:26:17,860 --> 00:26:20,180
especially for a Sunday afternoon at PyCon.

412
00:26:20,180 --> 00:26:21,020
That's it, right?

413
00:26:21,020 --> 00:26:21,460
We're done.

414
00:26:21,460 --> 00:26:22,060
We're good.

415
00:26:22,060 --> 00:26:23,380
Time for Q&A.

416
00:26:23,380 --> 00:26:26,460
Well, frightfully, Nightmare's not over yet.

417
00:26:26,460 --> 00:26:28,700
There's one more problem to address.

418
00:26:28,700 --> 00:26:30,900
Collisions.

419
00:26:30,900 --> 00:26:35,540
Collisions can happen whenever multiple actors operate on shared resources.

420
00:26:35,540 --> 00:26:40,100
For example, they could happen whenever multiple testers simultaneously access the system

421
00:26:40,100 --> 00:26:43,940
or when automated tests run in parallel.

422
00:26:43,940 --> 00:26:47,020
Additional considerations apply.

423
00:26:47,020 --> 00:26:50,300
First and foremost, isolate your test environments.

424
00:26:50,300 --> 00:26:53,260
Please isolate your test environments.

425
00:26:53,260 --> 00:26:56,580
Prevent external actors from interrupting.

426
00:26:56,580 --> 00:27:00,180
If you have a shared test environment, block people from using it while tests are running

427
00:27:00,180 --> 00:27:01,940
or run off hours or something.

428
00:27:01,940 --> 00:27:03,620
If you're containerized, great.

429
00:27:03,620 --> 00:27:05,060
Run containers by yourself.

430
00:27:05,060 --> 00:27:08,780
Don't let anybody touch them.

431
00:27:08,820 --> 00:27:12,860
Try to get things as isolated as much as possible.

432
00:27:12,860 --> 00:27:16,460
Second, treat any shared data as immutable.

433
00:27:16,460 --> 00:27:20,220
When I say immutable, I mean constant, not changing.

434
00:27:20,220 --> 00:27:23,180
Nobody can go in there and tweak it.

435
00:27:23,180 --> 00:27:26,580
If tests run in parallel against the test environment, they may have to use the same

436
00:27:26,580 --> 00:27:27,940
product data.

437
00:27:27,940 --> 00:27:32,180
Or if an application has multiple components, certain components may be difficult to isolate

438
00:27:32,180 --> 00:27:33,180
for testing.

439
00:27:33,220 --> 00:27:38,740
So treat any shared data as constant so one thing can't mess up another.

440
00:27:38,740 --> 00:27:43,940
Third and finally, use dynamic data prep as much as possible.

441
00:27:43,940 --> 00:27:48,020
Tests can't collide on data they don't share.

442
00:27:48,020 --> 00:27:52,300
Keep statically prepared product data to a minimum.

443
00:27:52,300 --> 00:27:55,660
You will need it, but keep it minimal.

444
00:27:55,660 --> 00:27:59,140
Statically created data is more likely to become shared data, and shared data is more

445
00:27:59,140 --> 00:28:01,540
likely to cause collisions.

446
00:28:02,500 --> 00:28:04,260
Boom!

447
00:28:04,260 --> 00:28:05,260
We made it.

448
00:28:05,260 --> 00:28:07,820
We covered lots of information today.

449
00:28:07,820 --> 00:28:13,660
So again, I would say here's your money shot for a slide.

450
00:28:13,660 --> 00:28:16,700
There's two types of test data, product data, test case data.

451
00:28:16,700 --> 00:28:18,900
Product data can be static or dynamic.

452
00:28:18,900 --> 00:28:23,460
Test case data either controls how tests run or reflect the product data.

453
00:28:23,460 --> 00:28:25,940
Handle your references and shared data carefully.

454
00:28:25,940 --> 00:28:30,180
And overall, if there's one message you take away other than Pokemon is awesome, choose

455
00:28:30,260 --> 00:28:33,500
the best strategy to defeat your nightmares.

456
00:28:33,500 --> 00:28:35,140
Every product is different.

457
00:28:35,140 --> 00:28:36,700
Every team is different.

458
00:28:36,700 --> 00:28:40,500
Take the strategies I shared in this talk as suggestions.

459
00:28:40,500 --> 00:28:42,700
So thank you again for listening to my talk.

460
00:28:42,700 --> 00:28:45,460
Again, my name is Pandy Knight and I'm the Automation Panda.

461
00:28:45,460 --> 00:28:47,460
Be sure to check out my blog and follow me on Twitter.

462
00:28:47,460 --> 00:28:50,380
And I hope you enjoy the rest of PyCon 2022.

