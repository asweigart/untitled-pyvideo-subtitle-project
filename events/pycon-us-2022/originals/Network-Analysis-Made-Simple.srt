1
00:00:00,000 --> 00:00:07,840
Welcome, everybody.

2
00:00:07,840 --> 00:00:11,240
Thanks for coming to today's tutorial.

3
00:00:11,240 --> 00:00:13,440
Today's tutorial is on network analysis made simple.

4
00:00:13,440 --> 00:00:20,200
It's a tutorial that has been long running since, I think, 2015, seven years long thus

5
00:00:20,200 --> 00:00:21,440
far.

6
00:00:21,440 --> 00:00:26,680
We've updated Myrtle in the back, is my co-author for the tutorial.

7
00:00:26,680 --> 00:00:33,640
He is also one of the core developers of NetworkX, which is a core package that we use inside

8
00:00:33,640 --> 00:00:38,920
the tutorial for teaching network analysis and graph theory and applied network science

9
00:00:38,920 --> 00:00:40,560
and all that good stuff.

10
00:00:40,560 --> 00:00:49,200
So today you basically have access to a core developer of NetworkX who can answer lots

11
00:00:49,200 --> 00:00:52,920
and lots and lots of questions about NetworkX and network science as well.

12
00:00:53,280 --> 00:00:59,960
I've been teaching this tutorial with Myrtle basically since my days in grad school, 2015

13
00:00:59,960 --> 00:01:00,960
onwards.

14
00:01:00,960 --> 00:01:03,240
We've progressively updated the material.

15
00:01:03,240 --> 00:01:11,200
It is very much written from the standpoint of someone who did not understand network

16
00:01:11,200 --> 00:01:17,520
science in the past and needed to write teaching material to help learn network science.

17
00:01:17,520 --> 00:01:21,760
Learn by teaching is one of the ways that I have found to be the most effective for

18
00:01:21,800 --> 00:01:23,160
me to pick up anything new.

19
00:01:23,160 --> 00:01:24,200
It is really written.

20
00:01:24,200 --> 00:01:29,640
We try to write this from the perspective of a relative beginner, someone who doesn't

21
00:01:29,640 --> 00:01:35,000
really know network science, wants to get into network science, needs a little bit of

22
00:01:35,000 --> 00:01:39,560
help with the language and some grounding concepts, and then that forms your launch

23
00:01:39,560 --> 00:01:45,800
pad for exploring the wonderful world of network, applied network analysis and graph theory.

24
00:01:45,800 --> 00:01:52,720
So today, just now, we've tried to do a whole bunch of setup debugging issues.

25
00:01:52,720 --> 00:01:57,200
So I do want to raise a few things for all of you.

26
00:01:57,200 --> 00:02:03,440
So firstly, if you're not set up on either, on any one of the three options that we have,

27
00:02:03,440 --> 00:02:10,920
that is binder, VS code, local conda, slash VN installation, then raise your hand and

28
00:02:10,920 --> 00:02:14,680
then Riddle will come and help figure out the easiest way for you to get set up with

29
00:02:14,680 --> 00:02:16,120
the material.

30
00:02:16,120 --> 00:02:21,320
In order of priority, usually we would say go on binder because we don't want you to

31
00:02:21,320 --> 00:02:24,720
fiddle with local setup, right?

32
00:02:24,720 --> 00:02:31,600
That said, recently binder has been facing some financial constraints, and so we want

33
00:02:31,600 --> 00:02:37,280
to reserve binder's capacity, which is now limited, for those who really would struggle

34
00:02:37,280 --> 00:02:40,320
with getting set up on their local machine.

35
00:02:40,320 --> 00:02:47,040
So for today's tutorial, the order of priority is if you can get set up with VS code Dockerized

36
00:02:47,040 --> 00:02:51,360
dev containers or with a conda environment locally, then that's preferable.

37
00:02:51,360 --> 00:02:56,000
But if you can't, then take the easy way out, click on binder.

38
00:02:56,000 --> 00:03:02,680
If you get any issues on binder, basically the thing you need to do is refresh or open

39
00:03:02,680 --> 00:03:08,020
like network analysis material, made simple in incognito mode and refresh and refresh

40
00:03:08,020 --> 00:03:09,880
and refresh until it works.

41
00:03:10,080 --> 00:03:13,760
Trust me, that is the way that you get set up on binder.

42
00:03:13,760 --> 00:03:16,480
It is the proven way.

43
00:03:16,480 --> 00:03:24,480
Now for those of you who are running the tutorial in binder, you'll probably want to know that

44
00:03:24,480 --> 00:03:25,980
there is a timeout.

45
00:03:25,980 --> 00:03:33,560
This is in order to not waste the reservation of compute resources on this public service.

46
00:03:33,560 --> 00:03:43,600
So because there's a timeout, usually I would ask people to refresh or run, execute something

47
00:03:43,600 --> 00:03:47,880
inside binder every five to ten minutes or so.

48
00:03:47,880 --> 00:03:51,680
Now that's a little bit of a hassle, and in the spirit of automating anything that can

49
00:03:51,680 --> 00:03:55,960
be automated, today I learned from Myrtle a hack.

50
00:03:55,960 --> 00:03:59,080
Myrtle used to work on binder infrastructure as well.

51
00:03:59,080 --> 00:04:00,240
So here's the hack.

52
00:04:00,280 --> 00:04:04,160
I'm highlighting a bunch of code, which is right up on the screen.

53
00:04:04,160 --> 00:04:10,280
If you are on binder, put that inside a Jupyter notebook anywhere and let it run in the background

54
00:04:10,280 --> 00:04:12,040
for the rest of the tutorial.

55
00:04:12,040 --> 00:04:14,420
That will guarantee that you never timeout.

56
00:04:14,420 --> 00:04:19,400
This is actually, if I remember correctly, what Myrtle said is that this is the official

57
00:04:19,400 --> 00:04:21,280
recommended — is that —

58
00:04:21,280 --> 00:04:22,280
Okay.

59
00:04:22,280 --> 00:04:26,240
I'm not supposed to — no, no.

60
00:04:26,240 --> 00:04:29,840
Sorry, that's Siri.

61
00:04:29,840 --> 00:04:36,740
So basically do this so that you can keep the session running, and then of course out

62
00:04:36,740 --> 00:04:42,000
of courtesy for the rest of the binder universe of users, at the end of the tutorial, close

63
00:04:42,000 --> 00:04:47,080
your binder session so that the capacity can be freed up for other people.

64
00:04:47,080 --> 00:04:48,080
All right?

65
00:04:48,080 --> 00:04:49,080
Cool.

66
00:04:49,080 --> 00:04:54,640
Final note is there will be lots of exercises in this tutorial, so this is not going to

67
00:04:54,640 --> 00:04:58,160
be me lecturing for three and a half hours.

68
00:04:58,160 --> 00:05:00,160
That would be incredibly boring.

69
00:05:00,160 --> 00:05:03,140
I don't think you'd want to hear my voice for three and a half hours.

70
00:05:03,140 --> 00:05:08,480
With respect to the masking policy, I know that just like I mentioned just now, I know

71
00:05:08,480 --> 00:05:14,260
that some people need to read lips in order to listen effectively, like that's me.

72
00:05:14,260 --> 00:05:18,480
So when I'm in teaching mode, I will have my mask off and my glasses on.

73
00:05:18,480 --> 00:05:24,160
And when I'm in social mode, it will switch to — I will switch to glasses off, mask

74
00:05:24,160 --> 00:05:25,160
on.

75
00:05:25,480 --> 00:05:31,120
Basically, this will be the way that we handle today's tutorial for the masking policy.

76
00:05:31,120 --> 00:05:33,200
All right.

77
00:05:33,200 --> 00:05:37,960
And this is mostly just so that there's clarity of audio as well for the recording that goes

78
00:05:37,960 --> 00:05:39,160
up on YouTube.

79
00:05:39,160 --> 00:05:44,400
So what I mean by social mode is like if there's any issues that show up with the code, you're

80
00:05:44,400 --> 00:05:48,120
having trouble with the exercises and you'd like a debug, you can raise your hand.

81
00:05:48,120 --> 00:05:54,320
Myrtle and I will come by and I will switch over to social mode to debug.

82
00:05:54,320 --> 00:05:55,320
Okay.

83
00:05:55,320 --> 00:05:56,320
Cool.

84
00:05:56,320 --> 00:06:03,960
Before we go on, can we just make sure everyone has one of the three ways of running code

85
00:06:03,960 --> 00:06:04,960
up and running locally?

86
00:06:04,960 --> 00:06:05,960
Like, you're all okay?

87
00:06:05,960 --> 00:06:07,960
Thumbs up if you're good?

88
00:06:07,960 --> 00:06:08,960
Awesome.

89
00:06:08,960 --> 00:06:09,960
Awesome, awesome, awesome.

90
00:06:09,960 --> 00:06:10,960
This is great.

91
00:06:10,960 --> 00:06:14,760
Then I guess we can get — we can get started then.

92
00:06:14,760 --> 00:06:20,800
So today's tutorial is a tutorial that is on network science, graph theory, and network

93
00:06:20,800 --> 00:06:23,200
analysis more generally.

94
00:06:23,200 --> 00:06:31,440
And so at the beginning, what we probably would — so what we should do at the beginning

95
00:06:31,440 --> 00:06:36,080
here is actually properly define what we mean by networks.

96
00:06:36,080 --> 00:06:42,640
And what I think is a very useful way of approaching a definition of a network is to actually first

97
00:06:42,640 --> 00:06:49,480
open up with a discussion on what we think are examples of networks and then we'll introduce

98
00:06:49,480 --> 00:06:52,080
a very formal definition of them.

99
00:06:52,080 --> 00:06:59,600
So I'd like to open up the — open this time up to have you maybe either talk with your

100
00:06:59,600 --> 00:07:05,240
neighbor or think about it on your own, but I would like you to come up with, say, two

101
00:07:05,240 --> 00:07:10,000
or three examples of networks that are kind of categorically distinct, right?

102
00:07:10,000 --> 00:07:15,520
They're not like very similar things that you might encounter in your daily life, but

103
00:07:15,520 --> 00:07:18,320
they are like very distinct examples of networks.

104
00:07:18,320 --> 00:07:21,300
So I'd like you to talk with your neighbors or think about it on your own for a minute

105
00:07:21,300 --> 00:07:25,020
or two and then we'll come and discuss that together.

106
00:07:25,020 --> 00:07:27,020
Okie dokes.

107
00:07:27,020 --> 00:07:29,020
All right.

108
00:07:29,020 --> 00:07:31,020
Let's regroup.

109
00:07:31,020 --> 00:07:33,020
Let's regroup.

110
00:07:33,020 --> 00:07:41,100
I'd love to hear from all of you some examples that you all came up with of networks that

111
00:07:41,100 --> 00:07:43,980
you've encountered in your — that you've seen before.

112
00:07:43,980 --> 00:07:47,980
Any volunteers?

113
00:07:47,980 --> 00:07:48,980
The highway system.

114
00:07:48,980 --> 00:07:49,980
Okay.

115
00:07:49,980 --> 00:07:53,980
Can you describe what makes you think that is a network?

116
00:07:53,980 --> 00:07:55,980
Right?

117
00:07:55,980 --> 00:07:57,980
Yep.

118
00:07:57,980 --> 00:07:58,980
Yep.

119
00:07:58,980 --> 00:08:04,100
So cities are the nodes in this case then and highways that connect cities are sort

120
00:08:04,100 --> 00:08:11,540
of the relations or the connectivity things that — the edges basically inside the graph.

121
00:08:11,540 --> 00:08:12,540
Cool.

122
00:08:12,540 --> 00:08:13,540
Cool.

123
00:08:13,540 --> 00:08:14,540
All right.

124
00:08:14,540 --> 00:08:15,540
Any other examples?

125
00:08:15,540 --> 00:08:16,540
Airline routes.

126
00:08:16,540 --> 00:08:17,540
Nice.

127
00:08:17,540 --> 00:08:21,940
So what would you consider to be the nodes and what would you consider to be the edges?

128
00:08:21,940 --> 00:08:24,580
The airports.

129
00:08:24,580 --> 00:08:26,580
Flights moving from one airport to the next.

130
00:08:26,580 --> 00:08:27,580
That's right.

131
00:08:27,580 --> 00:08:31,700
And we have one more in the background.

132
00:08:31,700 --> 00:08:32,700
Social network websites.

133
00:08:32,700 --> 00:08:33,700
Yes.

134
00:08:33,700 --> 00:08:34,700
Okay.

135
00:08:34,700 --> 00:08:36,860
So what would be nodes in there?

136
00:08:36,860 --> 00:08:45,860
Users are a node.

137
00:08:45,860 --> 00:08:46,860
Right.

138
00:08:47,780 --> 00:08:53,620
If say for example on Twitter someone follows another person then there's an edge defined

139
00:08:53,620 --> 00:08:54,620
there.

140
00:08:54,620 --> 00:08:55,620
Okay.

141
00:08:55,620 --> 00:08:56,620
Let's do two more.

142
00:08:56,620 --> 00:08:57,620
Any other examples in the front?

143
00:08:57,620 --> 00:08:58,620
Yes.

144
00:08:58,620 --> 00:08:59,620
Yes.

145
00:08:59,620 --> 00:09:00,620
Yes.

146
00:09:00,620 --> 00:09:01,620
Yes.

147
00:09:01,620 --> 00:09:02,620
That's right.

148
00:09:02,620 --> 00:09:11,260
So you have users are the nodes and when they make a phone call to the next person they

149
00:09:11,260 --> 00:09:12,660
have an edge between them.

150
00:09:12,660 --> 00:09:14,660
That's right.

151
00:09:14,660 --> 00:09:16,380
The pandemic.

152
00:09:16,380 --> 00:09:17,380
Right up my alley.

153
00:09:17,380 --> 00:09:18,380
Yes.

154
00:09:18,380 --> 00:09:19,380
Yes.

155
00:09:19,380 --> 00:09:20,380
Yes.

156
00:09:20,380 --> 00:09:32,620
So people in a contact tracing setting are the nodes and whether they have had contact

157
00:09:32,620 --> 00:09:35,140
or not is one definition of the edge.

158
00:09:35,140 --> 00:09:36,140
Cool.

159
00:09:36,140 --> 00:09:37,140
Right.

160
00:09:37,140 --> 00:09:43,820
So I think we all have a pretty good sense of an intuitive sense of what a network is.

161
00:09:43,820 --> 00:09:48,420
More formally networks are comprised of two sets of objects.

162
00:09:48,420 --> 00:09:49,540
So please keep this in mind.

163
00:09:49,540 --> 00:09:55,200
This is like an extremely important definition that motivates a lot of the design decisions

164
00:09:55,200 --> 00:09:58,900
of how network X and other graph packages are designed.

165
00:09:58,900 --> 00:10:01,140
There's always two sets of things.

166
00:10:01,140 --> 00:10:04,300
And by sets we really mean mathematical definition of a set.

167
00:10:04,300 --> 00:10:07,460
That means you can only have unique items inside there.

168
00:10:07,460 --> 00:10:10,020
You don't have duplicate items for example.

169
00:10:10,020 --> 00:10:11,020
All right.

170
00:10:11,100 --> 00:10:14,060
So that is the definition of a graph.

171
00:10:14,060 --> 00:10:15,500
Two sets of objects.

172
00:10:15,500 --> 00:10:21,580
One being the node set and the other being the edge set.

173
00:10:21,580 --> 00:10:25,700
Sometimes colloquially you'll get node list edge list.

174
00:10:25,700 --> 00:10:31,980
And if you are if you're not careful it's easy to mistake node list edge list for node

175
00:10:31,980 --> 00:10:36,660
set edge set and think that you can have like duplicate nodes inside the graph.

176
00:10:36,660 --> 00:10:38,620
But actually that's not correct.

177
00:10:38,620 --> 00:10:41,340
Every node is a unique entity inside a graph.

178
00:10:41,340 --> 00:10:43,580
And you cannot have duplicate nodes in a graph.

179
00:10:43,580 --> 00:10:46,060
Likewise you cannot have duplicate edges in a graph.

180
00:10:46,060 --> 00:10:52,880
Your definition of an edge and your definition of a node are very precise in the graph.

181
00:10:52,880 --> 00:11:00,360
So when it comes to other examples of networks that we might encounter I'm a computer plus

182
00:11:00,360 --> 00:11:03,160
biology person by training.

183
00:11:03,160 --> 00:11:08,340
And so I study proteins more just generally speaking.

184
00:11:08,380 --> 00:11:11,860
And protein interaction networks are also an example.

185
00:11:11,860 --> 00:11:16,020
Protein interaction networks.

186
00:11:16,020 --> 00:11:23,380
Protein interaction networks really do illuminate this problem of the specificity of the definition

187
00:11:23,380 --> 00:11:25,380
of stuff.

188
00:11:25,380 --> 00:11:30,020
When we think about proteins interacting with one another there are many types of interactions

189
00:11:30,020 --> 00:11:31,220
that can occur.

190
00:11:31,220 --> 00:11:34,040
You can have things physically sticking to one another.

191
00:11:34,040 --> 00:11:36,100
That is one type of interaction.

192
00:11:36,100 --> 00:11:41,300
But you can also have a type of interaction where one protein does an enzymatic reaction

193
00:11:41,300 --> 00:11:47,460
that passes a molecule onto another protein and that could also be considered an interaction

194
00:11:47,460 --> 00:11:48,740
of some kind.

195
00:11:48,740 --> 00:11:53,600
Now what exactly is the definition of an interaction in this case?

196
00:11:53,600 --> 00:11:58,060
We have to be extremely precise because otherwise our inferences about what we're talking about

197
00:11:58,060 --> 00:12:00,860
become very imprecise as well.

198
00:12:00,860 --> 00:12:06,780
So now I want you to think in the spirit of getting practice about being very precise

199
00:12:06,780 --> 00:12:11,780
with our definitions we're going to do another short discussion here which is for the graphs

200
00:12:11,780 --> 00:12:19,340
that you've sort of examples that you've talked about with your neighbors can you think of

201
00:12:19,340 --> 00:12:20,340
two things.

202
00:12:20,340 --> 00:12:26,820
One how precise of a definition do you have to can you come up with for the definition

203
00:12:26,820 --> 00:12:30,580
of a relationship between two nodes.

204
00:12:30,580 --> 00:12:32,560
That is the definition of an edge.

205
00:12:32,560 --> 00:12:37,020
And two what are ways that you could be very imprecise about the definition.

206
00:12:37,020 --> 00:12:47,620
So please go ahead talk with your neighbor about that for a minute or two.

207
00:12:47,620 --> 00:12:48,620
All right.

208
00:12:48,620 --> 00:12:49,620
All right.

209
00:12:49,620 --> 00:12:51,740
I see some of the discussion subsiding.

210
00:12:51,740 --> 00:12:58,780
So I'd like to hear again from all of you for a given network example that you might

211
00:12:58,780 --> 00:13:01,380
have brought up previously.

212
00:13:01,380 --> 00:13:06,940
What would constitute a very precise definition of a relationship or an edge between two nodes

213
00:13:06,940 --> 00:13:11,340
and what would constitute a very imprecise definition.

214
00:13:11,340 --> 00:13:12,340
Any volunteers?

215
00:13:12,340 --> 00:13:13,340
Yes.

216
00:13:13,340 --> 00:13:22,860
OK.

217
00:13:22,860 --> 00:13:30,740
Let's bring it out and talk about it.

218
00:13:30,740 --> 00:13:31,740
Retail data.

219
00:14:01,740 --> 00:14:08,580
You're running into these objects called hyper graphs.

220
00:14:08,580 --> 00:14:14,540
So let's let's simplify things a little bit and focus only on like customer and store

221
00:14:14,540 --> 00:14:19,260
right as the two nodes types that are available.

222
00:14:19,260 --> 00:14:25,720
And one thing I like about the way that you've defined the edge is you're talking about in

223
00:14:25,720 --> 00:14:29,540
terms of a unique transaction identifier.

224
00:14:29,540 --> 00:14:39,940
Every transaction that happens between a customer and a store is a unique edge that exists between

225
00:14:39,940 --> 00:14:42,820
the node and the pairs of nodes.

226
00:14:42,820 --> 00:14:51,140
So this would for the purposes of analyzing for example for the purposes of data modeling

227
00:14:51,140 --> 00:14:53,920
sorry for the purposes of data modeling.

228
00:14:54,920 --> 00:15:02,320
Allows you to create a sort of relational table right where you have one column being customer

229
00:15:02,320 --> 00:15:10,200
ID and then next column being store ID and the third column being a transaction ID right

230
00:15:10,200 --> 00:15:16,000
or sorry that in that table the transaction ID itself is just like the indexer in that

231
00:15:16,000 --> 00:15:17,000
table right.

232
00:15:17,000 --> 00:15:18,960
Exactly exactly.

233
00:15:18,960 --> 00:15:24,920
And so for particular purposes where you want to analyze for example the volume of

234
00:15:24,920 --> 00:15:33,300
transactions between the distribution of volume of transactions between a customer and a store

235
00:15:33,300 --> 00:15:35,800
then that would be a very precise definition right.

236
00:15:35,800 --> 00:15:40,440
But you can imagine situations in which if you're trying to drill down into the product

237
00:15:40,440 --> 00:15:45,760
level then this becomes a very imprecise definition right.

238
00:15:45,960 --> 00:15:53,120
OK so this is a really awesome example because what it's illuminated is the kind of question

239
00:15:53,120 --> 00:16:00,160
that you're asking defines how precise you need to be about the definition of the edge.

240
00:16:00,160 --> 00:16:04,880
If you want it to go down to a product level then you would have to rejig the configuration

241
00:16:04,880 --> 00:16:05,880
of the graph.

242
00:16:05,880 --> 00:16:13,680
I don't have an immediate way of rejigging the graph we brought up as an example in the

243
00:16:13,720 --> 00:16:16,920
moment but there probably is a way to do it right.

244
00:16:16,920 --> 00:16:19,680
So that's that that is a very awesome example.

245
00:16:19,680 --> 00:16:22,680
Are there others that you can think of?

246
00:16:22,680 --> 00:16:23,680
Phone.

247
00:16:23,680 --> 00:16:24,680
Yes.

248
00:16:24,680 --> 00:16:25,680
Yeah.

249
00:16:25,680 --> 00:16:32,680
Yeah yeah yeah yeah yeah that's right.

250
00:16:32,680 --> 00:16:38,680
So you could if you again this again depends on the kind of question you're asking of your

251
00:16:38,680 --> 00:16:39,680
data right.

252
00:16:39,680 --> 00:16:44,680
So if you were to ask questions about like how do you do that and then you can do it

253
00:16:44,680 --> 00:16:45,680
in a more precise way.

254
00:16:45,680 --> 00:16:50,680
So you could if you were to ask questions about like how do you do that and then you

255
00:16:51,680 --> 00:17:00,680
So if you were to ask questions about like any kind of contact between people text message

256
00:17:00,680 --> 00:17:07,680
and audio calls would be considered within like reasonable things to keep to model inside

257
00:17:07,680 --> 00:17:09,680
your graph.

258
00:17:09,680 --> 00:17:16,680
But if you wanted to drill down more specifically into just the text messaging patterns then

259
00:17:16,680 --> 00:17:21,680
the definition of the edge being any kind of contact becomes too imprecise for answering

260
00:17:21,680 --> 00:17:22,680
that question.

261
00:17:22,680 --> 00:17:23,680
OK this is awesome.

262
00:17:23,680 --> 00:17:24,680
This is a very good example.

263
00:17:24,680 --> 00:17:30,680
Again it it shows how being precise or imprecise is very context dependent.

264
00:17:30,680 --> 00:17:34,680
You need to think through the logic of the exact thing you're trying to answer.

265
00:17:34,680 --> 00:17:39,680
Yeah.

266
00:17:39,680 --> 00:17:44,680
I promise this was I did not plant this in you because this is the perfect segue into

267
00:17:44,680 --> 00:17:45,680
what's coming next.

268
00:17:45,680 --> 00:17:46,680
Right.

269
00:17:46,680 --> 00:17:52,680
The kind of edge that the directionality of an edge is also really important.

270
00:17:52,680 --> 00:17:53,680
Right.

271
00:17:53,680 --> 00:18:00,680
So and the directionality of the edge can be such that if you are interested in any

272
00:18:00,680 --> 00:18:05,680
kind of contact between people you wouldn't bother with the directionality.

273
00:18:05,680 --> 00:18:13,680
However if you were interested in how say in a phone contact network how people are

274
00:18:13,680 --> 00:18:18,680
who is the instigator of the call versus who is the recipient of the call and you're

275
00:18:18,680 --> 00:18:23,680
interested in that pattern of say information flow right then modeling the directionality

276
00:18:23,680 --> 00:18:27,680
of that contact becomes really important.

277
00:18:27,680 --> 00:18:28,680
Right.

278
00:18:28,680 --> 00:18:29,680
Cool.

279
00:18:29,680 --> 00:18:37,680
So in the Jupiter notebooks that we have on the tutorial repository there are a few examples

280
00:18:37,680 --> 00:18:39,680
that are a little bit more pedestrian I guess.

281
00:18:39,680 --> 00:18:46,680
Airport networks social network protein networks the definition of the edge really really

282
00:18:46,680 --> 00:18:49,680
depends on what kind of question you're answering.

283
00:18:49,680 --> 00:18:55,680
Now harping a lot on the definition of an edge because as we'll see later on through

284
00:18:55,680 --> 00:19:01,680
all of our examples that we'll see here what makes a graph interesting is not the nodes.

285
00:19:01,680 --> 00:19:04,680
What makes a graph interesting is the edges.

286
00:19:05,680 --> 00:19:11,680
So if you get the edge definition precise the kind of questions you can answer about

287
00:19:11,680 --> 00:19:15,680
graph data that you have also become very precise.

288
00:19:15,680 --> 00:19:16,680
OK.

289
00:19:16,680 --> 00:19:17,680
Cool.

290
00:19:17,680 --> 00:19:21,680
So when it comes to graphs directionality is also really important.

291
00:19:21,680 --> 00:19:26,680
So if in a phone network you're interested in how information flows that's one way to

292
00:19:26,680 --> 00:19:27,680
do it.

293
00:19:27,680 --> 00:19:32,680
If we were to take the very relatable example of a social network right in a social network

294
00:19:33,680 --> 00:19:39,680
you have people who might be so-called connected to one another.

295
00:19:39,680 --> 00:19:42,680
But the type of the underlying connection might be different.

296
00:19:42,680 --> 00:19:47,680
So in Facebook and LinkedIn for example or sorry now what did they call it now meta right.

297
00:19:47,680 --> 00:19:48,680
Let's just use LinkedIn.

298
00:19:48,680 --> 00:19:49,680
I don't know.

299
00:19:49,680 --> 00:19:50,680
I don't know tech.

300
00:19:50,680 --> 00:19:59,680
If we do if we use LinkedIn as an example right would we consider that the edge is between

301
00:20:00,680 --> 00:20:05,680
two LinkedIn users is directed or undirected.

302
00:20:05,680 --> 00:20:08,680
Undirected.

303
00:20:08,680 --> 00:20:11,680
For what reason.

304
00:20:11,680 --> 00:20:14,680
OK.

305
00:20:14,680 --> 00:20:15,680
Right.

306
00:20:15,680 --> 00:20:16,680
Right.

307
00:20:16,680 --> 00:20:19,680
And what about Twitter.

308
00:20:19,680 --> 00:20:22,680
It is directional and the reason is.

309
00:20:22,680 --> 00:20:25,680
Right.

310
00:20:25,680 --> 00:20:28,680
You can follow someone and they don't have to necessarily follow you.

311
00:20:28,680 --> 00:20:33,680
So one thing that's cool about undirected graphs is the underlying.

312
00:20:33,680 --> 00:20:37,680
Another way to think about undirected graphs is that they have automatic bi-directional

313
00:20:37,680 --> 00:20:40,680
edges just as was mentioned in the back.

314
00:20:40,680 --> 00:20:41,680
Right.

315
00:20:41,680 --> 00:20:45,680
So that is again like a modeling trick that you can keep in mind when you're thinking

316
00:20:45,680 --> 00:20:49,680
about graphs and the data structures that you build.

317
00:20:49,680 --> 00:20:50,680
Cool.

318
00:20:50,680 --> 00:20:58,680
So before we go on to actual programming I want to really motivate this discussion

319
00:20:58,680 --> 00:21:03,680
about edges with this quote that I picked up while in grad school.

320
00:21:03,680 --> 00:21:06,680
This was I think 2015.

321
00:21:06,680 --> 00:21:07,680
I was in a seminar.

322
00:21:07,680 --> 00:21:10,680
It was at the Harvard School of Public Health.

323
00:21:10,680 --> 00:21:12,680
Professor John Quackenbush there.

324
00:21:12,680 --> 00:21:15,680
I forgot what he was talking about.

325
00:21:15,680 --> 00:21:21,680
I don't remember what his whole like what new nature paper he was talking about.

326
00:21:21,680 --> 00:21:26,680
But I do remember a quote from his talk and I jotted it down.

327
00:21:26,680 --> 00:21:31,680
The heart of a graph lies in its edges not in its nodes.

328
00:21:31,680 --> 00:21:37,680
And what makes a graph interesting is the edges the relationships between the nodes.

329
00:21:37,680 --> 00:21:43,680
The nodes basically are like you can rethink of them as being entries in a table.

330
00:21:43,680 --> 00:21:44,680
Right.

331
00:21:44,680 --> 00:21:48,680
So your user table gives you your nodes in a database.

332
00:21:48,680 --> 00:21:52,680
But the way they're connected makes the whole system interesting.

333
00:21:52,680 --> 00:21:53,680
Right.

334
00:21:53,680 --> 00:21:58,680
And so this is this is really something that I want to convey through this tutorial.

335
00:21:58,680 --> 00:22:03,680
So so with that we're going to move on to the first notebook.

336
00:22:03,680 --> 00:22:07,680
We're going to go on to sorry we're going to go on to the second notebook and this notebook

337
00:22:07,680 --> 00:22:12,680
is located in 01 introduction.

338
00:22:12,680 --> 00:22:17,680
And it is its notebook name is 02 network X intro.

339
00:22:17,680 --> 00:22:24,680
What we're going to do here is do a very quick hands on introduction to the network X API.

340
00:22:24,680 --> 00:22:29,680
And the reason I think the network X API is awesome for learning about network science

341
00:22:29,680 --> 00:22:35,680
is because it the naming conventions of the algorithms and the methods class methods inside

342
00:22:35,680 --> 00:22:40,680
there match up very closely with what you would see in the prevailing literature.

343
00:22:40,680 --> 00:22:45,680
And it is also a pure Python package which means if you're interested in any of the algorithms

344
00:22:45,680 --> 00:22:46,680
it's very accessible.

345
00:22:46,680 --> 00:22:51,680
You can peek inside the source code and see what exactly how exactly an algorithm is implemented.

346
00:22:51,680 --> 00:22:57,680
There is no translation for example to linear algebra land which some algorithms some graph

347
00:22:57,680 --> 00:22:59,680
algorithms can be implemented in terms of linear algebra.

348
00:22:59,680 --> 00:23:00,680
There's no translation there.

349
00:23:00,680 --> 00:23:06,680
You just think about nodes and edges and you follow the logic of the code at the same time

350
00:23:06,680 --> 00:23:08,680
because it's pure Python it's very easy to install.

351
00:23:08,680 --> 00:23:13,680
You don't really need to have too much else.

352
00:23:13,680 --> 00:23:20,680
And it's for small graphs up to say I'd say about 100,000 to millions of nodes.

353
00:23:20,680 --> 00:23:21,680
Right.

354
00:23:21,680 --> 00:23:26,680
Like this is relatively small in the world of like graph analytics at least for these

355
00:23:26,680 --> 00:23:31,680
small sized graphs network X can comfortably handle the problem even if it may not necessarily

356
00:23:31,680 --> 00:23:34,680
be an interactive time you're at least not waiting for like months on end for things

357
00:23:34,680 --> 00:23:35,680
to run.

358
00:23:35,680 --> 00:23:36,680
All right.

359
00:23:36,680 --> 00:23:37,680
So yes.

360
00:23:49,680 --> 00:23:55,680
You might need to hack something to work with spark graph algorithms by their very nature

361
00:23:55,680 --> 00:24:02,680
sometimes involve if you're familiar with the order of complexity some graph algorithms

362
00:24:02,680 --> 00:24:07,680
are often called O N 3 with the number of nodes or exponential with the number of nodes.

363
00:24:07,680 --> 00:24:14,680
So it's it can get a little tricky and the data model underneath being like pure Python

364
00:24:14,680 --> 00:24:21,680
dictionary like things means I'm not sure how like distributed how distributing computation

365
00:24:21,680 --> 00:24:25,680
on the of stuff on a graph might look like.

366
00:24:25,680 --> 00:24:27,680
So that would be something to explore on the side.

367
00:24:27,680 --> 00:24:29,680
That said there are alternatives right.

368
00:24:29,680 --> 00:24:35,680
Some graph algorithms have been implemented on GPUs for example with the graph project

369
00:24:35,680 --> 00:24:37,680
by the Rapids team at Nvidia.

370
00:24:37,680 --> 00:24:43,680
So that is another outlet if that if that algorithm that you're interested in is available

371
00:24:43,680 --> 00:24:44,680
on the GPU.

372
00:24:55,680 --> 00:24:56,680
Yes.

373
00:24:56,680 --> 00:25:02,680
If you look at one of the later advanced notebooks which is 04 advanced and then 02

374
00:25:02,680 --> 00:25:07,680
Linalge it does depend on some of the other content that we've that is in the repo but

375
00:25:07,680 --> 00:25:12,680
you'll see a comparison between like using network X methods versus using a linear algebra

376
00:25:12,680 --> 00:25:16,680
interpretation of the exact same method and it's almost like a hundredfold difference

377
00:25:16,680 --> 00:25:17,680
in speed.

378
00:25:17,680 --> 00:25:22,680
But then of course like the interpretation of the readability of that Linalge thing is

379
00:25:22,680 --> 00:25:25,680
more difficult so it's less easy to figure out what's going on inside there.

380
00:25:25,680 --> 00:25:26,680
All right.

381
00:25:26,680 --> 00:25:27,680
Cool.

382
00:25:27,680 --> 00:25:29,680
So we're going to go on to the network X intro.

383
00:25:29,680 --> 00:25:33,680
Like I mentioned it's it's it's an important one.

384
00:25:33,680 --> 00:25:36,680
And so I'm going to ask you all to do a few things.

385
00:25:36,680 --> 00:25:37,680
First off run.

386
00:25:37,680 --> 00:25:38,680
Let me see here.

387
00:25:38,680 --> 00:25:44,680
I'm going to restart my notebook and we're going to run a few cells.

388
00:25:44,680 --> 00:25:49,680
And I want you to run up cells up to this point where you see G is equal to CF dot load

389
00:25:49,680 --> 00:25:51,680
seventh grader network.

390
00:25:51,680 --> 00:25:52,680
Right.

391
00:25:52,680 --> 00:25:55,680
So we'll just get the setup notebook set up for us.

392
00:25:55,680 --> 00:26:03,680
So a key thing to note about the underlying data model of network X is that it's very

393
00:26:03,680 --> 00:26:08,680
dictionary like right dictionaries are built on top of sets right.

394
00:26:08,680 --> 00:26:15,680
Sets are part of the core definition of graphs dictionaries allow us to have no maps to dictionary

395
00:26:15,680 --> 00:26:21,680
like data structures sorry allow us to map node and edges to their properties that we

396
00:26:21,680 --> 00:26:24,680
want to attach onto them as well.

397
00:26:24,680 --> 00:26:32,680
So the way that the way that we create graphs and manipulate them is what we're going to

398
00:26:32,680 --> 00:26:33,680
see inside this notebook.

399
00:26:33,680 --> 00:26:39,680
So canonically when you create a graph you would do G is equal to an X dot graph network

400
00:26:39,680 --> 00:26:40,680
X dot graph.

401
00:26:40,680 --> 00:26:44,680
And if you wanted a directed graph there are directed graph objects.

402
00:26:44,680 --> 00:26:50,680
If you wanted graphs which you had multiple edges between nodes but each edge is like

403
00:26:50,680 --> 00:26:53,680
a unique edge that is also possible and there's multigraph.

404
00:26:53,680 --> 00:26:56,680
So that's also data structure that's available.

405
00:26:56,680 --> 00:27:03,680
And then key to the data structure the graph data structure in network X is G dot nodes

406
00:27:03,680 --> 00:27:09,680
and G dot edges G dot nodes lets you access the nodes that are present in a graph and

407
00:27:09,680 --> 00:27:13,680
G dot edges allows you to access the edges that are in the graph.

408
00:27:13,680 --> 00:27:14,680
OK.

409
00:27:14,680 --> 00:27:19,680
So to keep things concrete and less abstract what we're going to do here is we're going

410
00:27:19,680 --> 00:27:25,680
to run through we're going to load in an example graph that has already been created so you

411
00:27:25,680 --> 00:27:28,680
don't have to worry about how it was created just yet.

412
00:27:28,680 --> 00:27:32,680
And we're going to try to do a few things where we manipulate the graph and query the

413
00:27:32,680 --> 00:27:34,680
graph for information.

414
00:27:34,680 --> 00:27:40,680
So this is a study this graph that we're going to load is a study of seventh grade students

415
00:27:40,680 --> 00:27:45,680
in Victoria I believe Australia not British Columbia my hometown.

416
00:27:45,680 --> 00:27:54,680
So and in this graph there what the data the data that we're modeling is as follows.

417
00:27:54,680 --> 00:28:01,680
These students were asked on three separate occasions to nominate their preferred classmates

418
00:28:01,680 --> 00:28:04,680
for those respective activities.

419
00:28:04,680 --> 00:28:05,680
Right.

420
00:28:05,680 --> 00:28:10,680
So you could as a student nominate three or five or 15 people as your preferred like

421
00:28:10,680 --> 00:28:14,680
preferred partners in different activities.

422
00:28:14,680 --> 00:28:22,680
Every node therefore is defined as a student and every edge is defined as they have had one

423
00:28:22,680 --> 00:28:28,680
or more times where they've shown a preference for the other student.

424
00:28:28,680 --> 00:28:29,680
All right.

425
00:28:29,680 --> 00:28:32,680
So let's just do a quick pulse check here.

426
00:28:32,680 --> 00:28:37,680
Is this directional or undirected directional.

427
00:28:37,680 --> 00:28:38,680
Exactly.

428
00:28:38,680 --> 00:28:39,680
This is not a trick question at all.

429
00:28:39,680 --> 00:28:40,680
OK.

430
00:28:40,680 --> 00:28:41,680
Cool.

431
00:28:41,680 --> 00:28:44,680
So this so and then the edge weights will run between one and three.

432
00:28:44,680 --> 00:28:45,680
Right.

433
00:28:45,680 --> 00:28:51,680
So you have metadata that's stored on the edge that says this student prefers that student

434
00:28:51,680 --> 00:28:54,680
one time two time or three times.

435
00:28:54,680 --> 00:28:55,680
Right.

436
00:28:55,680 --> 00:28:56,680
Cool.

437
00:28:56,680 --> 00:29:01,680
Now in the original data set this was made this was taken from an all boys school.

438
00:29:01,680 --> 00:29:07,680
What I've done here is modified the data set for some visualization purposes later on

439
00:29:07,680 --> 00:29:09,680
so we can look at like different node categories.

440
00:29:09,680 --> 00:29:13,680
So we have the data set modified to come from a mixed gender school.

441
00:29:13,680 --> 00:29:14,680
Right.

442
00:29:14,680 --> 00:29:17,680
So you have boys and girls both inside the data set.

443
00:29:17,680 --> 00:29:25,680
So now what we're going to do is we're going to start by querying the graph for key information

444
00:29:25,680 --> 00:29:27,680
that is stored in the graph.

445
00:29:27,680 --> 00:29:30,680
So the first one is to know what is the type of the graph.

446
00:29:31,680 --> 00:29:38,680
So in Python if you do type of G it will show you that this is a directed graph.

447
00:29:38,680 --> 00:29:42,680
So we've instantiated the graph object as an NX.

448
00:29:42,680 --> 00:29:47,680
DIGRAF directed graph and this will be reflected in its type.

449
00:29:47,680 --> 00:29:50,680
By contrast if you did NX.

450
00:29:50,680 --> 00:29:54,680
GRAPH alone to create the graph object you would get.

451
00:29:54,680 --> 00:29:55,680
Classes.

452
00:29:55,680 --> 00:29:56,680
Graph.

453
00:29:56,680 --> 00:29:57,680
Graph.

454
00:29:57,680 --> 00:29:58,680
Without the DI inside there.

455
00:29:58,680 --> 00:29:59,680
OK.

456
00:29:59,680 --> 00:30:01,680
So if you run those two cells you'll see that.

457
00:30:01,680 --> 00:30:07,680
So next thing we're going to do is we're going to take a look at one thing that's really

458
00:30:07,680 --> 00:30:11,680
important when you get a graph is you want to know what nodes are present inside that

459
00:30:11,680 --> 00:30:12,680
graph.

460
00:30:12,680 --> 00:30:13,680
OK.

461
00:30:13,680 --> 00:30:19,680
So one way to do that is to I'm going to comment this out and type this for you guys.

462
00:30:19,680 --> 00:30:20,680
G.Nodes.

463
00:30:20,680 --> 00:30:21,680
Right.

464
00:30:21,680 --> 00:30:27,680
If you do G.Nodes and you run the cell locally on your Jupiter sessions you notice that what

465
00:30:27,680 --> 00:30:32,680
you get returned is this thing called a node view object.

466
00:30:32,680 --> 00:30:33,680
Right.

467
00:30:33,680 --> 00:30:39,680
It is an immutable view of the nodes that are present in the graph.

468
00:30:39,680 --> 00:30:43,680
You can still add and remove nodes in the graph but you just can't manipulate the graph

469
00:30:43,680 --> 00:30:45,680
by looking at G.Nodes.

470
00:30:45,680 --> 00:30:46,680
OK.

471
00:30:46,680 --> 00:30:49,680
So this is this is an important concept.

472
00:30:50,680 --> 00:30:58,680
One thing that is true about the G.Nodes thing is I don't believe it is subscriptable because

473
00:30:58,680 --> 00:31:05,680
if you think about the definition of a set you can't slice a set because it is inherently

474
00:31:05,680 --> 00:31:06,680
unordered.

475
00:31:06,680 --> 00:31:10,680
So if you were to try this with me G.Nodes 0 to 5 should get an error.

476
00:31:10,680 --> 00:31:11,680
Right.

477
00:31:12,680 --> 00:31:18,680
This again reinforces the very strict mathematical definition of a graph.

478
00:31:18,680 --> 00:31:19,680
Right.

479
00:31:19,680 --> 00:31:27,680
So if you do want to like obtain a subset of nodes what you would want to do is cast

480
00:31:27,680 --> 00:31:33,680
G.Nodes inside a list and then slice into it afterwards.

481
00:31:33,680 --> 00:31:34,680
Right.

482
00:31:34,680 --> 00:31:35,680
How are we doing so far?

483
00:31:35,680 --> 00:31:36,680
So far so good?

484
00:31:36,680 --> 00:31:37,680
Feeling OK?

485
00:31:37,680 --> 00:31:40,680
Shouldn't be too difficult up to this point.

486
00:31:40,680 --> 00:31:43,680
Maybe the exception of you can't slice into G.Nodes.

487
00:31:43,680 --> 00:31:44,680
Right.

488
00:31:44,680 --> 00:31:49,680
Like that's the only sort of gotcha that makes sense once you think again about the definition

489
00:31:49,680 --> 00:31:53,680
of the node set rather than a node list.

490
00:31:53,680 --> 00:31:55,680
OK.

491
00:31:55,680 --> 00:32:02,680
So one thing that you can do with G.Nodes is you can check how many nodes are present

492
00:32:02,680 --> 00:32:03,680
inside the graph.

493
00:32:03,680 --> 00:32:06,680
So you do line of G.Nodes you'll get 29 over here.

494
00:32:06,680 --> 00:32:07,680
And here's a really cool thing.

495
00:32:07,680 --> 00:32:14,680
If there is metadata that is attached on top of each node you can do G.Nodes data equals

496
00:32:14,680 --> 00:32:18,680
true and you'll get back this data structure.

497
00:32:18,680 --> 00:32:19,680
OK.

498
00:32:19,680 --> 00:32:25,680
So let's kind of do a quick Python check here.

499
00:32:25,680 --> 00:32:31,680
What is the data structure if we were to describe this in words what is the data structure of

500
00:32:31,680 --> 00:32:33,680
this like list of things?

501
00:32:33,680 --> 00:32:43,680
This is a list of tuples of length to in which the first element is the node ID and the second

502
00:32:43,680 --> 00:32:50,680
element is a metadata dictionary that maps key value pairs that are metadata attached

503
00:32:50,680 --> 00:32:51,680
to the node.

504
00:32:51,680 --> 00:32:52,680
Right.

505
00:32:52,680 --> 00:32:53,680
So far so good?

506
00:32:53,680 --> 00:32:54,680
OK.

507
00:32:54,680 --> 00:32:55,680
Cool.

508
00:32:55,680 --> 00:32:56,680
Yes.

509
00:32:56,680 --> 00:33:03,680
That's right.

510
00:33:03,680 --> 00:33:04,680
These are the nodes.

511
00:33:04,680 --> 00:33:07,680
We'll get to the edges soon.

512
00:33:07,680 --> 00:33:09,680
We can also select out individual nodes.

513
00:33:09,680 --> 00:33:10,680
Right.

514
00:33:10,680 --> 00:33:17,680
So if we run G.Nodes of one what we'll get back is the dictionary of metadata that is

515
00:33:17,680 --> 00:33:21,680
associated with that node one.

516
00:33:21,680 --> 00:33:22,680
All right.

517
00:33:22,680 --> 00:33:26,680
So you might be wondering at this point like what do nodes have to be integers?

518
00:33:26,680 --> 00:33:27,680
Actually, no.

519
00:33:27,680 --> 00:33:31,680
They only strictly speaking have to be hashable things.

520
00:33:31,680 --> 00:33:38,680
So you can't make a list a node because lists are not hashable but you can make a tuple

521
00:33:38,680 --> 00:33:41,680
a node because tuples are hashable.

522
00:33:41,680 --> 00:33:42,680
Right.

523
00:33:42,680 --> 00:33:43,680
So that is possible.

524
00:33:43,680 --> 00:33:49,680
But for most applications I would say that most people would use strings as nodes just

525
00:33:49,680 --> 00:33:53,680
because they are human readable, easily identifiable.

526
00:33:53,680 --> 00:33:58,680
So when you do G.Nodes and you look at what nodes are present like it's very obvious

527
00:33:58,680 --> 00:33:59,680
what the nodes are.

528
00:33:59,680 --> 00:34:07,680
When I was when I do when I played around with genome graphs at work in their every

529
00:34:07,680 --> 00:34:11,680
position comma letter pair right is a node.

530
00:34:11,680 --> 00:34:17,680
So you can actually represent that by a tuple in which you have the first element being

531
00:34:17,680 --> 00:34:23,680
the position in a sequence and the letter of the nucleotide or protein sequence being

532
00:34:23,680 --> 00:34:25,680
the letter the second element.

533
00:34:25,680 --> 00:34:31,680
And that was sort of the data structure that was used to represent this so-called genome

534
00:34:31,680 --> 00:34:32,680
graph.

535
00:34:32,680 --> 00:34:33,680
Right.

536
00:34:33,680 --> 00:34:34,680
And I can explain genome graphs in like a different setting.

537
00:34:34,680 --> 00:34:38,680
I won't go into over there but I just want to make the point that anything that is hashable

538
00:34:38,680 --> 00:34:40,680
is doable as a node.

539
00:34:40,680 --> 00:34:41,680
Right.

540
00:34:41,680 --> 00:34:44,680
If you play around with an API later you can you can do that too.

541
00:34:44,680 --> 00:34:45,680
Cool.

542
00:34:45,680 --> 00:34:52,680
Now because the node data view with data equals true that's dictionary like.

543
00:34:52,680 --> 00:34:57,680
So you can actually loop over it as if you were doing for key value in dictionary dot

544
00:34:57,680 --> 00:34:58,680
items.

545
00:34:58,680 --> 00:34:59,680
Right.

546
00:34:59,680 --> 00:35:03,680
In this case you would do for node comma data in G.Nodes data equals true.

547
00:35:03,680 --> 00:35:09,680
Now you have access to every node with its corresponding metadata dictionary.

548
00:35:09,680 --> 00:35:17,680
So this then brings us to the first exercise of today which is to count the number of boys

549
00:35:17,680 --> 00:35:20,680
and girls that are present inside this data set.

550
00:35:20,680 --> 00:35:21,680
Right.

551
00:35:21,680 --> 00:35:23,680
So I'd like you to attempt this exercise.

552
00:35:23,680 --> 00:35:30,800
Feel free to talk with your whoever's your neighbor in this like lattice graph of people

553
00:35:30,800 --> 00:35:33,360
who are sitting in the tutorial room.

554
00:35:33,360 --> 00:35:38,680
Feel free to talk with your neighbor and we'll spend about a minute or two just to work on

555
00:35:38,680 --> 00:35:39,680
this exercise.

556
00:36:09,680 --> 00:36:14,680
While you all are doing it I'm going to try to implement the answer from memory.

557
00:36:14,680 --> 00:36:20,680
I have it I have it all at the bottom of the notebook but this is a great way for me to

558
00:36:20,680 --> 00:36:21,680
pace myself.

559
00:36:21,680 --> 00:36:36,680
Why is the output collapsed?

560
00:36:36,680 --> 00:36:52,680
There we go.

561
00:36:52,680 --> 00:36:53,680
OK.

562
00:36:53,680 --> 00:36:58,680
So given given the lack of specificity in the phrasing of the task you can probably find

563
00:36:58,680 --> 00:37:02,680
other creative ways of counting the number of males or females that are in the data set

564
00:37:02,680 --> 00:37:04,680
in the graph.

565
00:37:04,680 --> 00:37:06,680
I use collections that counter.

566
00:37:06,680 --> 00:37:07,680
You don't have to.

567
00:37:07,680 --> 00:37:08,680
You can do it your own way.

568
00:37:08,680 --> 00:37:15,680
But as long as you figure out that there are 12 boys and 17 girls inside the data set you're

569
00:37:15,680 --> 00:37:20,680
pretty much on track.

570
00:37:20,680 --> 00:37:21,680
A loop.

571
00:37:21,680 --> 00:37:22,680
OK.

572
00:37:22,680 --> 00:37:28,680
That works too.

573
00:37:28,680 --> 00:37:32,680
So just to do a quick pulse check how many of you feel OK with this exercise or would

574
00:37:32,680 --> 00:37:36,680
like a little bit if you if you feel OK give me a thumbs up if you'd like a little bit

575
00:37:36,680 --> 00:37:41,680
more time then raise your hand or something or I should have put like sticky notes.

576
00:37:41,680 --> 00:37:44,680
There's a there's a very nice and discreet way of doing this.

577
00:37:44,680 --> 00:37:48,680
If you are feeling if you're struggling you put a red sticky note on your laptop.

578
00:37:48,680 --> 00:37:51,680
If you're not struggling then you put a yellow sticky note on your laptop.

579
00:37:51,680 --> 00:37:53,680
I should have done that.

580
00:37:53,680 --> 00:37:54,680
Cool.

581
00:37:54,680 --> 00:37:58,680
So in the interest of time we'll move on but hopefully this this is a good exercise that

582
00:37:58,680 --> 00:38:05,680
shows you how you can query the metadata that is on the node set right of the graph and

583
00:38:05,680 --> 00:38:14,680
use that to derive summary statistics about the node set down below.

584
00:38:14,680 --> 00:38:20,680
I have this thing here which is about testing right.

585
00:38:20,680 --> 00:38:27,680
So this is this is sort of a side point but as a practicing computational slash data

586
00:38:27,680 --> 00:38:34,680
scientists we run into data quality issues all the time especially in my realm of not

587
00:38:34,680 --> 00:38:41,680
like highly structured streaming data but actually lab lab scientist generated data.

588
00:38:41,680 --> 00:38:46,680
We have lots of potential data quality issues so there's this practice that I've started

589
00:38:46,680 --> 00:38:51,680
to engage in which is to test data that comes in and validate all the data that comes in

590
00:38:51,680 --> 00:38:55,680
that they fit the assumptions that I believe that they they should fit.

591
00:38:55,680 --> 00:39:02,680
And so leveraging test functions like this throughout the code base is one way of doing

592
00:39:02,680 --> 00:39:03,680
it.

593
00:39:03,680 --> 00:39:07,680
There are other tooling for like say pandas data frames there's Pandera and great expectations

594
00:39:07,680 --> 00:39:10,680
that let you validate your data on the fly.

595
00:39:10,680 --> 00:39:17,680
But as basically this this for me is like a defensive programming way of operating and

596
00:39:17,680 --> 00:39:23,680
it has saved my posterior many many times when I'm doing my analysis work.

597
00:39:23,680 --> 00:39:24,680
Cool.

598
00:39:24,680 --> 00:39:27,680
So now we queried node information.

599
00:39:27,680 --> 00:39:29,680
Let's also query edge information.

600
00:39:29,680 --> 00:39:37,680
So analogous to G dot nodes you can do G dot edges and that will give you an edge view

601
00:39:37,680 --> 00:39:39,680
again just like the node view.

602
00:39:39,680 --> 00:39:42,680
This is an immutable data structure.

603
00:39:42,680 --> 00:39:46,680
You can't modify this guy and therefore modify the underlying graph.

604
00:39:46,680 --> 00:39:49,680
There are explicit methods for this so you can do that.

605
00:39:49,680 --> 00:39:58,680
Again this is an edge set so you can't index you can't slice directly into it.

606
00:39:58,680 --> 00:40:04,680
This will be out edge view does not support slicing so it fits the definition of edge set.

607
00:40:04,680 --> 00:40:10,680
But there is a very helpful error error message put over here which suggests exactly what

608
00:40:10,680 --> 00:40:16,680
to do next which is to do G dot list of G dot edges which is exactly what the original

609
00:40:16,680 --> 00:40:17,680
was all about.

610
00:40:17,680 --> 00:40:22,680
So if you do list of G dot edges I believe you actually don't need the parentheses either.

611
00:40:22,680 --> 00:40:24,680
That also works.

612
00:40:24,680 --> 00:40:28,680
Same should apply for the nodes as well.

613
00:40:28,680 --> 00:40:33,680
If you do list of G dot edges you'll get back a sliceable data structure.

614
00:40:33,680 --> 00:40:34,680
Okay.

615
00:40:34,680 --> 00:40:39,680
At the same time you can do line of G dot edges to get the number of edges that are

616
00:40:39,680 --> 00:40:46,680
present and just with as with G dot nodes you can pass data equals true and get back

617
00:40:46,680 --> 00:40:48,680
the metadata that's associated.

618
00:40:48,680 --> 00:40:53,680
So likewise over here you can also get back the metadata that's associated with every

619
00:40:53,680 --> 00:40:54,680
single edge.

620
00:40:54,680 --> 00:40:56,680
So then again this is not a trick question.

621
00:40:56,680 --> 00:40:57,680
What is this data structure?

622
00:40:57,680 --> 00:41:07,680
This is a list of tuples of length three in which the first element is one of the nodes

623
00:41:07,680 --> 00:41:09,680
in the edge.

624
00:41:09,680 --> 00:41:11,680
First node in the edge that's right.

625
00:41:11,680 --> 00:41:16,680
The second element is the other node in the edge and then third element is the dictionary

626
00:41:16,680 --> 00:41:18,680
of metadata that are present.

627
00:41:18,680 --> 00:41:19,680
Okay.

628
00:41:19,680 --> 00:41:21,680
You can also select out individual edges.

629
00:41:21,680 --> 00:41:24,680
Now the way that this syntax works is kind of nice.

630
00:41:24,680 --> 00:41:30,680
You actually do the square bracket selector syntax and then you do node one comma node

631
00:41:30,680 --> 00:41:31,680
two.

632
00:41:31,680 --> 00:41:37,680
It used to be G dot edges and then select node one and then select node two but this

633
00:41:37,680 --> 00:41:40,680
in my opinion is actually a little bit saner of a syntax.

634
00:41:40,680 --> 00:41:42,680
So it was recently added.

635
00:41:42,680 --> 00:41:44,680
So you do G dot edges 15 comma 10.

636
00:41:44,680 --> 00:41:50,680
You'll get back the metadata that's associated with the edge between node 15 and node 10.

637
00:41:50,680 --> 00:41:51,680
All right.

638
00:41:51,680 --> 00:41:52,680
Question.

639
00:41:52,680 --> 00:41:53,680
Yes.

640
00:41:53,680 --> 00:42:04,680
So the question is when the graph is not directed can you swap the indices and still be a valid

641
00:42:04,680 --> 00:42:05,680
edge?

642
00:42:05,680 --> 00:42:06,680
The answer is yes.

643
00:42:06,680 --> 00:42:12,680
So in an undirected graph the left comma right order does not matter.

644
00:42:12,680 --> 00:42:15,680
In a directed graph the left comma right order absolutely matters.

645
00:42:15,680 --> 00:42:19,680
In a directed graph left is the source, right is the sink.

646
00:42:19,680 --> 00:42:28,680
So 15 to 10 means student 15 nominated student 10 in this case twice for their activity.

647
00:42:28,680 --> 00:42:29,680
Right.

648
00:42:29,680 --> 00:42:32,680
So that is a very good question.

649
00:42:32,680 --> 00:42:35,680
You'll get a key error if an edge does not exist.

650
00:42:35,680 --> 00:42:39,680
So this obviously we won't run.

651
00:42:39,680 --> 00:42:48,680
And like just like just as it is with G dot nodes where you have an iterable of three

652
00:42:48,680 --> 00:42:51,680
tuples, same thing happens over here.

653
00:42:51,680 --> 00:42:56,680
So you have N1, N2, D as your loop variables if you were to loop over G dot edges data

654
00:42:56,680 --> 00:42:57,680
equals true.

655
00:42:57,680 --> 00:42:58,680
Okay.

656
00:42:58,680 --> 00:43:00,680
So what we're going to do next is another exercise.

657
00:43:00,680 --> 00:43:02,680
Summarize the edge metadata.

658
00:43:02,680 --> 00:43:03,680
Actually, sorry.

659
00:43:03,680 --> 00:43:11,680
It's verified that the maximum number of times that we've recorded for count is three, right?

660
00:43:11,680 --> 00:43:14,680
Like this is again a data validation check on the graph.

661
00:43:14,680 --> 00:43:16,680
So let's attempt that exercise.

662
00:43:33,680 --> 00:43:53,680
And when you're done, feel free to give me a thumbs up.

663
00:43:53,680 --> 00:44:01,680
By the way, I forgot to mention at the beginning if we're running too slow for you and you

664
00:44:01,680 --> 00:44:06,680
want to just speed ahead and do all the exercises below on your own time, I'm completely unaffended.

665
00:44:06,680 --> 00:44:07,680
Like, please do it.

666
00:44:07,680 --> 00:44:08,680
Not a problem.

667
00:44:08,680 --> 00:44:09,680
Okay.

668
00:44:09,680 --> 00:44:10,680
Give like.

669
00:44:10,680 --> 00:44:11,680
Yeah, exactly.

670
00:44:11,680 --> 00:44:16,680
We actually do have enough material for a six hour tutorial, which would be extremely

671
00:44:16,680 --> 00:44:17,680
tiring for everybody.

672
00:44:17,680 --> 00:44:20,680
But as you can see, there's been a lot of time put into this guy.

673
00:44:20,680 --> 00:44:21,680
So cool.

674
00:44:21,680 --> 00:44:24,680
I have the following implementation on the screen.

675
00:44:24,680 --> 00:44:29,680
Basically loop over this G.edges with data equals true, append count, and then get its

676
00:44:29,680 --> 00:44:30,680
max.

677
00:44:30,680 --> 00:44:35,680
If you look at the official answer, there's actually a compact list comprehension that

678
00:44:35,680 --> 00:44:37,680
is used inside there as well.

679
00:44:37,680 --> 00:44:42,680
So if you look at the actual list, you can see that there's a list of the things that

680
00:44:42,680 --> 00:44:44,680
are actually being used inside there.

681
00:44:45,680 --> 00:44:50,680
And likewise over here, we can test to make sure that the answer is correct.

682
00:44:50,680 --> 00:44:54,680
Once again, this is a sort of data validation check.

683
00:44:54,680 --> 00:44:55,680
Cool.

684
00:44:55,680 --> 00:44:58,680
So now we know how to query a graph object.

685
00:44:58,680 --> 00:45:01,680
The next thing that we want to do is know how to manipulate it.

686
00:45:01,680 --> 00:45:03,680
So you can create a graph.

687
00:45:03,680 --> 00:45:05,680
You know, you can create a graph.

688
00:45:05,680 --> 00:45:07,680
You can create a graph.

689
00:45:07,680 --> 00:45:09,680
You can create a graph.

690
00:45:09,680 --> 00:45:11,680
You can create a graph.

691
00:45:11,680 --> 00:45:13,680
And you can create a graph.

692
00:45:13,680 --> 00:45:15,680
You can create a graph.

693
00:45:15,680 --> 00:45:17,680
You can create a graph.

694
00:45:17,680 --> 00:45:20,680
And now you have an empty graph with no nodes and no edges.

695
00:45:20,680 --> 00:45:23,680
Or you might have a graph that someone gave you.

696
00:45:23,680 --> 00:45:27,680
In this case, the graph that we have over here, the G is equal to NX.digraph with a

697
00:45:27,680 --> 00:45:30,680
whole bunch of nodes and edges already present inside there.

698
00:45:30,680 --> 00:45:33,680
How do you add nodes and how do you add edges?

699
00:45:33,680 --> 00:45:37,680
And correspondingly, you can ask the question how do you remove nodes and remove edges or

700
00:45:37,680 --> 00:45:40,680
modify nodes and their metadata and properties.

701
00:45:40,680 --> 00:45:43,680
So we focus only on just adding nodes.

702
00:45:43,680 --> 00:45:48,680
There are corresponding methods for removing nodes as well.

703
00:45:48,680 --> 00:45:51,680
So this is what we're going to be doing over here.

704
00:45:51,680 --> 00:45:58,680
So if you want to add a node into a graph, you do G.addNode.

705
00:45:58,680 --> 00:46:05,680
And what you do is the first argument is the hashable entity that represents the node.

706
00:46:05,680 --> 00:46:11,680
Every keyword argument that follows automatically gets collected and squashed into a metadata

707
00:46:11,680 --> 00:46:14,680
dictionary entry that gets attached to the node.

708
00:46:14,680 --> 00:46:15,680
All right?

709
00:46:15,680 --> 00:46:24,680
So literally, if we did G.addNode of this node with the keyword argument node data one

710
00:46:24,680 --> 00:46:31,680
equals something over there, then that node will have in the metadata dictionary node data

711
00:46:31,680 --> 00:46:34,680
one, string node data one as the key.

712
00:46:34,680 --> 00:46:37,680
And the value will be this some value thing over here.

713
00:46:37,680 --> 00:46:42,680
And then if you add in a second one, which is node data two, then literally in the metadata

714
00:46:42,680 --> 00:46:49,680
dictionary, string of node underscore data two is the key that becomes part of its metadata.

715
00:46:49,680 --> 00:46:52,680
And it will be assigned whatever value that is.

716
00:46:52,680 --> 00:46:54,680
It will map to whatever value that is over here.

717
00:46:54,680 --> 00:46:55,680
Question?

718
00:46:55,680 --> 00:46:56,680
That's right.

719
00:46:56,680 --> 00:46:57,680
That's right.

720
00:46:57,680 --> 00:47:10,680
So this is one of the ways that you have this is where network access flexibility is really

721
00:47:10,680 --> 00:47:11,680
shown.

722
00:47:11,680 --> 00:47:15,680
Of course, we know that when you have flexibility, you have a lot of power, which means you could

723
00:47:15,680 --> 00:47:21,680
end up misspelling something and accidentally adding the wrong key, which FYI has happened

724
00:47:21,680 --> 00:47:22,680
to me as well.

725
00:47:22,680 --> 00:47:23,680
Right?

726
00:47:23,680 --> 00:47:26,680
So take a lesson.

727
00:47:26,680 --> 00:47:31,680
You can if it happens to you, just know that more experienced people have also suffered

728
00:47:31,680 --> 00:47:33,680
the same fate as well.

729
00:47:33,680 --> 00:47:39,680
As we'll see later on, there are ways to load tables like pandas data frames into a graph.

730
00:47:39,680 --> 00:47:44,680
And that provides a nice structured way of avoiding a lot of typographical errors that

731
00:47:44,680 --> 00:47:45,680
might show up.

732
00:47:45,680 --> 00:47:48,680
So that's an alternative you could think about.

733
00:47:48,680 --> 00:47:49,680
So we have addNode.

734
00:47:49,680 --> 00:47:51,680
Same thing happens for addEdge.

735
00:47:51,680 --> 00:47:55,680
The only difference here is you have node1, node2.

736
00:47:55,680 --> 00:48:01,680
So the first two positional arguments are the nodes that are present inside that edge.

737
00:48:01,680 --> 00:48:07,680
And then edgeData1, edgeData2 become literal keys in the metadata dictionary.

738
00:48:07,680 --> 00:48:08,680
Question?

739
00:48:08,680 --> 00:48:12,680
I was wondering if this is for validation of nodes.

740
00:48:12,680 --> 00:48:16,680
Would we add node validation into the graph?

741
00:48:16,680 --> 00:48:17,680
That's a really good question.

742
00:48:17,680 --> 00:48:18,680
Question?

743
00:48:18,680 --> 00:48:24,680
You can add nodes into a graph by just doing g.addEdge.

744
00:48:24,680 --> 00:48:25,680
That is doable.

745
00:48:25,680 --> 00:48:27,680
That is allowable.

746
00:48:27,680 --> 00:48:32,680
I forgot what the rationale is for that design decision, but if I were to imagine what it

747
00:48:32,680 --> 00:48:37,680
was, sometimes you're provided with an edge list and not the node list.

748
00:48:37,680 --> 00:48:43,680
So the way, the convenient way to add in nodes into the graph is to loop over that edge table

749
00:48:43,680 --> 00:48:48,680
that you might be given and just automatically add in a whole bunch of nodes while you're

750
00:48:48,680 --> 00:48:49,680
at it.

751
00:48:49,680 --> 00:48:50,680
Good question.

752
00:48:50,680 --> 00:48:51,680
Anything else?

753
00:48:51,680 --> 00:48:52,680
All right.

754
00:48:52,680 --> 00:48:53,680
Cool.

755
00:48:53,680 --> 00:48:57,680
So what we're going to do is embark on this exercise down below.

756
00:48:57,680 --> 00:49:03,680
In this exercise, we're going to figure out that we've left two students out of this network.

757
00:49:03,680 --> 00:49:07,680
They are student number 30 and student number 31.

758
00:49:07,680 --> 00:49:09,680
One of them is a male student.

759
00:49:09,680 --> 00:49:10,680
The other is a female student.

760
00:49:10,680 --> 00:49:14,680
So they want to add that information into the graph.

761
00:49:14,680 --> 00:49:18,680
And they love hanging out with one another, and they love hanging out with student number

762
00:49:18,680 --> 00:49:19,680
seven as well.

763
00:49:19,680 --> 00:49:24,680
So the way that we express that they love hanging out with one another is that we set

764
00:49:24,680 --> 00:49:28,680
their edge attribute count equals three on the graph.

765
00:49:28,680 --> 00:49:33,680
So I'd like you to go ahead and add this information onto the graph.

766
00:49:33,680 --> 00:49:37,680
You've seen the necessary APIs that are needed to make this happen.

767
00:49:37,680 --> 00:49:39,680
So spend about two minutes or so.

768
00:49:39,680 --> 00:49:45,680
And then once we're done with that, we can actually take a quick break.

769
00:50:07,680 --> 00:50:26,680
That's ugly.

770
00:50:26,680 --> 00:50:51,680
All right.

771
00:50:51,680 --> 00:51:18,680
All right.

772
00:51:18,680 --> 00:51:30,680
Okay.

773
00:51:30,680 --> 00:51:34,680
Can I just quickly check how many of you have added both nodes and added at least two of

774
00:51:34,680 --> 00:51:35,680
those edges?

775
00:51:35,680 --> 00:51:36,680
Okay.

776
00:51:36,680 --> 00:51:37,680
Cool.

777
00:51:37,680 --> 00:51:38,680
We can move on.

778
00:51:38,680 --> 00:51:41,680
This is mostly in the interest of time.

779
00:51:41,680 --> 00:51:48,680
So I know how tedious it can be if you want to manually add edges inside the graph, which

780
00:51:48,680 --> 00:51:51,680
is the way that the official answer does.

781
00:51:51,680 --> 00:51:58,680
So as long as you get the idea that you can do g.addNode something, g.addNode something

782
00:51:58,680 --> 00:52:02,680
with the metadata attached to it, same for the edges, you're good.

783
00:52:02,680 --> 00:52:08,680
The other key thing to remember is that this is a directed graph, not an undirected graph.

784
00:52:08,680 --> 00:52:14,680
So if you want to add the bidirectional nature, you actually have to explicitly add in the

785
00:52:14,680 --> 00:52:15,680
reverse.

786
00:52:15,680 --> 00:52:16,680
Right?

787
00:52:16,680 --> 00:52:21,680
So if I add in node 30 to 31, I also need to add 31 to 30.

788
00:52:21,680 --> 00:52:25,680
That is important because that is the specification of what was inside the exercise.

789
00:52:25,680 --> 00:52:26,680
Right?

790
00:52:26,680 --> 00:52:28,680
They love hanging out with one another.

791
00:52:28,680 --> 00:52:31,680
So there's no way out of this one.

792
00:52:31,680 --> 00:52:32,680
Cool.

793
00:52:32,680 --> 00:52:35,680
Any questions on this so far?

794
00:52:35,680 --> 00:52:40,680
At this year's ODSC, I got a question about, like, oh, but what if I need to add, like,

795
00:52:40,680 --> 00:52:42,680
a whole bunch of nodes?

796
00:52:42,680 --> 00:52:44,680
Do I really have to do this all the way?

797
00:52:44,680 --> 00:52:45,680
Not really.

798
00:52:45,680 --> 00:52:49,680
You can write a for loop if you have a prepared data structure that you can loop over.

799
00:52:49,680 --> 00:52:54,680
You can then call g.addEdge, g.addNode, right, inside there as well.

800
00:52:54,680 --> 00:52:55,680
Okay?

801
00:52:55,680 --> 00:53:02,680
If you are really curious, go to the NAMs directory.

802
00:53:02,680 --> 00:53:08,680
Then go to solutions and then go to, sorry, no, not solutions.

803
00:53:08,680 --> 00:53:16,680
Go to load data.py and you will see how a lot of these edges, these graphs are created.

804
00:53:16,680 --> 00:53:21,680
And they give you an example path, example of how you can, like, create graph objects

805
00:53:21,680 --> 00:53:26,680
from predefined text files, CSV files, et cetera, et cetera.

806
00:53:26,680 --> 00:53:28,680
All right?

807
00:53:28,680 --> 00:53:30,680
Cool.

808
00:53:30,680 --> 00:53:33,680
So we're going to move on real quick.

809
00:53:33,680 --> 00:53:37,680
I have this another test here, not so important.

810
00:53:37,680 --> 00:53:44,680
If you get the idea of what do you call, data integrity tests, then write these for yourself

811
00:53:44,680 --> 00:53:45,680
all over the place.

812
00:53:45,680 --> 00:53:47,680
They are very, very handy.

813
00:53:47,680 --> 00:53:51,680
At the bottom are some coding patterns that we have over here.

814
00:53:51,680 --> 00:53:59,680
And as I mentioned, some of the official answers inside the repo use list comprehensions.

815
00:53:59,680 --> 00:54:01,680
That is also very idiomatic.

816
00:54:01,680 --> 00:54:05,680
The most important thing, though, is that you can loop over g.edges and g.nodes.

817
00:54:05,680 --> 00:54:12,680
And as long as you know how to expand the tuple of loop variables, then you're in a good spot.

818
00:54:12,680 --> 00:54:13,680
All right?

819
00:54:13,680 --> 00:54:19,680
So in this case, if we do g.nodes, we can expand the loop variable tuple into, like,

820
00:54:19,680 --> 00:54:25,680
N, comma, D. And if we're doing g.edges with data equals true, then we can expand the loop

821
00:54:25,680 --> 00:54:33,680
tuple variable into N1, N2, D and access all of that information in an idiomatic fashion.

822
00:54:33,680 --> 00:54:35,680
All right.

823
00:54:35,680 --> 00:54:37,680
So with that, we're going to pause for five minutes.

824
00:54:37,680 --> 00:54:39,680
We finished at 10 a.m.

825
00:54:39,680 --> 00:54:42,680
So this first section of the tutorial at 10 a.m.

826
00:54:42,680 --> 00:54:43,680
So that's awesome.

827
00:54:43,680 --> 00:54:47,680
Let's pause for a five-minute bio break and reconvene at 10.05.

828
00:54:47,680 --> 00:54:51,680
And I'm going to go back into social mode.

829
00:54:51,680 --> 00:55:13,680
No, I think we can keep the recording going.

830
00:55:13,680 --> 00:55:19,680
I believe the post editing is when they might cut out the breaks or something.

831
00:55:19,680 --> 00:55:21,680
Setup?

832
00:55:21,680 --> 00:55:23,680
Ah, okay.

833
00:55:23,680 --> 00:55:25,680
Oh, you sent an email?

834
00:55:25,680 --> 00:55:27,680
Ah.

835
00:55:27,680 --> 00:55:33,680
I sent it through the official tutorial, like, PyCon messaging system about last week.

836
00:55:33,680 --> 00:55:37,680
So did you register for the tutorial after recently?

837
00:55:37,680 --> 00:55:39,680
Okay.

838
00:55:39,680 --> 00:55:41,680
Ah, okay.

839
00:55:41,680 --> 00:55:43,680
That explains it.

840
00:55:43,680 --> 00:55:45,680
Okay.

841
00:55:45,680 --> 00:55:49,680
So for setup, let me see here.

842
00:55:49,680 --> 00:55:53,680
I don't have a way of forwarding the emails.

843
00:55:53,680 --> 00:55:55,680
Hold on.

844
00:55:55,680 --> 00:55:57,680
I might, actually.

845
00:55:57,680 --> 00:55:59,680
Okay.

846
00:55:59,680 --> 00:56:01,680
Middle can help you with that.

847
00:56:01,680 --> 00:56:03,680
And I'm going to get some coffee myself.

848
00:56:03,680 --> 00:56:05,680
I'll mute myself.

849
00:56:05,680 --> 00:56:07,680
Okay.

850
00:56:07,680 --> 00:56:09,680
So I'm going to go back to the chat.

851
00:56:09,680 --> 00:56:11,680
I'm going to go back to the chat.

852
00:56:11,680 --> 00:56:13,680
I'll mute myself.

853
00:56:41,680 --> 00:56:43,680
Okay.

854
00:57:11,680 --> 00:57:13,680
Okay.

855
00:57:41,680 --> 00:57:43,680
Okay.

856
00:58:11,680 --> 00:58:13,680
Okay.

857
00:58:41,680 --> 00:58:43,680
Okay.

858
00:59:11,680 --> 00:59:13,680
Okay.

859
00:59:41,680 --> 00:59:43,680
Okay.

860
01:00:11,680 --> 01:00:13,680
Okay.

861
01:00:41,680 --> 01:00:43,680
Okay.

862
01:01:11,680 --> 01:01:13,680
Okay.

863
01:01:41,680 --> 01:01:43,680
Okay.

864
01:02:11,680 --> 01:02:13,680
Okay.

865
01:02:41,680 --> 01:02:43,680
Okay.

866
01:03:11,680 --> 01:03:13,680
Okay.

867
01:03:41,680 --> 01:03:43,680
Okay.

868
01:03:43,680 --> 01:03:45,680
Okay.

869
01:03:45,680 --> 01:03:47,680
Okay.

870
01:03:47,680 --> 01:03:49,680
Okay.

871
01:03:49,680 --> 01:03:51,680
Okay.

872
01:03:51,680 --> 01:03:53,680
Okay.

873
01:03:53,680 --> 01:03:55,680
Okay.

874
01:03:55,680 --> 01:03:57,680
Okay.

875
01:03:57,680 --> 01:03:59,680
Okay.

876
01:03:59,680 --> 01:04:01,680
Okay.

877
01:04:01,680 --> 01:04:03,680
Okay.

878
01:04:03,680 --> 01:04:05,680
Okay.

879
01:04:05,680 --> 01:04:07,680
Okay.

880
01:04:07,680 --> 01:04:09,680
Okay.

881
01:04:09,680 --> 01:04:11,680
All right.

882
01:04:11,680 --> 01:04:13,680
I'm back in teaching mode.

883
01:04:13,680 --> 01:04:15,680
Almost.

884
01:04:15,680 --> 01:04:17,680
Missing this.

885
01:04:17,680 --> 01:04:19,680
There we go.

886
01:04:19,680 --> 01:04:21,680
Now I can see everybody clearly.

887
01:04:21,680 --> 01:04:29,680
I found that after a whole year and a half of just like staring at my computer screen, my eyesight has just gotten worse.

888
01:04:29,680 --> 01:04:31,680
It's happened.

889
01:04:31,680 --> 01:04:33,680
Pardon me?

890
01:04:33,680 --> 01:04:37,680
This one has, but usually because it's close enough, I don't have it on.

891
01:04:37,680 --> 01:04:41,680
So it's taken a toll on my eyesight.

892
01:04:41,680 --> 01:04:43,680
All righty.

893
01:04:43,680 --> 01:04:45,680
So we're a little bit over, but that's okay.

894
01:04:45,680 --> 01:04:47,680
Let's get started.

895
01:04:47,680 --> 01:04:59,680
One thing that often comes up is as an early sort of question, I think, is what is the most important thing that you do to get started?

896
01:04:59,680 --> 01:05:07,680
As an early sort of question when dealing with graphs is how do I visualize it, right?

897
01:05:07,680 --> 01:05:13,680
Visualizing a graph helps you sanity check that the graph was constructed correctly.

898
01:05:13,680 --> 01:05:27,680
I remember in my early days of using NetworkX, I would be incredibly confused because I would manipulate the graph, but I had no, as we saw in Notebook 02, NetworkX intro, but I had no way of figuring out,

899
01:05:27,680 --> 01:05:29,680
did I do it right?

900
01:05:29,680 --> 01:05:30,680
Like, what's interesting?

901
01:05:30,680 --> 01:05:32,680
Can I just see it?

902
01:05:32,680 --> 01:05:44,680
And one of the early frustrations I encountered was that I was mixing up the visualization of a graph with the construction of the abstract sort of graph object in computer memory, right?

903
01:05:44,680 --> 01:05:49,680
It's really important that this be clarified, right?

904
01:05:49,680 --> 01:06:08,680
Like, when you create a graph and you manipulate it in memory, there is a way to turn that into circles and lines in a map.lib canvas, but until you explicitly call for that, we're actually just dealing with the thing in memory, in abstract.

905
01:06:08,680 --> 01:06:14,680
We're modeling entities and their relationships, but we're not yet going to see them, right?

906
01:06:14,680 --> 01:06:18,680
So what this notebook here is all about, how do we visualize graphs?

907
01:06:18,680 --> 01:06:23,680
So what I'm going to do with this notebook is it's not going to be as interactive.

908
01:06:23,680 --> 01:06:28,680
It's going to be a very, very short, quick lecture, probably 10 to 15 minutes tops.

909
01:06:28,680 --> 01:06:32,680
I'm going to have you all run the notebook from top to bottom.

910
01:06:32,680 --> 01:06:38,680
So you should, if you're in JupyterLab, there's this like fast forward icon that you can click.

911
01:06:38,680 --> 01:06:40,680
It'll restart the kernel and then run everything.

912
01:06:40,680 --> 01:06:41,680
That's one way to do it.

913
01:06:41,680 --> 01:06:47,680
If you're in VS code, there's a run all button at the top that I'm mousing over on my screen over here, right there.

914
01:06:47,680 --> 01:06:51,680
So you can click on that guy and they'll produce all of the visualizations.

915
01:06:51,680 --> 01:07:01,680
But I do want to talk about visualizations because I've seen some pretty bad, complicated, horrible hairballs, and I want to encourage people to get away from hairballs.

916
01:07:01,680 --> 01:07:03,680
That's basically the whole message of this notebook.

917
01:07:03,680 --> 01:07:16,680
If you've seen how a certain subclass of physicists who study the Internet make their diagrams of the Internet,

918
01:07:16,680 --> 01:07:21,680
you might see something that looks analogous to what you see on the screen here.

919
01:07:21,680 --> 01:07:35,680
That is, you see a bunch of circles that are separated in this, laid out according to some force physics based force directed algorithm that puts stuff that are really,

920
01:07:35,680 --> 01:07:42,680
that puts stuff that are highly connected to each other clumped up and puts stuff that are poorly connected out on the periphery.

921
01:07:42,680 --> 01:07:46,680
It is indeed one way of visualizing graphs.

922
01:07:47,680 --> 01:07:52,680
But as you can see with this graph that came from the previous notebook,

923
01:07:52,680 --> 01:08:03,680
this is going to very easily turn into a hairball, especially as you go to more and more nodes and more and more connections inside the graph.

924
01:08:03,680 --> 01:08:07,680
So how do we, how do we deal with this problem?

925
01:08:07,680 --> 01:08:20,680
That is a problem if you want to make, if you want to use a visualization of a graph to help you either understand something about the structure of the graph or to communicate some idea about the graph.

926
01:08:20,680 --> 01:08:28,680
What's even worse actually is that hairballs are initialized oftentimes with a random seed.

927
01:08:28,680 --> 01:08:35,680
So unless you explicitly remember to control the random seed, you will not get a reproducible figure.

928
01:08:35,680 --> 01:08:38,680
Your node layout will always look slightly different.

929
01:08:38,680 --> 01:08:42,680
So yeah, hairballs.

930
01:08:42,680 --> 01:08:44,680
This graph has like 28 nodes.

931
01:08:44,680 --> 01:08:46,680
It already looks like a hairball.

932
01:08:46,680 --> 01:08:49,680
So imagine what happens when you go to 200 nodes.

933
01:08:49,680 --> 01:08:51,680
It's going to look even worse.

934
01:08:51,680 --> 01:09:03,680
So there are ways to visualize graphs in such a way that you can derive insights and communicate effectively using those visualizations without resorting to hairballs.

935
01:09:03,680 --> 01:09:12,680
My whole message is of this notebook is let's talk about, let's avoid hairballs and think carefully about how we design rational graph visualizations.

936
01:09:12,680 --> 01:09:17,680
So here's one way that we can visualize the network.

937
01:09:17,680 --> 01:09:22,680
This is done by creating a matrix plot.

938
01:09:22,680 --> 01:09:23,680
All right.

939
01:09:23,680 --> 01:09:25,680
So let me explain a little bit about the matrix plot.

940
01:09:26,680 --> 01:09:35,680
Just to check with the camera, if I move over to the screen and start pointing, that's totally captured inside the video, right?

941
01:09:35,680 --> 01:09:36,680
OK, awesome.

942
01:09:36,680 --> 01:09:47,680
So in the matrix plot, what you do is you actually lay out the nodes on the X and Y axes of the matrix.

943
01:09:47,680 --> 01:09:57,680
And then you fill in an entry between every pair of nodes, depending on whether an edge exists between them or not.

944
01:09:57,680 --> 01:10:04,680
In a directed graph, you'll have to define carefully what is the source and what is the sink.

945
01:10:04,680 --> 01:10:11,680
So you can, for example, put the source on the X axis and the sink on the Y axis.

946
01:10:11,680 --> 01:10:12,680
And that is totally fine.

947
01:10:12,680 --> 01:10:14,680
Or you can swap the two around.

948
01:10:14,680 --> 01:10:15,680
And that's totally fine, too.

949
01:10:15,680 --> 01:10:22,680
But where you fill in the edge over here will depend on your definition of source and sink.

950
01:10:22,680 --> 01:10:23,680
All right.

951
01:10:23,680 --> 01:10:34,680
Now, immediately, what's visible from this graph is that the entries in this matrix are asymmetric.

952
01:10:34,680 --> 01:10:37,680
Does this make sense for a directed graph?

953
01:10:37,680 --> 01:10:38,680
It does, right?

954
01:10:38,680 --> 01:10:43,680
Because you can have an edge going from one to the other, but not the other way around.

955
01:10:43,680 --> 01:10:56,680
And by contrast, if you were to have a symmetric matrix plot, then you would know immediately that this graph was undirected or can be modeled as an undirected graph.

956
01:10:56,680 --> 01:11:05,680
So already, the type of the graph is easily visualizable from just this plot.

957
01:11:05,680 --> 01:11:11,680
In addition to that, you can do other things when you prioritize the position of the nodes.

958
01:11:11,680 --> 01:11:17,680
And by, for example, grouping the nodes according to some category that you have.

959
01:11:17,680 --> 01:11:24,680
So in this case, we have the male and female nodes separated out with one another.

960
01:11:24,680 --> 01:11:28,680
You might even be able to do some other cool things, like ordering.

961
01:11:28,680 --> 01:11:37,680
If we had the information, we could order the nodes according to their birthday in the calendar year and figure out if there were some sub patterns that we weren't picking up.

962
01:11:37,680 --> 01:11:42,680
Okay, you're back. Come back.

963
01:11:42,680 --> 01:11:51,680
We could be able to do that and see if there were certain patterns in the edges that were induced from this ordering of nodes down to the bottom.

964
01:11:51,680 --> 01:11:52,680
Right.

965
01:11:52,680 --> 01:12:04,680
So key lesson over here is if you want to draw your graphs in a rational fashion, you really want to prioritize the position of the nodes.

966
01:12:04,680 --> 01:12:19,680
If you can prioritize them by grouping, ordering, and laying them out in some fashion, then your graph visualization immediately yields some useful insights.

967
01:12:19,680 --> 01:12:22,680
Okay. Any questions?

968
01:12:22,680 --> 01:12:38,680
So for having a case that where you don't have one of those orders and you want to like, you know, look at the graph from my last one to this one, do you think you could create a more efficient partial order?

969
01:12:38,680 --> 01:12:49,680
Yes, yes. So let's say you have a graph data set that is in which every month you have a slightly different configuration of the graph.

970
01:12:49,680 --> 01:13:02,680
One way to visualize this is to ensure first off that you include nodes that are, you ensure that the node set is constant from month to month to month, even if it isn't present and connected in one of the months.

971
01:13:02,680 --> 01:13:07,680
You order them in exactly the same way from month to month to month.

972
01:13:07,680 --> 01:13:15,680
And then you only change, the only thing that becomes different are the entries in the matrix for in this example.

973
01:13:15,680 --> 01:13:27,680
Right. And then you can see how you can like almost imagine creating a PowerPoint deck where you flip through the slides and each slide has one one of these matrix plots.

974
01:13:27,680 --> 01:13:34,680
Because the node set is kept constant, all you're seeing is the difference in the structure from slide to slide to slide to slide.

975
01:13:34,680 --> 01:13:37,680
Right. So it becomes very useful for communication.

976
01:13:37,680 --> 01:13:40,680
Any other questions here?

977
01:13:40,680 --> 01:13:42,680
So I want to raise one other point.

978
01:13:42,680 --> 01:13:49,680
The fact that we can do a matrix plot already hints at the connections between graphs and linear algebra.

979
01:13:49,680 --> 01:14:04,680
Right. Because there is this data linear algebra data structure, linear linear algebra based data structure called the adjacency matrix, which can be weighted or simply binary that records which nodes are connected to which other nodes.

980
01:14:04,680 --> 01:14:09,680
Right. You can imagine a two dimensional matrix of numbers to represent that.

981
01:14:09,680 --> 01:14:11,680
Okay.

982
01:14:11,680 --> 01:14:13,680
Cool.

983
01:14:13,680 --> 01:14:15,680
Yeah, yeah, yeah, yeah, yeah.

984
01:14:15,680 --> 01:14:20,680
There's one other really obvious thing in this graph.

985
01:14:20,680 --> 01:14:23,680
What do you notice about the diagonals? Yes, I saw the arm.

986
01:14:23,680 --> 01:14:26,680
There's the diagonals have nothing inside there. Right.

987
01:14:26,680 --> 01:14:33,680
Which is kind of nice, right. You're not raising a generation of narcissists who are okay.

988
01:14:33,680 --> 01:14:40,680
So I'm not going to go down that 1940s quote from World War II.

989
01:14:40,680 --> 01:14:42,680
Yeah, yeah, that's right.

990
01:14:42,680 --> 01:14:58,680
If exactly exactly you can also take a look at like in in ter versus in trun node sort of connectivity over here just by just by simply grouping your nodes in a in a sane fashion.

991
01:14:58,680 --> 01:15:02,680
Cool. Awesome. Awesome. Awesome.

992
01:15:02,680 --> 01:15:05,680
So here's an odd here's an alternative visualization.

993
01:15:05,680 --> 01:15:08,680
It's called the arc plot.

994
01:15:08,680 --> 01:15:15,680
And the way that the arc plot is drawn is you group and order your nodes on the x axis over here.

995
01:15:15,680 --> 01:15:19,680
And all you do is draw circular arcs between anything that is connected.

996
01:15:19,680 --> 01:15:24,680
Right. That is one possible thing that you could draw.

997
01:15:24,680 --> 01:15:39,680
Right. And if there were say for example, if the x axis was time based and you saw a lot of large arcs, you would know that people connected are connected far in time.

998
01:15:39,680 --> 01:15:46,680
Whereas if you only saw very local arcs, you would know that your nodes are very locally connected in time.

999
01:15:46,680 --> 01:15:52,680
Right. So that is another visual insight that is possible from the graph.

1000
01:15:52,680 --> 01:15:54,680
The third one is the circles plot.

1001
01:15:54,680 --> 01:15:59,680
And all this is is you take the ends of the arc plot and you join them together.

1002
01:15:59,680 --> 01:16:03,680
You draw nice little arcs inside inside there as well.

1003
01:16:03,680 --> 01:16:10,680
Circos plots are actually the first thing that I encountered when it came to nicer graph visualizations.

1004
01:16:10,680 --> 01:16:17,680
They really enable you to visualize lots of groups of nodes together and how they're connected.

1005
01:16:17,680 --> 01:16:19,680
I encountered them.

1006
01:16:19,680 --> 01:16:32,680
The most memorable example that I can think of is in either a science or a nature paper where there was an analysis of the migration of humans throughout natural history and how genomes were connected.

1007
01:16:32,680 --> 01:16:41,680
Genomes from continents were connected based on sort of migration patterns and similarity of gene content.

1008
01:16:41,680 --> 01:16:45,680
Right. So that was another really cool example.

1009
01:16:45,680 --> 01:16:52,680
Now, of course, that one involved a lot of custom graph graph stuff that had to happen.

1010
01:16:52,680 --> 01:16:58,680
So this the implementation here is not as scalable as what would be needed for that.

1011
01:16:58,680 --> 01:17:02,680
That level of detail that was still a very, very cool thing.

1012
01:17:02,680 --> 01:17:07,680
The final one that I want to show is the hive plot.

1013
01:17:07,680 --> 01:17:09,680
Oops, sorry.

1014
01:17:09,680 --> 01:17:11,680
Let me see if I can.

1015
01:17:11,680 --> 01:17:13,680
Zoom out on this guy a little bit.

1016
01:17:13,680 --> 01:17:15,680
There we go. That's exactly what I wanted.

1017
01:17:15,680 --> 01:17:28,680
Okay. So with a hive plot, what you do is you take your group of nodes up to three groups per hive and you split them out onto different axes.

1018
01:17:28,680 --> 01:17:30,680
One axis is for one group.

1019
01:17:30,680 --> 01:17:40,680
So if you had three groups over here, you would have like a 12 o'clock, 4 o'clock, 8 o'clock sort of positioning of your axes.

1020
01:17:40,680 --> 01:17:57,680
What's really cool here is you can actually clone the axes and as a result of that, visualize the intra group and inter group connections separately.

1021
01:17:57,680 --> 01:18:01,680
This is another one of those really cool visualizations.

1022
01:18:01,680 --> 01:18:05,680
Both the hive plot and the circus plot.

1023
01:18:05,680 --> 01:18:17,680
I picked these up from a series of articles written by Martin Kraswinski, who is at the British Columbia Cancer Research Center as a research scientist slash visualization scientist.

1024
01:18:17,680 --> 01:18:21,680
And he had a lot of really good articles and I was curious about it.

1025
01:18:21,680 --> 01:18:35,680
So I started making my own implementations of Circos and hive plots in Python built on top of Matplotlib because the tooling back in 2014 for making this stuff was all in Perl.

1026
01:18:35,680 --> 01:18:38,680
I didn't know Perl.

1027
01:18:38,680 --> 01:18:44,680
I knew Python enough of Python to be dangerous to try to implement these on my own.

1028
01:18:44,680 --> 01:18:53,680
And so these plots are inside a Python package that I've built and had many contributions from other people.

1029
01:18:53,680 --> 01:18:55,680
The API has evolved quite a little bit over time.

1030
01:18:55,680 --> 01:18:56,680
It's called NXViz.

1031
01:18:56,680 --> 01:19:04,680
It's a graph visualization package that works explicitly with NetworkX graph objects.

1032
01:19:04,680 --> 01:19:23,680
Its intent is to be a, what do you call, its intent is to be this sort of a half research like my part time, very, very, very much part time research into graph is and sort of figuring out what our rational ways of graph visualization.

1033
01:19:23,680 --> 01:19:38,680
But I also do use the package at moments at work for when I need to put up a visualization and do some sort of a communication about like what exactly is inside a graph that I'm talking about in a scientific presentation.

1034
01:19:38,680 --> 01:19:43,680
So it does come in handy for so-called scientific communication uses as well.

1035
01:19:43,680 --> 01:19:48,680
If you're curious about it, there I think are links inside the notebook to NXViz.

1036
01:19:48,680 --> 01:19:54,680
There is an API documentation outside on GitHub pages as well.

1037
01:19:54,680 --> 01:19:59,680
And its API is very much trying to be like Seaborn, where it's declarative.

1038
01:19:59,680 --> 01:20:01,680
It's not very imperative.

1039
01:20:01,680 --> 01:20:06,680
And it also has a few flavors of ggplot where you sort of compose in annotations on top.

1040
01:20:06,680 --> 01:20:10,680
But it's all done in a way that's compatible with Matplotlib.

1041
01:20:10,680 --> 01:20:11,680
Question.

1042
01:20:11,680 --> 01:20:23,680
I'd have to see.

1043
01:20:23,680 --> 01:20:26,680
I forgot whether that's possible in the implementation.

1044
01:20:26,680 --> 01:20:29,680
Might be able to do that.

1045
01:20:29,680 --> 01:20:31,680
I'd have to double check.

1046
01:20:31,680 --> 01:20:35,680
Yeah.

1047
01:20:35,680 --> 01:20:38,680
No, this is Matplotlib based.

1048
01:20:38,680 --> 01:20:46,680
There have been requests to make this compatible with HVplot, which is built on top of Bokeh.

1049
01:20:46,680 --> 01:20:51,680
I just haven't had the bandwidth myself to write the layout algorithms.

1050
01:20:51,680 --> 01:20:52,680
Sorry.

1051
01:20:52,680 --> 01:20:55,680
I haven't had the bandwidth to execute on that.

1052
01:20:55,680 --> 01:21:03,680
I think the layout algorithms, the node layout and edge drawing algorithms are all back end agnostic.

1053
01:21:03,680 --> 01:21:08,680
But it's just getting the thing onto a canvas, which I haven't had the time to do.

1054
01:21:08,680 --> 01:21:17,680
By weight.

1055
01:21:17,680 --> 01:21:20,680
By weight.

1056
01:21:20,680 --> 01:21:21,680
Yes, actually.

1057
01:21:21,680 --> 01:21:29,680
So the recommended way for handling weights, in my opinion, personal opinion, is to use transparency.

1058
01:21:29,680 --> 01:21:38,680
And if you have a way of mapping your weight scale to zero one, then you have a very clear path.

1059
01:21:38,680 --> 01:21:46,680
The alternative, of course, is if you can categorize your weights, continuous weights into discrete bins,

1060
01:21:46,680 --> 01:21:51,680
they make for a little bit easier visualizations.

1061
01:21:51,680 --> 01:21:57,680
But of course, you trade off the sort of nuance in the weights.

1062
01:21:57,680 --> 01:22:00,680
So that is something to keep in mind.

1063
01:22:00,680 --> 01:22:03,680
Was there any other questions?

1064
01:22:03,680 --> 01:22:04,680
Okay.

1065
01:22:04,680 --> 01:22:12,680
So if not, I'm going to leave this notebook with you with sort of just one key idea.

1066
01:22:12,680 --> 01:22:17,680
That is, you should prioritize the placement of your nodes.

1067
01:22:17,680 --> 01:22:20,680
Think really hard and carefully about how you want to prioritize the placement of your nodes.

1068
01:22:20,680 --> 01:22:29,680
If you do that, then you will find that your graph visualizations become much easier to talk about and communicate when you're in a real setting.

1069
01:22:29,680 --> 01:22:32,680
Like the hairball just doesn't cut it anymore.

1070
01:22:32,680 --> 01:22:33,680
This is 2021.

1071
01:22:33,680 --> 01:22:34,680
2022, sorry.

1072
01:22:34,680 --> 01:22:36,680
Why am I still living in 2021?

1073
01:22:36,680 --> 01:22:37,680
Gosh.

1074
01:22:37,680 --> 01:22:38,680
This is 2022, right?

1075
01:22:38,680 --> 01:22:43,680
So we got to move graph viz into a more modern direction.

1076
01:22:43,680 --> 01:22:44,680
All right.

1077
01:22:44,680 --> 01:22:58,680
So if we're cool on this front, we're going to move on to some of the more exciting things, the things that really highlight how the structure of the graph gives rise to the important features, important parts of the graph.

1078
01:22:58,680 --> 01:23:05,680
So what I'd like you to do is open up notebook 02 algorithms, and we're going to walk through.

1079
01:23:05,680 --> 01:23:13,680
Hopefully we can make it through notebooks one to three over the next hour.

1080
01:23:13,680 --> 01:23:16,680
We will break at 11 for another bio break.

1081
01:23:16,680 --> 01:23:21,680
But by 1130, I'm hopeful we should be able to finish all three notebooks together.

1082
01:23:21,680 --> 01:23:24,680
Okay.

1083
01:23:24,680 --> 01:23:28,680
So let's get started over here.

1084
01:23:28,680 --> 01:23:37,680
This notebook is all about figuring out which nodes in a graph are important.

1085
01:23:37,680 --> 01:23:48,680
Now, as you probably can intuit if you have a graph where someone is connected to many people, right, that node might be that person might be a really important person.

1086
01:23:48,680 --> 01:23:53,680
That's kind of the core idea that we'll hint at today.

1087
01:23:53,680 --> 01:23:57,680
So the graph that we're going to load is called the social patterns data set.

1088
01:23:57,680 --> 01:24:01,680
And this text describes exactly what that data set is.

1089
01:24:01,680 --> 01:24:04,680
Basically, there's an exhibit.

1090
01:24:04,680 --> 01:24:07,680
It is an exhibit on infectious diseases.

1091
01:24:07,680 --> 01:24:10,680
Just to clarify, this is not a contact tracing data set, right?

1092
01:24:10,680 --> 01:24:16,680
This is not one where we're actually trying to figure out who spread the germs to the next spread a virus to the next person.

1093
01:24:16,680 --> 01:24:27,680
This is instead a data set that is asking, did two people have face to face contact for more than 20 seconds inside this gallery exhibit?

1094
01:24:27,680 --> 01:24:36,680
And it's for simplicity, what I have done here is I have actually only taken you can have multiple contacts, right, between people over time.

1095
01:24:36,680 --> 01:24:42,680
But for simplicity, I have only taken the last contact between people.

1096
01:24:42,680 --> 01:24:54,680
And so just to sanity check, in this case, is the data model of a directed graph or an undirected graph a little bit more appropriate?

1097
01:24:54,680 --> 01:25:06,680
Undirected, right. And for the reason probably that if I have face to face contact with you for 20 seconds, you automatically have face to face contact with me for 20 seconds.

1098
01:25:06,680 --> 01:25:09,680
It's kind of an automatic bidirectional.

1099
01:25:09,680 --> 01:25:13,680
So let's go ahead and run this cell down here.

1100
01:25:13,680 --> 01:25:18,680
We can also verify that this graph is an undirected graph.

1101
01:25:18,680 --> 01:25:20,680
And this is implemented as an undirected graph.

1102
01:25:20,680 --> 01:25:27,680
So we never have to worry about the directionality when we access graph edge information.

1103
01:25:27,680 --> 01:25:38,680
And as always, when you get a graph object, make sure you know how many nodes and edges are present.

1104
01:25:38,680 --> 01:25:50,680
So when it comes to figuring out what's an important node in a graph, one metric that can be used is the number of neighbors that the node has.

1105
01:25:50,680 --> 01:25:58,680
Neighbors has a very specific definition that comes from the edge structure in a graph.

1106
01:25:58,680 --> 01:26:07,680
That is to say, if a node is connected to another node, they have an edge between each other, then they are neighbors of one another.

1107
01:26:07,680 --> 01:26:19,680
Okay. So NetworkX has in the graph API, you can do g.neighbors of a particular node that is present inside the graph.

1108
01:26:19,680 --> 01:26:28,680
And what you'll get here is actually a kind of generator that doesn't immediately return the exact neighbors list.

1109
01:26:28,680 --> 01:26:35,680
But what we can do over here is cast g.neighbors of seven into a list.

1110
01:26:35,680 --> 01:26:39,680
Now, you can imagine some of the design decisions that are being made in NetworkX here.

1111
01:26:39,680 --> 01:26:47,680
Some of these may have a million connections. If you were to return the list straight away, that would get pretty bad.

1112
01:26:47,680 --> 01:27:00,680
So having an iterator, a generator basically, over the neighbors is sometimes a saner, in this case, I think a saner design decision than to immediately return the list for you.

1113
01:27:00,680 --> 01:27:11,680
In this case, we're dealing with nodes, a graph in which nodes don't have on the order of 10 to the 6 connections, edges, right, in which they're participating in.

1114
01:27:11,680 --> 01:27:16,680
So we're okay to just do list of g.neighbors here.

1115
01:27:16,680 --> 01:27:25,680
So one of the things I'd like you to do then, right, now that you know how to query a graph for the number for its neighbors,

1116
01:27:25,680 --> 01:27:34,680
what I'd like you to try out over here is to create a ranked list of nodes based on how many neighbors they have, right.

1117
01:27:34,680 --> 01:27:38,680
So spend about maybe five minutes, three to five minutes on this exercise.

1118
01:27:38,680 --> 01:27:54,680
And I would encourage you to pair program with your neighbor because this is a really great way of like sharing knowledge.

1119
01:27:54,680 --> 01:28:02,680
Okay. So I'm going to very quickly run through my own solution.

1120
01:28:02,680 --> 01:28:10,680
It does rely on pandas, which I believe is maybe a modern Python idiomatic way of handling the problem.

1121
01:28:10,680 --> 01:28:20,680
The first time I implemented the solution, I used sorted with lambda functions and I felt really clunky and lots of people were like, what, what are you doing here?

1122
01:28:20,680 --> 01:28:24,680
Right. So I think pandas makes this problem a little easier to handle.

1123
01:28:24,680 --> 01:28:36,680
The first thing that in order to solve this problem, that is to rank order nodes, the first thing that we need is a mapping from node ID to the number of neighbors that it has.

1124
01:28:36,680 --> 01:28:41,680
So that is what this first three lines, seven, eight and nine in the code block are intended to do.

1125
01:28:41,680 --> 01:28:46,680
That is to map node to the number of neighbors that it has.

1126
01:28:46,680 --> 01:28:48,680
So we create a dictionary over here.

1127
01:28:48,680 --> 01:28:54,680
Once we have a dictionary, every dictionary can be cast into a panda series.

1128
01:28:54,680 --> 01:29:00,680
The keys become the index and the values become the values inside the panda series.

1129
01:29:00,680 --> 01:29:06,680
So if we do PD series, sorry, let me comment stuff out first and walk you through it.

1130
01:29:06,680 --> 01:29:10,680
Neighbors mapping over here looks like a dictionary, right?

1131
01:29:10,680 --> 01:29:13,680
So key value pairs.

1132
01:29:13,680 --> 01:29:15,680
Then what happens afterwards?

1133
01:29:15,680 --> 01:29:17,680
We cast this as a panda series.

1134
01:29:17,680 --> 01:29:24,680
The index is the node ID and the number of neighbors is on the value inside the panda series.

1135
01:29:24,680 --> 01:29:35,680
And if we add in a sort values over here, then the first row in this series, first entry in this series will be the one that the node that has the most number of neighbors.

1136
01:29:35,680 --> 01:29:42,680
And you should get node 51 followed by node 272, followed by node 235, et cetera, et cetera.

1137
01:29:42,680 --> 01:29:47,680
So that's sort of the answer here.

1138
01:29:47,680 --> 01:29:54,680
If you want to look at what the original solution looked like, it looked like this.

1139
01:29:54,680 --> 01:29:55,680
Right?

1140
01:29:55,680 --> 01:29:58,680
And you can imagine why people are going like, what?

1141
01:29:58,680 --> 01:30:00,680
What are you doing here?

1142
01:30:00,680 --> 01:30:09,680
So it involves anonymous lambda functions and the likes and not really the most learner-friendly implementation.

1143
01:30:09,680 --> 01:30:13,680
There's also one that is like a generator-based way of handling the problem.

1144
01:30:13,680 --> 01:30:18,680
I have friends who looked at the repo and were like, you know, this could be solved with generators.

1145
01:30:18,680 --> 01:30:20,680
And then they went and solved it with generators.

1146
01:30:20,680 --> 01:30:22,680
And then I looked at their answer and went, what?

1147
01:30:22,680 --> 01:30:23,680
What are you doing?

1148
01:30:23,680 --> 01:30:24,680
Right?

1149
01:30:24,680 --> 01:30:38,680
So but in my case, now that we have pandas as a fairly idiomatic, well-known package, it feels right, sensible to depend on pandas and use its data structures and methods as much as possible.

1150
01:30:39,680 --> 01:30:42,680
OK, so let's think about neighbors.

1151
01:30:42,680 --> 01:30:48,680
A small graph that has 15 nodes.

1152
01:30:48,680 --> 01:30:49,680
Right?

1153
01:30:49,680 --> 01:30:55,680
How many, if I'm a node inside that graph, how many possible neighbors could I have?

1154
01:30:55,680 --> 01:30:58,680
14 if.

1155
01:30:58,680 --> 01:31:02,680
Sorry.

1156
01:31:02,680 --> 01:31:06,680
What conditions would it be 14 and not 15?

1157
01:31:06,680 --> 01:31:11,680
Almost there.

1158
01:31:11,680 --> 01:31:15,680
The key question is whether you are allowed to be connected to yourself.

1159
01:31:15,680 --> 01:31:17,680
There's this concept of self loops.

1160
01:31:17,680 --> 01:31:19,680
I didn't introduce this before.

1161
01:31:19,680 --> 01:31:20,680
My apologies.

1162
01:31:20,680 --> 01:31:23,680
But this is a very key idea.

1163
01:31:23,680 --> 01:31:24,680
Right?

1164
01:31:24,680 --> 01:31:35,680
If you are a node in a graph, the total number of nodes that you could possibly be connected to is either n minus one, where n is the total number of nodes in the graph,

1165
01:31:35,680 --> 01:31:45,680
minus yourself, under the condition that you can't be connected to yourself, or it will be n, which is all of the nodes, under the condition that you are allowed to be connected to yourself.

1166
01:31:45,680 --> 01:31:46,680
Right?

1167
01:31:46,680 --> 01:31:48,680
That's a very important thing to keep in mind.

1168
01:31:48,680 --> 01:31:55,680
OK, so this node in a small graph has 14 neighbors.

1169
01:31:55,680 --> 01:32:00,680
Out of 14 possible neighbors.

1170
01:32:00,680 --> 01:32:12,680
This other node in another graph has 478 neighbors out of a total possible of 650 neighbors.

1171
01:32:12,680 --> 01:32:23,680
In each graph, which node is more, when you compare the two graphs, are we able to use neighbors, do you think, to make a statement about which node is more important?

1172
01:32:23,680 --> 01:32:29,680
How so?

1173
01:32:29,680 --> 01:32:32,680
Well, the node in the bigger graph has more neighbors.

1174
01:32:32,680 --> 01:32:36,680
So is the node in the bigger graph relative to the size of the graph?

1175
01:32:36,680 --> 01:32:37,680
Yes, exactly.

1176
01:32:37,680 --> 01:32:51,680
So this is where we're going to go into the next idea here, where we're not talking about simply the number of neighbors that a node has, but rather what we call the degree centrality metric.

1177
01:32:51,680 --> 01:33:00,680
That is to say, how important is a node given its broader graph context while factoring in the number of neighbors that it has as well?

1178
01:33:00,680 --> 01:33:10,680
So in this case, a node that has 14 neighbors out of 14 possible neighbors would be really important in that small graph.

1179
01:33:10,680 --> 01:33:25,680
And if you were to rank that node against the other one that had 450 neighbors out of a possible 600, you might even say that this node in the small graph is actually more important for the small graph compared to that node in the bigger graph.

1180
01:33:25,680 --> 01:33:26,680
Right?

1181
01:33:26,680 --> 01:33:29,680
That's what this centrality metric is all about.

1182
01:33:29,680 --> 01:33:39,680
So the concept that maps onto the NetworkX API is called degree centrality.

1183
01:33:39,680 --> 01:33:40,680
Right?

1184
01:33:40,680 --> 01:33:53,680
We calculate degree centrality by taking the number of neighbors that a node has and dividing it by the total number of neighbors that a node could possibly have.

1185
01:33:53,680 --> 01:34:03,680
And the definition of the number of neighbors that a node could possibly have is dependent on whether you have self loops allowed or not.

1186
01:34:03,680 --> 01:34:13,680
In the NetworkX API, if I remember correctly, self loops are not by default allowed or not by default considered.

1187
01:34:13,680 --> 01:34:18,680
So your denominator is always number of nodes in the graph minus one.

1188
01:34:18,680 --> 01:34:23,680
So NetworkX does provide a degree centrality function.

1189
01:34:23,680 --> 01:34:28,680
The way that you use it is you use nx.degreeCentrality, pass in the graph object g.

1190
01:34:28,680 --> 01:34:34,680
I'm going to do this step by step, actually.

1191
01:34:34,680 --> 01:34:47,680
And what you get back is a dictionary that maps node to degree centrality metric, which then if you know the patterns that we're trying to establish, you can pass that into a Panda series and do stuff like rank ordering and the likes.

1192
01:34:48,680 --> 01:34:53,680
OK, so that is one thing that you can do here.

1193
01:34:53,680 --> 01:35:08,680
Again, if we sort the degree centralities Panda series by in descending order, we should get the exact same order of nodes, 51, 272, 235, 195, etc, etc.

1194
01:35:08,680 --> 01:35:17,680
So what we're going to do next is we're going to make a plot of the degree centrality metrics.

1195
01:35:17,680 --> 01:35:24,680
Every node has a degree centrality entry. So if you consider all of the nodes, you get a distribution of degree centralities.

1196
01:35:24,680 --> 01:35:35,680
Let's talk about how we might plot this distribution. I'll explain why the distribution matters later, but let's first talk about how we would plot it.

1197
01:35:35,680 --> 01:35:39,680
If you have a distribution of values, what would you use?

1198
01:35:39,680 --> 01:35:42,680
Sorry, what would you canonically reach for?

1199
01:35:42,680 --> 01:35:47,680
Histogram and.

1200
01:35:47,680 --> 01:35:53,680
Let me see, 2015 was when I learned about ECDF. So pre 2015 me would reach for histograms as well.

1201
01:35:53,680 --> 01:36:00,680
But in 2015, I learned about a different kind of distribution plot that blew my mind and I would like to share that with you.

1202
01:36:00,680 --> 01:36:04,680
And it's called the empirical cumulative distribution function. How many of you have heard of this?

1203
01:36:04,680 --> 01:36:14,680
This one. Cool. Awesome. Those who have heard about it know how awesome the ECDF is, but also know how unfamiliar most people are with the ECDF.

1204
01:36:14,680 --> 01:36:22,680
Right. So here's what the ECDF is.

1205
01:36:22,680 --> 01:36:28,680
So on the X axis, you plot, you have the values that are present in your data set.

1206
01:36:28,680 --> 01:36:38,680
And on the Y axis, you plot the cumulative fraction of data points in your data set that are at that value or below.

1207
01:36:38,680 --> 01:36:46,680
All right. And that is another way that is an alternative way of visualizing the distribution of values.

1208
01:36:46,680 --> 01:37:06,680
So if you do, if you do inside here, we have inside this next exercise, we have a thing called a function called ECDF that will return exactly the values in sorted order and the cumulative fraction that you need to be able to plot.

1209
01:37:06,680 --> 01:37:16,680
So what I'd like you to do first is attempt the exercise, probably two to three minutes and use that to plot the degree centrality distribution.

1210
01:37:16,680 --> 01:37:28,680
I will then explain once we have the degree centrality distribution plot up why ECDFs are so awesome.

1211
01:37:28,680 --> 01:37:34,680
Cool. So let's take a look at what's going on over here. I'm going to first explain the ECDF.

1212
01:37:34,680 --> 01:37:42,680
Then I'm going to explain why visualizing the distribution of some metrics of a graph is really important.

1213
01:37:42,680 --> 01:37:50,680
First off, let's take a look at the ECDF. You have on the X axis, like I mentioned, all the values that are present in your data set.

1214
01:37:50,680 --> 01:38:00,680
And then on the Y axis, it is the cumulative fraction of data points that fall within that have a particular value or less.

1215
01:38:00,680 --> 01:38:12,680
OK, on the right, I've done the exact same data set, the distribution of degree centralities, except done as a histogram.

1216
01:38:12,680 --> 01:38:25,680
And immediately, it should be clear that the histogram can hide information about your data set that would be otherwise exposed immediately with empirical cumulative distribution function.

1217
01:38:25,680 --> 01:38:35,680
So first off, have a question. Are there, if you looked at the histogram, would you be able to know if there are repeat values in your data set?

1218
01:38:35,680 --> 01:38:45,680
No. Can you tell if there are repeat values in the ECDF? How so? Yes, you have vertical bars of data points.

1219
01:38:46,680 --> 01:38:56,680
Second thing, from the histogram, can you tell what the median 25th percentile and 75th percentile values would be?

1220
01:38:56,680 --> 01:39:06,680
Completely impossible. On the other hand, you can very quickly guesstimate what the interquartile range might be.

1221
01:39:06,680 --> 01:39:16,680
If you want to know what the 25th percentile is, draw a line from the Y axis at 0.25 until you hit the ECDF and then draw a line down to the X axis, you get the value there.

1222
01:39:16,680 --> 01:39:25,680
You want to know what's at 50 percent, you can draw from the median, right? You go from 0.5 and draw down. Same thing for the 75th percentile.

1223
01:39:25,680 --> 01:39:34,680
You can do any arbitrary percentile. That's my point. OK, so you can very quickly read off arbitrary percentiles from ECDF. You can't do that with a histogram.

1224
01:39:34,680 --> 01:39:42,680
Thirdly, can you tell if there are potential outliers from a histogram? No, completely impossible.

1225
01:39:42,680 --> 01:39:49,680
On the other hand, three points show up immediately as potential really outlier kind of things, right?

1226
01:39:49,680 --> 01:40:04,680
So I hope at least these three points communicate to you that it is very easy to either intentionally lie or unintentionally obscure information that is important about a distribution by using histograms.

1227
01:40:04,680 --> 01:40:13,680
On the other hand, you have a lot more information that is immediately gleanable from an ECDF.

1228
01:40:13,680 --> 01:40:18,680
Final advantage. How many of you have tried plotting six histograms on top of one another?

1229
01:40:18,680 --> 01:40:25,680
You can plot six curves very easily. You can't do the same for histograms, right? Question.

1230
01:40:25,680 --> 01:40:44,680
People are attuned to area and height.

1231
01:40:44,680 --> 01:40:53,680
And so if we want to know where the maximum is, sorry, place of maximum density is, it's easier to visualize that in a histogram.

1232
01:40:53,680 --> 01:41:02,680
It's harder to visualize that in an ECDF. That is perhaps the one place that I would concede that a histogram makes a lot of sense.

1233
01:41:02,680 --> 01:41:17,680
But in that case, I would still preferably use instead of a histogram, I would do the one unit diff of the array of values here and plot that as the approximation of the density.

1234
01:41:17,680 --> 01:41:31,680
Right. Because the ECDF is actually the empirical area under curve of a histogram or of the empirical distribution. Question.

1235
01:41:31,680 --> 01:41:38,680
Outlier. Outlier means things that don't appear to look like they come from the rest of the distribution.

1236
01:41:38,680 --> 01:41:47,680
So in this case, there are three points that lie way out, right, compared to the rest of the distribution, which looks really nice and tight.

1237
01:41:47,680 --> 01:41:56,680
There are some cases, there are some distributions that can generate potentially arbitrarily looking like things that look like outliers, but they're actually part of the distribution.

1238
01:41:56,680 --> 01:42:07,680
So we have to be careful about calling them outliers. Yeah. So I'm just gonna leave it at that for now. Cool.

1239
01:42:07,680 --> 01:42:16,680
Any any questions on this point? This is like a slight detour around visualizing distributions. Visualizing distributions is really important, right?

1240
01:42:16,680 --> 01:42:34,680
Because there are ways to generate. There are three. There are these. There are ways, processes that we can imagine in which graphs are generated, and they will give us different distributions of things like degree centrality and other centrality metrics.

1241
01:42:34,680 --> 01:42:39,680
So imagine we have some data that is our current degree centrality metrics, right?

1242
01:42:39,680 --> 01:42:54,680
There may be there is a process of generating a graph whereby you initialize a pool of nodes and with a certain probability, you say that nodes should be connected to one another, right?

1243
01:42:54,680 --> 01:43:02,680
So you draw like point one point one point one coin flips for yes, no, these these two nodes should be connected by an edge.

1244
01:43:02,680 --> 01:43:08,680
That process generates a different distribution of degree centralities.

1245
01:43:08,680 --> 01:43:16,680
There's yet another process called preferential attachment in which you start with a bunch of nodes.

1246
01:43:16,680 --> 01:43:26,680
And you pick you start off by picking any pair of nodes at random and you do you do a coin flip to ask, should they be connected? That is your seed edge.

1247
01:43:26,680 --> 01:43:37,680
Now, every subsequent edge that you introduce into the graph or sorry, every subsequent node that you introduce into the graph, you can preference.

1248
01:43:37,680 --> 01:43:47,680
You can draw a coin biased coin flip that says it should be attached to something that already has a an edge versus something that does not have an edge already.

1249
01:43:47,680 --> 01:43:55,680
Right. So that will give a different distribution of degree centralities on the graph.

1250
01:43:55,680 --> 01:44:12,680
So if you know the characteristic distribution of degree centralities for certain graph generating processes, you can actually check to see whether your graph of interest was probably generated by that particular process or not.

1251
01:44:12,680 --> 01:44:21,680
Right. That is one way of asking answering the question. What is the what is the underlying process by which our graph was generated?

1252
01:44:21,680 --> 01:44:30,680
OK, so that that is one of the things I want to emphasize by introducing this idea of degree distributions.

1253
01:44:30,680 --> 01:44:38,680
That is different graph generating processes have different characteristic patterns in their degree distributions.

1254
01:44:38,680 --> 01:44:44,680
Yes.

1255
01:44:44,680 --> 01:44:51,680
Yeah, there is a paper by a Northeastern professor.

1256
01:44:51,680 --> 01:44:56,680
Laszlo Albert, Albert Laszlo Barbasi, right.

1257
01:44:56,680 --> 01:45:01,680
And his I think this was a year.

1258
01:45:01,680 --> 01:45:07,680
1999. Thank you, Murdo. 1999. He published this in Science, I think.

1259
01:45:07,680 --> 01:45:16,680
If you look up that article there, he makes the case for a graph that he named after himself.

1260
01:45:16,680 --> 01:45:25,680
Now I'm joking about that. I actually don't know where where the name of the name that graph name got associated with him as a result.

1261
01:45:25,680 --> 01:45:29,680
And it has its own sort of characteristic distribution of certain metrics as well.

1262
01:45:29,680 --> 01:45:34,680
Degree distribution is just one of those. Right. There are other characteristic distributions you can plot.

1263
01:45:34,680 --> 01:45:45,680
OK. Yeah, yeah, that's right. That's right. Cool. Thanks, Murdo. Cool. Let's move on.

1264
01:45:45,680 --> 01:45:53,680
Now we're going to skip a few exercises because those can be sort of exercises that you can do at home.

1265
01:45:53,680 --> 01:46:03,680
What we're going to do here is we're going to plot the Circos plot of this graph and do a little exercise in visual analytics.

1266
01:46:03,680 --> 01:46:15,680
OK, so we know we know that this is an exhibit, right, of people moving through people moving through the.

1267
01:46:16,680 --> 01:46:28,680
This is this is a this is a great data set of people moving through the exhibit and asking whether they had asking whether they had face to face contact.

1268
01:46:28,680 --> 01:46:32,680
Right. So we're going to plot here two views on the graph.

1269
01:46:32,680 --> 01:46:37,680
One is the Circos plot and one is the arc plot version.

1270
01:46:37,680 --> 01:46:45,680
The nodes happen to be ordered by the time in which they entered into the exhibit.

1271
01:46:45,680 --> 01:46:51,680
Studied, for example, the arc plot or the Circos plot. You can look at it either laptop.

1272
01:46:51,680 --> 01:47:00,680
What can you tell about the pattern of connectivity that is happening inside this exhibit?

1273
01:47:01,680 --> 01:47:08,680
Yeah, yeah. So there there seem to be people. Can you explain a little bit actually?

1274
01:47:08,680 --> 01:47:17,680
Yeah, cluster, cluster, cluster, cluster, cluster, cluster, cluster, cluster.

1275
01:47:17,680 --> 01:47:28,680
Right. Absolutely. And I agree with that. That means a lot of if you if you squint hard enough, you see something like over here, over here, over here, over here ish.

1276
01:47:28,680 --> 01:47:32,680
Maybe overlapping a little bit with the next one and then over there. Right.

1277
01:47:32,680 --> 01:47:38,680
So that means a lot of connections were local. Cool. What else?

1278
01:47:38,680 --> 01:47:48,680
That's the big broad brush stroke structure. What about something that is special or unusual that you might see?

1279
01:47:48,680 --> 01:48:05,680
Yeah, that's that's a really awesome question. Exactly.

1280
01:48:05,680 --> 01:48:13,680
So if we notice that most of the connections are kind of local and clustered, what's up with these big ones?

1281
01:48:13,680 --> 01:48:22,680
So immediately looking at a rational plot gave you the hint of a next question that could be answered.

1282
01:48:22,680 --> 01:48:38,680
I don't have the answer, unfortunately, but it is a very, very awesome example of we did the plot in a rational fashion and therefore we have that immediately pops out the next logical question that we might want to go and answer.

1283
01:48:38,680 --> 01:48:46,680
Try answering, try fishing that question out with a hairball. You would not. You would not. Right. Cool.

1284
01:48:46,680 --> 01:48:51,680
So that's the visual insights thing.

1285
01:48:51,680 --> 01:48:58,680
We're going to stop at this point on this notebook because it's 11 and I want to make sure there's enough time for a bio break.

1286
01:48:58,680 --> 01:49:05,680
So I wanted to reflect a little bit very quickly before we go for the bio break.

1287
01:49:05,680 --> 01:49:19,680
This is the first example in this tutorial that shows how the structure of a graph that is the edges that connect nodes together give rise to something that's interesting about the nodes, right?

1288
01:49:19,680 --> 01:49:26,680
Nodes that are connected to lots of people would be something of potential interest to look at.

1289
01:49:26,680 --> 01:49:36,680
You can imagine the utility of identifying the high degree connect high degree centrality nodes in a network in many situations.

1290
01:49:36,680 --> 01:49:45,680
If you're trying to amplify a message through social media, you want to get through to the celebrities on social media who are connected to lots of people.

1291
01:49:45,680 --> 01:49:59,680
If you're trying to find the super spreaders in a network, right, as was done, say, for example, during the HIV spread in the 1990s, right, super spreaders were identified by looking at who had the most number of contacts with other people.

1292
01:49:59,680 --> 01:50:07,680
Right. This is another application using the degree centrality metric or the number of neighbors that is inside there inside a graph.

1293
01:50:07,680 --> 01:50:11,680
So this is again the first one in the second and the third notebooks.

1294
01:50:11,680 --> 01:50:17,680
We're going to figure out other ways in which the graph edge structure gives rise to more interesting stuff.

1295
01:50:17,680 --> 01:50:22,680
So we're going to take a if we generally need like nine to ten minutes for breaks.

1296
01:50:22,680 --> 01:50:36,680
So let's do let's come back at eleven ten and then we'll continue on with the next notebook.

1297
01:50:36,680 --> 01:50:43,680
All righty. In the interest of time, we'll reboot. Let's get started.

1298
01:50:43,680 --> 01:50:57,680
So this time around, we're going to run through notebook zero to sorry, we're going to run through the paths notebook, which is under zero to algorithms slash zero to paths that I find B.

1299
01:50:57,680 --> 01:50:59,680
So I'd like you all to open up that one.

1300
01:50:59,680 --> 01:51:07,680
So in this notebook, we're going to encounter the most challenging exercises of the tutorial.

1301
01:51:07,680 --> 01:51:18,680
So brace yourselves for a little bit of like brain work, probably about 10 to 15 minutes worth of coding time, pair coding if you want.

1302
01:51:18,680 --> 01:51:28,680
We're going to actually see how to think on a graph, pretending that we are a dumb computer that doesn't know how to just see the structure of a graph.

1303
01:51:28,680 --> 01:51:45,680
Right. So when we think about the structure of a graph, one thing that's really cool is we can actually start figuring out whether two nodes are connected implicitly to one another, even if they are not like directly connected to one another.

1304
01:51:45,680 --> 01:51:48,680
And that involves reasoning about paths through the graph.

1305
01:51:48,680 --> 01:51:57,680
Right. You jump from one node to the next, to the next, to the next until you hit your destination node of interest.

1306
01:51:57,680 --> 01:52:05,680
It's kind of important if you're thinking about routing stuff through a transportation network, for example.

1307
01:52:05,680 --> 01:52:16,680
Right. And you want to figure out what is the shortest path that is available given that you go from this to the next place, the next place, the next place, and so on and so forth.

1308
01:52:16,680 --> 01:52:31,680
So what we're essentially going to figure out in this notebook is how to think like a computer when trying to solve for whether two nodes are connected inside a graph by a path.

1309
01:52:31,680 --> 01:52:41,680
Right. If you think about it as a human being, we put a map of all the nodes up on a map plotlib canvas.

1310
01:52:41,680 --> 01:52:49,680
You can sort of just look at the graph and go, yeah, this here, there, there, there, there. Right. And then you're done.

1311
01:52:49,680 --> 01:53:02,680
And you've got your path. But if you want to programmatically solve that problem over and over and over, you can't rely on a human to use their visual cortex and go, yeah, yeah, yeah, yeah, yeah.

1312
01:53:02,680 --> 01:53:07,680
Right. Like that doesn't work for scaling up the problem. You need a programmatic way of handling the problem.

1313
01:53:07,680 --> 01:53:18,680
So that's where we're going to introduce in this notebook the breadth first search algorithm, which was is commonly taught in lots of computer science curricula.

1314
01:53:18,680 --> 01:53:21,680
How many of you have ever implemented it before?

1315
01:53:21,680 --> 01:53:27,680
Quite a number of you. So if you're familiar with the algorithm, treat this as like a refresher.

1316
01:53:27,680 --> 01:53:31,680
I remember when in 2015 I was trying to work through the breadth first search algorithm.

1317
01:53:31,680 --> 01:53:37,680
It took me at least three attempts with an MIT undergrad to figure out how to do it correctly.

1318
01:53:37,680 --> 01:53:40,680
Right. And we made lots of mistakes along the way.

1319
01:53:40,680 --> 01:53:54,680
So for those of you for which this is the first time that you've ever encountered the breadth first search algorithm, just know that I don't I have zero expectations that you'll be able to finish the exercise that we have, which is to implement the breadth first search algorithm.

1320
01:53:54,680 --> 01:54:05,680
I have zero expectations that you'll finish it within the 15 minutes that we're going to allot because it took me at least three three attempts of whiteboarding at the whiteboarding each session being an hour long to figure out exactly what to do.

1321
01:54:05,680 --> 01:54:21,680
All right. But what I hope this does illuminate, however, is this concept of thinking on a graph where now you're not just relying on intuitive visual cues to figure out how to solve a graph problem.

1322
01:54:21,680 --> 01:54:28,680
But you're really starting to reason step by step algorithmically what needs to happen on the graph in order to solve your problem.

1323
01:54:28,680 --> 01:54:33,680
Why is Siri doing stuff? Okay, cool.

1324
01:54:33,680 --> 01:54:45,680
All righty. So what we're going to do is sort of a two step thing. We're going to first for those of you, especially who have never attempted the breadth first search algorithm.

1325
01:54:45,680 --> 01:55:00,680
I'd like you to find a way to take a piece of paper or take a text editor of some kind on your laptop and write out what you would need to do step by step to solve the following problem.

1326
01:55:00,680 --> 01:55:17,680
I have a starter node and an end node and I want to figure out whether there is a path to be able to go from one place to the next one note to the other that will involve using a breadth first search kind of algorithm inside there.

1327
01:55:17,680 --> 01:55:23,680
So I'd like you to spend maybe about five to 10 minutes jotting notes, talk with your neighbor.

1328
01:55:23,680 --> 01:55:36,680
Now that we know the formal definition of a neighbor, talk with your neighbors about the problem, how you would solve it, and even better if you can try drawing out the steps algorithmically on a sheet of paper.

1329
01:55:36,680 --> 01:55:43,680
If you can't use a text editor as your aid. All right. Give it a shot.

1330
01:55:43,680 --> 01:55:53,680
All righty. Okay.

1331
01:55:53,680 --> 01:55:58,680
I hear the discussion subsiding a little bit.

1332
01:55:58,680 --> 01:56:16,680
Just now I had a flash of inspiration, and I think it's valuable to talk through what was difficult about this problem, right, because from there we get to learn a lot about how we where the struggles are that may be common for other people that I have also probably have gone through as well in trying to understand how to think on graphs.

1333
01:56:16,680 --> 01:56:37,680
So I guess the first question that I have for everybody was like, generally speaking, what was the difficult thing with respect to for sorry, what did you all find that was a key concept conceptual blocker in trying to design the design a breadth first search kind of algorithm.

1334
01:56:46,680 --> 01:57:04,680
Ah, yes. Yes. Yes. Okay. So that is that is one very important thing, right? So when you have a queue, basically what we're trying to do here is we want to be able to a queue is a key data structure that is needed to solve this problem.

1335
01:57:04,680 --> 01:57:07,680
And you what is the queue used for in this case?

1336
01:57:07,680 --> 01:57:32,680
That's right. So you need to keep a running queue of things that I need to check, right? As you go on and understanding that we can in a Python list, you can actually grab from the front while all the data is being used.

1337
01:57:34,680 --> 01:57:52,680
And also grab appending to the to the to the back, right is a very important concept that maybe not not all of us are very familiar with. Right. So that is kind of a very important key thing to recognize. So that's that's a cool one. What else was difficult?

1338
01:57:52,680 --> 01:58:14,680
I think so. That's right. I have to admit I don't have depth for search in my working memory right now. So I'm going to trust that is the right thing to do. So if if you use a stack, you probably would end up writing DFS rather than BFS. Anything else? What else was difficult about the problem?

1339
01:58:14,680 --> 01:58:19,680
Yeah.

1340
01:58:19,680 --> 01:58:26,680
Yeah.

1341
01:58:26,680 --> 01:58:30,680
Yeah.

1342
01:58:30,680 --> 01:58:43,680
Yeah.

1343
01:58:43,680 --> 01:58:47,680
Yeah.

1344
01:58:47,680 --> 01:58:56,680
Yes.

1345
01:58:56,680 --> 01:59:25,680
Yeah. Yeah. Yeah. Yeah. Yeah. Absolutely. So one thing I like about this response is that coming up with a minimal complex example is an incredibly challenging thing to do. But once you develop the skill takes practice. When you develop the skill of imagining minimal complex examples, things that capture the essence of the complexity of the problem.

1346
01:59:25,680 --> 01:59:54,680
But aren't too big that you can't reason about things in your head. That is an incredibly useful skill for solving computational problems more generally. And when it comes to graphs coming up with graphs that look complex enough, like developing a taste for graphs that look complex enough, but aren't too complicated that you can't reason about in your head is incredibly challenging as well. For that reason, I asked in here that you conjure up a graph of maybe about 15 to 20.

1347
01:59:54,680 --> 02:00:16,680
Nodes, which seems to be about the right level of complexity. You can, for example, try to implement breadth first search on a chain graph, which is just one node connected the next connects to the next to the next. And that would be too trivial. You would not have learned to solve edge cases in trying to solve breadth first search with a chain graph.

1348
02:00:16,680 --> 02:00:34,680
But if you set up something that had like a cloud of 15 to 20 points and you randomly connected them together and you just fixed your eyes on that graph for a moment and then started to try to reason through how you would create the queue, how you would populate the queue, what sort of things you would need to have to happen.

1349
02:00:34,680 --> 02:00:44,680
What kind of conditional logic you need, right? Like you don't want to revisit nodes, right? That is another one that is troublesome. So if you end up revisiting node, that's not good. So you need to bake logic in there as well.

1350
02:00:46,680 --> 02:01:07,680
Coming up with that minimal complex example is incredibly useful for solving computational problems. I remember at work just last year, we were solving again graph related problems and they were related to nucleotide sequences and how they were supposed to be assembled together.

1351
02:01:07,680 --> 02:01:23,680
And we spent roughly two thirds of the time solving this problem by coming up with an example that represented, that was small enough for us to reason about, but also representative of the complexity of nucleotide sequences that we would ever see at work.

1352
02:01:23,680 --> 02:01:40,680
So it was the bulk of the time. It's almost like when developers spend the bulk of their time writing unit tests first before really figuring out what the implementation is. In this case for data scientists, figuring out the minimal complex structure of the problem before going to solve the problem is where it's really useful.

1353
02:01:40,680 --> 02:01:49,680
So I love that answer. What else? Anything else that's like challenging about the problem?

1354
02:01:49,680 --> 02:02:10,680
Okay, so I'm going to leave you all with what I believe is the one correct answer for BFS or one of many variants of, one of many, not variants, permutations of letters that would give you the same BFS algorithm, right?

1355
02:02:10,680 --> 02:02:31,680
As I mentioned, it took me a few tries to get it right. I'm going to leave this as something that you can take home and try to reimplement for yourself if you've never done it before. Once again, I'm going to emphasize that it is really valuable to be able to think on graphs and the breadth-first search or depth-first search algorithm, right?

1356
02:02:31,680 --> 02:02:56,680
So figuring out that implementation and then writing it in code and then actually seeing it work is extremely validating for your ability to solve graph-related problems. And mark my words, I've experienced it before. When you have the skill of solving graph problems, suddenly a lot of things look like graph problems and they become solvable when they initially may not have looked solvable, all right?

1357
02:02:56,680 --> 02:03:19,680
Cool. So we're not going to actually implement the algorithm in this, over here. And the reason I said this was the most complicated exercise in the tutorial is for exactly that reason. Now it's also from the perspective of like, did we even need to do a breadth-first search algorithm?

1358
02:03:19,680 --> 02:03:38,680
No, because that is baked into NetworkX. And if you wanted to solve the path exists problem, NetworkX actually has a function called shortest path, which will implicitly give you whether a path exists between two nodes or not, right? So, pardon me.

1359
02:03:38,680 --> 02:03:53,680
So you don't actually have to know how to implement the breadth-first search. And you don't have to, sorry, you don't actually have to implement the breadth-first search over and over in your own work.

1360
02:03:53,680 --> 02:04:10,680
I think it is breadth-first search underneath the hood. Riddle, do you remember?

1361
02:04:23,680 --> 02:04:51,680
So, yeah, so just to repeat the question for YouTube later on, what algorithm is Nx.shortestpath using? Riddle's answer is basically it depends on the graph and you actually can configure, not, I don't think you configure the function, but you actually call on an explicit particular

1362
02:04:52,680 --> 02:05:01,680
NetworkX function to find the shortest path using a particular algorithm, whether it's DFS, Dijkstra, shortest path, etc.

1363
02:05:01,680 --> 02:05:16,680
So you wouldn't configure Nx.shortestpath, you would import Nx and then Nx.dijkstra shortest path on the graph between two nodes. All right? Cool. Awesome. Anything else? Any other questions so far?

1364
02:05:16,680 --> 02:05:34,680
All right. So, yeah, so implementing breadth-first search to find out whether a path exists between two nodes is completely unnecessary for solving the problem given that NetworkX has already solved the problem for you, which is kind of the point of having a software library that you can import and rely on.

1365
02:05:34,680 --> 02:05:57,680
So if you do Nx.shortestpath of, oh, did I forget to import something? So if you import NetworkX and you do Nx.shortestpath, you pass in a graph and two nodes, what it will do is it will return for you one shortest path.

1366
02:05:57,680 --> 02:06:11,680
And this may not be the only shortest path that exists between two nodes. There could be multiple shortest paths. It will return one of them for you. What's really nice then is you can use this to figure out the length of the shortest path, right?

1367
02:06:11,680 --> 02:06:30,680
The length of the shortest path in this case would be one hop, two hop, three hop, four hop, five hops. You need five hops to go from one node, node seven to node 400. Okay? So far so good? All good? So you can then use this to sort of understand the structure of the graph.

1368
02:06:30,680 --> 02:06:57,680
Now, if you wanted to visualize just this little portion of the graph, there is actually a way of creating subgraphs from a graph by passing in, by doing g.subgraph of a collection of nodes. And what that will give you is the nodes that only belong to that subgraph and how they're connected to one another.

1369
02:06:57,680 --> 02:07:21,680
So if you wanted to visualize just this path, right, we could do this set of class method calls. You do little g is big g.subgraph of the shortest path between those two nodes. And then we might, for example, plot a matrix plot of all of those nodes together.

1370
02:07:21,680 --> 02:07:47,680
And you can see that this has the characteristic signature of a chain graph where you have nothing on the diagonal and stuff on one off, on the one off diagonals, all right? And if you wanted to, you could also rely on network X's built in drawing functionality and see that this is indeed a chain graph as well. Okay?

1371
02:07:47,680 --> 02:08:02,680
Okay. If you tried, now notice that like, because the subgraph inherit is, well, it's not inherited, but it's sort of like we're isolating a smaller part of this bigger graph when we do a subgraph, right?

1372
02:08:02,680 --> 02:08:22,680
So as a result, that subgraph is not mutable. It is completely immutable because we're assuming that the bigger graph is the one that we're carrying about and we're sort of isolating just as little section of that bigger graph. So you can't actually add in nodes into a subgraph, right? That is a very important thing to keep in mind.

1373
02:08:22,680 --> 02:08:28,680
In network X, I think this is called a frozen graph, right?

1374
02:08:28,680 --> 02:08:44,680
Okay, so one of the things then that we might want to do is grab out the chain graph of interest, but also visualize stuff that are one degree of separation off nodes on the chain, right?

1375
02:08:44,680 --> 02:08:50,680
This gives us a little sense of the context of the chain, the local context of the chain in the broader graph.

1376
02:08:50,680 --> 02:09:13,680
So here's an exercise for us to attempt, which is to draw the paths with draw out the, to be able to visualize the graph, the path that we have, but also all of the nodes that are one degree of separation out from every node on the chain on that path, right?

1377
02:09:13,680 --> 02:09:35,680
So I'd like you to solve, try to attempt to solve that problem. You have all of the API tools that are needed to solve this problem.

1378
02:09:35,680 --> 02:09:49,680
So in the interest of time, I'll walk everybody through the solution. Of course, with the knowledge that we always can go back and try to attempt the exercise on our own time, all right?

1379
02:09:49,680 --> 02:10:00,680
So the first thing's first, we know that we want to collect not only the nodes that are along a path, but also those nodes neighbors at the same time.

1380
02:10:00,680 --> 02:10:16,680
So what we can do is we can initialize a list that contains nodes on the path. And then as we iterate through nodes in the path, what we do is we append to that list or extend that list with the neighbors of that particular node.

1381
02:10:16,680 --> 02:10:37,680
So that is what we're doing here. So we instantiate the nodes of interest with just the nodes in the path first, and then we iterate over the path, grab out all of the neighbors for each node, and then we extend the node of interest with neighbors with those neighbors.

1382
02:10:37,680 --> 02:10:52,680
Now, you might have realized, as I just just just just did, that the better way to handle this is with sets if we really wanted to guarantee that there were no duplicate additions of neighbors into the list, right?

1383
02:10:52,680 --> 02:11:07,680
So if we do that, we might do this. And then we might do node of interest equals node of interest dot union of neighbors. I think that should work.

1384
02:11:07,680 --> 02:11:22,680
And yes, it does. And we get we get the same. We got the same solution. For effect, I'm showing again the hairball. You kind of can glean where the path, the chain graph looks like, but it's not perfect.

1385
02:11:22,680 --> 02:11:37,680
So in the official solution, we use NXViz to plot the path with neighbors, and we use a little bit of the highlighting capability in network NXViz to highlight particular edges that correspond to the original path.

1386
02:11:37,680 --> 02:11:43,680
And then the rest of the edges show sort of the local structure around those path that path.

1387
02:11:43,680 --> 02:11:47,680
Any questions about this?

1388
02:11:47,680 --> 02:11:57,680
Seems OK. Basically, the thing that I wanted to get everybody to get practice with was the G dot neighbors API, as well as the G dot sub graph API. All right.

1389
02:11:57,680 --> 02:12:13,680
This hopefully was a bit of exercise that helps with that. Now, why are we talking about paths? Well, not only is our paths important for routing, but also paths through a graph can can lead us to this next very important step.

1390
02:12:13,680 --> 02:12:19,680
Which is this idea of bottleneck nodes. If you have information flowing on a graph.

1391
02:12:19,680 --> 02:12:31,680
One way of well, OK, let me let me step back a little bit. We were talking in the last notebook about notebook about nodes that are important because of the edges that exist between them and their neighbors.

1392
02:12:31,680 --> 02:12:34,680
So knows that have a lot of neighbors.

1393
02:12:34,680 --> 02:12:37,680
They may be considered really important.

1394
02:12:38,680 --> 02:12:45,680
Now there is another way of assessing node importance, and that is asking if I were to remove a node.

1395
02:12:45,680 --> 02:12:51,680
Would information flow on the graph be disrupted severely right?

1396
02:12:51,680 --> 02:12:58,680
And one way of figuring that out is asking the question. How many shortest paths flow through a particular node?

1397
02:12:58,680 --> 02:13:06,680
Right. If in a graph we have a node that is really, really important in the exchange of nodes, then we have to be able to do that.

1398
02:13:06,680 --> 02:13:14,680
So that node is really important in the extreme case. It is the only node that bridges to sort of sub communities.

1399
02:13:14,680 --> 02:13:21,680
If you remove that node, those two sub communities are going to be completely disconnected.

1400
02:13:21,680 --> 02:13:27,680
So that node somehow has a lot of importance, but it may not have a lot of neighbors.

1401
02:13:27,680 --> 02:13:31,680
Right. Right. So that's that's a really important thing to keep in mind.

1402
02:13:31,680 --> 02:13:35,680
So give us another definition of importance of nodes.

1403
02:13:35,680 --> 02:13:41,680
That is what we call these what we call this is the betweenness centrality metric.

1404
02:13:41,680 --> 02:13:51,680
Right. And what betweenness centrality metric measures is how many shortest paths run through a particular node.

1405
02:13:51,680 --> 02:13:56,680
Relative to all of the shortest paths that could exist in the graph.

1406
02:13:56,680 --> 02:13:59,680
All right. That is the betweenness centrality metric.

1407
02:13:59,680 --> 02:14:06,680
What's up with Siri? Gosh, never mind. I'm just not going to wear it.

1408
02:14:06,680 --> 02:14:14,680
Cool. So the betweenness centrality metric in network X is provided as a function and it is just like the degree degree centrality metric.

1409
02:14:14,680 --> 02:14:25,680
So you think over here. We can calculate the degree centrality for sorry betweenness centrality for every single node in this graph.

1410
02:14:25,680 --> 02:14:37,680
Now, one thing that we can do is where we we can actually plot and compare how degree centrality in betweenness centrality might look like.

1411
02:14:37,680 --> 02:14:45,680
Now, having not having not plotted shown the answer just yet. What are some of your priors?

1412
02:14:45,680 --> 02:14:52,680
Do you expect them to be well correlated, even if not perfectly correlated, or do you expect them to be not necessarily correlated at all?

1413
02:14:56,680 --> 02:14:59,680
Not necessarily would be my prior as well.

1414
02:14:59,680 --> 02:15:05,680
So if you were to attempt the exercise, you would get something that looks like this guy over here.

1415
02:15:05,680 --> 02:15:15,680
I skipped over the exercise in the interest of time because I want to make sure we have time to address some of the more advanced things that others have asked about in this tutorial.

1416
02:15:15,680 --> 02:15:24,680
So you can see then that degree centrality and betweenness centrality do not necessarily have to correlate with one another.

1417
02:15:24,680 --> 02:15:35,680
I mean, if you were to zoom in hard enough and restrict your view of betweenness centrality to just zero and zero point zero five, you might see a bit of a y equals x kind of scatter plot.

1418
02:15:35,680 --> 02:15:39,680
But, you know, that's that's a very tentative way of looking at data. Please don't do that.

1419
02:15:39,680 --> 02:15:42,680
Like, please don't.

1420
02:15:42,680 --> 02:15:56,680
Okay, so now if you think about the situations in which degree centrality and betweenness centrality may not necessarily correlate, this is the exact example that we're talking about just now.

1421
02:15:56,680 --> 02:16:02,680
It's a special type of graph. It's called the barbell graph, just because it looks like a barbell.

1422
02:16:02,680 --> 02:16:13,680
And what it highlights here is that you can have a node that has a very low degree centrality because it's not connected to very many things.

1423
02:16:13,680 --> 02:16:24,680
But it's got such a high betweenness centrality because information to get from this community to that community must flow through that one little node there.

1424
02:16:24,680 --> 02:16:32,680
So if you remove this guy, the two become disconnected. You can less extreme situations where you might have two paths, right?

1425
02:16:32,680 --> 02:16:38,680
And if you disrupt, so you might have a second node over here that stuff can also flow through.

1426
02:16:38,680 --> 02:16:45,680
But then they both would have really high betweenness centrality. So if you remove one, you really increase the load on the other.

1427
02:16:45,680 --> 02:16:59,680
And that's a really important visual. For me, this is the minimal complex example that highlights why degree centrality and betweenness centrality do not necessarily have to be correlated with one another.

1428
02:16:59,680 --> 02:17:03,680
All right. Any questions on this thus far?

1429
02:17:03,680 --> 02:17:06,680
All right.

1430
02:17:06,680 --> 02:17:20,680
Let's see. I am going to make a call that we do an early bio break for eight minutes till noon and then we'll come back and we'll talk about.

1431
02:17:20,680 --> 02:17:26,680
The linear algebra and data I O notebooks. All right.

1432
02:17:26,680 --> 02:17:45,680
So let's go for a bio break for till noon and then come back at noon for the final two notebooks.

1433
02:17:45,680 --> 02:18:00,680
Yeah.

1434
02:18:00,680 --> 02:18:04,680
Test test. All right. We're good. All right.

1435
02:18:04,680 --> 02:18:14,680
Final 20 to 25 minutes of today's tutorial. We're going to let our brains relax. I'm going to provide all the entertainment.

1436
02:18:14,680 --> 02:18:27,680
It will be primarily lecture style. But please feel free to ask questions along the way. All right. This is how we keep the so-called lecture style portion a little bit more interactive and entertaining that way.

1437
02:18:27,680 --> 02:18:36,680
A lot of the times I get questions. We get questions about like, OK, yeah, you've given us a graph object, but how exactly do you load that data in?

1438
02:18:36,680 --> 02:18:46,680
And we sort of kind of addressed that question early on in the tutorial. But today, but in this notebook, I actually want to address this question head on. All right.

1439
02:18:46,680 --> 02:18:52,680
All right. So let's see here.

1440
02:18:52,680 --> 02:19:01,680
In this notebook, what we show is an example of how to load tabular data into network X.

1441
02:19:01,680 --> 02:19:17,680
Now, what's really important as a conceptual thing to remember is that your graph data, because it is a node set and an edge set, two sets of objects, you actually can represent your graph data as two tables.

1442
02:19:17,680 --> 02:19:33,680
And if you think about what's going on in a database where you have a relational database that is almost kind of a good anchoring example that you can use to reason analogously about what's happening inside graph table.

1443
02:19:33,680 --> 02:19:51,680
All right. So you have to represent your graph as two tables. You need firstly the node table, which gives which is indexed by node ID or node unique identifier and has as columns the metadata that are associated with the nodes.

1444
02:19:51,680 --> 02:20:11,680
And then you need the edge table, which has as sort of two indexing columns, the two nodes identifiers that are present inside the that are that comprise each edge and then columns of data that represent the metadata that's inside there.

1445
02:20:11,680 --> 02:20:19,680
I'm going to show you an example of this with down here.

1446
02:20:19,680 --> 02:20:27,680
First off, we're going to go through a simple example, and then we're going to walk through a slightly more complicated example.

1447
02:20:27,680 --> 02:20:39,680
So if you were to have a graph that has three nodes inside here, you could have you could have them as a plain text file in which one line is one node.

1448
02:20:39,680 --> 02:20:48,680
You have the node set node list, for example, and if you had metadata, you could tag it out. You could do like a comma separated file that looks like this guy.

1449
02:20:48,680 --> 02:20:56,680
All right. And the same can be said for edge sets. Right. You have one row is one edge.

1450
02:20:56,680 --> 02:21:02,680
And if you had metadata that's on top of it, you can represent it in a CSV format, too.

1451
02:21:03,680 --> 02:21:16,680
So and then if you if you really wanted to, you could construct a combined representation that has both the node and edge metadata inside there.

1452
02:21:16,680 --> 02:21:24,680
By definition, you're going to end up with a lot of duplication of information, as you can see over here. Right.

1453
02:21:24,680 --> 02:21:31,680
And two is in this place. We have CC in N2 and an N1 over here.

1454
02:21:31,680 --> 02:21:37,680
So you see the shape one num one and shape two num two being duplicated across the rows.

1455
02:21:37,680 --> 02:21:42,680
That is a convenience. That is the price of convenience. You get a lot of duplication in your data.

1456
02:21:42,680 --> 02:21:50,680
So the most compact representation is actually the what do they call fully normalized in database land. Right.

1457
02:21:50,680 --> 02:21:57,680
They have the normalized tables where you have just the node information and just the edge information and they're not combined together.

1458
02:21:57,680 --> 02:22:02,680
All right. But this is also possible. So now that was a toy example.

1459
02:22:02,680 --> 02:22:09,680
Here's an actual example where we do the what the Divi bike sharing data set.

1460
02:22:09,680 --> 02:22:17,680
And this was a public bike sharing ride sharing data set inside there from the city of Chicago.

1461
02:22:17,680 --> 02:22:24,680
Inside there, what they have are stations and trips taken between stations.

1462
02:22:24,680 --> 02:22:31,680
The edges are actually unique trips. What I've done inside this notebook is just to collapse them into number of trips.

1463
02:22:31,680 --> 02:22:35,680
All right. So this is mostly a convenience thing.

1464
02:22:35,680 --> 02:22:43,680
So as you can see over here, let me just run through things a little bit.

1465
02:22:43,680 --> 02:22:50,680
This is the node table as a CSV file. Now as a panda's data frame.

1466
02:22:50,680 --> 02:22:59,680
And down below here is the trips table, which I'm going to.

1467
02:22:59,680 --> 02:23:04,680
The trips table, which I'm going, which is the summary table that we're going to work with.

1468
02:23:04,680 --> 02:23:10,680
And this says from station ID to station ID, which is pretty much analogous to your edge. Right.

1469
02:23:10,680 --> 02:23:15,680
From node to node. And then in this case, we have metadata, which is number of trips.

1470
02:23:15,680 --> 02:23:23,680
So that is to say how many trips occurred between this these two stations within this time period.

1471
02:23:23,680 --> 02:23:28,680
Any questions at this point? So I hope this is like kind of clear.

1472
02:23:28,680 --> 02:23:32,680
There's nothing complicated, fancy like breadth first search going on.

1473
02:23:32,680 --> 02:23:37,680
There's no math, linear algebra going on. There's no deep database theory going on.

1474
02:23:37,680 --> 02:23:42,680
It is literally I have nodes as a table and their metadata as columns.

1475
02:23:42,680 --> 02:23:48,680
And I have edges also as a table. And the columns of information that are metadata are also stored inside there.

1476
02:23:48,680 --> 02:23:56,680
You all you need to have is the unique identifiers correctly placed in each table. OK.

1477
02:23:56,680 --> 02:23:59,680
So then now how do we load that in as a graph?

1478
02:23:59,680 --> 02:24:08,680
So Network X does have a function called from pandas edge list.

1479
02:24:08,680 --> 02:24:18,680
And that's what this does for you is it gives you the ability to specify what the source column and the target column should be,

1480
02:24:18,680 --> 02:24:21,680
as well as what the edge attribute should be.

1481
02:24:21,680 --> 02:24:26,680
Should be like which columns constitute edge attributes and underneath the hood.

1482
02:24:26,680 --> 02:24:31,680
It will automatically create the graph object for you.

1483
02:24:31,680 --> 02:24:37,680
So we can do, for example, and next up info on G.

1484
02:24:37,680 --> 02:24:46,680
And print out how many nodes and edges are present inside the graph and take a look at this guy over here,

1485
02:24:46,680 --> 02:24:53,680
which is to say that which gives us the edge table except now represented as part of the Network X graph object.

1486
02:24:53,680 --> 02:24:57,680
OK. So this is all really, really useful.

1487
02:24:57,680 --> 02:25:02,680
Notice, however, we don't have any of the node metadata that are present.

1488
02:25:02,680 --> 02:25:11,680
Right. And that's because when you add nodes into a graph from the edge list, you by definition don't have any node metadata.

1489
02:25:11,680 --> 02:25:15,680
So what we need to do then is we need to annotate the node metadata afterwards.

1490
02:25:15,680 --> 02:25:22,680
So if we wanted to, for example, add the name, the latitude, longitude, the capacity,

1491
02:25:22,680 --> 02:25:27,680
landmark unique identifier and the data at which this thing came online,

1492
02:25:27,680 --> 02:25:34,680
then what we would need to do is loop over the node table,

1493
02:25:34,680 --> 02:25:41,680
grab out the metadata that we want and add them as key value pairs inside the graph.

1494
02:25:41,680 --> 02:25:45,680
All right. So there's no automatic way to handle the node metadata just yet.

1495
02:25:45,680 --> 02:25:54,680
But the edge metadata is automatically handled. All right. Questions at this point.

1496
02:25:54,680 --> 02:25:57,680
OK. Looks like it's all pretty pedestrian. Right.

1497
02:25:57,680 --> 02:26:01,680
Like this is this is not this is there's nothing like I mentioned, nothing.

1498
02:26:01,680 --> 02:26:04,680
No fancy math, no fancy concepts involved here.

1499
02:26:04,680 --> 02:26:10,680
Most of it is brute force data processing. You can write a for loop.

1500
02:26:10,680 --> 02:26:15,680
You can do almost anything you want programmatically. All right. Cool.

1501
02:26:15,680 --> 02:26:21,680
One of the things that we do inside this notebook, which I'm not going to harp on too much,

1502
02:26:21,680 --> 02:26:27,680
is that we can filter the graph for particular properties.

1503
02:26:27,680 --> 02:26:32,680
So sorry. Like if you have edges, sorry, if you have a graph like this guy over here

1504
02:26:32,680 --> 02:26:40,680
and you wanted to plot only, say, the edges that had a hundred trips or more between bike stations,

1505
02:26:40,680 --> 02:26:49,680
then by necessity, we have to filter the graph and get rid of or not consider edges that are less than a hundred.

1506
02:26:49,680 --> 02:27:01,680
So there is an exercise inside here that lets you filter out filter out edges that sorry that for which the ask is to filter out edges that are less

1507
02:27:01,680 --> 02:27:05,680
that have a count of less than 50 trips that are present inside there.

1508
02:27:05,680 --> 02:27:18,680
And then you can take advantage of the geo plot capabilities of NXViz to make a visualization of the graph.

1509
02:27:18,680 --> 02:27:25,680
Right. The geographic spatial graph inside of this of this data set.

1510
02:27:25,680 --> 02:27:30,680
And you can see it probably has that like Chicago kind of layout that you would expect.

1511
02:27:30,680 --> 02:27:35,680
However, I'm going to caveat this by saying you probably do want to use Pysal,

1512
02:27:35,680 --> 02:27:43,680
which is for a spatial analysis library for Python to do more concrete,

1513
02:27:43,680 --> 02:27:49,680
more complicated or more principled analysis of geographic graphs. Right.

1514
02:27:49,680 --> 02:27:53,680
That's that's what I would recommend. You can use NXViz for quick and dirty views.

1515
02:27:53,680 --> 02:27:59,680
But go to Pysal if you want to do anything that's serious with geographic networks.

1516
02:27:59,680 --> 02:28:14,680
OK, cool. And then the final thing about graph I.O. that I think is important is that because network X graphs are because network X graphs are Python objects,

1517
02:28:14,680 --> 02:28:20,680
they are pickable, which means you can dump them to disk and then reload them on another place.

1518
02:28:20,680 --> 02:28:24,680
Doing so comes with all of the caveats of pickling. Right.

1519
02:28:24,680 --> 02:28:34,680
So if you know all the caveats of pickling are there, basically you need to be able to trust that the pickle does not contain malicious code that will automatically run on your computer.

1520
02:28:34,680 --> 02:28:38,680
Right. So don't do this unless you're in a real pinch.

1521
02:28:38,680 --> 02:28:46,680
Riddle.

1522
02:28:46,680 --> 02:28:50,680
OK, this is good. This is good. So I'm actually going to.

1523
02:28:50,680 --> 02:28:58,680
So in the next release, we're actually getting rid of right G pickle and read your pickle.

1524
02:28:58,680 --> 02:29:07,680
Yeah, that's like this is good because like network X, the library is reintroducing friction into the processes that should not happen. Right.

1525
02:29:07,680 --> 02:29:13,680
Right. So like we make the easy the right thing easy to do and the wrong thing a little harder to do.

1526
02:29:13,680 --> 02:29:18,680
So you don't do it as often. Right. And so that friction should build up and you don't end up pickling graphs.

1527
02:29:18,680 --> 02:29:25,680
But if you really needed to. OK, fine. Just just do it. Right. Cool.

1528
02:29:25,680 --> 02:29:30,680
And that's it for this notebook on graph I.O. right.

1529
02:29:30,680 --> 02:29:42,680
It gives you one example of how to read data from a text file and turn it into a graph key concept is no table edge table no table edge table.

1530
02:29:42,680 --> 02:29:53,680
You remember these two things. Even if you forget the exact API calls, you'll still be able to repopulate and create a graph graph network X graph object in memory.

1531
02:29:53,680 --> 02:29:56,680
All right. Cool stuff. Awesome.

1532
02:29:56,680 --> 02:30:08,680
We're going to skip over testing. Yeah.

1533
02:30:08,680 --> 02:30:22,680
Yeah. Probably.

1534
02:30:22,680 --> 02:30:30,680
You don't know that it would. Sorry. Ah. So performance depends on what you mean by performance.

1535
02:30:30,680 --> 02:30:41,680
I think if you were to do the initial graph creation in network X and you were talking about like tens of millions of people in the social network at that scale, don't use network X. Right.

1536
02:30:41,680 --> 02:30:54,680
Right. Use graph, for example, graph being the rapids. I'll flash up graph actually. It's a pretty cool package.

1537
02:30:54,680 --> 02:31:04,680
So in Nvidia naturally has a vested interest in writing GPU accelerated algorithms for the Python community.

1538
02:31:04,680 --> 02:31:28,680
So they invested a lot of manpower, a lot of resources into building out the rapids package. So if you look for rapids, AI and video, that will be that will give you access to essentially the Python data stack or as whatever it could cover of the Python data stack accelerated on GPUs.

1539
02:31:28,680 --> 02:31:40,680
So coup df for Panda's data frames on GPUs coup graph for network X on GPUs and so on and so forth. There's like a whole ecosystem of stuff that they've built out at that scale.

1540
02:31:40,680 --> 02:31:47,680
We would want to probably defer to coup graph.

1541
02:31:47,680 --> 02:32:02,680
Potentially, actually. So if you if you explicitly wanted to keep node metadata and edge metadata, then actually so data frames being one way of doing the thing graph databases being the alternative.

1542
02:32:02,680 --> 02:32:12,680
And yes, Neo4j plus a whole suite of other open source alternatives that are out there as well could be could be viable solutions. Cool.

1543
02:32:12,680 --> 02:32:14,680
Okay.

1544
02:32:14,680 --> 02:32:20,680
Cool. So we're going to skip over bipartite and go to linear algebra.

1545
02:32:20,680 --> 02:32:32,680
I found this one fascinating and mind blowing. The first time I encountered encountered the connection between linear algebra and graphs.

1546
02:32:32,680 --> 02:32:50,680
So what I'm going to do here is I'm going to run the entire notebook first and talk a little bit about three key ideas that we can represent using linear algebra methods.

1547
02:32:50,680 --> 02:32:59,680
The first is pathfinding. As it turns out, you can do pathfinding if you know how to take powers of the adjacency matrix.

1548
02:32:59,680 --> 02:33:08,680
Right. That's the first one. The second one is message passing. Message passing happens if you know how to do dot products.

1549
02:33:08,680 --> 02:33:15,680
And the third one is something that touches on a notebook that we've skipped. But I will explain the key idea.

1550
02:33:15,680 --> 02:33:32,680
If you have a bipartite graph that is nodes that have two partitions that are never connected within each other and only connected across partitions, then you can actually create the projection of this bipartite graph.

1551
02:33:32,680 --> 02:33:39,680
That is how nodes of one partition are connected with each other based on their connections to the other partition.

1552
02:33:39,680 --> 02:33:46,680
So if you have a partition that is a node that has two partitions, you can create that partition simply by doing linear algebra.

1553
02:33:46,680 --> 02:33:56,680
So let's go through the first one, which is pathfinding. For pathfinding, let's say we have a chain graph over here.

1554
02:33:56,680 --> 02:34:03,680
I did mention chain graphs are really bad for like minimal complex examples, but in this case, any more complicated than a chain graph.

1555
02:34:03,680 --> 02:34:13,680
Pathfinding with linear algebra methods. So if you have the chain graph that looks like this, you can obtain the adjacency matrix.

1556
02:34:13,680 --> 02:34:19,680
The adjacency matrix is obtained as such.

1557
02:34:19,680 --> 02:34:24,680
Adjacency matrix of G1.

1558
02:34:24,680 --> 02:34:30,680
And what you get here is a sparse, psi pi sparse matrix.

1559
02:34:30,680 --> 02:34:37,680
I believe if we import numpy.

1560
02:34:37,680 --> 02:34:41,680
That didn't work. Mural, can you help me with this? Is it too dense?

1561
02:34:41,680 --> 02:34:44,680
Thank you.

1562
02:34:44,680 --> 02:34:54,680
You get the numpy array version. Ignore the fact that it shows matrix. That API, I think, is being deprecated. You really should just be using numpy arrays.

1563
02:34:54,680 --> 02:35:06,680
So you can see the chain structure in the adjacency matrix where there's nothing on the diagonal and stuff on the one off diagonals.

1564
02:35:06,680 --> 02:35:10,680
And then that is also visualized inside the matrix plot.

1565
02:35:10,680 --> 02:35:18,680
Oh, well, OK. What did I do? I did this. To numpy array. Sorry about that. So there we go.

1566
02:35:18,680 --> 02:35:30,680
So when we when we do pathfinding, one of the things we want to be able to answer is whether two nodes are connected to one another.

1567
02:35:30,680 --> 02:35:43,680
Right. As it turns out, if you use the adjacency matrix and you take linear algebra matrix powers of the adjacency matrix, you can answer a related question,

1568
02:35:43,680 --> 02:35:50,680
which is how many paths of length K, which is the power, exist between two nodes?

1569
02:35:50,680 --> 02:36:02,680
So let's show that. So a one a one is the graph of sorry, the adjacency matrix of our graph of the chain graph.

1570
02:36:02,680 --> 02:36:08,680
If I take the second matrix power, so raise it to the matrix power two, here's what we get.

1571
02:36:08,680 --> 02:36:22,680
You get a diagonal of one, two, two, one and then an off diagonal, one off diagonal of zeros and then a two off diagonal of ones and then a zeros at the corners.

1572
02:36:22,680 --> 02:36:26,680
So what's the interpretation in here?

1573
02:36:26,680 --> 02:36:38,680
We're saying there is only one path to go from node that first node back to itself in two steps.

1574
02:36:38,680 --> 02:36:46,680
For this guy, there are two ways to go from that middle node and back to itself in two steps.

1575
02:36:46,680 --> 02:36:53,680
Here there's two ways as well. And the final terminal node, there's only one to go back to itself in two steps.

1576
02:36:53,680 --> 02:37:02,680
And then so things that are one degree of separation away, by definition, you can never go from one node to its neighbor in two steps.

1577
02:37:02,680 --> 02:37:09,680
Now you try to do it like you either go one over or you go back. Right. There's no way to go to your one degree neighbor in two steps.

1578
02:37:09,680 --> 02:37:12,680
That's why this is zero. Then you do that over there.

1579
02:37:12,680 --> 02:37:18,680
There's only one way to go from something from one node to a two degree neighbor in two steps. Right.

1580
02:37:18,680 --> 02:37:26,680
There's only one way to do it. And there's no way to go to a neighbor that's three degrees away in two steps.

1581
02:37:26,680 --> 02:37:33,680
Zero ways. So that's the interpretation of this first like power to matrix.

1582
02:37:33,680 --> 02:37:47,680
What do we do here? So if we do a third matrix power, notice how everything here becomes zero on the diagonals because there's zero ways that you can go from a node back to itself.

1583
02:37:47,680 --> 02:37:51,680
In three steps, zero ways you can try to work it out in your head.

1584
02:37:51,680 --> 02:38:00,680
There is only one way of going from a node to something that is three degrees of separation in three steps.

1585
02:38:00,680 --> 02:38:10,680
And that's the matrix power. So you can imagine then if you wanted to figure out a brute force way of using matrix powers to figure out whether there's a.

1586
02:38:11,680 --> 02:38:22,680
Yeah, if you wanted to use a brute force way to figure out how many whether there is a path between one node and another do consecutive matrix powers, which is cheap, right?

1587
02:38:22,680 --> 02:38:28,680
Fast to do at least and see whether the entry between two nodes ever is non zero.

1588
02:38:28,680 --> 02:38:35,680
If you ever get a non zero entry, you know that there is a path from one node to that other node.

1589
02:38:36,680 --> 02:38:41,680
Right. That was mind blowing. Matrix powers, matrix powers.

1590
02:38:41,680 --> 02:38:45,680
OK, same can be said for directed graphs.

1591
02:38:46,680 --> 02:38:55,680
The interpretation is identical. It is how many ways are there to go from source to sink in K power steps.

1592
02:38:56,680 --> 02:39:05,680
Right. So if you do K to the power K is equal to two over here, there's one way to go from this node to stuff to down two degrees of separation.

1593
02:39:05,680 --> 02:39:09,680
But because there's directionality in the edge, there's no back. There's no going back.

1594
02:39:09,680 --> 02:39:13,680
Right. So there's actually zero ways on the diagonal over here.

1595
02:39:13,680 --> 02:39:22,680
There's no way to go from one node to the neighbor and then back on the directed chain graph, which is kind of cool.

1596
02:39:23,680 --> 02:39:25,680
Right.

1597
02:39:28,680 --> 02:39:31,680
Next up, message passing.

1598
02:39:33,680 --> 02:39:36,680
Message passing requires two matrices.

1599
02:39:36,680 --> 02:39:44,680
You need to have the adjacency matrix and you have to have an indicator matrix that asks where the message is on the graph.

1600
02:39:44,680 --> 02:39:57,680
So the indicator matrix is sort of like the node is it is a length number of nodes and it has a one where the message is indicated to be present on that node and zero everywhere else.

1601
02:39:57,680 --> 02:39:59,680
OK, so if you do.

1602
02:40:02,680 --> 02:40:10,680
The message matrix dot product against the adjacency matrix of say this directed chain graph.

1603
02:40:10,680 --> 02:40:19,680
Take a look at what the result is. You actually get the message moving from the original position to one position over.

1604
02:40:24,680 --> 02:40:27,680
How does that work? Right. Mind blowing.

1605
02:40:28,680 --> 02:40:35,680
And then if you do a dot product against the adjacency matrix again, you move the message twice over.

1606
02:40:35,680 --> 02:40:39,680
Now, FFMPEG is where this comes in.

1607
02:40:39,680 --> 02:40:49,680
I don't know if this will work, actually. Let's see. Does it work? Does it work? Ah, it doesn't work. Does it not work? No, it doesn't work here, but it will work on the website.

1608
02:40:51,680 --> 02:40:54,680
You can visualize message passing.

1609
02:40:56,680 --> 02:40:58,680
Let me just see.

1610
02:40:58,680 --> 02:41:08,680
Here we go. I want to make this full screen. That is what happens when you message pass and then reset the graph and message pass over again.

1611
02:41:09,680 --> 02:41:10,680
So.

1612
02:41:11,680 --> 02:41:19,680
Dot product of the message indicator matrix against the adjacency matrix. As long as you get the array shapes correct, it will work.

1613
02:41:19,680 --> 02:41:20,680
All right. So.

1614
02:41:21,680 --> 02:41:32,680
Dot product of the message indicator matrix against the adjacency matrix. As long as you get the array shapes correct, you do the dot product. You can simulate message passing on the graph. It's mind blowing.

1615
02:41:34,680 --> 02:41:35,680
Final thing we'll go through.

1616
02:41:36,680 --> 02:41:40,680
Bipartite graphs. Let me explain really, really briefly what bipartite graphs are.

1617
02:41:41,680 --> 02:41:55,680
As I mentioned, bipartite graphs are where you have collections of nodes and you have nodes that within each, you have, you break them up into two partitions and you are, nodes can only be connected across partition.

1618
02:41:56,680 --> 02:42:06,680
They cannot be connected within partition. If you need an anchoring example, people buying goods. People are one partition. Goods are another partition.

1619
02:42:06,680 --> 02:42:17,680
We are hopefully past the era of people buying people. All right. So you only have people buying goods and not goods buying goods or people buying people. All right.

1620
02:42:18,680 --> 02:42:26,680
So that is an example of a bipartite graph. You can represent that by what they call a buy adjacency matrix.

1621
02:42:27,680 --> 02:42:29,680
So I scroll down here.

1622
02:42:30,680 --> 02:42:42,680
Rows. This customer product matrix, for example, is one where we have rows as customers, columns as products, and one is customer bought product.

1623
02:42:43,680 --> 02:42:48,680
Okay. So we have in here three product, three customers, four products.

1624
02:42:48,680 --> 02:42:58,680
If you want to figure out which customers are similar to one another based on shared product purchases, do a dot product.

1625
02:42:59,680 --> 02:43:15,680
You take this matrix, this guy over here, dot product against its transpose, and you will now get a customer by customer matrix in which the customer is the same as the customer.

1626
02:43:15,680 --> 02:43:24,680
So this is a matrix in which the diagonals show the number of things that they have purchased. Right.

1627
02:43:25,680 --> 02:43:33,680
And the off diagonals show between customer one and customer three, they share only one purchase.

1628
02:43:34,680 --> 02:43:38,680
Between customer two and customer three, they share two purchases and so on and so forth.

1629
02:43:40,680 --> 02:43:42,680
The math works out.

1630
02:43:45,680 --> 02:43:49,680
That was my exact reaction.

1631
02:43:50,680 --> 02:43:52,680
That is insanely cool. Right.

1632
02:43:53,680 --> 02:44:08,680
Now, someone kindly put up a customer product graph from Amazon and the bottom of the notebook, which you can review on your own time, shows how if you were to do what they call, sorry, let me backtrack a little bit.

1633
02:44:08,680 --> 02:44:15,680
Doing this operation is called calculating the projection of a bipartite graph onto one partition.

1634
02:44:16,680 --> 02:44:26,680
So we're projecting this bipartite graph onto just the customer partition, or we do the same onto products. Okay.

1635
02:44:26,680 --> 02:44:35,680
If you were to use NetworkX's thingy, let me just see here. Where do we show this? Performance objects versus matrices.

1636
02:44:37,680 --> 02:44:53,680
If you were to use NetworkX's API to calculate the projection on this graph that is however many hundreds of thousands of nodes, you might take a certain amount of time, like 15 seconds.

1637
02:44:53,680 --> 02:44:59,680
However, if you reframe the entire problem into linear algebra operations, half a second.

1638
02:45:01,680 --> 02:45:21,680
So once you know the connection between graphs and linear algebra, primarily through the adjacency matrix, but also through other things, you get down a really fascinating performance and conceptualization.

1639
02:45:21,680 --> 02:45:39,680
Performance and conceptual rabbit hole. Graph neural nets. For those of you who might be interested in neural nets that work with graph structured data, they have at their core the message passing algorithm that I showed you just now.

1640
02:45:39,680 --> 02:45:51,680
If you're interested in recommendation systems, they have deep connections to linear algebra. You can recast your entire graph problem in a linear algebra setting and obtain a lot of performance that way.

1641
02:45:51,680 --> 02:46:04,680
On the converse, what's also really cool is when you start seeing matrices, you can't stop seeing graphs. Once you know this connection, every matrix is a graph at that point.

1642
02:46:04,680 --> 02:46:18,680
And it just depends on whether it's symmetric or asymmetric, whether it is same number of nodes on each side, therefore, you know, unipartite graph or different number of nodes, then potentially bipartite.

1643
02:46:18,680 --> 02:46:31,680
So I'm going to leave us with that. I hope the last notebook that we showed was mind blowing for you all. Just as it was mind blowing for myself.

1644
02:46:31,680 --> 02:46:51,680
Okay, cool. Keep in mind, all of the material are available online. Network analysis made simple. It's freely available. You can run the code at any point on your own. If you want to get practice, you can always launch a binder session.

1645
02:46:51,680 --> 02:47:02,680
If there's spare capacity, you'll be able to launch into it. Get practice with the code. Get practice with the API. This world of graphs, network science, graph theory, et cetera, is fascinating.

1646
02:47:02,680 --> 02:47:10,680
And I'm hoping that this tutorial has given you an awesome introduction to it. So thanks for coming and we'll see you around PyCon.

