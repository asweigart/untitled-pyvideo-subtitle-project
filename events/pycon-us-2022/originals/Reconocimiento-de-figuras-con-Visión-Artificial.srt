1
00:00:00,000 --> 00:00:11,640
Bueno, entonces, nos dejamos con la tercera charla del día. Estamos con Alison Orellana

2
00:00:11,640 --> 00:00:16,000
y hoy nos vamos a estar hablando de reconocimiento de figuras con visión artificial.

3
00:00:16,000 --> 00:00:26,360
Muchas gracias, perdón por la espera. Y bueno, sí, voy a presentar lo que es reconocimiento

4
00:00:26,360 --> 00:00:32,640
de figuras con visión artificial. Estoy utilizando algunas librerías de Python, justamente.

5
00:00:32,640 --> 00:00:38,760
Y bueno, primeramente presentarme. Soy Alison Orellana Ríos, licenciada en ingeniería

6
00:00:38,760 --> 00:00:44,560
informática de Bolivia. Soy ahora actualmente maestrante en diseño y producción multimedia

7
00:00:44,560 --> 00:00:50,000
dentro de la Universidad de España y actualmente soy líder organizer de Pailadies Cochabamba,

8
00:00:50,000 --> 00:00:55,200
eso también en Bolivia. También soy instructora de programación en Cisco Networking Academy y

9
00:00:55,200 --> 00:01:01,320
también en otras academias de programación. Bueno, primeramente hablando de visión artificial,

10
00:01:01,320 --> 00:01:11,880
esta básicamente va a ser una parte de machine learning que permite utilizar o realizar algún

11
00:01:11,880 --> 00:01:16,760
tipo de técnicas de reconocimiento de imágenes con este tipo de métodos, es decir, algoritmos

12
00:01:16,760 --> 00:01:22,120
que ya están realizados dentro de la visión artificial, dentro de la misma librería. Entonces,

13
00:01:22,120 --> 00:01:26,880
qué voy a permitir con esto. Yo ya tengo métodos que permitan procesar esas imágenes,

14
00:01:26,880 --> 00:01:32,160
analizarlas y de alguna forma obtenerlas del mundo real para poder dar algún tipo de feedback.

15
00:01:32,160 --> 00:01:38,600
Entonces, esta información va a ser tratada por una máquina, voy a poder analizar la información,

16
00:01:38,600 --> 00:01:46,800
voy a poder sacar distintos pedazos o segmentos de una imagen. Como mencionaba, es una disciplina

17
00:01:46,800 --> 00:01:52,040
de machine learning, incluye métodos para adquirir del mundo real las imágenes, procesarlas y

18
00:01:52,040 --> 00:01:59,120
analizarlas posteriormente. Dentro de esto están los campos de la aplicación para visión artificial,

19
00:01:59,120 --> 00:02:06,160
que son variados. Acá tengo Computer Graphics para obtener información de imágenes, sacar algún

20
00:02:06,160 --> 00:02:11,120
tipo de segmentos, Immersion Signal Processing para procesar las imágenes, ya sea en una

21
00:02:11,120 --> 00:02:19,000
cadena de distintas figuras, distintos colores y así posteriormente. Sensor Technology para

22
00:02:19,000 --> 00:02:25,200
utilizar esto ya sea en empresas donde se puede clasificar algún objeto, las figuras,

23
00:02:25,200 --> 00:02:31,080
igual, de la misma manera. Artificial Intelligence, inteligencia artificial, donde yo voy a poder

24
00:02:31,080 --> 00:02:36,680
utilizar estos métodos, estas técnicas que ya se tienen de la parte más básica, eso es lo que

25
00:02:36,680 --> 00:02:42,200
ingresa en visión artificial. Y posteriormente Machine Learning para poder clasificar y hacer

26
00:02:42,200 --> 00:02:49,680
algún tipo de información con este tipo de datos. Dentro de este procesamiento para la visión

27
00:02:49,680 --> 00:02:56,360
artificial se tienen estos cuatro pasos, primero la captura, luego el preprocesado, luego la segmentación

28
00:02:56,360 --> 00:03:02,720
y el reconocimiento en sí mismo. Vamos a ver cada uno de esos pasos y para ello primero se tiene la

29
00:03:02,720 --> 00:03:07,520
captura. Esto es la adquisición de las imágenes digitales mediante algún tipo de dispositivo,

30
00:03:07,520 --> 00:03:12,800
algún tipo de sensores que van a permitir obtener la imagen, capturarla y eso va a depender de la

31
00:03:12,800 --> 00:03:17,560
resolución del tipo de tecnología que se utilice. Entonces, ¿qué es lo que se hace con esto? Se

32
00:03:17,560 --> 00:03:23,160
traduce el mundo analógico en imágenes que son ya digitalizadas para poder utilizarlo dentro de la

33
00:03:23,160 --> 00:03:30,400
máquina con los distintos cálculos, con los distintos algoritmos en sí. El preprocesado

34
00:03:30,400 --> 00:03:36,000
sería la preparación de las imágenes según las partes de interés que sucede. Yo ya obtengo la

35
00:03:36,000 --> 00:03:41,400
imagen, saco una captura, puede ser una imagen fija como cualquier fotografía o puede ser en

36
00:03:41,400 --> 00:03:46,400
movimiento, es decir, un video que es una sucesión de imágenes que van transcurriendo en poco tiempo

37
00:03:46,400 --> 00:03:52,880
con un lapso más corto. Entonces, yo agarro esas imágenes, las tomo, las preparo para poder utilizar

38
00:03:52,880 --> 00:04:00,040
alguna información que tenga, que sea de mi interés. Esto lo que significa es, yo saco una

39
00:04:00,040 --> 00:04:06,920
foto cualquiera, puede ser incluso esta presentación y como les muestro acá. Entonces, yo obtengo

40
00:04:06,920 --> 00:04:14,240
mediante esos algoritmos la imagen de interés, el momento, el espacio, perdón, el espacio para sacar

41
00:04:14,240 --> 00:04:20,080
algún tipo de información. En nuestro caso de la primera imagen es de wrong way, un cuadro donde yo

42
00:04:20,080 --> 00:04:26,400
obtengo, por ejemplo, lo que es la forma, simplemente el cuadrado, el rectángulo. De ahí saco lo que no

43
00:04:26,400 --> 00:04:33,720
me sirve, en este caso las letras, las de alguna forma las limito y obtengo sólo la parte de interés,

44
00:04:33,720 --> 00:04:40,960
que es la parte oscura. En esta situación es similar, tengo otro cuadro, yo saco las partes

45
00:04:40,960 --> 00:04:47,320
de interés, hago un filtrado y saco la imagen que necesito utilizar y así mismo en este otro,

46
00:04:47,320 --> 00:04:52,200
simplemente saco el círculo. Entonces, eso es preprocesar, hacer algún tipo de filtrado especial

47
00:04:52,200 --> 00:04:57,040
para poder hacer después un análisis más intensivo en esa imagen.

48
00:04:59,800 --> 00:05:04,440
Luego el tercer paso sería la segmentación, que es aislar los elementos de interés para su

49
00:05:04,440 --> 00:05:11,360
posterior interpretación. Acá se tiene un ejemplo, una imagen de un hombre con una cantidad de

50
00:05:11,360 --> 00:05:17,680
animales, en ese caso eran ovejas y el de al lado es un perro. Entonces, ¿qué es lo que saco? Obtengo

51
00:05:17,680 --> 00:05:23,600
ese tipo de información, saco los segmentos que necesito, hace reconocimiento mediante algunos

52
00:05:23,600 --> 00:05:29,840
algoritmos de machine learning y me reconoce que son perros o que son ovejas. Las reconoce y puede

53
00:05:29,840 --> 00:05:36,240
hacer una segmentación ya sea semántica o de instancia, una semántica donde los separa

54
00:05:36,240 --> 00:05:41,560
simplemente por son objetos distintos y son animales, de qué tipo, no importa, son todos iguales.

55
00:05:41,560 --> 00:05:47,000
O la de instancia donde saco cada uno de los objetos y ya puedo ir contabilizándolos o hacer otro

56
00:05:47,000 --> 00:05:53,440
tipo de, sacar algún tipo de información que sea más relevante. Finalmente el cuarto paso,

57
00:05:53,440 --> 00:05:58,120
que sería el reconocimiento en sí mismo, ya obtengo los segmentos y ya sé que hay un tipo

58
00:05:58,120 --> 00:06:03,560
de imágenes que se diferencian unas de otras, entonces de ahí ya puedo hacer el reconocimiento

59
00:06:03,560 --> 00:06:08,680
específico. Esta es una silla, esta es una persona, ese es un televisor, esa es una mesa,

60
00:06:08,680 --> 00:06:13,640
lo que se requiera y yo puedo interpretar ese tipo de información y mostrarlo, lo que se suele

61
00:06:13,640 --> 00:06:18,800
hacer en este tipo de sistemas de reconocimiento visual, que en algún momento se ha utilizado ya

62
00:06:18,800 --> 00:06:24,280
con lo que es mascarillas, la cuestión de tal vez de temperatura por color, todo ese tipo de

63
00:06:24,280 --> 00:06:30,000
aplicaciones que pueden hacerse. Entonces son esos cuatro pasos que se tienen dentro esto.

64
00:06:30,000 --> 00:06:34,440
Y bueno, también para ver lo que es el funcionamiento de la visión artificial, algunos

65
00:06:34,440 --> 00:06:40,800
ejemplos que se tienen que van a ir ligados a este procesamiento. Se habrían aplicar estos

66
00:06:40,800 --> 00:06:45,960
algoritmos, se van a tener los datos binarios, dentro de la máquina los algoritmos van a hacer

67
00:06:45,960 --> 00:06:50,480
esa transformación y se puede obtener tantas características como se requiera, ya sea las

68
00:06:50,480 --> 00:06:58,440
bordes, características como el color, el tipo de imagen que es, la figura, la forma o también segmentos.

69
00:07:00,800 --> 00:07:05,800
Las técnicas de procesamiento serían la detección de bordes, por un lado la segmentación,

70
00:07:05,800 --> 00:07:11,720
como habíamos visto anteriormente, simplemente separando unos objetos de otros, la clasificación,

71
00:07:11,720 --> 00:07:18,760
obtener esa información y clasificar de alguna forma, ya sea por tipo, color, forma y demás.

72
00:07:18,760 --> 00:07:23,760
Y la detección de funciones de coincidencia, si es que algo coincida con una imagen, esto se hace

73
00:07:23,760 --> 00:07:30,280
como matching pattern, patrones que se siguen y según eso se va igual clasificando.

74
00:07:30,280 --> 00:07:37,920
Y bueno, dentro de estas técnicas entonces se tiene la de bordes, yo tengo una imagen, saco algún

75
00:07:37,920 --> 00:07:44,360
tipo de filtrado, con Kani por ejemplo se sacan los bordes, se puede ver primero las líneas, de ahí si

76
00:07:44,360 --> 00:07:49,200
se reconoce que una línea pertenece a la misma línea, se sacan los que son los bordes justamente.

77
00:07:49,200 --> 00:07:54,120
Los segmentos ya habíamos visto anteriormente, igual, se reconoce que son una figura similar

78
00:07:54,120 --> 00:07:59,840
a otra, entonces son distintos segmentos dentro de una misma imagen. La clasificación, un ejemplo

79
00:07:59,840 --> 00:08:04,760
con las frutas, ahí tengo naranjas y limones, puedo ver en qué posición se encuentran,

80
00:08:04,760 --> 00:08:09,880
si es que se están moviendo, puedo hacerlo en cámara dentro de una imagen fija o con una cámara

81
00:08:09,880 --> 00:08:14,800
que esté procesándolo en tiempo real. Y las coincidencias, que esto igual, como se ve en el

82
00:08:14,800 --> 00:08:22,460
ejemplo, es obtener alguna información que se repite, ciertos patrones. Bien, entonces para esta

83
00:08:22,460 --> 00:08:27,160
parte las herramientas tecnológicas que se están utilizando son Python, obviamente, OpenCV,

84
00:08:27,160 --> 00:08:34,120
la librería igual de código abierto y Collaboratory. Python, todos conocemos por

85
00:08:34,120 --> 00:08:40,160
Guido Van Rossum que lo ha creado, es un lenguaje de alto nivel, simple, fácil de aprender,

86
00:08:40,160 --> 00:08:46,920
entonces ¿por qué está? Básicamente porque esa sintaxis permite hacer este tipo de código en muy

87
00:08:46,920 --> 00:08:52,920
pocas líneas, a comparación de por ejemplo Java o C++ en las que también se hace con OpenCV,

88
00:08:53,240 --> 00:08:57,360
me ha gustado mucho más acá, por ejemplo, porque justamente es más fácil de leer,

89
00:08:57,360 --> 00:09:00,760
más fácil de entender, incluso seguir de ahí con otros algoritmos de machine learning,

90
00:09:01,760 --> 00:09:08,280
con sus propias librerías, obviamente. OpenCV es la librería Open Source Computer Vision Library,

91
00:09:08,280 --> 00:09:13,080
la biblioteca para machine learning y visión computacional o visión por computador.

92
00:09:14,520 --> 00:09:19,240
Y Collaboratory finalmente, que es de Google, herramienta que me va a permitir ejecutar este

93
00:09:19,240 --> 00:09:24,080
tipo de programas sin necesidad de tener que pasar los programas, instalar algún tipo de

94
00:09:24,080 --> 00:09:32,240
instancias o librerías. Y bueno, sí pasaría la parte de demostración ahora, yo tengo acá

95
00:09:32,240 --> 00:09:38,560
mi libreta de Collaboratory y vamos a hacer lo que es el reconocimiento de las figuras,

96
00:09:38,560 --> 00:09:43,880
una vez que se reconozcan voy a contarlas, voy a hacer el conteo, entonces lo primero que hago va

97
00:09:43,880 --> 00:09:48,600
a ser, bueno, primero que corre a la librería, en todo caso dentro de Collaboratory se va a conectar,

98
00:09:50,240 --> 00:09:55,200
y ya está. Entonces, ya estaría importando, estos son parches que son de OpenCV porque

99
00:09:55,200 --> 00:10:02,200
Google no lo maneja directamente. Importo la librería que es CV2 y primero voy a sacar una

100
00:10:02,200 --> 00:10:09,200
imagen. En nuestro caso voy a, perdón, eso sí que no, pues acá.

101
00:10:22,720 --> 00:10:25,400
Voy a salvarla porque esta no la tenía en mi máquina, perdón.

102
00:10:32,200 --> 00:10:38,320
Voy a Collaboratory y acá voy a importar la imagen.

103
00:11:02,200 --> 00:11:10,920
Entonces ya tengo la imagen importada y la voy a llamar, que es imagen 1, simplemente

104
00:11:10,920 --> 00:11:19,920
leo la imagen, in read, básicamente para eso sirve, y la voy a mostrar, entonces me

105
00:11:19,920 --> 00:11:25,760
reconocería que está, tengo esta imagen. Posteriormente lo que voy a hacer es convertirla,

106
00:11:25,760 --> 00:11:30,080
hacerle el filtrado de una imagen para que no tenga demasiada información que me llene

107
00:11:30,080 --> 00:11:34,760
en la máquina. Entonces para eso voy a sacar lo que son los colores, para eso le estoy

108
00:11:34,760 --> 00:11:39,680
sacando el color a todo grises y lo estoy mostrando. Entonces el primer filtrado. El

109
00:11:39,680 --> 00:11:45,280
segundo es sacarle la información muy fuerte que tenga, es decir, si es muy contrastante

110
00:11:45,280 --> 00:11:49,040
también puede generarme mucho conflicto y mucha información interna. Entonces hago

111
00:11:49,040 --> 00:11:56,040
un pequeño blur, un pequeño difuminado de la imagen y se nota un poco más borrosa.

112
00:11:57,040 --> 00:12:02,720
Luego saco los bordes. Una vez sacado los bordes yo puedo definir, ok, esta es una línea,

113
00:12:02,720 --> 00:12:06,720
esta es otra línea, entonces este es un borde, ya tengo la cantidad de imágenes. Si notan

114
00:12:06,720 --> 00:12:12,600
hay una pequeña diferencia de la anterior imagen, justamente con el triángulo. De acá

115
00:12:12,600 --> 00:12:16,560
entonces lo que hago es sacar los contornos, contar los contornos que has reconocido como

116
00:12:16,560 --> 00:12:23,520
bordes y ya estaría corriendo esto acá. Y estos son los que me has reconocido, los

117
00:12:23,520 --> 00:12:27,560
que has dibujado alrededor. Entonces con eso yo tengo una cantidad de imágenes que

118
00:12:27,560 --> 00:12:32,480
obviamente al final me va a decir tengo una cantidad de figura 5, no 6 como muestra la

119
00:12:32,480 --> 00:12:36,080
imagen. Eso debido a que no has reconocido el amarillo como un color muy contrastante.

120
00:12:36,080 --> 00:12:42,080
Y la otra que es la clasificación, bueno aquí es la misma imagen, la voy a cargar

121
00:12:42,080 --> 00:12:49,080
la M1. Ok.

122
00:12:53,520 --> 00:13:00,520
Voy a hacer algo similar, voy a sacar los colores, los bordes y demás. Y acá.

123
00:13:13,760 --> 00:13:19,920
Estoy sacando y estoy verificando qué imágenes son cuál. Entonces me reconoce que este es

124
00:13:19,920 --> 00:13:26,520
un cuadrilátero, que este es un polígono, que este es una figura igual. Las tengo como

125
00:13:26,520 --> 00:13:30,560
cuadrilátero, como triángulo y demás. Ahora, ¿por qué me está generando conflicto? Porque

126
00:13:30,560 --> 00:13:35,080
los estás reconociendo varios en uno. Entonces hay que considerar también este tipo de

127
00:13:35,080 --> 00:13:42,080
problemas dentro de las imágenes. Vuelvo acá.

128
00:13:45,080 --> 00:13:49,900
Bien, entonces ahí tenemos una visión básica de lo que podría reconocerse. Tengo también

129
00:13:49,980 --> 00:13:54,700
otra que es la de colores, pero bueno esa no, es similar. Entonces no hay mucho problema,

130
00:13:54,700 --> 00:13:59,260
es la misma idea. Aplicaciones, reconocimiento de movimiento por un lado. Se puede hacer

131
00:13:59,260 --> 00:14:04,940
este tipo de misma secuencia de utilizar esos pasos, sacar, filtrar y obtener algún tipo

132
00:14:04,940 --> 00:14:10,300
de reconocimiento, ya sea de figuras, el tipo de figuras que son o también simplemente

133
00:14:10,300 --> 00:14:15,780
reconocer un conteo. Se puede utilizar en realidad aumentada, esto igual en tiempo real.

134
00:14:15,780 --> 00:14:21,500
Los coches autónomos es lo que suelen hacer para obtener partes de forma más detallada.

135
00:14:21,500 --> 00:14:26,300
La restauración de imagen para poder completar alguna parte que falta de una imagen. La

136
00:14:26,300 --> 00:14:30,500
eliminación de ruido también tiene algunas partes de la librería para hacer eso. Y la

137
00:14:30,500 --> 00:14:34,980
robótica, una línea de producción por ejemplo, donde yo puedo verificar una cantidad de objetos

138
00:14:34,980 --> 00:14:39,120
que pasa de forma muy rápida. Porque los algoritmos es lo que hacen, justamente hacen

139
00:14:39,120 --> 00:14:41,260
algo más rápido que los humanos.

140
00:14:41,740 --> 00:14:46,740
Acá hay unos ejemplos, esto es de la, completando una imagen, acá una línea de producción

141
00:14:46,740 --> 00:14:50,740
por ejemplo, esto es en tiempo real como está segmentando la imagen que habíamos visto

142
00:14:50,740 --> 00:14:52,940
anteriormente, igual para piezas más pequeñas.

143
00:14:55,460 --> 00:14:59,740
Acá otro donde es para una tienda, por ejemplo, yo verifico qué cantidad hay, pueden ser

144
00:14:59,740 --> 00:15:05,680
grupos, puede contar internamente cuándo se existen, el tipo, puede también filtrármelos

145
00:15:05,680 --> 00:15:11,000
de cierta forma. Para reconocimiento facial también se utiliza este tipo de algoritmos

146
00:15:11,000 --> 00:15:16,480
de machine learning, perdón, de visión artificial que tienen la misma librería. Para la cantidad

147
00:15:16,480 --> 00:15:20,520
de personas, en algún momento he visto una aplicación que muestra el distanciamiento

148
00:15:20,520 --> 00:15:25,480
que tienen las personas. Y también el nivel de salud, puedo obtener algún tipo de gráfico,

149
00:15:25,480 --> 00:15:29,840
algún tipo de marca específica, una forma, figura, color, para poder verificar que hay

150
00:15:29,840 --> 00:15:31,880
algún problema de forma ya automática.

151
00:15:31,880 --> 00:15:38,960
Los desafíos dentro de esto, al ver esta aplicación ya corriendo, es que podría relacionarse

152
00:15:38,960 --> 00:15:45,280
más también con la parte técnica, es decir, depende de que mi imagen sea bien tomada,

153
00:15:45,280 --> 00:15:49,960
que esté bien definida, el color, la forma, la figura que sea bien notorio para que se

154
00:15:49,960 --> 00:15:54,960
reconozca de forma correcta. Otro sería que los datos sean ruidosos o incompletos, en

155
00:15:54,960 --> 00:15:59,160
nuestro caso el color amarillo, yo ya tenía la imagen similar, el amarillo no lo reconoce

156
00:15:59,240 --> 00:16:04,680
bien, en algún momento en cuestión de colores el naranja lo confunde entre rojo y amarillo,

157
00:16:04,680 --> 00:16:09,280
entonces hay parámetros que se tienen que verificar un poco más, ajustarlo para que

158
00:16:09,280 --> 00:16:11,240
funcione correctamente.

159
00:16:11,240 --> 00:16:16,280
El procesamiento en tiempo real es un problema por ese lado que, justamente, si no reconoce

160
00:16:16,280 --> 00:16:20,840
muy bien una imagen va a clasificarla mal, si es que no la clasifica bien, la siguiente

161
00:16:20,840 --> 00:16:25,760
también la va a clasificar mal y así es un proceso en cadena. Y los recursos limitados,

162
00:16:25,760 --> 00:16:31,760
es decir, de una máquina a otra puede variar, en el caso de, por ejemplo, puede ser una

163
00:16:31,760 --> 00:16:38,000
imagen muy grande o un dato muy pesado para una máquina que tenga este tipo de algoritmos

164
00:16:38,000 --> 00:16:41,440
y no los va a reconocer bien por más que todo esté correctamente implementado.

165
00:16:41,440 --> 00:16:48,760
Y bueno, finalmente, las conclusiones que, bueno, esta visión artificial va a reducir

166
00:16:48,760 --> 00:16:53,840
lo que es el tiempo de la participación, en cierta forma, de los humanos en este tipo

167
00:16:53,880 --> 00:16:59,400
de aplicaciones. La participación humana, obviamente, va a ser también de cierta forma

168
00:16:59,400 --> 00:17:05,280
excluida, ¿por qué? Porque en una fábrica, por ejemplo, al tener este tipo de trayecto

169
00:17:05,280 --> 00:17:10,120
con visión artificial no se van a necesitar humanos para volver a revisar ese tipo de,

170
00:17:10,120 --> 00:17:17,120
ya sean problemas, algún tipo de, no sé, detalles que hayan salido mal, por ejemplo.

171
00:17:17,120 --> 00:17:21,040
Evita daños, reduce el tiempo y costos de mantenimiento por la cuestión de componentes,

172
00:17:21,040 --> 00:17:26,520
justamente con la misma idea, entonces no hay humanos y al no tener humanos,

173
00:17:26,520 --> 00:17:29,960
es la parte donde uno se puede equivocar, es mucho más reducida.

174
00:17:31,960 --> 00:17:39,480
Y permite interactuar con el medio facilitando esas tareas, colores, formas, figuras, rostros,

175
00:17:39,480 --> 00:17:45,520
clasificación, cantidades, entonces todo ese tipo de aplicaciones son mucho más rápidas,

176
00:17:45,520 --> 00:17:49,680
mucho más fáciles con esta librería. Y las herramientas de gran utilidad,

177
00:17:49,680 --> 00:17:56,400
ya sea en medicina para verificar algún tipo de problema, ya sea en radiografía o otro tipo

178
00:17:56,400 --> 00:18:05,120
de imágenes, la parte de imagenología. En la parte industrial, ya sean procesos que van en cadena o

179
00:18:05,120 --> 00:18:09,600
procesos bien específicos donde se verifican partes si es que están bien o si están mal.

180
00:18:09,600 --> 00:18:16,800
En el área de, por ejemplo, de diseño, cuestión de colores, si es que se adapta uno a otro.

181
00:18:17,360 --> 00:18:26,160
La parte de robótica, similar. Y bueno sí, de hecho creo que en todas las áreas se podría

182
00:18:26,160 --> 00:18:33,000
utilizar, de hecho estaba viendo hace poco que hay eso de Visión Artificial Reality,

183
00:18:33,000 --> 00:18:38,680
entonces incluso ahí se puede utilizar, la idea sería que se tenga la imagen real,

184
00:18:38,680 --> 00:18:43,600
como se suele utilizar los lentes, se puede utilizar ese tipo de algoritmo dentro de un

185
00:18:43,600 --> 00:18:48,160
glass, por ejemplo, y se puede hacer ese tipo de informaciones. No estamos tan lejos de eso,

186
00:18:48,160 --> 00:18:54,920
entonces solamente es de ver qué funcionalidades le damos. Y bueno, eso sería todo por mi parte.

187
00:18:54,920 --> 00:18:59,000
Ahí están si quieren seguirme. Muchas gracias.

188
00:19:04,880 --> 00:19:06,480
No sé si tienen alguna duda.

189
00:19:13,600 --> 00:19:19,880
¿Cuáles son los datos o es suficiente el modo que se puede para verificar si las

190
00:19:19,880 --> 00:19:23,880
miembros más complicadas, por ejemplo, se atienden a la gente?

191
00:19:23,880 --> 00:19:27,880
¿Puede ir con eso más o no?

192
00:19:27,880 --> 00:19:30,880
¿O es que se acabe el tipo de acompañamiento de los demás?

193
00:19:30,880 --> 00:19:36,040
Es más sencillo, sí, se puede. Para reconocer, por ejemplo, objetos como desayacillas, mesas y demás,

194
00:19:36,040 --> 00:19:41,200
hay librerías con una cuestión de datos ya predefinidos, entonces se los carga,

195
00:19:41,280 --> 00:19:45,280
esos datos, no se necesita hacer el entrenamiento ni nada, ya están ahí.

196
00:19:45,280 --> 00:19:54,040
Entonces solamente se llama, creo que es, no recuerdo el nombre, pero son como dos líneas de código más,

197
00:19:54,040 --> 00:19:59,760
y se los carga, se los utiliza y si es que lo tienes en tu cámara, ya funciona.

198
00:20:01,920 --> 00:20:06,080
Eso, gracias en todo caso. No sé si hay otra duda por allá.

199
00:20:11,200 --> 00:20:24,320
¿La CPU por un lado? Bueno, en realidad por la cuestión de cómo se reconozca, la cámara por un lado sería la parte más importante,

200
00:20:24,320 --> 00:20:27,800
porque si captura mal, todo el proceso va a ser malo.

201
00:20:27,800 --> 00:20:33,520
Ahora, la cuestión de memoria sería que si es que es una imagen o un conjunto de imágenes,

202
00:20:33,520 --> 00:20:37,320
en este caso teníamos seis figuras, y aún así reconoció una mal.

203
00:20:38,000 --> 00:20:47,600
Entonces depende de primero ese tipo de parámetros para reconocer el color, por ejemplo, que el amarillo no lo has reconocido directamente.

204
00:20:47,600 --> 00:20:54,080
Y si es que es con seis que está fallando, uno que es amarillo, lo hacemos en una gran cantidad de datos,

205
00:20:54,080 --> 00:20:56,560
posiblemente todos los amarillos los reconozcan mal.

206
00:20:56,560 --> 00:21:04,120
Entonces eso depende de, primero la imagen como tal y lo otro es que cuánto pueda soportar una máquina incluso ahí.

207
00:21:05,120 --> 00:21:07,120
Está bien, gracias.

208
00:21:07,120 --> 00:21:11,120
¿Puede que la redacción pueda dar?

209
00:21:11,120 --> 00:21:19,120
¿Cuál es la solución para cambiar el color?

210
00:21:19,120 --> 00:21:23,120
¿Cómo puede ir?

211
00:21:23,120 --> 00:21:28,120
Pues sí, habría que aplicar más filtros.

212
00:21:28,120 --> 00:21:38,120
Possiblemente hay varios tipos de filtrados, lo bueno es que OpenCV tiene su misma librería, su mismo espacio de trabajo donde están los tutoriales para poder ver.

213
00:21:38,120 --> 00:21:44,120
Hay muchos filtrados, en este caso, por ejemplo, yo estoy utilizando el Bare Behead to Gray.

214
00:21:44,120 --> 00:21:52,120
Para el que sí es, por ejemplo, acá el Median Blur.

215
00:21:52,120 --> 00:22:01,120
Hay otro que es un Blur más intenso, no recuerdo el nombre ahora, pero ahí, entonces se va probando, se van cambiando algunas características.

216
00:22:01,120 --> 00:22:09,120
Recuerdo que yo lo cambié porque este venía con otro, creo que es Gaussian Blur, si es que no estoy mal, y lo reduce un poco menos, es menos el filtrado.

217
00:22:09,120 --> 00:22:15,120
Entonces hay que adaptar ese tipo de partes y con eso se obtiene.

218
00:22:15,120 --> 00:22:20,120
Perfecto, muchas gracias.

