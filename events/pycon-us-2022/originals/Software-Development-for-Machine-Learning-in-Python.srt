1
00:00:00,000 --> 00:00:18,560
Hello, everyone. Welcome back. We have a next talk by Paolo Alkein on software development

2
00:00:18,560 --> 00:00:21,320
for machine learning in Python. Over to you, Paolo.

3
00:00:21,320 --> 00:00:37,800
Okay. Now it's better, right? We will have like a constraint to my hands a lot, so let's hope that

4
00:00:37,800 --> 00:00:44,040
it works. Okay. So first of all, welcome everyone. Thank you very much for attending. I'm very happy

5
00:00:44,160 --> 00:00:49,760
to be here and thank you also to all the crew that made this possible and makes it possible

6
00:00:49,760 --> 00:00:57,400
every day for this amazing conference we're having. I'd like for us to have the following

7
00:00:57,400 --> 00:01:03,960
minutes discussing a little bit about something that is very interesting for not only for me,

8
00:01:03,960 --> 00:01:08,360
but also in the latest developments that we've been having in the machine learning industry as

9
00:01:08,360 --> 00:01:15,320
a whole and it's trying to discuss a little bit what kind of software development we need in

10
00:01:15,320 --> 00:01:21,680
general in machine learning. So let's begin by taking a very simple problem, right? This is a

11
00:01:21,680 --> 00:01:26,680
very well-known problem that happens everywhere. If you go to a tutorial of scikit-learn or many

12
00:01:26,680 --> 00:01:32,320
pages that try to ease you into the classification problem, you probably are aware of the Iris

13
00:01:32,320 --> 00:01:37,440
classification, right? Here we have the Iris flowers in which the idea is for us to be able

14
00:01:37,520 --> 00:01:44,560
to classify them all by four of the features. The petal length, the petal width, the sepal length,

15
00:01:44,560 --> 00:01:49,440
and the sepal width. And from these four features we have to figure out which of the variety it

16
00:01:49,440 --> 00:01:55,960
belongs to, right? If it's setosa, versicolor, or virginiga. Just like a first disclaimer,

17
00:01:55,960 --> 00:02:01,520
first of all, since these are going to be slides, you will see like the strings of the columns being

18
00:02:01,520 --> 00:02:07,960
way too shortened, right? This is not something that I encourage. It's better to have like the

19
00:02:07,960 --> 00:02:13,160
best column names as possible, but we are like saving real estate in the slides in this case,

20
00:02:13,160 --> 00:02:18,440
right? But I want to say not in favor of naming columns like this in production code, right?

21
00:02:18,440 --> 00:02:26,040
Now, the first thing that you can do when you take a look at this problem and how to solve it,

22
00:02:26,040 --> 00:02:31,120
usually you like spin up a notebook or a Python interpreter or whatever, and you start working

23
00:02:31,120 --> 00:02:35,600
with it as a playground, right? Like trying new ideas and figuring out how to solve this problem.

24
00:02:35,600 --> 00:02:42,440
So a very, very simple solution to this problem can be this one here, right? A very simple solution

25
00:02:42,440 --> 00:02:47,680
to this problem in which we are using the technical stack that is very usual for machine learning

26
00:02:47,680 --> 00:02:54,840
developers or data scientists that is basically using pandas and scikit-learn, right? So you can

27
00:02:54,840 --> 00:02:59,680
see like the bunch of imports in the beginning, and then we are basically loading a data set,

28
00:02:59,680 --> 00:03:06,200
okay? From the data set that we've loaded as the CSV, we recognize the features and the target,

29
00:03:06,200 --> 00:03:11,800
right? And then we build a classifier with the pipeline object that we have from scikit-learn,

30
00:03:11,800 --> 00:03:16,440
right? In this case, this pipeline object consists of two steps. In the first one,

31
00:03:16,440 --> 00:03:23,240
we select the two best of the features according to the specific criteria. Even we can choose if

32
00:03:23,240 --> 00:03:29,440
we want to, right? And from those features, we classify them with a logistic regression

33
00:03:29,440 --> 00:03:38,080
directly to see, to figure out which variety they belong to. This is like the declaration

34
00:03:38,080 --> 00:03:42,120
of the classifier. In the next step, we actually do the fitting of the model,

35
00:03:42,120 --> 00:03:47,680
what we normally know as training of the model of machine learning. And then we compute the

36
00:03:47,680 --> 00:03:52,120
accuracy score that we have over the training set, right? This is only just to show one of the things

37
00:03:52,120 --> 00:03:57,280
we can do. Again, I'm not saying that you should figure out the accuracy of your model on the

38
00:03:57,280 --> 00:04:03,480
training set, right? But after we calculate the accuracy, we simply inform and realize

39
00:04:03,480 --> 00:04:11,760
what's the accuracy score that we got. Whoa, I didn't expect that. There's something strange

40
00:04:11,760 --> 00:04:19,400
going on with the slides. It's like I'm having like a sub slide under my slide. This is not being

41
00:04:19,400 --> 00:04:34,720
shown here. Let me just try to quickly sort this out. Okay, so this is like live settings. Oh my.

42
00:04:34,720 --> 00:04:48,280
Okay. Wow. Okay, so yeah, it looks like some machine learning model understood what I was

43
00:04:48,280 --> 00:04:57,880
trying to do, right? Okay, let's get it from here now. Okay, it might happen again. I don't know how

44
00:04:57,880 --> 00:05:04,440
I solved it, so probably I'll have to shoot it again if it happens. Okay, now this is what we have

45
00:05:04,440 --> 00:05:08,560
as the playground, right? Usually, actually, this pipeline that we are seeing here is what I took

46
00:05:08,560 --> 00:05:12,480
almost verbatim from the tutorial that you have in Scikit-learn when you try to implement the

47
00:05:12,480 --> 00:05:20,360
pipeline, right? Now, when we have to put this into production, there are several hurdles that

48
00:05:20,360 --> 00:05:26,320
appear when we try to put this tiny source of code in production, right? This is a very well-known

49
00:05:26,320 --> 00:05:31,920
image from a paper known as Hidden Technical Depth in Machine Learning Systems. I recommend every

50
00:05:31,920 --> 00:05:36,160
data scientist, machine learning developer, or machine learning engineer that hasn't read this

51
00:05:36,160 --> 00:05:43,920
yet to take a look at it because it will allow you to see what's on the other side of your scope,

52
00:05:43,920 --> 00:05:47,560
right? If you are a machine learning engineer, you realize what are the problems that typically

53
00:05:47,560 --> 00:05:51,600
data scientists have when taking a look at, when working with production code and vice versa.

54
00:05:51,600 --> 00:05:57,640
Putting things into production implies a lot of different challenges, right? I won't name all of

55
00:05:57,640 --> 00:06:03,000
them, but basically, I think that the ones that we usually don't consider when thinking about this

56
00:06:03,000 --> 00:06:08,800
are the, at least we as data scientists, right? Sometimes we don't consider the continuous training

57
00:06:08,800 --> 00:06:14,960
in the deployment, the provisioning of infrastructure to actually do the training of the models, the model

58
00:06:14,960 --> 00:06:20,200
tracking, and then how to serve it, right? This is only like a subset of the multitude of problems

59
00:06:20,200 --> 00:06:23,920
you can see, not problems, but challenges you can see when you have to put this into production.

60
00:06:23,920 --> 00:06:29,760
And one of the key elements of the paper that we are seeing here is that the machine learning code

61
00:06:29,800 --> 00:06:39,120
that we've just built is only like a small part of this whole structure, right? And I'm going to

62
00:06:39,120 --> 00:06:50,200
discuss today how we can make this small but very fundamental part of the code, how we can make it

63
00:06:50,200 --> 00:06:58,800
work so it can serve the purpose of going into production and also having an easy exploration

64
00:06:58,800 --> 00:07:04,840
for the scientist in general, right? So why do we say that it's important for the data scientists

65
00:07:04,840 --> 00:07:09,400
or the machine learning developers to know how the codes are going into production, right? What we say

66
00:07:09,400 --> 00:07:15,800
is that the developer experience of the data scientist is very tightly coupled to what production

67
00:07:15,800 --> 00:07:20,440
looks like, right? So in the first example, let's suppose that we have a first data scientist that

68
00:07:20,440 --> 00:07:26,120
does a couple of changes, maybe on this base model we've just seen, and deploys it to production

69
00:07:26,120 --> 00:07:30,520
directly, right? By saying deploy to production, what we're saying is that he or she is the one in

70
00:07:30,520 --> 00:07:36,760
charge of actually writing what we call production code, right? What is going to belong to the

71
00:07:36,760 --> 00:07:44,520
structure we've seen before. Even in this case, it's clear that the data scientist or machine

72
00:07:44,520 --> 00:07:52,240
learning developer has a lot of coupling with what production code looks like, but it's also

73
00:07:52,360 --> 00:07:59,640
relevant to notice that if the next data scientist comes and they try to do some changes on top of

74
00:07:59,640 --> 00:08:05,280
this, they have to be able to understand what the production code was, right? So the coupling

75
00:08:05,280 --> 00:08:10,600
between the experience is both for the first writing of the code, but also for understanding

76
00:08:10,600 --> 00:08:15,640
the code to actually do changes afterwards. Now there's another extreme solution, right,

77
00:08:15,640 --> 00:08:21,360
that we can think about it. Let's put like a barrier there, right? We put the machine learning

78
00:08:21,520 --> 00:08:27,840
engineering team between the data scientist and the production code, and we say, hey, you're not

79
00:08:27,840 --> 00:08:32,160
going to be the one writing the production code. Don't worry about it. You just like think about

80
00:08:32,160 --> 00:08:37,040
the model, think how it works, do it all in your playground, and I will be in charge of writing

81
00:08:37,040 --> 00:08:42,520
this into production code. And while this looks like can decouple the data scientist from the

82
00:08:42,520 --> 00:08:47,960
production code itself, the problem remains when the next data scientist comes and try to understand

83
00:08:47,960 --> 00:08:53,480
what's happening, right? They have to get the latest code that we have into production, and they

84
00:08:53,480 --> 00:08:59,000
have to understand what it means and how to work with it. Now this can be solved in many different

85
00:08:59,000 --> 00:09:02,960
ways, right? One possibility is to say that the machine learning engineer is the one that's going

86
00:09:02,960 --> 00:09:08,280
to explain the production code to each of the data scientists. Another possibility to say that the

87
00:09:08,280 --> 00:09:14,240
data scientists have to talk among each other, and these are all like very usual solutions that work

88
00:09:14,400 --> 00:09:20,880
in many different aspects. But today I want to discuss with you a software design solution for

89
00:09:20,880 --> 00:09:28,560
the productionization of machine learning code, right? What if we can learn how to write this code

90
00:09:28,560 --> 00:09:34,480
so that it works according to the following four pillars? The first one is that the code has to

91
00:09:34,480 --> 00:09:39,880
have fast and easy exploration. We know that the solutions that we have for these problems are very

92
00:09:39,880 --> 00:09:47,000
speculative, and the models change way too often, right? So we have to allow the data scientists to

93
00:09:47,000 --> 00:09:54,560
work with new ideas on top of the production code. But we also want it to be declarative and

94
00:09:54,560 --> 00:10:00,960
intention revealing, right? Martin Fowler put it much better than I probably can do, and one of the

95
00:10:00,960 --> 00:10:06,440
things that he said was that the code is the only artifact that we have that is sufficiently

96
00:10:06,560 --> 00:10:12,640
detailed and precise to act as documentation. This doesn't mean that we don't have to write any

97
00:10:12,640 --> 00:10:16,920
documentation apart from the code, of course. That's not what I'm saying. What I'm saying is

98
00:10:16,920 --> 00:10:22,360
that we have to seize the opportunity of this production code here, right? We have to be able

99
00:10:22,360 --> 00:10:27,640
to take advantage of the code that we have in production, right? We have to make it as

100
00:10:27,640 --> 00:10:34,640
declarative as possible. Another important thing that we need is to have what we will call sensible

101
00:10:34,640 --> 00:10:41,280
checkpoints, right? We will then try to define better what I mean by this. But the main goal that

102
00:10:41,280 --> 00:10:46,120
we have here is that if we have a pipeline in which we are doing many different stuff in the

103
00:10:46,120 --> 00:10:52,720
whole production code, we want to be able to hook into a problem, right, with our own solution that

104
00:10:52,720 --> 00:10:59,000
we had before and simply reuse one of the steps. And we also want to be able to hook out of the

105
00:10:59,000 --> 00:11:06,440
problem, right, and use the previous steps as things for our exploration and so on, right? So

106
00:11:06,440 --> 00:11:12,680
the reusing of these steps is very important. Keep in mind that sometimes it's even necessary,

107
00:11:12,680 --> 00:11:17,400
right, because some of these steps can take way too long to run. And if you have to wait like four

108
00:11:17,400 --> 00:11:22,560
or five hours for a step to run, you won't be able to do a faster and easier exploration.

109
00:11:22,560 --> 00:11:29,840
And another very important thing is that we need to have seamless tracking and monitoring of the

110
00:11:29,840 --> 00:11:37,400
code that's working in production. And by this I mean that we have to track the code, but we cannot

111
00:11:37,400 --> 00:11:41,760
track it in a way that pollutes the declarative and intention code that we've just described,

112
00:11:41,760 --> 00:11:46,360
right? Suppose the case in which we are seeing like the same playground code that we have,

113
00:11:46,360 --> 00:11:52,800
but we have like 30 or 40 calls to log this, log that, and so on, right? This is a solution that

114
00:11:52,800 --> 00:11:57,680
while it does log the model, it pollutes a lot the development space, right? So we want to avoid it.

115
00:11:57,680 --> 00:12:04,600
Now with these four pillars that I've just discussed, we're going to do like a cautionary

116
00:12:04,600 --> 00:12:11,880
tale on the productionizing of the model that we have just seen. Now this is the training file

117
00:12:11,880 --> 00:12:17,800
that we've just written down. The imports are now collapsed, and they will probably collapse for

118
00:12:17,800 --> 00:12:22,040
some part of the talk. But just keep in mind we're importing whatever it takes for it to work, right?

119
00:12:22,040 --> 00:12:26,640
So this is the code that we've just had. And one of the things that we realized from the code we're

120
00:12:26,640 --> 00:12:33,120
seeing here is that there's no way that this is going to go into production, right? Why? Because

121
00:12:33,120 --> 00:12:40,240
the model that we've just trained in the classifier.fit line only lives inside the scope of this Python

122
00:12:40,240 --> 00:12:45,800
file, right? We need to find a way to persist this model somewhere for us to be able to load it later

123
00:12:45,800 --> 00:12:52,280
on to do whatever we need to do. For example, I don't know, like an online serving of the model

124
00:12:52,280 --> 00:12:57,760
and things like. So the first thing we realize is that instead of checking the accuracy of code,

125
00:12:57,760 --> 00:13:03,120
what we actually want to do is to save the model as a pickle file, for example, right? We know that

126
00:13:03,120 --> 00:13:10,120
pickle is a library that's very useful for this, and we can load it directly with this very simple

127
00:13:10,120 --> 00:13:18,040
two sentence here thanks to the with statement, right? Now, when we do this, then the prediction

128
00:13:18,040 --> 00:13:24,440
part of the file that we have will actually load the model file that we have. And on an unseen data

129
00:13:24,440 --> 00:13:29,640
set, this unseen iris that we're seeing here, we will predict and actually checking the accuracy

130
00:13:29,640 --> 00:13:34,000
score here, right? Now keep in mind that this is just one of the possible implementation of the

131
00:13:34,000 --> 00:13:39,200
prediction. Of course, we can do it this way. From the moment we decouple the training from the

132
00:13:39,280 --> 00:13:45,040
serving, we can actually serve with, I don't know, through a REST endpoint or through fast API or

133
00:13:45,040 --> 00:13:50,240
however we want, we are free to do it in any way. So consider these files as a token for all the

134
00:13:50,240 --> 00:13:56,200
possible ways in which we can serve the model once it's persisted. Now, the first thing we realize

135
00:13:56,200 --> 00:14:01,840
in the code that we've just written is that we are exposing implementation details, right? When we take

136
00:14:01,840 --> 00:14:08,320
a look at these two things, we're saying, hey, maybe we don't want to tell in the code that we

137
00:14:08,320 --> 00:14:12,480
are seeing how we are saving the model. If we're saving it with pickle and however it's something

138
00:14:12,480 --> 00:14:17,360
and we want to abstract, right? We want to abstract it away. We know how to do it, right? We abstract

139
00:14:17,360 --> 00:14:22,240
this into functions. We create the save model function and the load model function that is in

140
00:14:22,240 --> 00:14:29,960
charge of actually doing this under the hood. The moment I do this, two things, two very important

141
00:14:29,960 --> 00:14:37,560
things start to happen. The first one is that you can see in the train.py file that we've

142
00:14:37,560 --> 00:14:42,720
just removed this with statement that was like maybe two verbose and put it in a declarative

143
00:14:42,720 --> 00:14:49,520
fashion, right? Now we know that we are actually saving the model somewhere. But another thing that

144
00:14:49,520 --> 00:14:54,840
starts to happen is that we've now split the whole codebase. Well, the whole codebase, just three files,

145
00:14:54,840 --> 00:15:00,720
right? Anyway, we split the whole codebase in two different semantic spaces. One is the one that

146
00:15:00,720 --> 00:15:05,320
we are seeing on the top. That's what we're going to call the library space, right? These are the

147
00:15:05,320 --> 00:15:08,680
things in which we're going to develop all the tools that are going to be used in the application

148
00:15:08,680 --> 00:15:16,880
space that are the things in the bottom, right? So what we are going to do now is work on the

149
00:15:16,880 --> 00:15:23,360
library space to see how we simplify the application code that is what we expect the data scientist or

150
00:15:23,360 --> 00:15:32,160
the machine learning developer to iterate on top. Now, after we do this, right? After we build the

151
00:15:32,160 --> 00:15:39,480
save model function, yeah, and the load model function, this is now what the train.py file looks

152
00:15:39,480 --> 00:15:44,400
like. See that this is important. That's why I left the imports here, that now we are not importing

153
00:15:44,400 --> 00:15:51,120
pickle directly. We're importing from our own library the save model function. And now we take

154
00:15:51,120 --> 00:15:55,680
a look at this that we have and we say, hey, there's something similar to what we've just seen going

155
00:15:55,680 --> 00:16:02,000
on here, right? What's going on with this classifier that we have? Can't we do something similar to

156
00:16:02,000 --> 00:16:07,000
what we've done with the load model and the save model? We have this idea, right? We need to abstract

157
00:16:07,000 --> 00:16:11,920
them into functions. And with this idea, I will give you a little spoiler. This is where like the

158
00:16:11,920 --> 00:16:17,280
fall of our approach begins. So I want to make it very, very clear. I didn't know how to make it

159
00:16:17,280 --> 00:16:22,880
clear enough that this is how we start to go down a slippery slope that we will see what kind of

160
00:16:22,880 --> 00:16:29,120
thing it goes beyond, right? So it doesn't matter, right? We don't know the spoiler yet. We're very

161
00:16:29,120 --> 00:16:35,560
happy and we're like building this feed model function that what it's doing actually is loading

162
00:16:35,560 --> 00:16:40,240
the classifier and doing the feeding itself, right? So this is the part of the feeding of the model.

163
00:16:40,240 --> 00:16:49,120
Now, one of the things that we know and Sandy Metz put it in an awesome fashion in a talk that is

164
00:16:49,120 --> 00:16:53,200
called, I think, All the Little Things. If you haven't seen it, I recommend you go and see it.

165
00:16:53,280 --> 00:16:59,560
That when you're seeing this kind of pattern in which you have like a repeated prefix or a repeated

166
00:16:59,560 --> 00:17:06,200
suffix in your code, what you're seeing is actually an object in there being tortured, screaming to

167
00:17:06,200 --> 00:17:13,040
get out, right? There's an object here that we have to find out its name. And it's very clear here

168
00:17:13,040 --> 00:17:18,040
that the object that we are seeing is the model object, right? So we do a small refactor and we

169
00:17:18,040 --> 00:17:23,080
change the function that we have into methods of this model object. See that now it looks even

170
00:17:23,080 --> 00:17:28,760
prettier, right? Because the classifier now belongs to the init part and the feed only does the

171
00:17:28,760 --> 00:17:37,060
feeding. And the train.py file still looks very declarative, very intentionally building, and now

172
00:17:37,060 --> 00:17:45,800
more in this like object-oriented fashion, right? Now, we're not only content with this path we've

173
00:17:45,800 --> 00:17:50,960
gone through. We also say, hey, there's something similar going on with that asset, right? Can't I

174
00:17:50,960 --> 00:17:58,040
do something with that asset similar to what I've done with the model? And again, I'm not going to

175
00:17:58,040 --> 00:18:02,800
start like putting this into functions and so on. We already know like the end of this tale. We will

176
00:18:02,800 --> 00:18:09,200
build the data set object, right? So the next step we do is to say, hey, maybe like the features and

177
00:18:09,200 --> 00:18:13,320
the target that you are seeing here are part of an abstraction that is called the data set object.

178
00:18:13,320 --> 00:18:21,000
And we want to give it a name, right? We have the data set. That is what we're going to do. And the

179
00:18:21,000 --> 00:18:27,680
features we have written down there inside the constructor what the features and the target mean.

180
00:18:27,680 --> 00:18:34,240
And now we take a look at the train.py file that we've seen. And man, doesn't this look like much

181
00:18:34,240 --> 00:18:39,840
cleaner than what we had before, right? We have a much more concise code and we even got the chance

182
00:18:39,840 --> 00:18:47,280
put our abstractions in here, right? See that now the model.fit doesn't take like the features and

183
00:18:47,280 --> 00:18:53,240
the target like it used to before. It now takes the data set that we've just built, right? Our own

184
00:18:53,240 --> 00:18:59,560
abstraction. Now we're very happy with this, but as I told you, this is not how the story ends well,

185
00:18:59,560 --> 00:19:06,280
right? Because now all of a sudden someone tells us, hey, we don't want to pick always the best

186
00:19:06,280 --> 00:19:10,440
two of these features. Sometimes you want to pick three, sometimes you want to pick one. Can you work

187
00:19:10,440 --> 00:19:19,120
your code? Someone that is just trying to do an exploration of this data set, right? They just

188
00:19:19,120 --> 00:19:23,680
want to see how it would perform if we didn't have to pick the best two features. And we say,

189
00:19:23,680 --> 00:19:29,520
okay, we know how to do it, right? Let's keep calm. We know how to do this. Instead of hard

190
00:19:29,520 --> 00:19:34,160
coding the two there, we pass the number of selected features of the parameter, right? And

191
00:19:34,320 --> 00:19:38,760
now we are very happy because we've saved the day, right? Now you can pick the number of selected

192
00:19:38,760 --> 00:19:44,160
that you want, right? The requirement is fulfilled. And all of a sudden they say, hey, well,

193
00:19:44,160 --> 00:19:48,960
sometimes we don't actually want to pick. We want to do a logistic relation on all of the

194
00:19:48,960 --> 00:19:54,640
numbers that we have. On all of the features. And we say, okay, we can make this work, right?

195
00:19:54,640 --> 00:20:00,800
Because I'm going to put a contract with you in which if the number of selected that you're sending

196
00:20:01,280 --> 00:20:08,480
is none, then I will completely disregard the selection step, right? And now this is feeling

197
00:20:08,480 --> 00:20:13,320
kind of weird, right? I mean, having this comparison with none is not something that we enjoy a lot.

198
00:20:13,320 --> 00:20:20,680
But also we are in the drift of making all these changes that people ask for us. And all of a

199
00:20:20,680 --> 00:20:25,460
sudden someone tells, well, actually we don't always want a logistic relation. We want to try

200
00:20:25,460 --> 00:20:33,380
out like a multi-layer perceptron. And we are like so deep in this train of thought that we've just

201
00:20:33,380 --> 00:20:38,820
shackled us into that the only thing we can think of is just adding another if to this constructor,

202
00:20:38,820 --> 00:20:44,820
right? This is something that happens a lot while you're trying to give to your library the

203
00:20:44,820 --> 00:20:52,580
flexibility that it's needed, right? So now if the previous part was a bit eerie, now this is

204
00:20:52,740 --> 00:20:59,220
completely terrifying, right? We have the comparison with a string. We have to raise an error if

205
00:20:59,220 --> 00:21:06,300
someone even did a small typo when passing the classifier type. This doesn't make any sense at

206
00:21:06,300 --> 00:21:11,500
all, right? I mean, we're not going through the right path here. There has to be a better way to

207
00:21:11,500 --> 00:21:17,500
do this. And then we realize that the problem is that we don't actually know what is the model

208
00:21:17,500 --> 00:21:21,820
that we want, right? All the things that have been changing, what I'm actually explaining is that the

209
00:21:21,820 --> 00:21:28,460
model, as we said, is very speculative and we will never know what the model looks like. So the main

210
00:21:28,460 --> 00:21:33,180
problem that we're having from the beginning is to say that the model has to be instantiated in

211
00:21:33,180 --> 00:21:38,740
here, right? That the classifier has to be in here. What if instead of instantiating the model here,

212
00:21:38,740 --> 00:21:44,620
we simply pass it as a parameter, right? In the constructor, instead of doing like all those weird

213
00:21:44,620 --> 00:21:49,380
stuff that we've done with the strings and with the number of selective, with none and so on,

214
00:21:49,380 --> 00:21:55,860
we simply say that the backend model, and I mean backend in terms of the one that is actually going

215
00:21:55,860 --> 00:22:00,420
to be doing the computing of the feed, can be passed as a parameter in the constructor.

216
00:22:00,420 --> 00:22:07,780
Now, this is what the model looks like when we start doing this and what we've just figured out

217
00:22:07,780 --> 00:22:12,940
here isn't anything new, right? We haven't discovered anything. It's like a very well-known

218
00:22:12,940 --> 00:22:18,940
design pattern of object-oriented design that is called dependence injection, right? Actually,

219
00:22:18,940 --> 00:22:25,100
if you are familiar with the solid acronym, dependence injection is the D in the solid acronym,

220
00:22:25,100 --> 00:22:31,060
right? That's how important it is. For us in Python, usually dependence injection just means

221
00:22:31,060 --> 00:22:36,500
parameterizing something in the constructor, right? And as typical in these dependence injection and

222
00:22:36,500 --> 00:22:42,100
composition mechanisms, what we end up having is the delegation of the methods, right? So the feed

223
00:22:42,100 --> 00:22:48,700
that we are calling from our model class actually delegates the call to the feed of the backend

224
00:22:48,700 --> 00:22:54,340
classifier, right? This is like a figure that you're going to see happening a lot when you

225
00:22:54,340 --> 00:23:00,380
start doing dependence injection and composition. Now, this is what the model looks like and see

226
00:23:00,380 --> 00:23:06,620
that what we have done is removing the coupling from the model that we've just built. We've

227
00:23:06,620 --> 00:23:10,860
removed the coupling from it and the actual implementation that we want to do, right? Now,

228
00:23:10,860 --> 00:23:18,540
the implementation is also back in the surface. So now we have this idea of dependence injection

229
00:23:18,540 --> 00:23:25,060
as fixing some of the problems we've just put ourselves into, right? Then all of a sudden,

230
00:23:25,060 --> 00:23:30,340
someone tells us, I want to remove a feature, right? From the data set that we had, I want to

231
00:23:30,340 --> 00:23:34,900
simply remove a feature away. It's not something that is going to go into production. I just want

232
00:23:34,900 --> 00:23:40,300
to know how the model would perform if we didn't have one of these features. And we take a look at

233
00:23:40,300 --> 00:23:45,420
the code that we have and we say on one hand, well, yes, maybe some dependence injection can

234
00:23:45,420 --> 00:23:53,380
help. I'm not saying that it doesn't. But nonetheless, if this is what we want to do,

235
00:23:53,380 --> 00:23:59,020
we will have to re-implement the removal of features inside of this code, right? I mean,

236
00:23:59,020 --> 00:24:02,340
we will have to write it, we will have to document it, we will have to test it,

237
00:24:02,340 --> 00:24:08,060
we will have to troubleshoot any problems that the users are going to have. So what we're seeing

238
00:24:08,060 --> 00:24:14,100
here is that in this data set .py file, there's something different that we have to do. And what

239
00:24:14,100 --> 00:24:20,860
we need to do to answer the question of what's the challenge that is put down here is to reflect

240
00:24:20,860 --> 00:24:25,580
on what we've done actually when doing the dependence injection, right? I argue here that

241
00:24:25,580 --> 00:24:30,460
what we've done isn't only the dependence injection of the scikit-learn model in the model step,

242
00:24:30,460 --> 00:24:37,820
but we've also exposed a known library to the data scientist, right? By doing the dependence

243
00:24:37,820 --> 00:24:43,940
injection, we didn't introduce any dependency. The dependency that we are introducing is the

244
00:24:43,940 --> 00:24:48,500
scikit-learn library that data scientists are very familiar with, right? They come already with this

245
00:24:48,500 --> 00:24:51,940
stack. If they have any question, they know how to Google for it, they know how to go to stack

246
00:24:51,940 --> 00:24:59,260
overflow, they know how to communicate with each other about possible solutions. So what if we take

247
00:24:59,260 --> 00:25:07,860
this lesson from what actually worked from here, and we do a similar thing with the data set. Right

248
00:25:07,860 --> 00:25:13,420
now the data set, instead of loading the CSV file and splitting into features and targets,

249
00:25:13,420 --> 00:25:25,660
and the target, sorry, now it simply fills the data frame attribute and we leave it exposed for

250
00:25:25,660 --> 00:25:31,860
everyone to use it, right? So the target and the feature selection are done in the application

251
00:25:31,860 --> 00:25:37,860
code and any change that we want to make is right away, right? It's at the tip of our hands when

252
00:25:37,860 --> 00:25:48,700
developing the application. So what is it that we have been building here, right? And I'd like for

253
00:25:48,700 --> 00:25:56,740
the moment to reflect on how it is that this works out. What we have been building with the

254
00:25:56,740 --> 00:26:02,140
data set, with the model and so on, are just abstractions, right? And there are many ways in

255
00:26:02,140 --> 00:26:08,140
which you can define the abstraction in software engineering, but one that I really like a lot is

256
00:26:08,140 --> 00:26:14,380
the one that Joel Spolsky wrote that is very simple but also cuts to the core of it, right?

257
00:26:14,380 --> 00:26:19,260
That an abstraction is a simplification of something much more complicated that is going

258
00:26:19,260 --> 00:26:25,380
on under the covers. And why do I like this explanation a lot? First of all, because it's

259
00:26:25,380 --> 00:26:33,220
like in a very plain language, but also because it exposes the subjective thing about what's an

260
00:26:33,220 --> 00:26:37,940
abstraction, right? What's an abstraction? What's an implementation detail? All of this is very

261
00:26:37,940 --> 00:26:43,620
subjective, right? We cannot know beforehand what should belong under the covers. We don't know

262
00:26:44,260 --> 00:26:49,580
what is much more complicated. Much more complicated for whom, right? Probably for the data scientists

263
00:26:49,580 --> 00:26:52,700
working with Scikit-learn. It's not much more complicated at all. It's something they have been

264
00:26:52,700 --> 00:26:58,220
doing for a lot of their professional time. In this article that is called The Law of Leaky

265
00:26:58,220 --> 00:27:04,980
Abstractions, that is 20 years old, this still amazes me, right? It's 20 years old and to me

266
00:27:04,980 --> 00:27:16,580
it's evergreen. Joel Spolsky writes The Law of Leaky Abstractions. What he says is that all non-trivial

267
00:27:16,580 --> 00:27:22,660
abstractions to some degree are leaky. What does it mean to have a leaky abstraction? What it means

268
00:27:22,660 --> 00:27:28,740
is that no matter how hard we try to hide the implementation details under the covers, some of

269
00:27:28,740 --> 00:27:33,300
the things are going to go back to the surface, right? Some of the things are going to appear.

270
00:27:33,300 --> 00:27:39,740
They're going to leak into application code, no matter how much effort you put in hiding them in

271
00:27:39,740 --> 00:27:44,540
the library code. Does this mean that we don't have to build abstractions? Absolutely not, right? We

272
00:27:44,540 --> 00:27:53,540
have to build abstractions, but we have to be wary of this because what we are seeing here is not only

273
00:27:53,540 --> 00:27:59,100
like the law of leaky abstractions working out in the wild. We're also seeing pressure for these

274
00:27:59,100 --> 00:28:04,340
abstractions to leak, right? The data scientists, the users of the application code are putting

275
00:28:04,340 --> 00:28:09,820
pressure for us to leak these implementation details or what we thought were implementation

276
00:28:09,820 --> 00:28:15,940
details. There is pressure for them to go back to the surface, right? So we have to make this

277
00:28:15,940 --> 00:28:21,500
compromise in our own abstractions, right? We have to let the abstractions leak because they will

278
00:28:21,500 --> 00:28:27,220
eventually do it, but from the moment we recognize that this is something that will happen and that

279
00:28:27,220 --> 00:28:37,380
simplifies the exploration, we can choose how they leak, right? So what we have been building here

280
00:28:37,380 --> 00:28:43,820
is not like simply a library. We're not trying to recreate pandas, nor recreate scikit-learn. What

281
00:28:43,820 --> 00:28:49,060
we're trying to do is to provide a framework for the code development, and while we're doing this

282
00:28:49,060 --> 00:28:54,180
framework, we're leveraging the knowledge of Python, of pandas, of scikit-learn that the

283
00:28:54,340 --> 00:29:01,660
application user already has, right? We are using them in our favor, and this would work also in the

284
00:29:01,660 --> 00:29:07,820
case of many other different libraries, right? If the library was PySpark, TensorFlow, PyTorch,

285
00:29:07,820 --> 00:29:11,900
whichever of the libraries that we have in the stack, we can do a similar approach in which we

286
00:29:11,900 --> 00:29:19,940
leverage the knowledge that the application user has and use it in our favor. So let's take a look

287
00:29:19,940 --> 00:29:25,340
at how this tries to fulfill the four pillars we discussed in the beginning. First of all,

288
00:29:25,340 --> 00:29:30,380
the fast and easy exploration, and I want us to think now that suppose that one of the things we

289
00:29:30,380 --> 00:29:36,740
want to try out is what would happen if, I don't know, if we remove the long sepals, right? What

290
00:29:36,740 --> 00:29:42,220
would happen if in our data set we wanted to remove the sepals that are longer than five? So

291
00:29:42,220 --> 00:29:50,180
the exploration is trivial, right? Data scientists already know how to deal with pandas. They already

292
00:29:50,180 --> 00:29:54,940
know how to write this query that is maybe like too verbose for us. We don't think about putting

293
00:29:54,940 --> 00:30:01,540
this like this directly into production, but they can do it if they want to, right? So we are allowing

294
00:30:01,540 --> 00:30:07,260
the possibility of this kind of exploration. But now, how do we make this declarative and

295
00:30:07,260 --> 00:30:11,780
intention revealing? And this is where the power of abstraction works in our favor, right? Not only

296
00:30:11,780 --> 00:30:16,400
the leakage works in favor of the application code developer, but the abstraction works in our

297
00:30:16,400 --> 00:30:23,420
favor as well. Because we can remove the weird query that we had that can be much, much larger,

298
00:30:23,420 --> 00:30:30,620
right? And with much more detail. We can abstract it and reify it into a method that is declarative

299
00:30:30,620 --> 00:30:35,740
and intention revealing enough. So now when we take a look at the code in train.py, we are very

300
00:30:35,740 --> 00:30:40,420
clearly seeing what's going on in here, right? We're not seeing like a query in pandas out in the

301
00:30:40,420 --> 00:30:48,020
wild. We are seeing that we are removing the long sepals from the data set, right? Another important

302
00:30:48,020 --> 00:30:52,860
thing here is what we've discussed as sensible checkpoints, right? The ability for us to latch

303
00:30:52,860 --> 00:31:01,580
on and latch off the production code whenever we want. And for this, I want to say something. There's

304
00:31:01,580 --> 00:31:09,300
a lot of stuff we can discuss in the checkpoints, right? From persisting to, I don't know, to change

305
00:31:09,460 --> 00:31:16,660
temporal views and so on. But I'd like for you to consider the idea of exposing the basic types,

306
00:31:16,660 --> 00:31:22,540
and by basic types here I also mean data frames, right? Consider exposing the basic types instead

307
00:31:22,540 --> 00:31:27,660
of your custom abstractions. This is what is going to bring flexibility between checkpoints,

308
00:31:27,660 --> 00:31:35,340
right? Because this is what will allow people to feed the features, to feed, sorry, to feed features

309
00:31:35,340 --> 00:31:42,700
and data sets however they built it as pandas data frame, right? So we would prefer or at least

310
00:31:42,700 --> 00:31:48,180
consider the idea of doing the implementation on top that has the feature and the target explicitly

311
00:31:48,180 --> 00:31:52,940
written down there instead of the feature on the, instead of the implementation on the bottom part

312
00:31:52,940 --> 00:31:58,740
of the screen. Now, I should say something. Just be wary when you do this. We don't have to pollute

313
00:31:58,740 --> 00:32:05,420
completely the code with basic data types. This is like a very well-known code smell that has,

314
00:32:05,420 --> 00:32:10,340
to me, one of the best names of the model. It's called the primitive obsession. We don't want to

315
00:32:10,340 --> 00:32:18,420
be obsessed with using the basic types, but we want to know when using them is a good compromise

316
00:32:18,420 --> 00:32:24,380
to provide the flexibility. How does this help us for seamless tracking and monitoring? Again,

317
00:32:24,380 --> 00:32:29,220
now the abstraction is working in our favor. Now inside the feed model that we were seeing there,

318
00:32:29,220 --> 00:32:36,260
we can add simply a logging line, right? With the custom logger, however we want to build it. There

319
00:32:36,260 --> 00:32:40,860
are many tools to do it automatically. I'm not saying that you have to write the logger by yourself.

320
00:32:40,860 --> 00:32:46,740
What I'm saying is that however you get to that logger, you can insert it in the code in the

321
00:32:46,740 --> 00:32:52,500
app, in the library part without touching at all the application, right? And this is one of the

322
00:32:52,740 --> 00:32:57,500
advantages that we have. Again, the abstraction playing in our favor for us to work on it.

323
00:32:57,500 --> 00:33:05,700
One word of caution when you start to do this kind of stuff that is going to happen. The API

324
00:33:05,700 --> 00:33:11,940
might be wider than what you expected. This is like a recurring theme when you're working with

325
00:33:11,940 --> 00:33:20,660
library development is that you want to have your library as narrow and as deep as possible, right?

326
00:33:20,900 --> 00:33:25,420
Not to expose a lot, but expose things that have a lot of depth, that do a lot of stuff,

327
00:33:25,420 --> 00:33:30,620
that abstract several things. Again, this is something that we should strive in general when

328
00:33:30,620 --> 00:33:36,140
trying to develop the code. But keep in mind that because of the abstraction leakage that we're

329
00:33:36,140 --> 00:33:43,260
going to have here, we will probably end up with wider APIs than we wanted to. This is an example

330
00:33:43,260 --> 00:33:47,180
that I write here that will probably happen the second you start doing this kind of development,

331
00:33:47,180 --> 00:33:53,180
in which different people say, I want to load sometimes from a data frame, sometimes I want

332
00:33:53,180 --> 00:34:01,220
to load from a CSV file, sometimes I want to load nothing, right? These kind of things are

333
00:34:01,220 --> 00:34:08,980
going to happen and we need to make sure that we provide this flexibility. Always, as I said,

334
00:34:08,980 --> 00:34:14,300
being very cautious about what you're using for exposing to the application and what you're using

335
00:34:14,500 --> 00:34:19,100
for your internal development, right? This is like a distinction that probably you can make in order

336
00:34:19,100 --> 00:34:26,060
to handle the complexity that will come eventually with this. Of course, if the APIs get too wide

337
00:34:26,060 --> 00:34:31,180
eventually, you might think about doing a little bit of refactoring and thinking about how this is

338
00:34:31,180 --> 00:34:38,500
a composition of different methods. But essentially, keep in mind that one of the goals that we cannot

339
00:34:38,500 --> 00:34:45,660
we cannot forgo here is that we have to give sensible checkpoints and fast exploration for

340
00:34:45,660 --> 00:34:54,420
the people that are going to be using our library. Okay, now as conclusions, first of all, one of the

341
00:34:54,420 --> 00:34:58,940
things that I've learned while doing this kind of stuff is that what is an implementation detail

342
00:34:58,940 --> 00:35:06,100
lies in the eye of the beholder. What for one can be a detail of very complicated things that we

343
00:35:06,100 --> 00:35:10,460
actually want to happen under the hood. For some people, it's the core of what they are developing,

344
00:35:10,460 --> 00:35:15,500
right? We need to understand the duality of the implementation and whether it's a detail or not

345
00:35:15,500 --> 00:35:22,860
as quickly as we can so we can use it in our favor instead of fighting against it, right?

346
00:35:22,860 --> 00:35:32,620
Another important thing is we have to allow the flexibility of the application code by letting

347
00:35:32,620 --> 00:35:37,700
it speak the language of the developer. We have application code developers that already know a

348
00:35:37,700 --> 00:35:44,020
lot about pandas, that already know a lot about CycleLearn, about PySpark, about TensorFlow. Don't

349
00:35:44,020 --> 00:35:49,540
hide this away from them. Allow them to write the code in the same way that they have been learning

350
00:35:49,540 --> 00:35:55,700
for their entire professional lives, right? Allow them to write things in a language that is common

351
00:35:55,700 --> 00:36:01,260
for these application developers, right? So they can troubleshoot questions with each other. They

352
00:36:01,260 --> 00:36:08,820
can even ask them in a wider forum and leverage help from different sources. Another thing is,

353
00:36:08,820 --> 00:36:16,060
as we mentioned in the... As we just mentioned, some of the abstractions will eventually leak

354
00:36:16,060 --> 00:36:22,600
to the application code. Instead of thinking hard about how we can make these abstractions,

355
00:36:22,600 --> 00:36:28,460
how we can prevent them from leaking, we can just be in peace with the fact that they are going to

356
00:36:28,460 --> 00:36:33,700
leak eventually. And instead of fighting them, channel them to leak in a way that allows us to

357
00:36:33,700 --> 00:36:41,420
have the code with fast exploration that eventually gets to be declarative, that has the sensible

358
00:36:41,420 --> 00:36:48,820
checkpoints, and that allows us to have seamless tracking of the experiments. That's it that I have

359
00:36:48,820 --> 00:36:49,860
for now. Thanks.

360
00:36:58,460 --> 00:37:04,420
Thank you, Paola, for the excellent talk.

