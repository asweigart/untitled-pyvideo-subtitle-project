1
00:00:00,000 --> 00:00:03,000
Okay, can you hear me well? Okay, amazing.

2
00:00:03,000 --> 00:00:05,000
Hi everybody, thanks for coming.

3
00:00:05,000 --> 00:00:07,000
Today I'm going to talk about testing.

4
00:00:07,000 --> 00:00:11,000
And testing is great, but if you do it wrong, sometimes it's not so great.

5
00:00:11,000 --> 00:00:16,000
Quick intro, my name is Shai. I've been in the industry for a while now.

6
00:00:16,000 --> 00:00:21,000
Mostly hands-on engineering, but also other roles like products and management.

7
00:00:21,000 --> 00:00:27,000
Principal developer at Codium AI, so my day job is working on tools to generate tests.

8
00:00:27,000 --> 00:00:30,000
So that's a pretty nice thing for someone who loves testing.

9
00:00:30,000 --> 00:00:35,000
Lots of interesting stuff going on in that field if you want to talk about, come catch me later.

10
00:00:35,000 --> 00:00:41,000
My purpose for the talk today is to help you get a better ROI on the way to doing testing.

11
00:00:41,000 --> 00:00:46,000
And I'm going to talk about concrete things I've seen that have a tendency to hurt that,

12
00:00:46,000 --> 00:00:50,000
either to make us work more on testing or make that work less effective.

13
00:00:50,000 --> 00:00:54,000
And naturally not everything is going to be a good match for everything.

14
00:00:54,000 --> 00:01:01,000
We saw some stuff also going through an adjustment, so we take the basic concepts and see what applies to you.

15
00:01:01,000 --> 00:01:07,000
We're going to talk about different practices, different ways that we can work,

16
00:01:07,000 --> 00:01:12,000
and how they affect our lives by changing some important properties of our tests.

17
00:01:12,000 --> 00:01:17,000
And the main properties that we're going to see, first, strength, how we good our tests are at catching bugs.

18
00:01:18,000 --> 00:01:24,000
Maintainability, how easy it is for us to deal with the test as things change.

19
00:01:24,000 --> 00:01:27,000
And dealing with change is very important because as developers,

20
00:01:27,000 --> 00:01:30,000
dealing with change is one of the main things that we do.

21
00:01:30,000 --> 00:01:36,000
Changes to requirements, changes to scale, even stuff like changes to the team as new developers join.

22
00:01:36,000 --> 00:01:40,000
And performance, long does it take for the test to run?

23
00:01:40,000 --> 00:01:45,000
And this might seem like a secondary consideration because computers are fast,

24
00:01:45,000 --> 00:01:48,000
but as we'll see, it doesn't matter.

25
00:01:48,000 --> 00:01:52,000
So, 10 ways to shoot yourself in the foot with tests.

26
00:01:52,000 --> 00:01:57,000
Foot gun one: there are no tests.

27
00:01:57,000 --> 00:02:01,000
It is better to have some tests than to not have any tests.

28
00:02:01,000 --> 00:02:06,000
Even if they're not well written, even if they seem like just a drop in the sea,

29
00:02:06,000 --> 00:02:08,000
they still catch bugs and it's still improvement.

30
00:02:08,000 --> 00:02:12,000
So if you don't have any tests, my suggestion, start with something small, simple,

31
00:02:12,000 --> 00:02:15,000
and just slowly keep improving.

32
00:02:15,000 --> 00:02:19,000
Foot gun two: If it doesn't fail, it doesn't pass.

33
00:02:19,000 --> 00:02:22,000
Sometimes our tests lie to us.

34
00:02:22,000 --> 00:02:26,000
We have a test that's supposed to protect us from something, but that something still happens.

35
00:02:26,000 --> 00:02:31,000
And obviously in these cases, the test just didn't check what we thought it does.

36
00:02:31,000 --> 00:02:34,000
Maybe we copypasted and forgot to change something.

37
00:02:34,000 --> 00:02:39,000
And my suggestion now to avoid this is to always make your test fail.

38
00:02:39,000 --> 00:02:42,000
Whenever you write a test and for every assertion,

39
00:02:42,000 --> 00:02:49,000
make a tiny change either to the code or to the test and see that it fails in the way that you expect it to fail.

40
00:02:49,000 --> 00:02:55,000
And only then after you've saw that it fails, consider it a passing test.

41
00:02:55,000 --> 00:02:56,000
Foot gun 3:

42
00:02:56,000 --> 00:02:58,000
Testing too many things.

43
00:02:58,000 --> 00:03:03,000
So, just like product code, if you try to put too many things in the same place, we get a mess.

44
00:03:03,000 --> 00:03:09,000
And my rule of thumb here is that we want to check a single fact about the behavior of the code.

45
00:03:09,000 --> 00:03:12,000
Right? And it helps you use these words mentally.

46
00:03:12,000 --> 00:03:15,000
Single fact about the behavior.

47
00:03:15,000 --> 00:03:20,000
For example, let's say we have a book store and we want to test the edit book functionality.

48
00:03:20,000 --> 00:03:24,000
Now, this is a single fact about the behavior of the code.

49
00:03:24,000 --> 00:03:26,000
The user can edit their own book.

50
00:03:26,000 --> 00:03:28,000
And this is not a single fact.

51
00:03:28,000 --> 00:03:29,000
Test edit book.

52
00:03:29,000 --> 00:03:30,000
It's general.

53
00:03:30,000 --> 00:03:32,000
How do they compare?

54
00:03:32,000 --> 00:03:35,000
Well, with a single fact test, it's clear what it checks.

55
00:03:35,000 --> 00:03:37,000
And it's clear that it only checks that.

56
00:03:37,000 --> 00:03:40,000
But with a more general test, we don't know.

57
00:03:40,000 --> 00:03:42,000
Anything can be there.

58
00:03:42,000 --> 00:03:47,000
And in order to understand, we're going to need to read and understand all the code of the test.

59
00:03:47,000 --> 00:03:54,000
And when the single fact test fails, it's very clear which functionality has stopped working.

60
00:03:54,000 --> 00:03:59,000
And also because it doesn't check a lot of things, it's probably going to be easy to debug it.

61
00:03:59,000 --> 00:04:04,000
But with a general test, if it fails anything related to edit book, might have failed.

62
00:04:04,000 --> 00:04:06,000
We're going to need to find out.

63
00:04:06,000 --> 00:04:11,000
And also, again, because it does a lot of stuff, it might be more difficult to debug.

64
00:04:11,000 --> 00:04:15,000
So I really recommend going with a simple, smaller one.

65
00:04:15,000 --> 00:04:16,000
Foot gun 4:

66
00:04:16,000 --> 00:04:18,000
Unclear language.

67
00:04:18,000 --> 00:04:23,000
The words that we use make a big difference in how we think about a test.

68
00:04:23,000 --> 00:04:27,000
And also, of course, in how easy it is to understand them.

69
00:04:27,000 --> 00:04:31,000
And the guidelines I use for myself is, first, like we said,

70
00:04:31,000 --> 00:04:34,000
try to test a single fact about the behavior of the code.

71
00:04:34,000 --> 00:04:38,000
Well, this is not the language itself, but it's a really sets the tone.

72
00:04:38,000 --> 00:04:43,000
We want to use decisive language, and we want our language to be specific and explicit.

73
00:04:43,000 --> 00:04:48,000
And a few examples, starting with the one that we saw, test edit book.

74
00:04:48,000 --> 00:04:53,000
Again, this is general and pretty hard to understand, so it's not the way that we want to go.

75
00:04:53,000 --> 00:05:00,000
Adding things like "works" or "is correct", usually that's just bloat and doesn't really help us.

76
00:05:00,000 --> 00:05:04,000
Test users should be able to edit their own book.

77
00:05:04,000 --> 00:05:08,000
So this is bloated and very long, but it's also better.

78
00:05:08,000 --> 00:05:10,000
It's much more specific.

79
00:05:10,000 --> 00:05:13,000
And the only problem here is this incisive language.

80
00:05:13,000 --> 00:05:16,000
It's pretty confusing.

81
00:05:16,000 --> 00:05:18,000
I mean, why "should"?

82
00:05:18,000 --> 00:05:20,000
Are we not sure about this?

83
00:05:20,000 --> 00:05:26,000
Is there any way that sometimes it's not going to be true? So that's not really optimal.

84
00:05:26,000 --> 00:05:29,000
And again, that just sounds like a single fact.

85
00:05:29,000 --> 00:05:31,000
A user can edit their own book.

86
00:05:31,000 --> 00:05:38,000
It's decisive, specific, and explicit, and I suggest to always try to go with this kind of language if you can.

87
00:05:38,000 --> 00:05:42,000
Foot gun 5: the devil's in the details.

88
00:05:42,000 --> 00:05:48,000
Tests that show or hide too much detail are much more difficult to understand.

89
00:05:48,000 --> 00:05:52,000
For example, let's say we're testing a browser and we have the data in a different file.

90
00:05:52,000 --> 00:05:56,000
So in the beginning of the test, we're going to read that file, then we're going to use that data.

91
00:05:56,000 --> 00:06:02,000
And no matter what the test checks, the problem is it's impossible to know if it's correct

92
00:06:02,000 --> 00:06:04,000
without going somewhere else and looking.

93
00:06:04,000 --> 00:06:06,000
It breaks the flow.

94
00:06:06,000 --> 00:06:12,000
And it's definitely a problem if it's in a different file, but even if it's a constant at the top of

95
00:06:12,000 --> 00:06:15,000
this file, it still breaks the flow.

96
00:06:15,000 --> 00:06:17,000
And sometimes we can't avoid this, right?

97
00:06:17,000 --> 00:06:19,000
But a lot of the times we can.

98
00:06:19,000 --> 00:06:21,000
Maybe try something like this.

99
00:06:21,000 --> 00:06:24,000
Exactly the same test, but the data is local.

100
00:06:24,000 --> 00:06:31,000
And if you can find a data sample that's small enough, that fits locally, it really does help.

101
00:06:31,000 --> 00:06:37,000
But the flip coin side of this is when we have too much detail, so much stuff going on.

102
00:06:37,000 --> 00:06:40,000
It's going to be pretty hard to spot the important stuff.

103
00:06:40,000 --> 00:06:44,000
So my suggestion here, just try organizing a little bit.

104
00:06:44,000 --> 00:06:46,000
Some empty lines in comments go a long way.

105
00:06:46,000 --> 00:06:50,000
Not a lot of work, but it still helps a lot.

106
00:06:52,000 --> 00:06:54,000
Foot gun six:

107
00:06:54,000 --> 00:06:56,000
The test are not isolated.

108
00:06:56,000 --> 00:07:02,000
If your test are not isolated, it means that if you run them in a different order or you only run

109
00:07:02,000 --> 00:07:05,000
some of them, you might get different behavior.

110
00:07:05,000 --> 00:07:09,000
What I have to say about tests are not isolated is... don't.

111
00:07:09,000 --> 00:07:11,000
Just don't do it.

112
00:07:11,000 --> 00:07:15,000
If you have 30 tests and test number 24 fails because of some stuff that happens during test 8

113
00:07:15,000 --> 00:07:19,000
and 15, I mean, you're not going to have a good time debugging.

114
00:07:19,000 --> 00:07:22,000
And this gets really, really, really bad.

115
00:07:22,000 --> 00:07:26,000
I cannot stress how much I think it is not a good idea.

116
00:07:28,000 --> 00:07:29,000
Foot gun seven:

117
00:07:29,000 --> 00:07:31,000
Improper test scope.

118
00:07:31,000 --> 00:07:34,000
This is the root cause of many, many testing problems.

119
00:07:34,000 --> 00:07:40,000
And my approach is to test some cohesive whole.

120
00:07:40,000 --> 00:07:42,000
Some makes-sense story.

121
00:07:42,000 --> 00:07:47,000
It's really similar to the notion of testing implementation instead of behavior, and it's just a more

122
00:07:47,000 --> 00:07:50,000
general way of phrasing something similar.

123
00:07:50,000 --> 00:07:54,000
Let's say that our bookstore is a web service and it uses a database.

124
00:07:54,000 --> 00:07:59,000
We're going to think about two alternative test suites that we might have chosen where to use behavior tests

125
00:07:59,000 --> 00:08:01,000
and implementation tests.

126
00:08:01,000 --> 00:08:06,000
And we're going to try to imagine how our lives are going to be different if we went with one of them

127
00:08:06,000 --> 00:08:07,000
or the other.

128
00:08:07,000 --> 00:08:11,000
We look at tests that are almost identical in both test suites.

129
00:08:11,000 --> 00:08:13,000
The test checks something very simple.

130
00:08:13,000 --> 00:08:19,000
If we edited the description of a book, then the value has really been updated.

131
00:08:19,000 --> 00:08:21,000
Both tests have exactly the same flow.

132
00:08:21,000 --> 00:08:27,000
We create a book, we edit the book, we update the book, we get the updated description, and then we make the

133
00:08:27,000 --> 00:08:28,000
assertion.

134
00:08:28,000 --> 00:08:34,000
And the behavior test is going to do everything against the external HTTP API in the same way as things

135
00:08:34,000 --> 00:08:38,000
will be done in the actual system.

136
00:08:38,000 --> 00:08:43,000
The implementation test is going to do some of the stuff at the lower level.

137
00:08:43,000 --> 00:08:50,000
It's going to create the book by directly creating a record in the database, and it's also going to get

138
00:08:50,000 --> 00:08:53,000
the updated description of the record in the database.

139
00:08:53,000 --> 00:08:58,000
Now, the behavior test only looks at the "what."

140
00:08:58,000 --> 00:09:04,000
It looks at the code only as it appears from outside.

141
00:09:04,000 --> 00:09:08,000
The implementation test also understands some things about "how."

142
00:09:08,000 --> 00:09:12,000
It knows how the code is going to change the database.

143
00:09:12,000 --> 00:09:20,000
And checking implementation like this, it's usually equivalent to checking behavior, but not always.

144
00:09:20,000 --> 00:09:23,000
So how does this affect us?

145
00:09:23,000 --> 00:09:25,000
Let's consider a scenario.

146
00:09:25,000 --> 00:09:28,000
Let's say we have this test for a while now.

147
00:09:28,000 --> 00:09:33,000
This takes weeks, maybe even years, we've invested a lot in them and we rely on them.

148
00:09:33,000 --> 00:09:36,000
And today we're making a change to optimize the database.

149
00:09:36,000 --> 00:09:42,000
We're moving the description out of the data, out of the book table, and into its own separate table.

150
00:09:42,000 --> 00:09:46,000
Now, the original description field: we're not deleting it yet.

151
00:09:46,000 --> 00:09:49,000
We're going to do that after we finish migrating the data.

152
00:09:49,000 --> 00:09:54,000
So we finished with everything else, and now it's time to update the edit book endpoint.

153
00:09:54,000 --> 00:09:59,000
Now, what if we forgot to update the edit book endpoint?

154
00:09:59,000 --> 00:10:01,000
Maybe we forgot.

155
00:10:01,000 --> 00:10:06,000
We can now update the wrong thing, so behavior-wise, it doesn't do anything.

156
00:10:06,000 --> 00:10:09,000
If we do go to production, we have a real problem, right?

157
00:10:09,000 --> 00:10:11,000
It's a major bug that's made it into production.

158
00:10:11,000 --> 00:10:18,000
Now, if we went to the behavior test, well, the behavior test only looks at the external behavior

159
00:10:18,000 --> 00:10:19,000
of the code.

160
00:10:19,000 --> 00:10:23,000
The behavior test does not care about implementation details.

161
00:10:23,000 --> 00:10:27,000
So if the behavior is correct, like here, the behavior test is going to fail,

162
00:10:27,000 --> 00:10:29,000
just like we need it to.

163
00:10:29,000 --> 00:10:33,000
The regression bug was prevented, and everything's okay.

164
00:10:33,000 --> 00:10:39,000
But if you want to do implementation tests, implementation tests looks at the outdated,

165
00:10:39,000 --> 00:10:41,000
wrong field in the database.

166
00:10:41,000 --> 00:10:46,000
So when the test runs, that field is going to be updated just like before,

167
00:10:46,000 --> 00:10:48,000
so the test is not going to fail.

168
00:10:48,000 --> 00:10:52,000
And this means that the regression bug is not going to get caught,

169
00:10:52,000 --> 00:10:56,000
and it will make it to production, which will make it not okay.

170
00:10:56,000 --> 00:11:01,000
The other side of this, what if we made the change correctly?

171
00:11:01,000 --> 00:11:05,000
We updated the edit book endpoint and everything is fine.

172
00:11:05,000 --> 00:11:10,000
If we went with the behavior test, well, they'll pass, because the behavior was correct.

173
00:11:10,000 --> 00:11:12,000
We didn't need to do anything.

174
00:11:12,000 --> 00:11:14,000
But if we went with the implementation test,

175
00:11:14,000 --> 00:11:18,000
they looked at the wrong field in the database, so it's going to fail.

176
00:11:18,000 --> 00:11:20,000
The test is going to fail.

177
00:11:20,000 --> 00:11:24,000
But the reason for failing is not because of the endpoint, right?

178
00:11:24,000 --> 00:11:29,000
The reason for failing is that the test is now become technically invalid.

179
00:11:29,000 --> 00:11:32,000
And we have extra work because of that.

180
00:11:32,000 --> 00:11:36,000
We're going to need to, first we're going to need to figure out whether the failure is technical,

181
00:11:36,000 --> 00:11:41,000
or real, and then we're going to need to update the test, either way.

182
00:11:41,000 --> 00:11:46,000
And another important thing that happens is that because we're changing it,

183
00:11:46,000 --> 00:11:50,000
this is no longer the test that we've been doing for two years.

184
00:11:50,000 --> 00:11:54,000
So the level of confidence in the test has become smaller.

185
00:11:54,000 --> 00:11:57,000
We're going to need to learn to trust it again.

186
00:11:57,000 --> 00:12:01,000
Now, in large code bases, it can become a real pain.

187
00:12:01,000 --> 00:12:04,000
You're always going to update the test even though the code is correct.

188
00:12:04,000 --> 00:12:10,000
And sometimes, even if the test has nothing to do with the feature that you're working on, right?

189
00:12:10,000 --> 00:12:15,000
And a lot of times, it spends hours and hours, and you really hate your test suite.

190
00:12:15,000 --> 00:12:18,000
So, summing up.

191
00:12:18,000 --> 00:12:20,000
Cohesive behavior tests:

192
00:12:20,000 --> 00:12:22,000
Closer to reality.

193
00:12:22,000 --> 00:12:25,000
The better at protecting us from bugs.

194
00:12:25,000 --> 00:12:30,000
We don't have redundant work because of them, and we trust them more.

195
00:12:30,000 --> 00:12:36,000
Another thing worth noting here is that what we saw here in this example is a small,

196
00:12:36,000 --> 00:12:42,000
incremental change, but sometimes we need to do big changes, scary changes.

197
00:12:42,000 --> 00:12:49,000
For example, in a lot of companies, there comes a day that the db doesn't do well with the scale.

198
00:12:49,000 --> 00:12:52,000
We start having stability issues in production.

199
00:12:52,000 --> 00:12:54,000
And we probably need to do some big change.

200
00:12:54,000 --> 00:12:59,000
Maybe we take a lot of data and move it to a different database type, right?

201
00:12:59,000 --> 00:13:03,000
And at that point, the tests are most important.

202
00:13:03,000 --> 00:13:08,000
And if we went with behavior tests, everything is going to be fine.

203
00:13:08,000 --> 00:13:10,000
Because they only look at the Delegate.

204
00:13:10,000 --> 00:13:15,000
So, the moment we reproduce the original behavior with a new database, they're going to pass.

205
00:13:15,000 --> 00:13:18,000
And we're done. We can move on.

206
00:13:18,000 --> 00:13:23,000
If we went with the implementation tests, well, they all become technically invalid and they all fail.

207
00:13:23,000 --> 00:13:29,000
So, we have there some work that we need to port them to a new database, but much worse than that,

208
00:13:29,000 --> 00:13:33,000
because we've changed them, we're not going to trust them enough to say,

209
00:13:33,000 --> 00:13:38,000
okay, the db has been moved, we've moved to the db correctly.

210
00:13:38,000 --> 00:13:43,000
So, this might make a difference between a project that might take just a few weeks to

211
00:13:43,000 --> 00:13:46,000
move a new database and is a company-level event.

212
00:13:46,000 --> 00:13:52,000
It drags on for months while the product has stability issues.

213
00:13:52,000 --> 00:13:57,000
So, test behavior, the cohesive whole.

214
00:13:57,000 --> 00:14:01,000
Foot gun 8: Test doubles everywhere.

215
00:14:01,000 --> 00:14:05,000
Sometimes in the test, we need to switch part of the system dependency,

216
00:14:05,000 --> 00:14:08,000
with some alternative implementation.

217
00:14:08,000 --> 00:14:12,000
These are called test doubles, stuff like mocks and fakes and stubs.

218
00:14:12,000 --> 00:14:16,000
The main reason we do this, there are others, but the main one is performance.

219
00:14:16,000 --> 00:14:21,000
If the real thing is too slow to run a lot of tests with it, then we switch it to the fast test doubles.

220
00:14:21,000 --> 00:14:26,000
And test doubles are very useful, but they are re-implementations.

221
00:14:26,000 --> 00:14:32,000
The test double knows the implementation details of the thing that it's replacing.

222
00:14:32,000 --> 00:14:36,000
Different test double types do it differently, but that's what they do.

223
00:14:36,000 --> 00:14:38,000
And the problem is that this is correctness, of course.

224
00:14:38,000 --> 00:14:42,000
The test double is not necessarily exactly the same as the real thing,

225
00:14:42,000 --> 00:14:46,000
and that makes the test less correct, less accurate.

226
00:14:46,000 --> 00:14:50,000
And also, as time goes by, we might be changing the real thing slowly,

227
00:14:50,000 --> 00:14:55,000
but the test double remains the same, so it gives further and further from reality.

228
00:14:55,000 --> 00:14:58,000
And this kind of thing can really hurt your foot.

229
00:15:00,000 --> 00:15:04,000
It's a flavor of the implementation versus behavior problem.

230
00:15:04,000 --> 00:15:07,000
And there are some differences, but essentially it's the same thing.

231
00:15:07,000 --> 00:15:09,000
Same category of issues.

232
00:15:09,000 --> 00:15:12,000
Test doubles are not as good at catching bugs,

233
00:15:12,000 --> 00:15:16,000
and sometimes they break even though everything's fine,

234
00:15:16,000 --> 00:15:19,000
and cause all that extra work, as we've talked about.

235
00:15:19,000 --> 00:15:23,000
So, test doubles: use with caution.

236
00:15:23,000 --> 00:15:25,000
But how do we avoid the pitfalls?

237
00:15:25,000 --> 00:15:27,000
How do we avoid getting into these problems?

238
00:15:27,000 --> 00:15:29,000
And I suggest a few different ideas.

239
00:15:29,000 --> 00:15:32,000
First, code design. So important.

240
00:15:32,000 --> 00:15:37,000
If you can, try to design the code so that you can test a good chunk of functionality

241
00:15:37,000 --> 00:15:40,000
and fast unit tests that don't need test doubles.

242
00:15:40,000 --> 00:15:44,000
Now, it's not always possible, but a lot of the times it is.

243
00:15:44,000 --> 00:15:49,000
Another thing is to choose what test double type you're working with.

244
00:15:49,000 --> 00:15:53,000
And I would suggest to normally, usually use fakes.

245
00:15:53,000 --> 00:15:57,000
Think of something that behaves like your dependency,

246
00:15:57,000 --> 00:15:59,000
but again, fast.

247
00:15:59,000 --> 00:16:03,000
For example, we can fake a db table with an in-memory list of tuples,

248
00:16:03,000 --> 00:16:05,000
where each tuple represents a row.

249
00:16:05,000 --> 00:16:08,000
And in the test, this is going to behave exactly the same.

250
00:16:10,000 --> 00:16:13,000
And about the correctness problem of the fakes,

251
00:16:13,000 --> 00:16:16,000
we can make them more reliable by testing them,

252
00:16:16,000 --> 00:16:20,000
by writing tests not for the code, but for the fake itself.

253
00:16:20,000 --> 00:16:24,000
An example of such tests can be to run the same actions against the fake

254
00:16:24,000 --> 00:16:28,000
and against the real thing, and make sure we always get the same results back.

255
00:16:28,000 --> 00:16:30,000
And they're never going to be 100% the same,

256
00:16:30,000 --> 00:16:31,000
but it's a tradeoff.

257
00:16:31,000 --> 00:16:35,000
We choose how much we want to invest in the thing, the reliability.

258
00:16:35,000 --> 00:16:39,000
Sometimes a reliable fake already exists.

259
00:16:39,000 --> 00:16:41,000
You can just take it and use it.

260
00:16:41,000 --> 00:16:44,000
For example, you're using SQLite.

261
00:16:44,000 --> 00:16:48,000
Python actually has built-in in-memory SQLite implementation.

262
00:16:48,000 --> 00:16:49,000
You can just take it.

263
00:16:49,000 --> 00:16:53,000
So it's worth Googling, maybe you'll get lucky.

264
00:16:55,000 --> 00:16:59,000
Another nice thing that we can do with fakes is that we can run the same tests,

265
00:16:59,000 --> 00:17:03,000
exactly the same tests, once against the fake and once against the real thing.

266
00:17:03,000 --> 00:17:08,000
And let's say for example we have 10 tests, but it's too slow to run the real database.

267
00:17:08,000 --> 00:17:12,000
So we run them with the fake, and then we choose the two most important ones,

268
00:17:12,000 --> 00:17:16,000
and these ones we run also against the real thing.

269
00:17:16,000 --> 00:17:20,000
And this way we get some real-world certainty.

270
00:17:20,000 --> 00:17:24,000
And the essence of the idea here is that we use the test doubles,

271
00:17:24,000 --> 00:17:28,000
but we selectively verify correctness until we get an acceptable tradeoff.

272
00:17:29,000 --> 00:17:35,000
Another way to use this idea of use-and-verify is by caching recordings.

273
00:17:35,000 --> 00:17:39,000
We can record side effects, for example, HTTP reports,

274
00:17:39,000 --> 00:17:43,000
or we can also record the db actions or anything like that,

275
00:17:43,000 --> 00:17:45,000
and we can then use them in the tests.

276
00:17:45,000 --> 00:17:49,000
For example, in Codium we have an HTTP service,

277
00:17:49,000 --> 00:17:56,000
and it uses another HTTP service, an AI model that analyzes and generates code.

278
00:17:56,000 --> 00:18:02,000
So in our test, we record the HTTP interactions between the two services.

279
00:18:02,000 --> 00:18:06,000
Locally, when we run the tests, we usually run them against the recordings,

280
00:18:06,000 --> 00:18:08,000
so they are very very fast.

281
00:18:08,000 --> 00:18:11,000
But we also need to verify them, so sometimes in the cloud,

282
00:18:11,000 --> 00:18:15,000
we also run tests against the real thing to make sure that the tests still pass,

283
00:18:15,000 --> 00:18:18,000
again giving us real-world certainty.

284
00:18:19,000 --> 00:18:22,000
Foot gun 9: Slow tests.

285
00:18:22,000 --> 00:18:24,000
Yeah, slow tests are not fun.

286
00:18:24,000 --> 00:18:27,000
We're going to talk about two ways in which they are not fun.

287
00:18:27,000 --> 00:18:32,000
The first one that I like to think of is the bottleneck and the time bomb.

288
00:18:32,000 --> 00:18:37,000
The bottleneck here is when the test was so slow that we get a long queue of tasks

289
00:18:37,000 --> 00:18:40,000
waiting to be merged into the main group.

290
00:18:41,000 --> 00:18:43,000
What kind of numbers are we talking about here?

291
00:18:43,000 --> 00:18:48,000
Let's say we have 10 work hours a day, and the tests take five minutes.

292
00:18:48,000 --> 00:18:55,000
That means that we can merge five tests per minute, 12 tests per minute, sorry,

293
00:18:55,000 --> 00:19:01,000
that's to main, on each hour, which is 120 tests to main each day.

294
00:19:01,000 --> 00:19:08,000
For most teams, this virtually never happens. So five minute test suites: not a bottleneck.

295
00:19:08,000 --> 00:19:13,000
The other extreme, you will never get that, but just so that it's easy to imagine,

296
00:19:13,000 --> 00:19:16,000
what if the test takes two hours?

297
00:19:16,000 --> 00:19:20,000
In that case, we can only merge five tasks per minute a day.

298
00:19:20,000 --> 00:19:27,000
And with these kinds of numbers, whenever we get a bunch of tasks that we need to wrap up quickly,

299
00:19:27,000 --> 00:19:32,000
the merge is going to take days, there will be days of waiting.

300
00:19:32,000 --> 00:19:37,000
And if some tests start failing, we can get to that on any random day.

301
00:19:37,000 --> 00:19:39,000
It doesn't work.

302
00:19:39,000 --> 00:19:42,000
The team will probably just stop waiting for the test to finish,

303
00:19:42,000 --> 00:19:46,000
before they merge to main, and spend a lot of time with the tests being broken.

304
00:19:46,000 --> 00:19:52,000
We can survive this way for a while, but it's a lot of extra work, and it's really not what we want.

305
00:19:52,000 --> 00:19:58,000
Really, even with most numbers, even a 30 minute test suite,

306
00:19:58,000 --> 00:20:04,000
same thing is going to happen, really not as often, but same thing is still going to be a real problem.

307
00:20:04,000 --> 00:20:08,000
And a few years ago, I was actually a part of a team where that happened.

308
00:20:08,000 --> 00:20:14,000
When the test took 20 minutes, I understood that we had a time bomb and at some time,

309
00:20:14,000 --> 00:20:17,000
at some point in the future, things were going to get really bad.

310
00:20:17,000 --> 00:20:23,000
But I didn't have this clear explanation of just how the slowness would be a problem,

311
00:20:23,000 --> 00:20:25,000
this bottleneck.

312
00:20:25,000 --> 00:20:28,000
And another problem that we had there is that the tests were flaky,

313
00:20:28,000 --> 00:20:31,000
so they always needed fixing real world, fixing them,

314
00:20:31,000 --> 00:20:34,000
and so it seemed to most people like flakiness was the issue,

315
00:20:34,000 --> 00:20:38,000
and the slowness was not the urgent thing to do.

316
00:20:38,000 --> 00:20:42,000
After a while, that was the situation where every few weeks,

317
00:20:42,000 --> 00:20:47,000
we would get these days-long merge queues and everything would stop, it was a real crisis mode.

318
00:20:47,000 --> 00:20:53,000
And it only became okay after we did an expensive project, and made all the tests running parallel.

319
00:20:53,000 --> 00:21:00,000
They would still fail, but sometimes, but it wasn't a crisis because the queue would go to zero fast enough,

320
00:21:00,000 --> 00:21:02,000
so it wasn't a crisis.

321
00:21:02,000 --> 00:21:07,000
And the question is, how do we avoid getting into this situation?

322
00:21:07,000 --> 00:21:12,000
We all want to do premature optimization, so what we need to do in day one

323
00:21:12,000 --> 00:21:18,000
is make sure that when we need to optimize, it is not going to be a very expensive project.

324
00:21:18,000 --> 00:21:22,000
And specifically, we want to make sure that we run the tests in parallel,

325
00:21:22,000 --> 00:21:25,000
because it's probably going to be the go-to solution.

326
00:21:25,000 --> 00:21:28,000
And that actually is easier than it seems,

327
00:21:28,000 --> 00:21:31,000
we just need to remember the foot gun about isolated tests.

328
00:21:31,000 --> 00:21:34,000
Tests that don't affect each other must be run in parallel.

329
00:21:34,000 --> 00:21:37,000
So I would suggest making this a must-have.

330
00:21:39,000 --> 00:21:44,000
Now, the other way we talk about that slow tests can hurt us is by making the feedback loop slower.

331
00:21:44,000 --> 00:21:50,000
And the feedback loop here is how long it takes us to find out about bugs and understand what happened.

332
00:21:50,000 --> 00:21:53,000
And I'm talking about any type of bug here, even a small typo.

333
00:21:53,000 --> 00:21:57,000
The feedback loop is super important, makes a lot of difference.

334
00:21:57,000 --> 00:22:03,000
Anything that impacts is a great thing, even a red squiggly line in the IDE is very important.

335
00:22:03,000 --> 00:22:05,000
But first today we're talking about tests.

336
00:22:05,000 --> 00:22:11,000
And I usually aim for a setup where I'm running, most of the time I'm running tests in watch mode,

337
00:22:11,000 --> 00:22:14,000
so they rerun every time a file changes.

338
00:22:14,000 --> 00:22:20,000
And I'm running some subset of the tests so they finish within at most three seconds.

339
00:22:20,000 --> 00:22:27,000
And being on the fast side like this, it has a lot of advantages, just one for example:

340
00:22:27,000 --> 00:22:32,000
If the test turns red three seconds after I change some code,

341
00:22:32,000 --> 00:22:34,000
I immediately know what happened.

342
00:22:34,000 --> 00:22:36,000
It was just three seconds ago.

343
00:22:36,000 --> 00:22:40,000
And compare that to slow tests with running CI, the commit with the failing test,

344
00:22:40,000 --> 00:22:44,000
it might have a lot of code, it might have a lot of bugs in it,

345
00:22:44,000 --> 00:22:46,000
plus, my brain has done a context switch.

346
00:22:46,000 --> 00:22:48,000
I went to check up on Slack.

347
00:22:48,000 --> 00:22:54,000
So when I get back to the test to check what went wrong, it's going to be a lot more work to understand.

348
00:22:55,000 --> 00:23:00,000
Now, some tests have to be slow, maybe some tests can only run in CI even,

349
00:23:00,000 --> 00:23:04,000
but the good news is that you can still have a pretty fast feedback loop.

350
00:23:04,000 --> 00:23:10,000
And what helps me is that instead of asking how long does it take for the test to run,

351
00:23:10,000 --> 00:23:13,000
I'm asking how long does it take to catch a bug.

352
00:23:13,000 --> 00:23:16,000
And I'm visualizing this using the bug funnel.

353
00:23:16,000 --> 00:23:22,000
All possible theoretical bugs come in, and at every stage some of them get figured out by the test that we catch them,

354
00:23:22,000 --> 00:23:24,000
at that stage.

355
00:23:24,000 --> 00:23:30,000
And the key observation here is that to have a good feedback loop, to be quick most of the time,

356
00:23:30,000 --> 00:23:32,000
we don't need to catch all of the bugs.

357
00:23:32,000 --> 00:23:34,000
We just need to catch most bugs.

358
00:23:34,000 --> 00:23:37,000
The feedback loop needs to be usually fast.

359
00:23:37,000 --> 00:23:41,000
For example, let's say we start out with a bug funnel, which is like this.

360
00:23:41,000 --> 00:23:45,000
We only have an integration test, slow integration test, and we only run them in the CI.

361
00:23:45,000 --> 00:23:49,000
And let's say we're working on some task and we would have done 10 bugs, right?

362
00:23:49,000 --> 00:23:56,000
So in this case, we would need to wait for the CI and debug the results, 10 times.

363
00:23:56,000 --> 00:24:05,000
Now, if we start writing the fast unit tests, pretty soon after a while we're going to get a bug funnel that looks more like this.

364
00:24:05,000 --> 00:24:10,000
We do need to wait sometimes for the CI, but not so much, maybe for just two of the bugs

365
00:24:10,000 --> 00:24:14,000
and most other bugs would be caught by tests a lot earlier.

366
00:24:14,000 --> 00:24:20,000
So most of our life is spent when the feedback loop is much, much faster.

367
00:24:20,000 --> 00:24:24,000
And consider also when we run some of these tests in watch mode.

368
00:24:24,000 --> 00:24:28,000
You have a two second feedback loop even if it's not for all the tests.

369
00:24:28,000 --> 00:24:37,000
Another thing we can do to improve the feedback loop is use tests double, that's what they're there for, making things faster.

370
00:24:37,000 --> 00:24:46,000
And by the way, specifically, one thing that specifically has a nice tradeoff here is using cached recordings locally.

371
00:24:46,000 --> 00:24:51,000
It's very nice, you really should try it, it makes a lot of difference.

372
00:24:51,000 --> 00:25:03,000
For a jump, over to the last foot gun, I didn't mention specific tooling, so here they are, a bunch of software worth checking.

373
00:25:03,000 --> 00:25:10,000
You don't need to take a picture of the slides and I put a link in at the end of the slides.

374
00:25:10,000 --> 00:25:14,000
Foot gun 10: wrong priorities.

375
00:25:14,000 --> 00:25:27,000
So we saw a lot of great work that can change our experiences by influencing the properties of our tests.

376
00:25:27,000 --> 00:25:31,000
Right? The bug funnel was all about performance.

377
00:25:31,000 --> 00:25:35,000
And testing implementation instead of behavior is strength and maintainability.

378
00:25:35,000 --> 00:25:41,000
The question is how do we prioritize, when we work, how do we choose what we put emphasis on?

379
00:25:41,000 --> 00:25:51,000
And to be clear, I mean, the objective of tests is their strength. We have tests so that they catch bugs, not for any other reasons.

380
00:25:51,000 --> 00:25:59,000
But the unintuitive thing is that's not the thing we should prioritize while we are working.

381
00:25:59,000 --> 00:26:04,000
First make them maintainable, then make sure they're fast enough, and then make them strong.

382
00:26:04,000 --> 00:26:10,000
And here's the thing, if the tests are slow, they are not going to be good at catching bugs.

383
00:26:10,000 --> 00:26:15,000
Slow tests are weak, or they are eventually weak.

384
00:26:15,000 --> 00:26:22,000
So, for example, the team really has decided that we're not willing for the tests to run for more than, say, 30 minutes.

385
00:26:22,000 --> 00:26:30,000
If the tests are slow, at some point they reach 30 minutes, and then it becomes more expensive to add more tests, a lot more expensive to add more tests.

386
00:26:30,000 --> 00:26:42,000
So, at some point, a lot of new code is going to have fewer tests, so it's not going to be well tested, and essentially the entire test suite is not going to be strong enough.

387
00:26:42,000 --> 00:26:45,000
The same thing happens with maintainability.

388
00:26:45,000 --> 00:26:51,000
A little more subtle, but essentially the same, if the tests are difficult to maintain, it costs more to have them.

389
00:26:51,000 --> 00:26:59,000
So, at a certain point, it's going to be too expensive, and we're going to have fewer tests for new code, and again, the tests are weak.

390
00:26:59,000 --> 00:27:04,000
Same thing happens sometimes with maintenance and performance.

391
00:27:04,000 --> 00:27:07,000
We saw an example with test isolation and parallelization.

392
00:27:08,000 --> 00:27:16,000
In other words, maintainability is sometimes a necessary condition for performance, and both are always a necessary condition for strength.

393
00:27:16,000 --> 00:27:19,000
So, make maintainability the priority.

394
00:27:19,000 --> 00:27:26,000
Test isolation, testing a single fact, code design, all of these.

395
00:27:26,000 --> 00:27:36,000
Whenever you need to make some choice, I suggest you almost always go with the choice that is more maintainable, even at the cost of other things.

396
00:27:37,000 --> 00:27:45,000
Because in the long run, that's the way we get the tests that help us move fast, and make us confident in our code.

397
00:27:45,000 --> 00:27:47,000
Thank you very much.

