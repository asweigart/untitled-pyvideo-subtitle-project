1
00:00:00,000 --> 00:00:04,520
All right, does this work?

2
00:00:04,520 --> 00:00:06,400
Can anyone, can everyone hear me?

3
00:00:06,400 --> 00:00:07,400
Yeah.

4
00:00:07,400 --> 00:00:08,400
All right.

5
00:00:08,400 --> 00:00:11,720
Hello everyone and thank you very much for coming to our talk today.

6
00:00:11,720 --> 00:00:17,240
I'm going to be talking about building large language model based agents and how you can

7
00:00:17,240 --> 00:00:22,720
build smart NLP driven applications with Haystack.

8
00:00:22,720 --> 00:00:25,160
But before I get into that, a bit about myself.

9
00:00:25,160 --> 00:00:30,640
This is my first time here in Salt Lake City and at PyCon, so I am a bit nervous and excited.

10
00:00:30,640 --> 00:00:32,480
I hope this goes well.

11
00:00:32,480 --> 00:00:39,080
My name is Twana and I'm the developer advocate at Deepset, which is the company behind Haystack,

12
00:00:39,080 --> 00:00:41,160
the open source tool we'll be talking about.

13
00:00:41,160 --> 00:00:45,720
I have a background in computer science but have been doing dev rel since about 2020.

14
00:00:45,720 --> 00:00:53,180
All right, so today's talk is going to follow roughly this structure.

15
00:00:53,180 --> 00:00:59,340
At the end of the day, I kind of want to pass on the message around how agents even became,

16
00:00:59,340 --> 00:01:00,340
how they were possible.

17
00:01:00,340 --> 00:01:05,580
Then we're going to look into a bit about what Haystack is, how you can interact with

18
00:01:05,580 --> 00:01:10,620
large language models using Haystack and then we're going to see how we might create our

19
00:01:10,620 --> 00:01:12,620
own agents with Haystack.

20
00:01:12,620 --> 00:01:18,380
There is going to be a bit of coding towards the end and also just a side note for everyone,

21
00:01:18,380 --> 00:01:21,860
given that this is about natural language processing, there is a lot of language on

22
00:01:22,540 --> 00:01:27,500
If you cannot see the text, I will be reading out the ones that are most necessary because

23
00:01:27,500 --> 00:01:32,580
we will be looking at some fairly long prompts and we'll see what that is later as well.

24
00:01:32,580 --> 00:01:43,220
All right, so without further ado, here is a brief history of the human, how humans search,

25
00:01:43,220 --> 00:01:45,780
let's say, according to me.

26
00:01:45,780 --> 00:01:48,300
So it's not very accurate.

27
00:01:48,340 --> 00:01:51,140
This is more about how humans extract information.

28
00:01:51,140 --> 00:01:54,140
So we communicate with each other, that's great.

29
00:01:54,140 --> 00:01:57,500
Then we have books, then we have the World Wide Web.

30
00:01:57,500 --> 00:02:01,420
Quite recently, I'm pretty sure without me having to tell you the exact name, a lot of

31
00:02:01,420 --> 00:02:06,000
us have been relying on a very well-known NLP technology.

32
00:02:06,000 --> 00:02:12,740
So I want to start explaining to you how agents even came about, how they work, the idea behind

33
00:02:13,380 --> 00:02:19,140
giving an example of some interactions I might have with this NLP technology.

34
00:02:19,140 --> 00:02:22,300
There are some memes in this slide deck.

35
00:02:22,300 --> 00:02:24,660
You can blame that all on Jasper over there.

36
00:02:24,660 --> 00:02:28,820
That's my colleague who gave me the feedback that your slide deck needs memes.

37
00:02:28,820 --> 00:02:30,900
So there you go.

38
00:02:30,900 --> 00:02:35,340
All right, let's start with some examples about what we can do with large language models.

39
00:02:35,340 --> 00:02:36,460
Let's start simple.

40
00:02:36,460 --> 00:02:41,820
And here is that interface I'm pretty sure a lot of you have already seen.

41
00:02:41,900 --> 00:02:44,300
This is simply a question.

42
00:02:44,300 --> 00:02:46,780
So we know we can ask questions to large language models.

43
00:02:46,780 --> 00:02:51,180
And we've got back a pretty accurate long answer.

44
00:02:51,180 --> 00:02:53,100
So that's one thing we can do.

45
00:02:53,100 --> 00:02:58,100
Here I've asked who was the first president of the USA, and I got a correct answer, quite

46
00:02:58,100 --> 00:02:59,620
a detailed answer.

47
00:02:59,620 --> 00:03:00,620
That's great.

48
00:03:00,620 --> 00:03:05,260
But the one thing to notice here that this is a question.

49
00:03:05,260 --> 00:03:06,260
What else can we do?

50
00:03:06,340 --> 00:03:12,460
Well, we can ask it instruct these large language models to do something.

51
00:03:12,460 --> 00:03:15,620
This is not necessarily a question to be answered.

52
00:03:15,620 --> 00:03:21,220
Here I've highlighted around my instruction, which says summarize the following text for

53
00:03:21,220 --> 00:03:22,220
me.

54
00:03:22,220 --> 00:03:25,580
And I've simply copy pasted the answer that I got before.

55
00:03:25,580 --> 00:03:27,900
And this is where you start to see how things are getting different.

56
00:03:27,900 --> 00:03:32,140
I'm instructing the large language model to do something for me.

57
00:03:32,140 --> 00:03:35,020
And I've got a pretty accurate summary.

58
00:03:35,060 --> 00:03:41,100
These models are generative, so you don't necessarily have to ask it for information.

59
00:03:41,100 --> 00:03:46,820
What's cool, you can also ask them to create content, create previously non-existent content.

60
00:03:46,820 --> 00:03:50,700
So you can achieve beautiful literature a bit like this too.

61
00:03:50,700 --> 00:03:55,180
Here I say, create a PyCon event schedule in the style of a poem.

62
00:03:55,180 --> 00:03:56,740
And it's beautiful.

63
00:03:56,740 --> 00:03:58,380
It knows about tutorials.

64
00:03:58,380 --> 00:04:00,780
It knows about talks, keynotes, et cetera.

65
00:04:00,780 --> 00:04:03,340
It's a pretty good poem.

66
00:04:03,340 --> 00:04:07,260
But then the next two slides is where I want to really draw your attention to, because

67
00:04:07,260 --> 00:04:11,660
this is where really the whole idea, the essence of agents come about.

68
00:04:11,660 --> 00:04:14,780
I know I've just started saying agents without actually having asked you, do you know what

69
00:04:14,780 --> 00:04:16,820
I'm talking about when I say agents?

70
00:04:16,820 --> 00:04:20,180
But hopefully you'll start to get an idea what they are.

71
00:04:20,180 --> 00:04:24,460
All right, so this is the first instruction.

72
00:04:24,460 --> 00:04:30,780
This one is different, because I've basically imagined up two things, which I'm going to

73
00:04:30,780 --> 00:04:32,820
be calling tools.

74
00:04:32,820 --> 00:04:38,700
And I said, you have the following tools, PyCon event QA, and I've explained what it's

75
00:04:38,700 --> 00:04:40,140
useful for.

76
00:04:40,140 --> 00:04:44,580
I've said useful for when you need to answer questions about PyCon.

77
00:04:44,580 --> 00:04:49,200
And then I've also said you've got web search, and I've said it's useful for when you need

78
00:04:49,200 --> 00:04:54,420
to search the web to answer general questions that other tools cannot.

79
00:04:54,420 --> 00:04:59,740
And then I've given a query saying, pick which tools you would use to resolve the following

80
00:05:00,740 --> 00:05:02,820
When is Twana's talk at PyCon?

81
00:05:02,820 --> 00:05:07,060
And what is the weather at Salt Lake City going to be like that day?

82
00:05:07,060 --> 00:05:11,540
And I've only asked it to pick the tools based on the descriptions I've given.

83
00:05:11,540 --> 00:05:16,740
And what I want you to notice is that it has picked the right tools in the right order

84
00:05:16,740 --> 00:05:22,340
according to what is the use that it has to learn, it has to find out.

85
00:05:22,340 --> 00:05:24,880
So that's one thing to keep in mind.

86
00:05:24,880 --> 00:05:28,740
The next one is quite long, so if anyone in the back cannot read this, don't worry, I'm

87
00:05:28,740 --> 00:05:32,460
going to highlight what's the most important part of this one.

88
00:05:32,460 --> 00:05:38,000
It is the same prompt, the same instruction, I haven't said prompt yet.

89
00:05:38,000 --> 00:05:42,340
It is the same exact instruction with one key difference.

90
00:05:42,340 --> 00:05:49,740
I have added a line saying, explain step by step how you arrive to your conclusion.

91
00:05:49,740 --> 00:05:54,180
This is often referred to as the chain of thought methodology.

92
00:05:54,180 --> 00:05:59,700
This is where we can ask the large language model to reason about why it's picking some

93
00:05:59,700 --> 00:06:06,020
tools and the response I want to really draw attention to number two here, which says,

94
00:06:06,020 --> 00:06:11,860
once I have located Twana's talk in the PyCon schedule, I would note the date and time of

95
00:06:11,860 --> 00:06:12,860
the talk.

96
00:06:12,860 --> 00:06:17,620
So you can see it's making decisions around what information is going to be important

97
00:06:17,620 --> 00:06:19,860
for the next tool.

98
00:06:19,860 --> 00:06:28,220
Now agents really in essence is this, the only difference is the tools do actually exist.

99
00:06:28,220 --> 00:06:32,980
This question here is going to be recurring throughout my talk, when is Twana's talk at

100
00:06:32,980 --> 00:06:37,620
PyCon and what is the weather going to be like at Salt Lake City on that day.

101
00:06:37,620 --> 00:06:41,860
Because I've gone ahead and built this agent and at the end of this talk what we want to

102
00:06:41,860 --> 00:06:47,520
get to is figuring out how we would build something that does the following and hopefully

103
00:06:47,600 --> 00:06:51,880
I can actually play this because I want to pause it at the end.

104
00:06:51,880 --> 00:06:55,080
You can see this running, agent.run.

105
00:06:55,080 --> 00:07:00,720
It's picked a tool saying speaker search and it's invoked that tool, actually run it, looked

106
00:07:00,720 --> 00:07:08,440
for Twana's talk and then picked web search and at the end you can see that it says final

107
00:07:08,440 --> 00:07:12,640
answer Twana Chalik will be presenting blah blah blah blah.

108
00:07:12,640 --> 00:07:14,200
We all know the title.

109
00:07:14,280 --> 00:07:19,080
Then finally it says the weather in Salt Lake City on that day is expected to be cold with

110
00:07:19,080 --> 00:07:25,480
temperatures between 1 and 10 degrees Celsius, snowfall and rain, not great weather for Salt

111
00:07:25,480 --> 00:07:28,080
Lake City.

112
00:07:28,080 --> 00:07:32,080
You can see that it's picked first a tool called speaker search.

113
00:07:32,080 --> 00:07:36,480
We're going to see what this tool even is and how it runs.

114
00:07:36,480 --> 00:07:41,080
Then it's extracted my talk from PyCon event data.

115
00:07:41,080 --> 00:07:46,160
Then once it knows what day my talk is, it's decided okay, now I need to use one of the

116
00:07:46,160 --> 00:07:49,280
tools called web search.

117
00:07:49,280 --> 00:07:54,720
What I really want to draw your attention to throughout this talk actually is the importance

118
00:07:54,720 --> 00:07:59,520
of the first instruction I give these large language models so that they are able to do

119
00:07:59,520 --> 00:08:00,720
this.

120
00:08:00,720 --> 00:08:06,400
All of those previous chat GPT screen shots you saw have one obvious thing in common which

121
00:08:06,440 --> 00:08:10,520
is the quite impressive language model itself.

122
00:08:10,520 --> 00:08:16,360
They also have a very well structured effective instruction which we call prompts.

123
00:08:16,360 --> 00:08:18,920
I'm going to be referring to them as prompts from now on.

124
00:08:18,920 --> 00:08:22,560
We're going to be looking at a lot of prompts.

125
00:08:22,560 --> 00:08:29,920
This is really well highlighted by this, why can't I go to the next slide?

126
00:08:29,920 --> 00:08:32,280
Also Jasper's meme by the way.

127
00:08:32,280 --> 00:08:37,600
This quote by Andrej who said the hottest new programming language is English.

128
00:08:37,600 --> 00:08:45,840
You're going to see how true that is when it comes to how agents are even able to exist.

129
00:08:45,840 --> 00:08:50,160
Before we dive into building an agent and seeing how these tools can be described, I

130
00:08:50,160 --> 00:08:55,040
want to do a quick introduction to Haystack.

131
00:08:55,040 --> 00:08:59,360
Haystack is a fully open source NLP framework.

132
00:08:59,360 --> 00:09:04,800
You can scan that QR code and you'll get to our GitHub page.

133
00:09:04,800 --> 00:09:11,520
It's maintained by my company Deepset plus a very vibrant large community of developers,

134
00:09:11,520 --> 00:09:15,280
open source developers who contribute to the project every day.

135
00:09:15,280 --> 00:09:21,120
The core idea behind Haystack is what you see on the right hand side here which is a

136
00:09:21,120 --> 00:09:24,000
pipeline.

137
00:09:25,000 --> 00:09:30,600
It allows you to mix and match components, NLP components that you might want to use

138
00:09:30,600 --> 00:09:33,160
depending on what your use case is.

139
00:09:33,160 --> 00:09:38,840
A very, very common way of doing a query pipeline is what you see on the left where you would

140
00:09:38,840 --> 00:09:45,320
use a retriever node which is really good at looking at a really large set of documents

141
00:09:45,320 --> 00:09:52,320
and deciding which ones are the most relevant for the user's query followed by a reader.

142
00:09:52,360 --> 00:09:56,920
We're not going to be looking at the reader today but the reader is basically a component

143
00:09:56,920 --> 00:09:59,560
that uses an extractive model.

144
00:09:59,560 --> 00:10:02,040
So it only looks at context and it extracts answers.

145
00:10:02,040 --> 00:10:05,440
It does not formulate a human-like response.

146
00:10:05,440 --> 00:10:10,480
You're able to use models off of depending on what you want to do, hugging face, open

147
00:10:10,480 --> 00:10:14,880
AI, cohere and also decide what database you want.

148
00:10:14,880 --> 00:10:21,720
You can decide to use a vector optimized database like pine cone, weaviate or you can go with

149
00:10:21,920 --> 00:10:26,360
open search, depending on what your tech stack looks like.

150
00:10:26,360 --> 00:10:32,040
So the whole idea is really a whole end to end NLP application will actually end up needing

151
00:10:32,040 --> 00:10:38,480
a lot of tooling around it, a lot of pre-processing maybe and we try to provide all of the quality

152
00:10:38,480 --> 00:10:42,720
of life features that you might need.

153
00:10:42,720 --> 00:10:47,560
At the end of the day, this is what a pipeline structure actually looks like.

154
00:10:48,120 --> 00:10:51,640
I'm going to come back to this slide later because you're going to see how this is kind

155
00:10:51,640 --> 00:10:54,160
of different to how agents operate.

156
00:10:54,160 --> 00:11:00,600
A pipeline is a predefined path made up of components based on what you have decided

157
00:11:00,600 --> 00:11:05,280
before what your application is going to do, what it's going to need.

158
00:11:05,280 --> 00:11:09,160
Like I said, a pipeline might look like this but you're free to mix and match.

159
00:11:09,160 --> 00:11:14,360
Let's say you switch over the reader with a generator so it's a generative model now.

160
00:11:14,360 --> 00:11:20,880
You can use elastic search, weaviate, quadrant, pine cone and decide which models you use

161
00:11:20,880 --> 00:11:26,640
for your retriever and your reader or generator based on what you want to achieve.

162
00:11:26,640 --> 00:11:30,480
And then you can also expose your application via REST API.

163
00:11:30,480 --> 00:11:34,740
So this really covers most of the basics of Haystack at this point.

164
00:11:34,740 --> 00:11:37,640
Now I'm going to start talking about where it changes.

165
00:11:37,640 --> 00:11:40,720
Again, this is a one path system.

166
00:11:40,720 --> 00:11:45,400
The path is predefined and your data is walking through that path.

167
00:11:45,400 --> 00:11:51,200
All right, so I want to build a pipeline with Haystack and this is going to be important

168
00:11:51,200 --> 00:11:56,520
because we're actually going to use this pipeline later on in the talk as one of our tools for

169
00:11:56,520 --> 00:11:58,480
an agent.

170
00:11:58,480 --> 00:12:03,720
So you saw that video I showed where it was actually running and doing speaker search

171
00:12:03,720 --> 00:12:07,000
and then deciding what the weather was like doing web search.

172
00:12:07,040 --> 00:12:14,200
I have actually called the PyCon event page and this is on Hugging Face.

173
00:12:14,200 --> 00:12:19,200
It's a data set and you can see it's got talks, tutorials, sponsored talks, everything there

174
00:12:19,200 --> 00:12:21,200
ready for me to use.

175
00:12:21,200 --> 00:12:23,160
I've got two options.

176
00:12:23,160 --> 00:12:30,200
I can either create a search application going through a retrieval and then a reader, so

177
00:12:30,200 --> 00:12:32,480
extractive model.

178
00:12:32,960 --> 00:12:40,280
Or I can basically do the same so I know that my generative model is getting retrieved documents

179
00:12:40,280 --> 00:12:43,560
from that data set you just saw there and I'm going to pick that one.

180
00:12:43,560 --> 00:12:48,400
I'm going to use a generative model because it's just a bit more interesting.

181
00:12:48,400 --> 00:12:53,600
All right, so the two components in Haystack that will allow you to interact with large

182
00:12:53,600 --> 00:12:57,760
language models with your own data are these two.

183
00:12:57,760 --> 00:13:02,200
The prompt template and the prompt node.

184
00:13:02,240 --> 00:13:07,480
The prompt template is basically allowing you to create a blueprint of how you want

185
00:13:07,480 --> 00:13:11,240
to interact with large language models and we're going to be looking at how we build

186
00:13:11,240 --> 00:13:13,200
our own.

187
00:13:13,200 --> 00:13:20,320
And it's flexible because you can change, actually change what the prompt is at query time.

188
00:13:20,320 --> 00:13:24,320
The prompt node is simply basically the connector to these large language models.

189
00:13:24,320 --> 00:13:31,320
So this is where we say I want to, I don't know, use GPT-4 or use Google's Flan models, etc.

190
00:13:31,360 --> 00:13:33,680
And this is the one that interacts with the large language model.

191
00:13:33,680 --> 00:13:38,560
So it's the one that sends the query and receives a response.

192
00:13:38,560 --> 00:13:45,560
All right, so we saw how, at the beginning, how instructions are important.

193
00:13:45,640 --> 00:13:52,120
So I've created my own instruction to do some search on PyCon event data.

194
00:13:52,120 --> 00:13:54,800
And here is my instruction.

195
00:13:54,800 --> 00:14:00,080
So I'm not sure if this is readable from the back but I'm going to read it out for you.

196
00:14:00,080 --> 00:14:06,040
So I've called it my prompt and I've said you will be provided a list of events, reply

197
00:14:06,040 --> 00:14:10,160
to the query based on the content of the provided events.

198
00:14:10,160 --> 00:14:14,840
And then the next few lines are important because I said query and then I've given this

199
00:14:14,840 --> 00:14:20,980
variable called query in curly brackets and then I've also said events and I've said in

200
00:14:20,980 --> 00:14:23,920
curly brackets join all the documents.

201
00:14:23,920 --> 00:14:25,320
So we'll see how this works.

202
00:14:25,320 --> 00:14:29,880
But basically these two things in curly brackets is where the magic happens.

203
00:14:29,920 --> 00:14:34,360
And at the end of the day I want to build a pipeline that actually sends the following

204
00:14:34,360 --> 00:14:35,360
prompt.

205
00:14:35,360 --> 00:14:38,400
This was really long so I've actually split this into two slides.

206
00:14:38,400 --> 00:14:43,280
But what's happened here is you can see that my query, what day is the talk about agents

207
00:14:43,280 --> 00:14:50,440
and LLMs, has been basically injected into the prompt that I am sending to an LLM in

208
00:14:50,440 --> 00:14:52,400
the query section.

209
00:14:52,400 --> 00:14:58,240
And you'll see how the retriever has retrieved some documents and joined them.

210
00:14:58,280 --> 00:15:03,120
And that's been where I fill the events, the curly brackets that say join events.

211
00:15:03,120 --> 00:15:04,880
Again, I've shortened this.

212
00:15:04,880 --> 00:15:06,440
There was a lot.

213
00:15:06,440 --> 00:15:09,720
And then finally we are saying, okay, now what's the answer?

214
00:15:09,720 --> 00:15:14,040
And we expect an answer from the large language model.

215
00:15:14,040 --> 00:15:17,960
So all right, so how do I make this happen basically?

216
00:15:17,960 --> 00:15:27,520
Well, first I declare a prompt template and I call this prompt template events QA.

217
00:15:27,520 --> 00:15:33,080
And I've said the prompt text is what I just created, my prompt.

218
00:15:33,080 --> 00:15:38,160
Finally I've created a prompt node and I've said your default prompt template.

219
00:15:38,160 --> 00:15:44,160
So anytime you get called by default you use this prompt template that has just been created.

220
00:15:44,160 --> 00:15:48,720
And I call this prompt node PyCon QA.

221
00:15:48,720 --> 00:15:51,480
And then I just create a pipeline.

222
00:15:51,480 --> 00:15:56,000
I say I've got a pipeline and I add my first node.

223
00:15:56,000 --> 00:15:57,200
Let's assume we have a retriever.

224
00:15:57,240 --> 00:16:00,240
I did not really want to dive into retrievers right now.

225
00:16:00,240 --> 00:16:05,120
But the retriever has access to all those documents you saw on Hugging Face basically.

226
00:16:05,120 --> 00:16:08,160
And the first thing that gets the query is this retriever.

227
00:16:08,160 --> 00:16:14,800
So the first job is first I need to find the most relevant documents events out there.

228
00:16:14,800 --> 00:16:17,840
The second node is my prompt node.

229
00:16:17,840 --> 00:16:22,360
The second node is the PyCon QA node that already has a prompt template ready.

230
00:16:22,400 --> 00:16:28,040
So it's now ready to receive documents and a query and inject this into the prompt text

231
00:16:28,040 --> 00:16:29,960
that I created and send it over.

232
00:16:31,480 --> 00:16:36,640
Finally I ask it the question what day is the talk about agents and LLMs?

233
00:16:36,640 --> 00:16:40,440
And I receive a response a bit like this.

234
00:16:40,440 --> 00:16:41,240
It's quite long.

235
00:16:41,240 --> 00:16:46,600
It says the talk about agents and LLMs titled, gives the title of my presentation

236
00:16:46,600 --> 00:16:49,880
and says on Thursday, April 20th.

237
00:16:49,880 --> 00:16:55,960
I built this pipeline and ran it because and then I just wanted to try another query.

238
00:16:55,960 --> 00:16:57,640
This was using GPT-4.

239
00:16:57,640 --> 00:16:59,880
I'm going to be using GPT-4 for the agents as well.

240
00:17:00,880 --> 00:17:03,800
And I asked it the question I'm interested in NLP.

241
00:17:03,800 --> 00:17:05,280
What talks should I see?

242
00:17:05,280 --> 00:17:07,320
And I got a pretty good response actually.

243
00:17:07,320 --> 00:17:11,120
It also gave me the correct URLs for every talk.

244
00:17:11,120 --> 00:17:13,800
I was pretty impressed so decided I might add this in here.

245
00:17:14,480 --> 00:17:18,400
And everything you're seeing here is basically referred

246
00:17:18,400 --> 00:17:23,360
to as a retrieval augmented generative QA methodology.

247
00:17:23,360 --> 00:17:29,040
Another one that I wanted to share because I think it's cool and it gives you the idea

248
00:17:29,040 --> 00:17:34,360
of how this works and why retrieval augmentation is important is this hugging face space.

249
00:17:34,360 --> 00:17:37,800
You can scan that QR code and try it out.

250
00:17:37,800 --> 00:17:43,760
Given the Twitter username it actually inserts the latest Twitter streams of that user.

251
00:17:44,760 --> 00:17:49,360
And then gives you an idea, like the prompt is ready and it gives you an idea of what type

252
00:17:49,360 --> 00:17:53,920
of tweets this person tweets about and what languages they use, et cetera.

253
00:17:53,920 --> 00:17:59,040
Okay, now we're back to this slide again because I want to reiterate this.

254
00:17:59,040 --> 00:18:01,440
This again is a pipeline.

255
00:18:01,440 --> 00:18:03,160
I've added nodes.

256
00:18:03,160 --> 00:18:04,800
The path is set.

257
00:18:04,800 --> 00:18:10,200
Data is flowing from one node to the next and the knowledge base is also set.

258
00:18:10,240 --> 00:18:14,960
I can't ask anything about weather to this application.

259
00:18:14,960 --> 00:18:20,080
If I do the best thing that's happening is probably I'm getting some weird response,

260
00:18:20,080 --> 00:18:21,080
complete hallucination.

261
00:18:21,080 --> 00:18:24,400
The knowledge base is PyCon events.

262
00:18:24,400 --> 00:18:26,840
All right, so this is where agents get in.

263
00:18:26,840 --> 00:18:29,560
Also you can thank Jasper for this.

264
00:18:29,560 --> 00:18:31,800
All right, so features of an agent.

265
00:18:31,800 --> 00:18:34,400
So what is an agent?

266
00:18:34,400 --> 00:18:39,440
An agent is in essence a prompt node, that prompt node we were looking at,

267
00:18:39,480 --> 00:18:41,560
which connects to a large language model.

268
00:18:41,560 --> 00:18:47,280
But most importantly, it's got a very clear, very clever initial prompt.

269
00:18:47,280 --> 00:18:50,560
So we're going to look at what that prompt is.

270
00:18:50,560 --> 00:18:57,240
It has access to a variety of tools and these tools actually exist and they run.

271
00:18:57,240 --> 00:19:01,600
These tools might be haystack pipelines like the one we just built now.

272
00:19:01,600 --> 00:19:04,800
They could be other data connectors, complete the pipelines that have access

273
00:19:04,800 --> 00:19:07,120
to a completely different knowledge base.

274
00:19:07,120 --> 00:19:08,600
They could even be web search.

275
00:19:08,600 --> 00:19:10,000
It's really up to you.

276
00:19:10,000 --> 00:19:14,360
The idea is as well with haystack that people will be able to build their own tools.

277
00:19:16,480 --> 00:19:18,080
And this is important too.

278
00:19:18,080 --> 00:19:22,080
Each tool might be useful to achieve one specific thing or

279
00:19:22,080 --> 00:19:25,200
have access to a completely different set of data.

280
00:19:27,000 --> 00:19:30,840
And again, like we saw in the first few slides,

281
00:19:30,840 --> 00:19:37,400
where we said explain to me step by step how you're going to come to your conclusion.

282
00:19:37,560 --> 00:19:40,680
An agent is going to create an action plan to look at a query and

283
00:19:40,680 --> 00:19:44,200
say these are the tools I will use to resolve this query.

284
00:19:46,400 --> 00:19:52,440
Some more QR because these are basically the two papers that the implementation of

285
00:19:52,440 --> 00:19:54,320
agents in haystack is based on.

286
00:19:54,320 --> 00:19:55,560
Highly recommend reading them.

287
00:19:55,560 --> 00:19:57,080
They are very interesting.

288
00:19:57,080 --> 00:19:58,240
One of them is called React.

289
00:19:58,240 --> 00:20:03,080
The other one is called, well it's MRKL but pronounced Miracle Systems.

290
00:20:03,080 --> 00:20:06,400
So if you're interested, please take a picture of that.

291
00:20:07,520 --> 00:20:13,480
All right, so we know that what a large language model can produce is really,

292
00:20:13,480 --> 00:20:17,720
well not completely, but it really depends on the initial instruction or

293
00:20:17,720 --> 00:20:18,640
the prompt we give them.

294
00:20:18,640 --> 00:20:24,560
So what is the prompt we give to an agent for it to be able to do what it does?

295
00:20:24,560 --> 00:20:29,560
Well the default one in haystack is called the zero shot react prompt.

296
00:20:29,560 --> 00:20:33,040
And again, this is very long, so I've split this into two slides and

297
00:20:33,040 --> 00:20:35,440
I'm going to read out the ones that are the most important.

298
00:20:35,440 --> 00:20:40,280
Number one, it says you are a helpful and knowledgeable agent and

299
00:20:40,280 --> 00:20:43,960
to achieve your goal of answering complex questions,

300
00:20:43,960 --> 00:20:47,480
you have access to the following tools.

301
00:20:47,480 --> 00:20:49,200
And this is where you see the curly brackets again.

302
00:20:49,200 --> 00:20:52,200
So you're going to see how dynamically we can add more and

303
00:20:52,200 --> 00:20:53,480
more tools with descriptions.

304
00:20:54,600 --> 00:20:59,360
And then it actually tells the model how to think in a way.

305
00:20:59,360 --> 00:21:02,080
Because it says use the following format.

306
00:21:02,120 --> 00:21:04,240
And it says, first you're going to get a question.

307
00:21:05,520 --> 00:21:08,520
And then generate some thought, decide what your next steps should be.

308
00:21:10,120 --> 00:21:13,200
Then pick a tool and we give it the tool names.

309
00:21:14,760 --> 00:21:16,840
Then decide what the input to that tool should be.

310
00:21:17,880 --> 00:21:20,640
And then finally observe what the response of that tool is.

311
00:21:21,720 --> 00:21:26,400
And we say, we tell it to give us a very short answer, but

312
00:21:26,400 --> 00:21:28,000
actually it's back there.

313
00:21:28,000 --> 00:21:32,080
We ask it to continue this loop until it's reached a final answer.

314
00:21:32,080 --> 00:21:35,480
And this is where you'll see how it's starting to become a bit different than

315
00:21:35,480 --> 00:21:36,880
the whole pipeline concept.

316
00:21:38,360 --> 00:21:42,840
And then finally we provide a way to input the query to the agent.

317
00:21:44,040 --> 00:21:46,680
All right, so an agent at the end of the day, and

318
00:21:46,680 --> 00:21:52,080
this is again where it starts to differ from a pipeline, is a bit like this.

319
00:21:52,080 --> 00:21:53,960
It's always there.

320
00:21:53,960 --> 00:21:57,360
Technically you can define how many steps it should take,

321
00:21:57,360 --> 00:22:00,160
because otherwise sometimes maybe it goes on for too long.

322
00:22:00,160 --> 00:22:03,560
And you're sending too many requests to OpenAI and the bill is ranking up.

323
00:22:03,560 --> 00:22:06,280
So you can set that.

324
00:22:06,280 --> 00:22:12,120
But effectively, you have this agent that exists,

325
00:22:12,120 --> 00:22:17,080
that has an arsenal of tools that it can, at every iteration,

326
00:22:17,080 --> 00:22:18,760
decide which one it should use or not.

327
00:22:18,760 --> 00:22:21,000
So the path is definitely not predefined.

328
00:22:21,000 --> 00:22:25,080
The path is defined on the fly by these models who are making decisions about

329
00:22:25,080 --> 00:22:26,720
what to use.

330
00:22:26,720 --> 00:22:29,160
Another way of looking at this is this.

331
00:22:29,160 --> 00:22:34,760
Think of the agent as a loop at the end of every iteration.

332
00:22:34,760 --> 00:22:36,840
It's saying, have I got the final answer?

333
00:22:36,840 --> 00:22:41,960
No, back to another picking tool and creating thoughts iteration.

334
00:22:41,960 --> 00:22:44,760
If I do, great, I can end this.

335
00:22:44,760 --> 00:22:51,160
So I created this PyCon event agent.

336
00:22:51,160 --> 00:22:55,840
I did change the zero shot react prompt just a bit, because as you saw,

337
00:22:55,880 --> 00:22:58,560
it said, just give me a one to five word answer.

338
00:22:58,560 --> 00:23:01,440
I did not want a one to five word answer.

339
00:23:01,440 --> 00:23:05,160
I also helped it out a bit, and I very creatively called it the zero shot

340
00:23:05,160 --> 00:23:08,760
react PyCon prompt.

341
00:23:08,760 --> 00:23:10,720
It's very similar at the beginning.

342
00:23:10,720 --> 00:23:16,040
I do tell it to correctly consider the date topic speaker constraints of the

343
00:23:16,040 --> 00:23:18,640
user input.

344
00:23:18,640 --> 00:23:24,120
And I simply just at the end tell it to give it as detailed as an answer as it

345
00:23:24,120 --> 00:23:24,520
decides.

346
00:23:24,560 --> 00:23:28,440
I don't want a one to five word, very simple answer.

347
00:23:28,440 --> 00:23:33,240
And now we're going to look at how we might fill this prompt with the

348
00:23:33,240 --> 00:23:34,200
following.

349
00:23:34,200 --> 00:23:39,920
So in my prompt, I'm going to define something called PyCon event QA.

350
00:23:39,920 --> 00:23:43,520
It's going to be useful for when you need to answer questions about PyCon.

351
00:23:43,520 --> 00:23:47,440
Then I'm going to define speaker search.

352
00:23:47,440 --> 00:23:52,000
There's a reason for this, because I tried this with just PyCon event QA

353
00:23:52,000 --> 00:23:58,000
using a retriever that does embedding search rather than keyword search,

354
00:23:58,000 --> 00:24:01,400
which is not great to ask it, like, find me Twana's talk.

355
00:24:01,400 --> 00:24:05,720
Twana becomes the keyword there, so I ended up defining another one.

356
00:24:05,720 --> 00:24:10,960
And then I also have web search, which simply basically Googles your

357
00:24:10,960 --> 00:24:12,600
questions for you.

358
00:24:12,600 --> 00:24:16,400
And then again, we're going to look at the query, when is Twana's talk at

359
00:24:16,400 --> 00:24:21,520
PyCon, and what will the weather in Salt Lake City be like that day?

360
00:24:21,520 --> 00:24:25,520
All right, so how would we build this with Haystack?

361
00:24:25,520 --> 00:24:28,240
First thing, we define an agent.

362
00:24:28,240 --> 00:24:32,440
Again, an agent is in essence a prompt, and I provide it with that prompt

363
00:24:32,440 --> 00:24:35,120
template you just saw.

364
00:24:35,120 --> 00:24:38,040
And I use GPT-4 here.

365
00:24:38,040 --> 00:24:44,040
Then that pipeline we created before, that generative QA pipeline, I say

366
00:24:44,040 --> 00:24:45,280
this is my tool.

367
00:24:45,280 --> 00:24:50,760
I call it PyCon QA tool, and I say give it a name and give it a description

368
00:24:51,120 --> 00:24:54,800
saying useful for when you need to answer questions about PyCon.

369
00:24:54,800 --> 00:24:57,400
And then I simply add that tool to my agent.

370
00:24:57,400 --> 00:25:02,480
Now my agent has at least access to that pipeline, which has access to

371
00:25:02,480 --> 00:25:05,080
PyCon event data.

372
00:25:05,080 --> 00:25:08,880
The next thing I do, again, because of this keyword search situation,

373
00:25:08,880 --> 00:25:12,520
because I really wasn't able to ask it questions about specific speaker

374
00:25:12,520 --> 00:25:16,280
names or dates without some keyword search, I won't look into how we

375
00:25:16,280 --> 00:25:17,600
built that pipeline.

376
00:25:17,640 --> 00:25:21,400
But basically I define another one saying useful when you want to answer

377
00:25:21,400 --> 00:25:23,800
questions about specific speakers.

378
00:25:23,800 --> 00:25:28,920
And then I add that, and now we've got two.

379
00:25:28,920 --> 00:25:32,760
And then I can define a Web QA pipeline.

380
00:25:32,760 --> 00:25:36,600
This is also a new pipeline we have in Haystack.

381
00:25:36,600 --> 00:25:41,000
This simply long story short can Google your questions and return to you

382
00:25:41,000 --> 00:25:44,880
the most, first of all, the most relevant web pages and then generate

383
00:25:44,880 --> 00:25:46,720
answers from them as well.

384
00:25:46,760 --> 00:25:51,800
So I define this and basically I've defined this as my sort of fallback

385
00:25:51,800 --> 00:25:56,320
tool because I said anything that you cannot answer with PyCon event data,

386
00:25:56,320 --> 00:25:58,080
this is the knowledge base you should go to.

387
00:25:58,080 --> 00:26:00,560
Just Google it.

388
00:26:00,560 --> 00:26:02,880
And now I've got three tools.

389
00:26:02,880 --> 00:26:08,280
And now I can ask this question, agent.run, when is Twana's talk at PyCon

390
00:26:08,280 --> 00:26:10,880
and what will the weather in Salt Lake City be like that day?

391
00:26:10,880 --> 00:26:15,360
And I have an agent that has all the resources it needs to actually answer

392
00:26:15,360 --> 00:26:16,800
this question.

393
00:26:16,800 --> 00:26:19,080
So we end up with this.

394
00:26:19,080 --> 00:26:22,040
Again, it's the same video basically.

395
00:26:22,040 --> 00:26:27,080
And you can now see how it will first say, first I need to find Twana's talk,

396
00:26:27,080 --> 00:26:31,840
and then decide the tool input for speaker search should be Twana.

397
00:26:31,840 --> 00:26:37,200
And then it knows the date of my talk and it decides that the input for

398
00:26:37,200 --> 00:26:40,520
web search should be weather for Salt Lake City 20th of April.

399
00:26:40,520 --> 00:26:45,000
And that is the general idea behind agents.

400
00:26:48,040 --> 00:26:50,320
All right, thank you very much for listening.

401
00:26:50,320 --> 00:26:54,640
I hope I was able to deliver what agents are and how they come about.

402
00:26:54,640 --> 00:26:58,080
If you do want to try building your own agent,

403
00:26:58,080 --> 00:27:02,720
the first QR code is a tutorial that uses simply one tool.

404
00:27:02,720 --> 00:27:05,480
And it's great at doing multi-hop question answering because of that.

405
00:27:06,440 --> 00:27:12,040
And then the second QR code is an article explaining the agent's

406
00:27:12,040 --> 00:27:16,560
implementation in Haystack, what kind of tools you might use.

407
00:27:16,560 --> 00:27:20,640
And I tried to deliver the idea behind agents in this article.

408
00:27:21,720 --> 00:27:25,800
Myself and my two colleagues and a few more were here throughout PyCon.

409
00:27:25,800 --> 00:27:29,240
You can find us at booth 321.

410
00:27:29,240 --> 00:27:31,400
If you do want to come and have a chat with us or

411
00:27:31,400 --> 00:27:33,080
you simply want a sticker, that's also fine.

412
00:27:34,040 --> 00:27:37,400
But yeah, I hope you enjoyed that.

413
00:27:37,400 --> 00:27:39,640
And I guess we have some time for questions now.

414
00:27:39,640 --> 00:27:40,680
Yeah.

415
00:27:40,680 --> 00:27:50,680
What are the types of agents you support?

416
00:27:50,680 --> 00:28:00,280
With the Python, I can make a custom agent that's very local-mouthful.

417
00:28:00,280 --> 00:28:02,360
Actually, that's a really good question.

418
00:28:02,360 --> 00:28:05,520
So there's types of agents and there's types of tools.

419
00:28:05,520 --> 00:28:07,560
So I'm gonna address those two separately.

420
00:28:08,520 --> 00:28:11,680
The default one uses the zero-shot react right now, but

421
00:28:11,680 --> 00:28:15,200
you can completely build from scratch your own agent prompt.

422
00:28:15,200 --> 00:28:20,080
So we do have examples of, so this one is called zero-shot because

423
00:28:20,080 --> 00:28:24,120
we actually didn't give it any examples of how to react to questions.

424
00:28:24,120 --> 00:28:25,960
There are some cases where few-shot,

425
00:28:25,960 --> 00:28:28,880
where you do give examples, works really well.

426
00:28:28,880 --> 00:28:31,760
But the idea is, yes, you can build a tool.

427
00:28:31,760 --> 00:28:35,600
And I actually think I know a community member that's building a Wolfram Alpha

428
00:28:35,640 --> 00:28:38,400
tool for an agent.

429
00:28:38,400 --> 00:28:43,520
A tool can be another haystack node, a completely new pipeline that uses

430
00:28:43,520 --> 00:28:47,200
a prompt node or has a separate connection to another API, yes.

431
00:28:47,200 --> 00:28:52,000
Yeah, I was thinking about line change,

432
00:28:52,000 --> 00:28:55,440
but it's sort of a big problem.

433
00:28:55,440 --> 00:28:59,320
Yeah.

434
00:28:59,320 --> 00:29:00,920
Are there any other questions?

435
00:29:00,920 --> 00:29:01,920
Yes.

436
00:29:01,920 --> 00:29:07,160
So I think OpenAI has a limit of characters.

437
00:29:07,160 --> 00:29:08,160
Yes.

438
00:29:08,160 --> 00:29:09,960
I think it's like 4,000 or something like that.

439
00:29:09,960 --> 00:29:10,480
Yeah.

440
00:29:10,480 --> 00:29:14,840
So I'm just curious, can you use another open source?

441
00:29:14,840 --> 00:29:16,640
Actually, I should have referred to this in my talk, so

442
00:29:16,640 --> 00:29:18,240
I'm glad you asked this.

443
00:29:18,240 --> 00:29:21,400
Yes, so my example was with OpenAI, but

444
00:29:21,400 --> 00:29:24,240
the idea is you can use any language model,

445
00:29:24,240 --> 00:29:27,080
large language model that can follow instructions.

446
00:29:27,080 --> 00:29:31,360
So for example, I know a couple of people who use Haystack agents with

447
00:29:31,360 --> 00:29:36,680
the Google Flan models, and I don't know if we support it just yet,

448
00:29:36,680 --> 00:29:38,600
or I think we're looking into it.

449
00:29:38,600 --> 00:29:44,920
Quite recently, Databricks came up with Dolly, which is an open source model

450
00:29:44,920 --> 00:29:49,120
that, well, it's coined saying instruction following model, so

451
00:29:49,120 --> 00:29:50,640
maybe that will work as well.

452
00:29:50,640 --> 00:29:51,480
Yeah.

453
00:29:51,480 --> 00:29:53,280
And so I'm sorry, was it blue?

454
00:29:53,280 --> 00:29:56,680
Like, is it like, somewhere in the blue model?

455
00:29:56,680 --> 00:29:57,680
Yeah.

456
00:29:57,680 --> 00:30:00,600
I'm looking at Mattis because he's probably more likely to know the exact

457
00:30:00,600 --> 00:30:01,600
answer to this one.

458
00:30:01,600 --> 00:30:06,680
I think technically, yes, it's not easy to get to this, but

459
00:30:06,680 --> 00:30:12,360
you did know that good questions aren't used very much in the field yet,

460
00:30:12,360 --> 00:30:16,240
so you always have to look at technically, yes,

461
00:30:16,240 --> 00:30:22,480
it needs to be the correct class to use it, but does it often work as an agent

462
00:30:22,480 --> 00:30:25,240
for the performance model?

463
00:30:25,240 --> 00:30:29,040
Okay, so that one was called Dolly, which is probably the most-

464
00:30:29,120 --> 00:30:30,320
Dolly, yes, yeah.

465
00:30:32,520 --> 00:30:33,720
I think I saw another, yeah.

466
00:30:39,280 --> 00:30:40,280
Oh, thanks.

467
00:30:40,280 --> 00:30:42,080
Oh, nice.

468
00:30:42,080 --> 00:30:47,120
So you were using OpenAI's GPT-4 model.

469
00:30:47,120 --> 00:30:48,040
Yeah.

470
00:30:48,040 --> 00:30:52,040
If one created their own LLM from hugging,

471
00:30:52,040 --> 00:30:57,560
like using hugging this as tokenizer, can they still utilize that with ASTEP?

472
00:30:57,560 --> 00:31:02,560
So, Haystack already has an integration with Hugging Face,

473
00:31:02,560 --> 00:31:08,880
so if it is a model at the end of the day that could follow instructions,

474
00:31:08,880 --> 00:31:10,200
that should be possible.

475
00:31:10,200 --> 00:31:13,920
For example, the Google Flan models I was just mentioning,

476
00:31:13,920 --> 00:31:16,840
we actually just pulled out from Hugging Face.

477
00:31:16,840 --> 00:31:18,560
It's not a, yeah, it's not-

478
00:31:18,560 --> 00:31:21,080
Do you always have to be pulled from Hugging Face?

479
00:31:21,080 --> 00:31:24,760
No, so we have connectors to OpenAI.

480
00:31:24,760 --> 00:31:29,160
Kahir, even though we don't use it specifically for agents,

481
00:31:29,160 --> 00:31:33,120
Hugging Face, and you can use all of the Haystack pipelines you saw before,

482
00:31:33,120 --> 00:31:37,320
so the pipeline we built was Generative QA, for example.

483
00:31:37,320 --> 00:31:39,840
You can also simply use a local model.

484
00:31:39,840 --> 00:31:45,560
Okay, so you can build a model, download it into your laptop,

485
00:31:45,560 --> 00:31:47,640
add and run Haystack with it.

486
00:31:47,640 --> 00:31:49,600
Yeah, yeah, yeah.

487
00:31:49,600 --> 00:31:51,720
Cool, thank you.

488
00:31:51,720 --> 00:31:52,960
Yes.

489
00:31:53,480 --> 00:31:56,400
Do you guys have any support of your own tools?

490
00:31:56,400 --> 00:32:02,440
Tools, not yet, but well, actually technically, that one.

491
00:32:02,440 --> 00:32:04,680
You do technically create your own tool.

492
00:32:04,680 --> 00:32:07,480
It just happens to be a Haystack, another Haystack pipeline

493
00:32:07,480 --> 00:32:12,760
that becomes a tool, but yes, we are coming up with more examples.

494
00:32:12,760 --> 00:32:16,560
There's one coming up that actually creates Web QA as a tool as well.

495
00:32:16,560 --> 00:32:19,880
Okay, so I was thinking it would be really nice to sub it like that

496
00:32:20,400 --> 00:32:21,160
or something.

497
00:32:21,160 --> 00:32:23,320
That's like a web search instead of like,

498
00:32:23,320 --> 00:32:26,200
how do you suggest we use the server, is that it?

499
00:32:26,200 --> 00:32:29,920
Yes, I think, I believe there's also another one too.

500
00:32:29,920 --> 00:32:33,840
And yes, so agents are pretty new with Haystack.

501
00:32:33,840 --> 00:32:37,400
We have instructions on how to build your own custom nodes,

502
00:32:37,400 --> 00:32:39,520
and people who have built their own custom nodes have found

503
00:32:39,520 --> 00:32:42,040
that making that an agent tool has been quite smooth,

504
00:32:42,040 --> 00:32:44,680
but we need to add some instructions around that.

505
00:32:44,680 --> 00:32:46,000
Okay, thank you.

506
00:32:46,400 --> 00:32:52,440
There's one over there that I can see.

507
00:32:57,760 --> 00:32:59,080
Hi, I'm studying now.

508
00:32:59,080 --> 00:33:01,840
Can you ask someone in the field about what would you recommend

509
00:33:01,840 --> 00:33:07,720
or things that I could learn, like tools or things to research?

510
00:33:07,720 --> 00:33:10,200
Honestly, I would say agents are so new

511
00:33:10,200 --> 00:33:12,960
that I would really recommend those two papers.

512
00:33:13,800 --> 00:33:16,760
I actually have a background in computer vision, funnily enough,

513
00:33:16,760 --> 00:33:18,640
so NLP is still quite new to me,

514
00:33:18,640 --> 00:33:24,760
but those two papers are the React paper explains this whole

515
00:33:24,760 --> 00:33:27,600
reasoning aspect of large language models,

516
00:33:27,600 --> 00:33:30,040
and the Miracle paper is very interesting as well.

517
00:33:30,040 --> 00:33:34,000
And if you want to build full applications,

518
00:33:34,000 --> 00:33:37,800
I would really recommend looking into how tools will be built

519
00:33:37,800 --> 00:33:41,040
and which data sources might be interesting for you

520
00:33:41,080 --> 00:33:44,760
to build tools that an agent can have access to.

521
00:33:50,160 --> 00:33:51,480
Yes?

522
00:33:56,120 --> 00:34:00,760
Have you had any experience or faced building tools using

523
00:34:00,760 --> 00:34:06,960
like SQL or RQL or more specific querying languages

524
00:34:06,960 --> 00:34:10,320
so like you couldn't integrate this kind of databases?

525
00:34:10,320 --> 00:34:12,400
Not myself, but I think he has.

526
00:34:14,240 --> 00:34:18,440
So we have like this knowledge graph support in ASEC as well,

527
00:34:18,440 --> 00:34:23,360
but we have to honestly say that it doesn't really deliver

528
00:34:23,360 --> 00:34:26,480
the same performance that you're used to by now

529
00:34:26,480 --> 00:34:28,480
from large language models.

530
00:34:31,080 --> 00:34:33,800
But I think there's quite a few language models

531
00:34:33,800 --> 00:34:36,960
which are good at language to SQL basically,

532
00:34:36,960 --> 00:34:41,720
and that would work in a ASEC pipeline probably as well.

533
00:34:41,720 --> 00:34:46,440
So as a tool, maybe a small custom wrapper should work.

534
00:34:54,280 --> 00:34:57,280
I think that's about it.

535
00:34:57,280 --> 00:34:59,560
Really hope you enjoyed that.

536
00:34:59,560 --> 00:35:03,200
Yes, feel free to visit us in our booth, 321.

537
00:35:03,200 --> 00:35:06,600
We'll all be there until the end of PyCon.

538
00:35:06,600 --> 00:35:10,240
It would be really nice to meet you and see you all around.

