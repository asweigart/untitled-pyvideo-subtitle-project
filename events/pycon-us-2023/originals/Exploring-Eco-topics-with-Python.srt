1
00:00:00,000 --> 00:00:02,120
So this is 10.9 o'clock.

2
00:00:02,120 --> 00:00:07,120
Is everyone okay to start now?

3
00:00:07,120 --> 00:00:09,880
Yeah. Okay.

4
00:00:09,880 --> 00:00:12,960
Cool. Am I ready to start now?

5
00:00:12,960 --> 00:00:14,240
That's a question.

6
00:00:14,240 --> 00:00:17,000
Oh, no. Are people still coming?

7
00:00:21,000 --> 00:00:23,000
Right. Okay.

8
00:00:23,000 --> 00:00:28,880
I think we are going to start as soon

9
00:00:28,880 --> 00:00:30,880
as this person walks through the door.

10
00:00:30,880 --> 00:00:33,880
Sorry. Don't turn and look at them.

11
00:00:33,880 --> 00:00:35,880
Sorry.

12
00:00:35,880 --> 00:00:38,880
Okay. I think we are going to start now.

13
00:00:38,880 --> 00:00:40,880
Wave.

14
00:00:40,880 --> 00:00:43,880
Okay. Hi, everyone.

15
00:00:43,880 --> 00:00:47,880
So welcome to PyCon US 23.

16
00:00:47,880 --> 00:00:48,880
I mean, unless you were here yesterday,

17
00:00:48,880 --> 00:00:51,880
in which case you already know what we're doing here.

18
00:00:51,880 --> 00:00:56,880
So just so you know, you're in the right room.

19
00:00:56,880 --> 00:00:59,880
This is the Exploring Ecotopics with Python.

20
00:00:59,880 --> 00:01:01,880
So that's me.

21
00:01:01,880 --> 00:01:03,880
You can call me Chin.

22
00:01:03,880 --> 00:01:07,880
I mean, like this.

23
00:01:07,880 --> 00:01:09,880
Okay.

24
00:01:09,880 --> 00:01:12,880
You can still hear me? Great.

25
00:01:12,880 --> 00:01:17,880
Okay. So hopefully you've got, like, all the files,

26
00:01:17,880 --> 00:01:19,880
as I have already been stressing.

27
00:01:19,880 --> 00:01:21,880
Hopefully you've got all the software and files.

28
00:01:21,880 --> 00:01:23,880
There is a lot. I'll talk about that in a second.

29
00:01:23,880 --> 00:01:27,880
So we're just going to go through a couple of sort of

30
00:01:27,880 --> 00:01:29,880
ancillary things.

31
00:01:29,880 --> 00:01:32,880
The main bits are this, this, and this.

32
00:01:32,880 --> 00:01:35,880
I'm going to try and take 10 minutes breaks in between.

33
00:01:35,880 --> 00:01:37,880
But I'll sort of consult with you.

34
00:01:37,880 --> 00:01:39,880
We'll decide as a group how you want to use the time,

35
00:01:39,880 --> 00:01:41,880
because this is your time.

36
00:01:41,880 --> 00:01:43,880
So if you want to have more of a break or less of a break,

37
00:01:43,880 --> 00:01:45,880
we can figure it out.

38
00:01:45,880 --> 00:01:48,880
And then a wrap up, just if we have time.

39
00:01:48,880 --> 00:01:50,880
It may literally just be like the last line of code

40
00:01:50,880 --> 00:01:52,880
and then off to lunch.

41
00:01:52,880 --> 00:01:55,880
Okay. We'll see.

42
00:01:55,880 --> 00:01:57,880
I'll introduce myself in a second,

43
00:01:57,880 --> 00:02:01,880
but I just want to, like, set the expectations.

44
00:02:01,880 --> 00:02:06,880
So this tutorial is about you adding some of the Python skills

45
00:02:06,880 --> 00:02:09,880
that can help you find out what's happening to our planet.

46
00:02:09,880 --> 00:02:12,880
And when I say you, because also there is a recording,

47
00:02:12,880 --> 00:02:20,880
as you know, I'm sort of saying you as a potential scientist,

48
00:02:20,880 --> 00:02:24,880
scientist, researcher, policymaker,

49
00:02:24,880 --> 00:02:27,880
people whose livelihood depend on natural resources,

50
00:02:27,880 --> 00:02:30,880
people concerned, citizens concerned about the next generation.

51
00:02:30,880 --> 00:02:35,880
So, yeah, for the wider audience who hopefully will be watching this,

52
00:02:35,880 --> 00:02:38,880
this is to kind of help everyone.

53
00:02:38,880 --> 00:02:42,880
And then when we say Python skills, when I said Python skills,

54
00:02:42,880 --> 00:02:47,880
I was thinking of Python skills from the scientific Python ecosystem.

55
00:02:47,880 --> 00:02:49,880
So things like those.

56
00:02:49,880 --> 00:02:52,880
And then what's happening to our planet, I'm thinking,

57
00:02:52,880 --> 00:02:54,880
particularly what's happening to the planet,

58
00:02:54,880 --> 00:02:56,880
which is our fault as humans.

59
00:02:56,880 --> 00:03:01,880
So more of the anthropogenic impacts that we are having.

60
00:03:01,880 --> 00:03:03,880
So there we go, some little emojis,

61
00:03:03,880 --> 00:03:06,880
which will signpost where we're going.

62
00:03:06,880 --> 00:03:11,880
So at this point, as a data scientist, question mark.

63
00:03:11,880 --> 00:03:15,880
I just wanted to, if you are willing to share,

64
00:03:15,880 --> 00:03:17,880
can I understand a little bit more about yourselves?

65
00:03:17,880 --> 00:03:21,880
Like, it's going to just be like a hands up.

66
00:03:21,880 --> 00:03:24,880
Anyone, people who are scientists?

67
00:03:24,880 --> 00:03:27,880
Oh, yeah, okay, a couple, cool.

68
00:03:27,880 --> 00:03:29,880
They're working through all these like systematic, but yeah.

69
00:03:29,880 --> 00:03:33,880
Educators? No? Yeah, a little bit.

70
00:03:33,880 --> 00:03:35,880
Anyone want to volunteer who you are, what you are?

71
00:03:35,880 --> 00:03:38,880
It doesn't have to be like a long soliloquy,

72
00:03:38,880 --> 00:03:43,880
just concerned citizens, interested Pythonistas.

73
00:03:43,880 --> 00:03:48,880
Okay, that's cool. Yeah.

74
00:03:48,880 --> 00:03:50,880
Yeah, because it just kind of helps me shape, again,

75
00:03:50,880 --> 00:03:52,880
how we use the tutorial, so depending on your experience.

76
00:03:52,880 --> 00:03:54,880
So I guess the other thing I need to ask is,

77
00:03:54,880 --> 00:03:58,880
your experience with scientific Python.

78
00:03:58,880 --> 00:03:59,880
Are people familiar with these?

79
00:03:59,880 --> 00:04:01,880
You have experience with them before?

80
00:04:01,880 --> 00:04:05,880
So previous experience, yeah.

81
00:04:05,880 --> 00:04:09,880
I don't want to out people like first time newbies

82
00:04:09,880 --> 00:04:12,880
with scientific Python.

83
00:04:12,880 --> 00:04:13,880
Okay, cool.

84
00:04:13,880 --> 00:04:14,880
Oh, this is going to be easier.

85
00:04:14,880 --> 00:04:17,880
Then I can run through more of the tutorial faster.

86
00:04:17,880 --> 00:04:19,880
No, I'm joking.

87
00:04:19,880 --> 00:04:20,880
Okay, great.

88
00:04:20,880 --> 00:04:22,880
So who am I?

89
00:04:22,880 --> 00:04:23,880
You probably want to know.

90
00:04:23,880 --> 00:04:24,880
Oh, collage.

91
00:04:24,880 --> 00:04:28,880
Right, so obviously my name is Chin.

92
00:04:28,880 --> 00:04:29,880
I said that.

93
00:04:29,880 --> 00:04:32,880
I am basically a data science entrepreneur from London,

94
00:04:32,880 --> 00:04:35,880
specializing in open source outreach.

95
00:04:35,880 --> 00:04:40,880
I'd say people probably know, if you like Duck Duck Gomi,

96
00:04:40,880 --> 00:04:42,880
you will see a lot of my community work.

97
00:04:42,880 --> 00:04:47,880
So originally in 2016, sort of starting Our Lady's London,

98
00:04:47,880 --> 00:04:50,880
which then became Our Lady's Global.

99
00:04:50,880 --> 00:04:53,880
Then more recently, some of the work I do with my startup

100
00:04:53,880 --> 00:04:56,880
around outreach to disadvantaged young people,

101
00:04:56,880 --> 00:05:01,880
working in schools, mainly through sports, actually, analytics.

102
00:05:01,880 --> 00:05:03,880
So a lot of those references come up if you look at me,

103
00:05:03,880 --> 00:05:06,880
and you'll be like, oh, what does Chin got to do with eco stuff?

104
00:05:06,880 --> 00:05:09,880
So actually, what isn't publicly known

105
00:05:09,880 --> 00:05:12,880
is when I was head of data science at the Foreign Office

106
00:05:12,880 --> 00:05:16,880
in the UK government, I actually worked, and that was in 2017,

107
00:05:16,880 --> 00:05:18,880
I worked on a lot of these issues.

108
00:05:18,880 --> 00:05:22,880
So actually, illegal wildlife trade,

109
00:05:22,880 --> 00:05:25,880
some sort of energy sustainability, earth observation.

110
00:05:25,880 --> 00:05:29,880
I can't tell you too much because that was a security classified role.

111
00:05:29,880 --> 00:05:35,880
And unlike some people, some US Air Force National Guard,

112
00:05:35,880 --> 00:05:37,880
I keep official secret secrets.

113
00:05:37,880 --> 00:05:40,880
So we won't go too much into what I actually did,

114
00:05:40,880 --> 00:05:42,880
but just know that I did do stuff.

115
00:05:42,880 --> 00:05:44,880
Now, whilst that was six years ago,

116
00:05:44,880 --> 00:05:47,880
actually recently the past couple of years,

117
00:05:47,880 --> 00:05:49,880
two worlds have sort of emerged,

118
00:05:49,880 --> 00:05:51,880
and actually a lot of the schools and young people I work with

119
00:05:51,880 --> 00:05:54,880
have actually started, they're like, okay, Chin, the sports is great,

120
00:05:54,880 --> 00:05:57,880
but actually we kind of want to know about the disaster

121
00:05:57,880 --> 00:05:59,880
happening to the planet.

122
00:05:59,880 --> 00:06:03,880
So I've actually started doing more of that kind of ESG,

123
00:06:03,880 --> 00:06:07,880
ESG work, culminating in today.

124
00:06:07,880 --> 00:06:11,880
Okay, so I don't know if you've seen those four.

125
00:06:11,880 --> 00:06:13,880
I find this a really useful diagram,

126
00:06:13,880 --> 00:06:16,880
but anyway, as you already have experience with scientific Python,

127
00:06:16,880 --> 00:06:20,880
a lot of people, it'll just be useful, like a bit of a roadmap,

128
00:06:20,880 --> 00:06:22,880
a learning roadmap where we're going.

129
00:06:22,880 --> 00:06:26,880
So your tools, I'm kind of like, if you really know scientific Python,

130
00:06:26,880 --> 00:06:29,880
I don't know what, am I going to help you learn something?

131
00:06:29,880 --> 00:06:31,880
Okay, never mind, we'll find out.

132
00:06:31,880 --> 00:06:34,880
So as you know, obviously starting with Python

133
00:06:34,880 --> 00:06:37,880
as a basis of everything we're doing today,

134
00:06:37,880 --> 00:06:42,880
Jupyter, which hopefully you have some experience with,

135
00:06:42,880 --> 00:06:45,880
and then obviously everything stems from NumPy,

136
00:06:45,880 --> 00:06:49,880
although obviously they would say that from this article being about NumPy.

137
00:06:49,880 --> 00:06:56,880
So we are going to do a lot of NumPy, mainly under the hood rather than exposed,

138
00:06:56,880 --> 00:06:59,880
a lot of mapplotlib for plots.

139
00:06:59,880 --> 00:07:02,880
Sorry, I don't know if you can see this.

140
00:07:02,880 --> 00:07:05,880
So a good amount of pandas, some network X,

141
00:07:05,880 --> 00:07:08,880
but also some stuff which is off-diagram.

142
00:07:11,880 --> 00:07:14,880
So extending pandas with GeoPandas,

143
00:07:14,880 --> 00:07:17,880
which is the geographic extension for pandas,

144
00:07:17,880 --> 00:07:24,880
and then using some of the other JavaScript functionality,

145
00:07:24,880 --> 00:07:28,880
just a little bit via folium, and then a tiny little bit.

146
00:07:28,880 --> 00:07:30,880
We're using X-Ray and rear X-Ray,

147
00:07:30,880 --> 00:07:36,880
so X-Ray which is basically labeled multi-dimensional arrays,

148
00:07:36,880 --> 00:07:39,880
and then rear X-Ray which is the geographic extension of X-Ray.

149
00:07:39,880 --> 00:07:41,880
I'll just set your expectations now.

150
00:07:41,880 --> 00:07:44,880
We're not doing a lot, if you've looked at the test files,

151
00:07:44,880 --> 00:07:47,880
we're not delving really deep into the internals,

152
00:07:47,880 --> 00:07:50,880
and actually really internals of any of these.

153
00:07:50,880 --> 00:07:55,880
This is very much about using these tools, rather than behind the scenes,

154
00:07:55,880 --> 00:07:57,880
all that kind of stuff.

155
00:07:57,880 --> 00:08:00,880
But yeah, specifically X-Ray, rear X-Ray,

156
00:08:00,880 --> 00:08:05,880
to work with the satellite image data.

157
00:08:06,880 --> 00:08:08,880
Oh yeah, question mark.

158
00:08:08,880 --> 00:08:15,880
So people, you're kind of familiar with some of these things?

159
00:08:15,880 --> 00:08:19,880
Can people tell me your experience with your console with NumPy?

160
00:08:19,880 --> 00:08:23,880
You've worked with pandas. What have people done before?

161
00:08:23,880 --> 00:08:26,880
Nothing, anything? Yeah?

162
00:08:27,880 --> 00:08:30,880
Okay, so people know what they are,

163
00:08:30,880 --> 00:08:33,880
so I don't have to be like, this is an array.

164
00:08:33,880 --> 00:08:35,880
Okay, cool.

165
00:08:35,880 --> 00:08:37,880
I guess the other thing is, obviously,

166
00:08:37,880 --> 00:08:39,880
I'm assuming that you've worked with Jupyter,

167
00:08:39,880 --> 00:08:41,880
then people are comfortable with Jupyter.

168
00:08:41,880 --> 00:08:44,880
Oh yes, don't have to spend so much time on that.

169
00:08:44,880 --> 00:08:47,880
Sorry, this isn't like, let me take shortcuts.

170
00:08:47,880 --> 00:08:50,880
But it's just, yeah.

171
00:08:50,880 --> 00:08:53,880
You never know what kind of experience people have in the room,

172
00:08:53,880 --> 00:08:56,880
and obviously you want to make it as inclusive as possible.

173
00:08:56,880 --> 00:08:59,880
Okay, so let's preview the exploration outputs.

174
00:08:59,880 --> 00:09:01,880
Welcome.

175
00:09:01,880 --> 00:09:03,880
Can I get out of this?

176
00:09:03,880 --> 00:09:05,880
Come on, PowerPoint won't work with me.

177
00:09:05,880 --> 00:09:08,880
Okay, so, excuse me.

178
00:09:08,880 --> 00:09:10,880
Right, where are we going?

179
00:09:10,880 --> 00:09:15,880
So we are starting with the wildlife trade exploration.

180
00:09:15,880 --> 00:09:17,880
We'll start with society's data,

181
00:09:17,880 --> 00:09:21,880
and then you end up with a network graph.

182
00:09:21,880 --> 00:09:24,880
So this is for Pangolin specifically.

183
00:09:24,880 --> 00:09:30,880
And then we go to, in the second session, or second hour, hopefully,

184
00:09:30,880 --> 00:09:32,880
EPA, so Environmental Protection Agency.

185
00:09:32,880 --> 00:09:35,880
Sorry, I don't want to teach you the suck eggs,

186
00:09:35,880 --> 00:09:37,880
but I don't know what you know, what you don't know,

187
00:09:37,880 --> 00:09:39,880
so I'll probably try and do more or less,

188
00:09:39,880 --> 00:09:46,880
using some of the data from the greenhouse gas program,

189
00:09:46,880 --> 00:09:49,880
greenhouse gas emissions reporting program, GHGRP.

190
00:09:49,880 --> 00:09:51,880
So you go from that.

191
00:09:51,880 --> 00:09:55,880
So we'll go to universities, particularly this sector here,

192
00:09:55,880 --> 00:09:59,880
so that you can also use other stuff.

193
00:09:59,880 --> 00:10:05,880
And then we'll go, the flashy bits are actually the least Python bits,

194
00:10:05,880 --> 00:10:07,880
but never mind, use what is.

195
00:10:07,880 --> 00:10:14,880
So we go to fun interactive maps, and also boring maps as well.

196
00:10:14,880 --> 00:10:17,880
And then kind of more, I guess, traditional statistical graphs,

197
00:10:17,880 --> 00:10:20,880
but again, useful and stuff like this.

198
00:10:20,880 --> 00:10:26,880
And then the last section, we start with the Landsat data.

199
00:10:26,880 --> 00:10:29,880
Well, as in the data, we're not doing the whole workflow,

200
00:10:29,880 --> 00:10:32,880
so as you know, you've read all the data sets which are prepared,

201
00:10:32,880 --> 00:10:37,880
and then we end up with a pixel-based image classification,

202
00:10:37,880 --> 00:10:42,880
so land cover, thematic map, at the Brazil-Bolivian border.

203
00:10:42,880 --> 00:10:46,880
Okay, so that's where we're aiming.

204
00:10:46,880 --> 00:10:50,880
I'm not entirely sure if we're going to get through all of it, but we'll see.

205
00:10:50,880 --> 00:10:53,880
Now, okay, let's start.

206
00:10:53,880 --> 00:10:55,880
I have to find my actual Jupyter notebook.

207
00:10:55,880 --> 00:11:01,880
So I think with that, okay, over to the coding,

208
00:11:01,880 --> 00:11:04,880
because that's why we're here.

209
00:11:04,880 --> 00:11:08,880
So can you please open up your Jupyter notebook

210
00:11:08,880 --> 00:11:15,880
and whatever kind of IDE, or I am mostly using JupyterLab.

211
00:11:15,880 --> 00:11:18,880
In the browser.

212
00:11:18,880 --> 00:11:23,880
I know you said people were generally okay with Jupyter.

213
00:11:23,880 --> 00:11:26,880
Do people need any, as in, can we just start going,

214
00:11:26,880 --> 00:11:31,880
or do people need a bit of a run-through of some of the functionality?

215
00:11:31,880 --> 00:11:33,880
I'm going to take that as a note.

216
00:11:33,880 --> 00:11:37,880
It should be quite intuitive, but okay, I'll just read it quickly.

217
00:11:37,880 --> 00:11:39,880
So you've got the notebooks which are prepared,

218
00:11:39,880 --> 00:11:41,880
so you shouldn't really need to do much.

219
00:11:41,880 --> 00:11:44,880
Okay, if you are new, you might end up double-clicking stuff like that.

220
00:11:44,880 --> 00:11:46,880
Don't worry about that. Just run it.

221
00:11:46,880 --> 00:11:51,880
When I say run, use that, or do a shift-enter,

222
00:11:51,880 --> 00:11:53,880
because that kind of gets boring having to go back and forth.

223
00:11:53,880 --> 00:11:56,880
If you need to add more cells, it's like that.

224
00:11:56,880 --> 00:12:01,880
Delete is like that. You've also got, hello?

225
00:12:01,880 --> 00:12:06,880
I'm sorry? Oh, bigger, yeah, sure, of course.

226
00:12:06,880 --> 00:12:10,880
Pugrande. Yeah, sorry, I should have done that.

227
00:12:10,880 --> 00:12:16,880
So 150. Is that a bigger? Yeah, sure.

228
00:12:16,880 --> 00:12:21,880
Yeah? Okay, perfect.

229
00:12:21,880 --> 00:12:24,880
So yeah, that's adding cells.

230
00:12:24,880 --> 00:12:29,880
You've got, what do you call these, controls here, delete.

231
00:12:29,880 --> 00:12:35,880
Other fun things, so tab, controls, so import.

232
00:12:35,880 --> 00:12:39,880
So tab is great for autocomplete,

233
00:12:39,880 --> 00:12:45,880
and then shift-tab for docstrings.

234
00:12:45,880 --> 00:12:48,880
Okay, whatever. So shift-tab, we'll use that a lot as well,

235
00:12:48,880 --> 00:12:50,880
so we're already done with that.

236
00:12:50,880 --> 00:12:55,880
Okay, so with that in mind, oh, I should also just double-check.

237
00:12:55,880 --> 00:12:58,880
So can you set it, if you're in Jupyter like this,

238
00:12:58,880 --> 00:13:03,880
we'll see however you're using it, please have the tutorial,

239
00:13:03,880 --> 00:13:05,880
you've got the materials designed so that it's like,

240
00:13:05,880 --> 00:13:07,880
you're just basically dumped in the same directory,

241
00:13:07,880 --> 00:13:09,880
so you've got your three notebooks,

242
00:13:09,880 --> 00:13:12,880
you've got your data's all, I know, free and easy out here,

243
00:13:12,880 --> 00:13:16,880
and then you've got the subfolder, this is for, obviously, the deforestation,

244
00:13:16,880 --> 00:13:20,880
this has got your for-rester data files,

245
00:13:20,880 --> 00:13:24,880
and then that is the shape file which was downloaded from US Census.

246
00:13:24,880 --> 00:13:29,880
But obviously, if you are, because this is not a beginner's tutorial,

247
00:13:29,880 --> 00:13:34,880
if you, I presume you kind of know how to access, you know, local.

248
00:13:34,880 --> 00:13:36,880
We don't have access to this right now.

249
00:13:36,880 --> 00:13:40,880
No, no, sorry, this is just like how it's sort of set up,

250
00:13:40,880 --> 00:13:42,880
as in how, like, in the notebooks,

251
00:13:42,880 --> 00:13:44,880
when I'm calling things like the file path,

252
00:13:44,880 --> 00:13:47,880
we'll be assuming that things are local like that,

253
00:13:47,880 --> 00:13:49,880
but obviously depending on where you've put stuff,

254
00:13:49,880 --> 00:13:52,880
like maybe in downloads, but yeah, we can sort of run through that.

255
00:13:52,880 --> 00:13:57,880
I think also just before we start, oh, 14 minutes, not bad.

256
00:13:57,880 --> 00:14:00,880
As you can see, I have no TA.

257
00:14:00,880 --> 00:14:04,880
It's quite lucky that I can even sort of be here,

258
00:14:04,880 --> 00:14:08,880
given the crisis which is happening in the UK in terms of clustering.

259
00:14:08,880 --> 00:14:15,880
So if people have issues, as a room, like I believe in democracies,

260
00:14:15,880 --> 00:14:19,880
I, you just let me know how we want to kind of proceed.

261
00:14:19,880 --> 00:14:23,880
So if someone has an issue, like, do you want me to stop, and then I help them,

262
00:14:23,880 --> 00:14:26,880
or like, you know, yeah, stuff like, you know,

263
00:14:26,880 --> 00:14:29,880
I think we're just going to have to figure it out as we go along.

264
00:14:29,880 --> 00:14:32,880
But to be honest, this is an easier crowd, because like I said,

265
00:14:32,880 --> 00:14:35,880
normally I'm just dumped into, I just go into schools

266
00:14:35,880 --> 00:14:39,880
with teenage kids who really have no interest in anything.

267
00:14:39,880 --> 00:14:43,880
So you are, honestly, this is like an absolute holiday.

268
00:14:43,880 --> 00:14:47,880
You're not trying to sneak out and have a fag, you know, behind the bike sheds.

269
00:14:47,880 --> 00:14:49,880
You're actually paid to be here.

270
00:14:49,880 --> 00:14:51,880
I'm kind of hoping this is, that's why I was like,

271
00:14:51,880 --> 00:14:54,880
okay, maybe we can get through a lot more than actually than normal.

272
00:14:54,880 --> 00:14:57,880
So we're just going to go, okay, and we'll see how we go.

273
00:14:57,880 --> 00:14:59,880
Whew!

274
00:14:59,880 --> 00:15:02,880
Okay, so if you're going to open up your eco-tutorial,

275
00:15:02,880 --> 00:15:05,880
Wildlife Trade Exploration Notebook.

276
00:15:05,880 --> 00:15:07,880
Oh, I should probably start at the beginning.

277
00:15:07,880 --> 00:15:11,880
Okay, so a bit of a blurb.

278
00:15:11,880 --> 00:15:13,880
I'm sorry, I also use a lot of slang.

279
00:15:13,880 --> 00:15:18,880
Are people okay, I was going to say, with the level,

280
00:15:18,880 --> 00:15:20,880
the pace of English that I'm using?

281
00:15:20,880 --> 00:15:23,880
Yeah, okay, sorry, just want to make sure that's inclusive.

282
00:15:23,880 --> 00:15:26,880
I really try not to use slang, but I can't help it.

283
00:15:26,880 --> 00:15:28,880
Okay, right, I'll read off here.

284
00:15:28,880 --> 00:15:31,880
So what example of wildlife trade are we examining?

285
00:15:31,880 --> 00:15:35,880
Trade from 1975 to 2022 of all eight species of pangolins.

286
00:15:35,880 --> 00:15:37,880
People know what pangolins are, right?

287
00:15:37,880 --> 00:15:43,880
There's like artichoke, okay, cool, which became illegal

288
00:15:43,880 --> 00:15:47,880
for commercial purposes in early 2017, having been uplisted to societies.

289
00:15:47,880 --> 00:15:49,880
Anyway, scientific approaches.

290
00:15:49,880 --> 00:15:52,880
We're taking our graph theoretic and network science approaches.

291
00:15:52,880 --> 00:15:54,880
What outputs will we develop?

292
00:15:54,880 --> 00:15:57,880
Network graph, data structure, and visualizations of this.

293
00:15:57,880 --> 00:15:59,880
What will our outputs tell us?

294
00:15:59,880 --> 00:16:02,880
They'll support identification of the country's most involved

295
00:16:02,880 --> 00:16:05,880
in the illegal pangolin trade to date

296
00:16:05,880 --> 00:16:08,880
and the main international trading partnerships.

297
00:16:08,880 --> 00:16:11,880
Beyond the well-known eco-impacts of wildlife trade,

298
00:16:11,880 --> 00:16:14,880
sorry, biodiversity loss, what makes this example significant?

299
00:16:14,880 --> 00:16:17,880
So pangolins are currently the world's most trafficked wild mammal,

300
00:16:17,880 --> 00:16:20,880
despite the 2017 global commercial trade ban.

301
00:16:20,880 --> 00:16:23,880
In fact, many sources report that illegal pangolin trade

302
00:16:23,880 --> 00:16:27,880
has actually grown post-ban with the expansions of criminal networks.

303
00:16:27,880 --> 00:16:31,880
So tackling their illegal trade is therefore an urgent conservation priority

304
00:16:31,880 --> 00:16:34,880
and being able to identify the countries who are known to be

305
00:16:34,880 --> 00:16:38,880
most active in the legal pangolin trade, which is the aim of this example,

306
00:16:38,880 --> 00:16:41,880
is likely to have some predictive power in terms of tracing

307
00:16:41,880 --> 00:16:44,880
the apparently thriving black market.

308
00:16:44,880 --> 00:16:46,880
Okay.

309
00:16:46,880 --> 00:16:49,880
I know that also seems a bit school-y that I'm just kind of reading stuff up,

310
00:16:49,880 --> 00:16:53,880
but I have also designed the notebooks so that it's basically all the material

311
00:16:53,880 --> 00:16:56,880
so then you can use it as a resource like after.

312
00:16:58,880 --> 00:17:02,880
So, stuff on the data, so if you want to learn to print it, okay.

313
00:17:02,880 --> 00:17:05,880
Okay, section A.

314
00:17:05,880 --> 00:17:09,880
I should also just bring to your attention the table of contents.

315
00:17:09,880 --> 00:17:12,880
So, I mean, anyway, you can read that, that's fine,

316
00:17:12,880 --> 00:17:14,880
but just so you know where we're going.

317
00:17:14,880 --> 00:17:18,880
So A to F is where we are going, hopefully by 10 o'clock.

318
00:17:18,880 --> 00:17:22,880
Okay, A, set up cheaper notebook and pangolin trade data.

319
00:17:22,880 --> 00:17:24,880
Step A, zero, import the third-party packages,

320
00:17:24,880 --> 00:17:28,880
NumPyPanda, NetworkX, and the MatplotlibPyPlot submodule

321
00:17:28,880 --> 00:17:31,880
with conventional aliases.

322
00:17:31,880 --> 00:17:37,880
So, I've designed this so that we obviously type in together

323
00:17:37,880 --> 00:17:41,880
like an interactive lab, but obviously feel free just to like copy and paste.

324
00:17:41,880 --> 00:17:44,880
We may do that if we start running out of time.

325
00:17:44,880 --> 00:17:49,880
Or when the code doesn't really have a lot of pedagogical value

326
00:17:49,880 --> 00:17:51,880
for you to type it.

327
00:17:54,880 --> 00:17:56,880
I have not done that right.

328
00:17:58,880 --> 00:18:00,880
That's also not right.

329
00:18:00,880 --> 00:18:02,880
Ah, cold fingers.

330
00:18:04,880 --> 00:18:06,880
My set of words. Okay, A1.

331
00:18:06,880 --> 00:18:09,880
Excuse me. For auto-completion or if it's not working,

332
00:18:09,880 --> 00:18:11,880
try running this magic command.

333
00:18:11,880 --> 00:18:16,880
I'm just going to copy and paste because this is, again, not particularly exciting.

334
00:18:18,880 --> 00:18:22,880
A2, read in the pangolin trade data, wildlife trade data CSV,

335
00:18:22,880 --> 00:18:27,880
and assign to raw data. So, pd read CSV.

336
00:18:27,880 --> 00:18:29,880
Then you can do this however you want.

337
00:18:29,880 --> 00:18:32,880
This is just kind of how I tend to demonstrate.

338
00:18:32,880 --> 00:18:36,880
So I kind of go with the right-hand side first to be like,

339
00:18:36,880 --> 00:18:38,880
this is what we're actually loading.

340
00:18:38,880 --> 00:18:40,880
And then this is where we're assigning it.

341
00:18:42,880 --> 00:18:45,880
Phew, that worked. That would be awkward if it didn't.

342
00:18:45,880 --> 00:18:49,880
A3, make a copy of raw data called df prep.

343
00:18:49,880 --> 00:18:54,880
This will be the data frame we will prep and ultimately construct our network graph from.

344
00:18:54,880 --> 00:18:59,880
So raw data, auto-complete, copy.

345
00:18:59,880 --> 00:19:02,880
I really didn't need to bring that up because I knew that.

346
00:19:02,880 --> 00:19:07,880
So again, we'll do that basically every, what is it called, notebook.

347
00:19:07,880 --> 00:19:11,880
Okay, section B, inspect the data.

348
00:19:11,880 --> 00:19:13,880
Excuse me.

349
00:19:13,880 --> 00:19:17,880
Have a look at the prep data frame using head method to display the first five rows.

350
00:19:17,880 --> 00:19:20,880
So, df prep.

351
00:19:20,880 --> 00:19:27,880
Okay, so as you can see, there is a lot of data in there.

352
00:19:27,880 --> 00:19:34,880
So as you can see, there is whatever, various columns.

353
00:19:34,880 --> 00:19:37,880
We're actually not using most of these.

354
00:19:37,880 --> 00:19:43,880
The thing really to note is, as I said in the comments, this is a Pandas data frame.

355
00:19:43,880 --> 00:19:47,880
So as you already know this right, two-dimensional.

356
00:19:47,880 --> 00:19:52,880
So rows, columns, labeled.

357
00:19:52,880 --> 00:19:55,880
Show the label.

358
00:19:55,880 --> 00:19:57,880
So there.

359
00:19:57,880 --> 00:20:00,880
So that's the row label.

360
00:20:00,880 --> 00:20:02,880
Seriously.

361
00:20:02,880 --> 00:20:06,880
And then column labels.

362
00:20:06,880 --> 00:20:10,880
So, oh yeah, columns are potentially different types.

363
00:20:10,880 --> 00:20:14,880
Do you sort of know this already?

364
00:20:14,880 --> 00:20:16,880
Yes, okay, great.

365
00:20:16,880 --> 00:20:18,880
But okay, if you don't, I'll just quickly say.

366
00:20:18,880 --> 00:20:23,880
So yeah, what's interesting about Pandas data frames, as opposed to, for example, an array,

367
00:20:23,880 --> 00:20:25,880
you don't have to have a mod just data type.

368
00:20:25,880 --> 00:20:31,880
So here, for example, you've got obviously string object data, but also here, there's also numeric.

369
00:20:31,880 --> 00:20:33,880
So that's really handy.

370
00:20:33,880 --> 00:20:37,880
Okay.

371
00:20:37,880 --> 00:20:38,880
Panic.

372
00:20:38,880 --> 00:20:42,880
The other thing to note is that not all the transactions have data for every column.

373
00:20:42,880 --> 00:20:46,880
So this has been marked with nans, which that's one last number.

374
00:20:46,880 --> 00:20:48,880
So, b1.

375
00:20:48,880 --> 00:20:54,880
Let's just have a look at the number of rows and columns.

376
00:20:54,880 --> 00:21:01,880
So the interpretation of that is that the data set records 1,689 transactions where pangolin commodities were traded,

377
00:21:01,880 --> 00:21:05,880
which date between 1975 and 2022.

378
00:21:05,880 --> 00:21:10,880
So let's now look at the actual data types.

379
00:21:10,880 --> 00:21:12,880
Oh, sorry, I should say.

380
00:21:12,880 --> 00:21:17,880
See what type of data Pandas inferred was in each column when it originally went into CSV.

381
00:21:17,880 --> 00:21:19,880
Ignoring my own notes.

382
00:21:19,880 --> 00:21:24,880
So the object data type, as you see here, is one way that Pandas stores string data.

383
00:21:24,880 --> 00:21:26,880
There is another, I can't remember the name.

384
00:21:26,880 --> 00:21:31,880
Anyway, when you see object in our data sets, that basically means string data.

385
00:21:31,880 --> 00:21:34,880
Okay, section C. So I'll just give you a quick overview.

386
00:21:34,880 --> 00:21:38,880
So now we're preparing the data for exploring illegal wildlife trade,

387
00:21:38,880 --> 00:21:43,880
and then we've still got a couple of more data wrangly things to do.

388
00:21:43,880 --> 00:21:45,880
So the context for this.

389
00:21:45,880 --> 00:21:50,880
The original data request from CITES deliberately did not filter trade based on any recorded purposes.

390
00:21:50,880 --> 00:21:54,880
Let's review CITES purpose codes as per the database documentation.

391
00:21:54,880 --> 00:21:58,880
So these are all the codes. This is not obviously just for the pangolin data.

392
00:21:58,880 --> 00:22:03,880
This is within the trade database, the CITES trade database as a whole.

393
00:22:03,880 --> 00:22:09,880
Obviously, not all the transactions have complete data.

394
00:22:09,880 --> 00:22:12,880
So this is where they got a purpose.

395
00:22:12,880 --> 00:22:17,880
This is what they categorize it into, but obviously not all of them have a purpose.

396
00:22:17,880 --> 00:22:24,880
So C0 access the subset of DF prep containing just the transactions driven by the types of demand

397
00:22:24,880 --> 00:22:28,880
that could be more likely to persist after a ban, i.e. hunting for a free personal,

398
00:22:28,880 --> 00:22:31,880
circus or traveling exhibition or commercial purposes,

399
00:22:31,880 --> 00:22:36,880
as well as where this data is missing and reassign DF prep to points to the copied subset.

400
00:22:36,880 --> 00:22:38,880
So just some intuition.

401
00:22:38,880 --> 00:22:43,880
Again, if you actually did this, I guess for research purposes, you could do this in a more,

402
00:22:43,880 --> 00:22:47,880
I don't know, more whatever way depending on your purposes.

403
00:22:47,880 --> 00:22:50,880
But it was really more just like if there was a ban,

404
00:22:50,880 --> 00:22:55,880
I'm assuming the scientific community wouldn't just go underground, right?

405
00:22:55,880 --> 00:22:58,880
So I was like, which of these things might continue?

406
00:22:58,880 --> 00:23:02,880
But again, there isn't necessarily, this is only like partial data.

407
00:23:02,880 --> 00:23:06,880
It's just illustrative. Sorry. Yes, great.

408
00:23:06,880 --> 00:23:09,880
So, okay.

409
00:23:09,880 --> 00:23:14,880
So for people who haven't used Pandas, seen Pandas before, so okay, sorry.

410
00:23:14,880 --> 00:23:21,880
So data frame indexing operator, we're giving it a label, a column label in this instance.

411
00:23:21,880 --> 00:23:26,880
That would pull out the column like that.

412
00:23:26,880 --> 00:23:28,880
That won't work.

413
00:23:28,880 --> 00:23:32,880
So you can't see basically, is it in this list of stuff?

414
00:23:32,880 --> 00:23:35,880
Again, you can see this in the code detail, which I'm not going to talk through.

415
00:23:35,880 --> 00:23:37,880
It's again, just for your reference.

416
00:23:37,880 --> 00:23:44,880
But I apologize that it's a little bit busy on the slide, but you know, more information is less, right?

417
00:23:44,880 --> 00:23:53,880
So basically, let's bring out a Boolean for where the values are in one of these strings,

418
00:23:53,880 --> 00:24:00,880
which are the purpose codes and then NANDs as well, which there are lots.

419
00:24:00,880 --> 00:24:05,880
So there we go. There's your Boolean array or series.

420
00:24:05,880 --> 00:24:13,880
And that's how we're going to cut the data prep.

421
00:24:13,880 --> 00:24:18,880
So now we should only have the rows where that term, what was it?

422
00:24:18,880 --> 00:24:21,880
Purpose even. Without purpose.

423
00:24:21,880 --> 00:24:24,880
So there you go, NANDs, TPs.

424
00:24:24,880 --> 00:24:27,880
That's kind of what I want to see. Great.

425
00:24:27,880 --> 00:24:36,880
And then let's copy that. Copy even.

426
00:24:36,880 --> 00:24:40,880
Excuse me. So C1, let's sense check.

427
00:24:40,880 --> 00:24:45,880
So we should have less rows, right? So 1396. Great.

428
00:24:45,880 --> 00:24:50,880
Okay. And of course, the same number of columns, because we didn't do anything to that.

429
00:24:50,880 --> 00:24:56,880
C2, we need to be able to quantitatively compare transactions in the data set in terms of the volume of wild pangolin specimens lost.

430
00:24:56,880 --> 00:25:03,880
So let's compute a quick histogram, such frequency table, of the term column values to see the different pangolin commodities traded.

431
00:25:03,880 --> 00:25:08,880
So data frame, we're indexing again by column label.

432
00:25:08,880 --> 00:25:12,880
The column label is term, which of course breaks up that.

433
00:25:12,880 --> 00:25:16,880
Value counts, which if you haven't used patterns before is like the best.

434
00:25:16,880 --> 00:25:20,880
I am in love with this method. It's like my favorite thing ever.

435
00:25:20,880 --> 00:25:25,880
I use it far too much. So just so you know, the default is that the drop not equals true.

436
00:25:25,880 --> 00:25:29,880
So we're just going to override that. Although actually in this case it doesn't actually matter.

437
00:25:29,880 --> 00:25:39,880
But just, you know, illustrative. So you can see in this data set, again, this is just the number of trades which traded this type of product, right?

438
00:25:39,880 --> 00:25:51,880
This is not the number of products. There's no kind of proportionality in terms of the scale of like, was it like 428 transactions skins with one skin each versus like a thousand.

439
00:25:51,880 --> 00:25:56,880
Anyway, you get the idea. So this is just so you see what's in it and also a bit of the sample size.

440
00:25:56,880 --> 00:26:04,880
So unsurprisingly, we're also going to filter rows.

441
00:26:05,880 --> 00:26:09,880
I'm getting ahead of myself. I'll just walk through C3.

442
00:26:09,880 --> 00:26:25,880
As a necessary but imperfect approach to standardizing the trade, subset Df prep for the transactions involving commodities where each unit is more likely to represent one pangolin animal taken from the wild rather than a constituent part, i.e. skins, live bodies, excuse me, trophies and specimens.

443
00:26:25,880 --> 00:26:30,880
Be aware our remaining data will significantly undercount relevant traded pangolin numbers.

444
00:26:30,880 --> 00:26:42,880
So does that make sense intuitively? You understand what we're doing that we can't like you can't compare like a skin scrap to medicine to a scale like we just don't know.

445
00:26:42,880 --> 00:26:51,880
And obviously, if you were doing this properly, you could use, you know, you create some sort of algorithm to figure out how you estimate a whole pangolin from some of these other things.

446
00:26:51,880 --> 00:27:06,880
But we're not. Okay, so again, we're going to pull out the term column, which is still that, is in.

447
00:27:06,880 --> 00:27:18,880
So pass it a list of the values skins live bodies sorry it's a little bit gruesome.

448
00:27:18,880 --> 00:27:27,880
But you know that's that's what humans are doing. You know my people as well, or anyway, we'll talk about the country things later.

449
00:27:27,880 --> 00:27:31,880
So that gives you a billion.

450
00:27:31,880 --> 00:27:40,880
And that's what you of course index the data frame on, which then, maybe you can see here will give you less rows.

451
00:27:40,880 --> 00:27:47,880
So that looks sensible copy.

452
00:27:47,880 --> 00:27:55,880
Okay, so now let's properly look at the shape again. Sorry, see for check that DF prep now has even fewer first than before.

453
00:27:55,880 --> 00:27:58,880
I don't know why I write things that when I don't actually read it.

454
00:27:58,880 --> 00:28:02,880
So now we have 612 rows.

455
00:28:02,880 --> 00:28:11,880
See for comment, we have cut the number of pangolin transactions in our data set from 1689 originally to 1396 to now 612.

456
00:28:11,880 --> 00:28:17,880
Whilst the steps taken in the section to clean the original data that have undoubtedly dropped relevant as well as retained less relevant data.

457
00:28:17,880 --> 00:28:31,880
These remaining 612 trade records are still a useful subset for demonstrating a Python enabled graph theoretic approach and being able to derive limited but interpretable outputs related to real world illegal wildlife trade.

458
00:28:31,880 --> 00:28:38,880
Okay, so so don't like give me feedback. We like, oh, that's certainly why did you do bodies? Why did you? Why did you not do? It's like, I know, I know.

459
00:28:38,880 --> 00:28:44,880
This is not how you do it properly, but you can always refine this, you know, method if you need to.

460
00:28:44,880 --> 00:28:51,880
So section D just show you quickly. So now we're going to prepare for graph, graph construction.

461
00:28:51,880 --> 00:28:56,880
So finally, we're moving towards the you know, the fun exciting part.

462
00:28:56,880 --> 00:29:13,880
D zero intro. As previewed, we are preparing to turn our pangolin trade data into a network graph with a nodes vertices represent the country's importing and exporting pangolin commodities and the edges connected them represent trade from an exporting country to an importing country.

463
00:29:13,880 --> 00:29:21,880
Have people worked with networks before? Okay, cool. Yay. Tell you something.

464
00:29:21,880 --> 00:29:27,880
So I mean, it's again, it's intuitive, right? Okay, we'll go through that.

465
00:29:27,880 --> 00:29:36,880
There are multiple graph types. Please ask questions, by the way, I mean, not kind of like an hour long lengthy questions, but you know, if you need to.

466
00:29:36,880 --> 00:29:46,880
You're just not like disruptive teenagers. This is just very weird. There are multiple graph types. We will construct a multi digraph, which is a directed graph with self loops and parallel edges.

467
00:29:46,880 --> 00:29:56,880
And I will just bring this up because it is useful if you have not worked on network access. I mean networks are great. Sorry, I'm just like.

468
00:29:56,880 --> 00:30:05,880
So this is just give you a little bit of context. So a graph. Okay, so undirected basically it's like, so you know, think.

469
00:30:05,880 --> 00:30:14,880
Okay, like as they are a sponsor. Okay, so think matter. So Facebook, right? So Facebook friend your your friends, right? It's not well, hopefully it's not just one.

470
00:30:14,880 --> 00:30:25,880
You need to direct your friendship because that would be like creepy and stalkery. But okay, anyway, so that should be a friendship should be undirected, right? That'd be friend friend.

471
00:30:25,880 --> 00:30:26,880
Edge.

472
00:30:26,880 --> 00:30:30,880
Diagram. Okay, maybe I don't want to talk about stalkers.

473
00:30:30,880 --> 00:30:42,880
Then you could have knowns obviously which could be directed. It's like, you know, there is a direction. So I don't know maybe it's like a friend request right so someone sent a request to someone else like a LinkedIn connection something like that say, then multi

474
00:30:42,880 --> 00:30:56,880
Then multi-diagram. So parallel edges. So, okay, yeah, so it's like LinkedIn. So maybe someone sent that person like multiple. I know you can't do that bit. Let's say like whatever they send them multiple requests on different platforms or something.

475
00:30:56,880 --> 00:31:00,880
So you've got multiple edges from a node to another.

476
00:31:00,880 --> 00:31:04,880
Excuse me node and then multi-diagram.

477
00:31:04,880 --> 00:31:09,880
So again, that was our power edges. It's basically everything right so it's directed.

478
00:31:09,880 --> 00:31:22,880
It's got parallel edges. So it could be like that way, that way. And then also you can like for the other ones you can also have self loops, but we don't have that in the trade because you

479
00:31:22,880 --> 00:31:34,880
So it's, I guess in our example, because we wouldn't have it but it's like let's say the, let's say Japan sold pangolins to itself.

480
00:31:34,880 --> 00:31:41,880
You see what I mean? So like it would loop back but obviously that doesn't happen in our situation but yeah.

481
00:31:41,880 --> 00:31:47,880
Sorry, I can't remember. This first is a better example. Does that answer? Okay, great.

482
00:31:47,880 --> 00:32:00,880
Thank you for the question. Right, where were we here? For each directed edge we designate the country who exported, sold the goods, export country as a source node and the country who imported the, bought the goods as the target node.

483
00:32:00,880 --> 00:32:09,880
So, sorry, sorry, sorry. I'm trying to give you directions. So you sold it to this person. Yeah. Source node, target node.

484
00:32:09,880 --> 00:32:23,880
Hours are drawn from the source node, seller to the buyer. Parallel edges of our multi-diagraph will reflect a pair of countries who have made pangolin trades where one was the buyer and the other the seller and vice versa.

485
00:32:23,880 --> 00:32:31,880
So, because actually in this instance, as you will see, excuse me, okay let's say Japan and Singapore.

486
00:32:31,880 --> 00:32:42,880
So, you know, obviously Japan can sell to Singapore and Singapore can also sell to Japan, right? So that's your parallel edges between two nodes.

487
00:32:42,880 --> 00:32:52,880
Okay, D0. We can only construct a pangolin trade graph data structure from transactions with both defined source nodes and target nodes or else it's just like source node to nothing.

488
00:32:52,880 --> 00:33:04,880
Our visualization also requires quantity data for each transaction which we'll address after. First check if any NAND values exist in either the importer or exporter columns because then we cannot use them.

489
00:33:04,880 --> 00:33:13,880
So, we're indexing again, this time because we are indexing on multiple columns, we need to pass it a list with those column labels.

490
00:33:13,880 --> 00:33:18,880
So importer, exporter.

491
00:33:18,880 --> 00:33:21,880
That's not gonna work, sorry.

492
00:33:21,880 --> 00:33:25,880
It's gonna sound really weird on the recording. Isna.

493
00:33:25,880 --> 00:33:27,880
Okay, sorry, I should do this in steps.

494
00:33:27,880 --> 00:33:32,880
Right, so pulls out the columns, great. Isna.

495
00:33:32,880 --> 00:33:34,880
Yes, no, true, false.

496
00:33:34,880 --> 00:33:37,880
Values turns into an array.

497
00:33:37,880 --> 00:33:45,880
And then any, which is, I think this is definitely a non-play function, basically says

498
00:33:45,880 --> 00:33:54,880
are there any trues in that array, right? This is where your boolean logic goes.

499
00:33:54,880 --> 00:34:02,880
Are there any trues in this array, true or false? So we want it to be false.

500
00:34:02,880 --> 00:34:14,880
And it is false, thankfully. You can also run this step, D1, I'll give you another way which basically pull out the rows where both importers and exporters are NANDs, but we won't go through that.

501
00:34:14,880 --> 00:34:23,880
D2, now turning to the availability of quantity data for each transaction, try randomly sampling rows of the data set, say 10 at a time and maybe a couple of times,

502
00:34:23,880 --> 00:34:27,880
just because I actually, I don't want you to see some of my particular data.

503
00:34:27,880 --> 00:34:36,880
I can't remember the default, oh here we go, doc string, shift tab. So the default is one.

504
00:34:36,880 --> 00:34:39,880
Which is, I mean, cool.

505
00:34:39,880 --> 00:34:52,880
Okay, so I'm going to, I'm trying to demonstrate something. Okay, so these are the columns that we are interested in in this instance, right?

506
00:34:52,880 --> 00:35:04,880
Because we need to have a quantity value for each transaction. So you can see you've got NANDs, you can see sometimes you have the same data, which is really helpful if it's corroborating.

507
00:35:04,880 --> 00:35:14,880
I'm trying to find, okay, this is a really poor example, but here you do have two values, but they're not the same, right? There are some worse examples.

508
00:35:14,880 --> 00:35:26,880
Like this, okay, this is a good one, isn't it? This is five times the size. So, you know, like, again, things you need to think about, how do we handle that?

509
00:35:26,880 --> 00:35:38,880
And D3, how are we handling that? Oh, okay, we'll do that next time. D3, find any transaction rows which are missing both importer reported quantity and exporter reported quantity data.

510
00:35:38,880 --> 00:35:46,880
So basically like, at this point we're like, well, even if you give us two values, that's still something to work with, but we can't work with no values, right?

511
00:35:46,880 --> 00:36:02,880
So let's see where we have neither of these values because we cannot use that importer. Tab, yes. Thank you.

512
00:36:02,880 --> 00:36:10,880
That's not going to work.

513
00:36:10,880 --> 00:36:25,880
So I'm going to do this cheat way. So one condition, another condition. I'm just going to, that will work, right?

514
00:36:25,880 --> 00:36:41,880
And then I am, excuse me, indexing on those multiple conditions. Oh, no.

515
00:36:41,880 --> 00:36:58,880
Sorry. Oh, poor, poor, poor. Yep. Live debugging. Who doesn't love it? Okay, so you probably got there faster than I did.

516
00:36:58,880 --> 00:37:18,880
So thankfully there are no transactions where there is neither of these data. So that's great, I guess. D4, construct new quantity data for every transaction where the value is greater, the value is the greater of the reported quantities or the only reported quantity.

517
00:37:18,880 --> 00:37:31,880
Okay, so my method to deal with this is basically like, whoever said there was more quantities, because I'm assuming people don't want to like be like, yay, I like took loads of pangolins out of like the world.

518
00:37:31,880 --> 00:37:40,880
I'm going to assume that the one who said more is probably more correct, right? The other one was like, oh, it's just not that many. Don't worry, nothing to see here.

519
00:37:40,880 --> 00:37:50,880
So that is what we are doing in this code. So how did I start this? Okay, so we're creating a new column in D of prep.

520
00:37:50,880 --> 00:37:57,880
So think of this as like, if you haven't used this for this, like, you know, creating any dictionary key value pair.

521
00:37:57,880 --> 00:38:01,880
Creating a new column called quantity.

522
00:38:01,880 --> 00:38:24,880
That quantity, excuse me, is going to be calculated by applying a function to D of prep that particular function, which will use a lambda function is basically going to be a non max, which basically means take the max of these values and ignore the non's if there are any.

523
00:38:24,880 --> 00:38:29,880
So really great function. Thank you. Numpy. Love you.

524
00:38:29,880 --> 00:38:40,880
Importer.

525
00:38:40,880 --> 00:38:44,880
So tempted really just to copy my own code.

526
00:38:44,880 --> 00:38:48,880
That's probably not good practice.

527
00:38:48,880 --> 00:38:52,880
Max writes those columns.

528
00:38:52,880 --> 00:39:02,880
And then you have to specify access equals column so basically tell

529
00:39:02,880 --> 00:39:11,880
tell the method to look in the look in the columns for those labels, because they're not in the rows.

530
00:39:11,880 --> 00:39:15,880
I do not feel confident about that.

531
00:39:15,880 --> 00:39:18,880
Okay, I'm sorry. I'm just going to copy my because I don't want to create.

532
00:39:18,880 --> 00:39:20,880
I don't want to create a double.

533
00:39:20,880 --> 00:39:23,880
I don't want to create a quantity column twice.

534
00:39:23,880 --> 00:39:26,880
That is not what I prepared for.

535
00:39:26,880 --> 00:39:30,880
Okay.

536
00:39:30,880 --> 00:39:41,880
Right, so quantity. So sense check. Yes, yes, yes, yes. I mean we could, you know, maybe we should look at some other things just in case.

537
00:39:41,880 --> 00:39:43,880
Is there anything.

538
00:39:43,880 --> 00:39:49,880
Okay, well anyway, I can't find that example of like where there's two but it works.

539
00:39:49,880 --> 00:39:54,880
Okay, section E. So here we go. We're really getting more into the network stuff.

540
00:39:54,880 --> 00:40:02,880
I know. Sorry. It's that data sciencey thing where it's like 80% is the wrangling isn't it before you can actually get to the good things which take literally five seconds.

541
00:40:02,880 --> 00:40:10,880
Construct edge lists. So E intro and edge list is a data structure used to represent a network graph and as a listing of adjacent nodes.

542
00:40:10,880 --> 00:40:15,880
Our edge lists will differentiate between the source and target nodes, which is a necessary distinction for directed graphs.

543
00:40:15,880 --> 00:40:23,880
We will also include the new quantity data for each edge in our edge list. So quantity which will basically use to like change the width.

544
00:40:23,880 --> 00:40:28,880
As I said there, this edge actually we used as weights.

545
00:40:28,880 --> 00:40:36,880
Easier. Construct an initial edge list called edge list raw by copying the subset of DF prep with just the importer exporter and quantity columns.

546
00:40:36,880 --> 00:40:39,880
So DF prep.

547
00:40:39,880 --> 00:40:42,880
So we are just why are you there.

548
00:40:42,880 --> 00:40:47,880
We're going to pull out those column labels importer.

549
00:40:47,880 --> 00:40:49,880
Exporter.

550
00:40:49,880 --> 00:40:51,880
Exporter.

551
00:40:51,880 --> 00:40:53,880
Quantity.

552
00:40:53,880 --> 00:40:56,880
So there we go. Those are three columns.

553
00:40:56,880 --> 00:40:58,880
Oops.

554
00:40:58,880 --> 00:41:00,880
Make a copy.

555
00:41:00,880 --> 00:41:04,880
Edge list raw.

556
00:41:04,880 --> 00:41:07,880
And then we can have a quick peek at that.

557
00:41:07,880 --> 00:41:09,880
So cool.

558
00:41:09,880 --> 00:41:13,880
Okay. Things I'm about to point out in the next section.

559
00:41:13,880 --> 00:41:23,880
So you can see not surprisingly you do have like multiple transactions between the same exporter and importer.

560
00:41:23,880 --> 00:41:25,880
So E1 context.

561
00:41:25,880 --> 00:41:32,880
Whilst we could construct and draw a multi-diagram from this edge list raw as is the visualization would obscure significant edge detail.

562
00:41:32,880 --> 00:41:35,880
So repeated directed edges. So like those ones.

563
00:41:35,880 --> 00:41:39,880
Between a pair of nodes such as the two transactions from the Netherlands to Great Britain.

564
00:41:39,880 --> 00:41:50,880
When both drawn with the same default line drawing in the same position it will look indistinguishable from a single default line representing a single directed edge.

565
00:41:50,880 --> 00:41:58,880
And then even if the line bits could be drawn with varying widths in the case of multiple edges only the widest width would be visible dwarfing thinner lines.

566
00:41:58,880 --> 00:42:02,880
Does that sort of make sense? That's a really lengthy description.

567
00:42:02,880 --> 00:42:05,880
I don't know how it's been any faster.

568
00:42:05,880 --> 00:42:09,880
So yeah. We will therefore create another edge list with just the unique pairs of source and target nodes.

569
00:42:09,880 --> 00:42:13,880
So I just one reference of NLGP for example.

570
00:42:13,880 --> 00:42:15,880
USG.

571
00:42:15,880 --> 00:42:17,880
Well no there's not a double. Anyway. Good idea.

572
00:42:17,880 --> 00:42:24,880
Create another edge list with just the pairs of source and target nodes i.e. particular exporter importer with an aggregate quantity metric.

573
00:42:24,880 --> 00:42:31,880
Namely the totals of the quantities recorded in all the trades made between each particular exporter importer.

574
00:42:31,880 --> 00:42:36,880
This is why it's so it's like writing stuff is so painful.

575
00:42:36,880 --> 00:42:52,880
E1. Create edge list unique a data frame produced by performing a group by operation on edge list raw which groups rows by unique exporter and importer combo sums the row quantity values within each group and then also renames the quantity column as weight.

576
00:42:52,880 --> 00:42:58,880
I swear all these things are just like so much easier like to actually just demo but anyway.

577
00:42:58,880 --> 00:43:04,880
For learning purposes. Okay. So oops group by this is our first group by.

578
00:43:04,880 --> 00:43:07,880
If you don't use group by you should it's really cool.

579
00:43:07,880 --> 00:43:15,880
So this is not going to give us much because you have to like give it a kind of like action on it.

580
00:43:15,880 --> 00:43:20,880
So in this case we're going to do some.

581
00:43:20,880 --> 00:43:25,880
But again if this is the only thing group before you could also do all sorts of things like count.

582
00:43:25,880 --> 00:43:31,880
Which is telling you the number. I mean it's not particularly relevant in this case. I'm just showing that there are other things.

583
00:43:31,880 --> 00:43:35,880
Minimum Max etc etc.

584
00:43:35,880 --> 00:43:37,880
Actually give you a Max. Oh well anyway.

585
00:43:37,880 --> 00:43:40,880
Anyway.

586
00:43:40,880 --> 00:43:43,880
So we're summing it.

587
00:43:43,880 --> 00:43:47,880
I'll just do this before I forget because I forgot this in one of my practice runs.

588
00:43:47,880 --> 00:43:55,880
So you can see here it has the group by operation has automatically shifted export and import into the index or basically created a multi index.

589
00:43:55,880 --> 00:43:58,880
But we do not want that.

590
00:43:58,880 --> 00:44:02,880
Please do not have that because that messes up your code later.

591
00:44:02,880 --> 00:44:06,880
So bus as index equals false.

592
00:44:06,880 --> 00:44:10,880
So now when you do that now it's just not normal which is great.

593
00:44:10,880 --> 00:44:20,880
Sort now I want sort the rise because as you can see there is the sorting is by alphabetical by I guess exporter which is not particularly useful for us.

594
00:44:20,880 --> 00:44:23,880
So no values.

595
00:44:23,880 --> 00:44:28,880
By quantity.

596
00:44:28,880 --> 00:44:31,880
The default is ascending equals true.

597
00:44:31,880 --> 00:44:33,880
Which is never what I want.

598
00:44:33,880 --> 00:44:37,880
Maybe it's what you want. I hope I don't know. I hope it works better for you than for me.

599
00:44:37,880 --> 00:44:40,880
So ascending equals false.

600
00:44:40,880 --> 00:44:46,880
And then finally in this like massive chaining operations which I guess is my laziness.

601
00:44:46,880 --> 00:44:51,880
Rename the quantity column.

602
00:44:51,880 --> 00:44:56,880
Quantity as weight.

603
00:44:56,880 --> 00:44:59,880
Please tell me that's the end.

604
00:44:59,880 --> 00:45:02,880
Oh no it's not. I haven't assigned this.

605
00:45:02,880 --> 00:45:04,880
Unique.

606
00:45:04,880 --> 00:45:05,880
Please be right.

607
00:45:05,880 --> 00:45:06,880
Please be right.

608
00:45:06,880 --> 00:45:08,880
Okay.

609
00:45:08,880 --> 00:45:11,880
And then have a look at it.

610
00:45:11,880 --> 00:45:12,880
Great.

611
00:45:12,880 --> 00:45:13,880
Okay.

612
00:45:13,880 --> 00:45:16,880
So long and complicated.

613
00:45:16,880 --> 00:45:23,880
Anyway so now as you can see now we don't have duplicate edges.

614
00:45:23,880 --> 00:45:27,880
I mean not duplicate obviously because they're different transactions but you get the idea.

615
00:45:27,880 --> 00:45:28,880
I'm going to comment.

616
00:45:28,880 --> 00:45:35,880
The road I mentioned of this resulting edge list tells that there are 138 unique Pangolin trading relationships in this network.

617
00:45:35,880 --> 00:45:37,880
And then obviously you can sum this to see how many.

618
00:45:37,880 --> 00:45:39,880
Like basically what that adds up to.

619
00:45:39,880 --> 00:45:41,880
But I won't do it.

620
00:45:41,880 --> 00:45:43,880
But anyway just so you get a sense.

621
00:45:43,880 --> 00:45:45,880
And then remember that's also under counting.

622
00:45:45,880 --> 00:45:47,880
Okay section F.

623
00:45:47,880 --> 00:45:48,880
So here we go.

624
00:45:48,880 --> 00:45:53,880
We're really finally getting into the drawingy bit.

625
00:45:53,880 --> 00:45:55,880
Construct and draw multi-diagraph.

626
00:45:55,880 --> 00:45:56,880
F intro.

627
00:45:56,880 --> 00:45:59,880
And then at this point onwards we start to use map plot live in the tutorial.

628
00:45:59,880 --> 00:46:06,880
Be aware that there are a variety of styles slash APIs available for accessing map plot live functionality and this is reflected in the tutorial.

629
00:46:06,880 --> 00:46:09,880
There are some cheat sheets.

630
00:46:09,880 --> 00:46:15,880
Sorry I have opinions on map plot live but I shouldn't share them.

631
00:46:15,880 --> 00:46:17,880
Do people use map plot live?

632
00:46:17,880 --> 00:46:20,880
Yeah.

633
00:46:20,880 --> 00:46:21,880
Sorry.

634
00:46:21,880 --> 00:46:23,880
I really should say that.

635
00:46:23,880 --> 00:46:25,880
Again grateful that we have it.

636
00:46:25,880 --> 00:46:26,880
F0.

637
00:46:26,880 --> 00:46:33,880
Create a multi-diagraph object using the network X function from pandas edge list.

638
00:46:33,880 --> 00:46:34,880
Okay.

639
00:46:34,880 --> 00:46:37,880
I'm going to break this into steps.

640
00:46:37,880 --> 00:46:41,880
From pandas.

641
00:46:41,880 --> 00:46:44,880
So thank you network X.

642
00:46:44,880 --> 00:46:47,880
So they've made that really easy for us.

643
00:46:47,880 --> 00:46:49,880
Okay so then you need to pass.

644
00:46:49,880 --> 00:46:59,880
Passing required inputs from the edge list unique data frame as well as optionally specifying the weight column data as an attribute of the edges and the graph type to be multi-diagraph.

645
00:46:59,880 --> 00:47:02,880
So this is the data.

646
00:47:02,880 --> 00:47:07,880
The data frame we're using is obviously edge list unique.

647
00:47:07,880 --> 00:47:10,880
We're saying the source nodes are the export column.

648
00:47:10,880 --> 00:47:14,880
The target nodes are the importer column.

649
00:47:14,880 --> 00:47:19,880
And the edge we're giving it a edge attribute.

650
00:47:19,880 --> 00:47:21,880
Obviously not all of this is how are we doing for time?

651
00:47:21,880 --> 00:47:24,880
Oh pretty good.

652
00:47:24,880 --> 00:47:30,880
We're going to pass that weight.

653
00:47:30,880 --> 00:47:41,880
And then we're going to say create using the multi-diagraph.

654
00:47:41,880 --> 00:47:42,880
Okay.

655
00:47:42,880 --> 00:47:51,880
Create using that.

656
00:47:51,880 --> 00:47:53,880
Okay.

657
00:47:53,880 --> 00:47:55,880
So F1.

658
00:47:55,880 --> 00:47:57,880
Finally we can do some visualizations.

659
00:47:57,880 --> 00:48:06,880
Use network X's basic map plot lib drawing functionality to try a minimal visualization of our Pangolin trade network G.

660
00:48:06,880 --> 00:48:10,880
So this is where you discover if you created this correctly.

661
00:48:10,880 --> 00:48:11,880
I'm not entirely sure.

662
00:48:11,880 --> 00:48:14,880
So this is literally your absolute MVP, you know, minimum viable product.

663
00:48:14,880 --> 00:48:19,880
It's like all the defaults.

664
00:48:19,880 --> 00:48:20,880
And it's going to look ugly.

665
00:48:20,880 --> 00:48:27,880
Although you know that if you did the test notebook.

666
00:48:27,880 --> 00:48:28,880
So we're giving it.

667
00:48:28,880 --> 00:48:29,880
Oh here we go.

668
00:48:29,880 --> 00:48:32,880
So node positions.

669
00:48:32,880 --> 00:48:34,880
There are no positioning algorithms.

670
00:48:34,880 --> 00:48:36,880
You can obviously you could set them yourself.

671
00:48:36,880 --> 00:48:37,880
You could set them yourself.

672
00:48:37,880 --> 00:48:40,880
You know, be like this node is here, here, here, here.

673
00:48:40,880 --> 00:48:43,880
I do that a lot actually in sports analytics.

674
00:48:43,880 --> 00:48:44,880
You know, like a formation.

675
00:48:44,880 --> 00:48:50,880
But in this instance we're just going to be like the spring layout can just decide for us.

676
00:48:50,880 --> 00:48:54,880
But of course that means that it will be different every time unless you set a seed.

677
00:48:54,880 --> 00:48:56,880
So I'm not sending a seed here.

678
00:48:56,880 --> 00:49:01,880
So you'll see how that runs.

679
00:49:01,880 --> 00:49:02,880
Okay.

680
00:49:02,880 --> 00:49:03,880
So there we go.

681
00:49:03,880 --> 00:49:04,880
Ugly basic graph.

682
00:49:04,880 --> 00:49:06,880
But I mean fast, right?

683
00:49:06,880 --> 00:49:10,880
Like if you had data in edge list, that would be really quick.

684
00:49:10,880 --> 00:49:11,880
Okay.

685
00:49:11,880 --> 00:49:13,880
So K equals 20.

686
00:49:13,880 --> 00:49:18,880
So this is you can basically adjust this to let's do like five.

687
00:49:18,880 --> 00:49:20,880
So you can make that smaller.

688
00:49:20,880 --> 00:49:21,880
You can actually just play around.

689
00:49:21,880 --> 00:49:23,880
It's more mushy.

690
00:49:23,880 --> 00:49:26,880
There's less like force or like 50.

691
00:49:26,880 --> 00:49:28,880
So then things will be more further apart like that.

692
00:49:28,880 --> 00:49:30,880
So you play around.

693
00:49:30,880 --> 00:49:33,880
And then if you want to set a seed, which we'll do actually in the next section.

694
00:49:33,880 --> 00:49:36,880
So we like, okay, I should not do one.

695
00:49:36,880 --> 00:49:38,880
So actually I still keep wanting the same.

696
00:49:38,880 --> 00:49:40,880
I want the same positioning.

697
00:49:40,880 --> 00:49:43,880
So it'll just keep giving me that.

698
00:49:43,880 --> 00:49:44,880
Okay.

699
00:49:44,880 --> 00:49:45,880
So you get the idea.

700
00:49:45,880 --> 00:49:46,880
That's ugly.

701
00:49:46,880 --> 00:49:47,880
We want to do some more fun stuff.

702
00:49:47,880 --> 00:49:50,880
So you're literally at the last section here.

703
00:49:50,880 --> 00:49:52,880
G intro.

704
00:49:52,880 --> 00:49:56,880
FYI, NetworkX is not a plotting library.

705
00:49:56,880 --> 00:50:00,880
So as for the docs in the future, graph visualization functionality may be removed from NetworkX

706
00:50:00,880 --> 00:50:03,880
or only available as an add-on package.

707
00:50:03,880 --> 00:50:09,880
And they highly recommend that people visualize their graphs with tools dedicated to that task.

708
00:50:09,880 --> 00:50:13,880
So like not matplotlib.

709
00:50:13,880 --> 00:50:18,880
So therefore, because constructing matplotlib drawn NetworkX graphs has low transferability,

710
00:50:18,880 --> 00:50:23,880
I'm just going to use, we're going to use this section just to demonstrate ideas for fine tuning network visualizations.

711
00:50:23,880 --> 00:50:26,880
So not recommending specific inventations.

712
00:50:26,880 --> 00:50:27,880
So does that sort of make sense?

713
00:50:27,880 --> 00:50:30,880
Because obviously if you were doing this, you might use Geffi.

714
00:50:30,880 --> 00:50:32,880
You might use, I was like, Pi.

715
00:50:32,880 --> 00:50:33,880
I don't know.

716
00:50:33,880 --> 00:50:38,880
There's like, oh, in fact, there's lots of things which I referenced here.

717
00:50:38,880 --> 00:50:45,880
So yeah, this kind of stuff graph is, I mean, Pi dot.

718
00:50:45,880 --> 00:50:47,880
That was it.

719
00:50:47,880 --> 00:50:48,880
So there are other ways you do it.

720
00:50:48,880 --> 00:50:56,880
So yeah, I'm just going to show you ideas and then how you implement that in different packages would be totally different.

721
00:50:56,880 --> 00:50:59,880
So G0, don't bother typing this.

722
00:50:59,880 --> 00:51:00,880
Just literally just copy and paste.

723
00:51:00,880 --> 00:51:09,880
It's just producing two arrays, which will just, they're just like helper arrays, which will help change.

724
00:51:09,880 --> 00:51:10,880
Here we go.

725
00:51:10,880 --> 00:51:16,880
They'll be used to draw the edges of our multi-diagraph with varying widths and colors proportional to their weight, i.e. quantity.

726
00:51:16,880 --> 00:51:17,880
So don't worry too much about that.

727
00:51:17,880 --> 00:51:18,880
But you can always deep dive.

728
00:51:18,880 --> 00:51:20,880
I think it is intuitive enough to understand.

729
00:51:20,880 --> 00:51:34,880
G1, draw a customized map plot live visualization of our Pangolin trade network with a plotting routine that exploits more of the available options, i.e. functions to draw just nodes or just node labels, et cetera, rather than just that kind of like draw networks.

730
00:51:34,880 --> 00:51:35,880
Okay.

731
00:51:35,880 --> 00:51:45,880
So obviously do this how you want, but I'm going to just sort of do it in a kind of absolute build up from nothing.

732
00:51:45,880 --> 00:51:46,880
Okay.

733
00:51:46,880 --> 00:51:53,880
So you do need a pause layout.

734
00:51:53,880 --> 00:52:00,880
Because then that feeds in, you can see it feeds into these draw, draw, draw calls.

735
00:52:00,880 --> 00:52:03,880
So I'm going to give a, what did I say?

736
00:52:03,880 --> 00:52:04,880
Okay.

737
00:52:04,880 --> 00:52:05,880
40.

738
00:52:05,880 --> 00:52:06,880
I won't do a seed.

739
00:52:06,880 --> 00:52:07,880
Okay.

740
00:52:07,880 --> 00:52:08,880
So now I've got a pause.

741
00:52:08,880 --> 00:52:13,880
So you can draw nodes.

742
00:52:13,880 --> 00:52:18,880
The absolute basic is the graph and the positions.

743
00:52:18,880 --> 00:52:22,880
Those nodes literally do not have actually any labels.

744
00:52:22,880 --> 00:52:27,880
So you need to give that labels, which is node labels.

745
00:52:27,880 --> 00:52:29,880
Also needs G and pause.

746
00:52:29,880 --> 00:52:37,880
Then you can draw some edges or else you're just a bunch of floating nodes with labels.

747
00:52:37,880 --> 00:52:41,880
G, pause.

748
00:52:41,880 --> 00:52:43,880
Is that, what was the last one?

749
00:52:43,880 --> 00:52:45,880
Oh, okay.

750
00:52:45,880 --> 00:52:46,880
So that should work.

751
00:52:46,880 --> 00:52:47,880
So, okay.

752
00:52:47,880 --> 00:52:48,880
So there we go.

753
00:52:48,880 --> 00:52:51,880
So now you're basically at the last thing we just did in the last section.

754
00:52:51,880 --> 00:52:52,880
Okay.

755
00:52:52,880 --> 00:52:55,880
So we're going to work up from here and make it better.

756
00:52:55,880 --> 00:52:56,880
Okay.

757
00:52:56,880 --> 00:52:57,880
So, okay.

758
00:52:57,880 --> 00:53:04,880
First of all, I'm going to need to make this the fig size bigger because or else you just cannot see anything because the nerves are all like lumped over each other.

759
00:53:04,880 --> 00:53:07,880
So let's increase the fig size.

760
00:53:07,880 --> 00:53:12,880
Let's give the, okay.

761
00:53:12,880 --> 00:53:22,880
So we'll start with the edges because this is where we use that thing that I just made you create and didn't tell you anything about, which is really good practice.

762
00:53:22,880 --> 00:53:29,880
So this is where we're going to specify the widths now to actually the edge widths to vary.

763
00:53:29,880 --> 00:53:33,880
And then we're also going to change the edge colors again to vary.

764
00:53:33,880 --> 00:53:37,880
Color, custom, edges.

765
00:53:37,880 --> 00:53:40,880
So that should work.

766
00:53:40,880 --> 00:53:41,880
So there.

767
00:53:41,880 --> 00:53:57,880
So now you can see instead of just all those lines being exactly the same, they now, they don't necessarily look like they vary that much, but that's actually mainly because everything was sort of the same size apart from basically this bad boy here, which was massive.

768
00:53:57,880 --> 00:53:58,880
So, yeah.

769
00:53:58,880 --> 00:54:04,880
So this is on a scale of like greens to yellows to reds, but actually a lot of things were basically not a lot.

770
00:54:04,880 --> 00:54:08,880
So green and then a couple of just the one thing was like red.

771
00:54:08,880 --> 00:54:14,880
So that's where those two arrays I just told you to make without looking at are useful.

772
00:54:14,880 --> 00:54:16,880
And then I mean other things.

773
00:54:16,880 --> 00:54:21,880
I mean, I'm not going to type this because again, this is not particularly interesting for you to watch.

774
00:54:21,880 --> 00:54:25,880
But yeah, then you can change nodes.

775
00:54:25,880 --> 00:54:27,880
Again, no actual labels.

776
00:54:27,880 --> 00:54:28,880
Well, actually, no, sorry.

777
00:54:28,880 --> 00:54:31,880
There are labels, but the label default color is black.

778
00:54:31,880 --> 00:54:34,880
So you can't see them.

779
00:54:34,880 --> 00:54:37,880
So change the font.

780
00:54:37,880 --> 00:54:38,880
So now you can actually see.

781
00:54:38,880 --> 00:54:43,880
Sorry, I'm going to make this just small so you can actually see.

782
00:54:43,880 --> 00:54:44,880
What else?

783
00:54:44,880 --> 00:54:45,880
Anything else? Oh, arrows.

784
00:54:45,880 --> 00:54:46,880
Yeah.

785
00:54:46,880 --> 00:54:47,880
And then stuff like this.

786
00:54:47,880 --> 00:54:54,880
So because actually that's not directed at the moment, your edges are just, you know, your like friendship edges are friends.

787
00:54:54,880 --> 00:54:57,880
But, you know, this actually needs a direction.

788
00:54:57,880 --> 00:54:59,880
The min target margin.

789
00:54:59,880 --> 00:55:02,880
So what I've said is the target node.

790
00:55:02,880 --> 00:55:06,880
So the person who bought the country, you bought the pangolins.

791
00:55:06,880 --> 00:55:14,880
I'm giving you like a bit of a boundary so you can see the arrows and also it sort of differentiates the bar from the cell.

792
00:55:14,880 --> 00:55:15,880
So there we go.

793
00:55:15,880 --> 00:55:18,880
That's that margin there.

794
00:55:18,880 --> 00:55:22,880
I love map.lib.

795
00:55:22,880 --> 00:55:23,880
I really do.

796
00:55:23,880 --> 00:55:25,880
Plat axis.

797
00:55:25,880 --> 00:55:31,880
I'm going to turn that off so you don't get that box.

798
00:55:31,880 --> 00:55:32,880
So there.

799
00:55:32,880 --> 00:55:34,880
So yeah.

800
00:55:34,880 --> 00:55:36,880
And like I said, stuff like that you can play around.

801
00:55:36,880 --> 00:55:38,880
That's just an idea of the different things you can do.

802
00:55:38,880 --> 00:55:41,880
You can also save that as well.

803
00:55:41,880 --> 00:55:43,880
But I won't because I have about a thousand copies of it.

804
00:55:43,880 --> 00:55:45,880
I guess we could probably talk about some.

805
00:55:45,880 --> 00:55:48,880
We should like interpret it, I guess.

806
00:55:48,880 --> 00:55:49,880
This is a really ugly layout.

807
00:55:49,880 --> 00:55:57,880
I'm going to try another one.

808
00:55:57,880 --> 00:55:58,880
Okay, slightly better.

809
00:55:58,880 --> 00:56:03,880
So yeah, interpretation.

810
00:56:03,880 --> 00:56:07,880
Okay. So again, I know we couldn't be constrained.

811
00:56:07,880 --> 00:56:08,880
Our analysis cut lots of things.

812
00:56:08,880 --> 00:56:10,880
We made a lot of assumptions.

813
00:56:10,880 --> 00:56:12,880
Like I said, I knew that we were going to get some kind of

814
00:56:12,880 --> 00:56:14,880
change in the data that we could actually look at.

815
00:56:14,880 --> 00:56:16,880
That's why I did a lot of research with xyz.

816
00:56:16,880 --> 00:56:18,880
But within the framework of what we have,

817
00:56:18,880 --> 00:56:20,880
the data that we end up with.

818
00:56:20,880 --> 00:56:21,880
I thought this is really interesting.

819
00:56:21,880 --> 00:56:23,880
I didn't actually know this.

820
00:56:23,880 --> 00:56:25,880
I assumed when we were going to look at pangolins,

821
00:56:25,880 --> 00:56:27,880
I thought it was going to just be Asia.

822
00:56:27,880 --> 00:56:30,880
And all the normal sort of, you know,

823
00:56:30,880 --> 00:56:31,880
not stereotype, but you know,

824
00:56:31,880 --> 00:56:36,880
Things that people think about when they think about, yeah.

825
00:56:36,880 --> 00:56:38,880
People eating exotic animals and making medicine.

826
00:56:38,880 --> 00:56:46,720
So yes, Singapore, Japan, Malaysia, they obviously are still involved, so selling and buying.

827
00:56:46,720 --> 00:56:51,880
But actually what I thought was really interesting and I did not, like I said, plan it at all.

828
00:56:51,880 --> 00:57:00,000
But actually, the US bought a lot of pangolin commodities.

829
00:57:00,000 --> 00:57:05,440
They bought a lot of pangolin commodities from Japan, but also from lots of other places

830
00:57:05,440 --> 00:57:06,440
in the world.

831
00:57:07,000 --> 00:57:12,360
Yeah, and there's also, okay, you can't see that well, but yeah, Great Britain also pretty

832
00:57:12,360 --> 00:57:16,520
complicit, France, quite a lot of things happening there.

833
00:57:16,520 --> 00:57:20,200
Mexico actually, yeah, was more than I thought sort of surprising.

834
00:57:20,200 --> 00:57:24,840
Well, I don't know, surprising to me, but this is not my field, so I'm more than an expert.

835
00:57:24,840 --> 00:57:31,400
However, of course, while saying that, some caveats, again, the interpretation.

836
00:57:31,400 --> 00:57:35,400
A few of the further caveats and considerations redrawing inferences from our pangolin trade

837
00:57:35,400 --> 00:57:39,480
network graph include possible range in the quality of trade monitoring and record keeping

838
00:57:39,480 --> 00:57:42,840
by country, as well as influential geopolitical factors.

839
00:57:42,840 --> 00:57:45,480
For example, not all countries are parties to the convention.

840
00:57:45,480 --> 00:57:51,880
I don't actually have data on their trade or have been at all times.

841
00:57:51,880 --> 00:57:56,560
Plus there were changes to country boundaries existence between 1975 and 2022.

842
00:57:56,560 --> 00:58:04,800
For example, if you are my generation, so check the checklist of Vakia is now the Czech

843
00:58:05,200 --> 00:58:07,320
Republic and Slovakia.

844
00:58:07,320 --> 00:58:09,360
So things like that.

845
00:58:09,360 --> 00:58:17,000
And then obviously maybe the US has more data on their trade rather than another country

846
00:58:17,000 --> 00:58:23,960
where they don't monitor so well, so on and so forth.

847
00:58:23,960 --> 00:58:28,160
There is the section H. Okay, we'll do it really quickly in two minutes.

848
00:58:28,160 --> 00:58:29,160
Yes.

849
00:58:29,160 --> 00:58:44,840
So I, it's not necessarily what I would be suggesting, but I think there is probably

850
00:58:44,840 --> 00:58:53,960
the countries who have better data quality probably are going to look worse in analysis

851
00:58:53,960 --> 00:58:58,680
like this because they have, you know, the they have actually recorded those trades.

852
00:58:58,680 --> 00:59:02,080
They've kind of been transparent about their transactions.

853
00:59:02,080 --> 00:59:03,080
Whereas you know, there are other countries.

854
00:59:03,080 --> 00:59:04,080
Oh, this is all recording.

855
00:59:04,080 --> 00:59:05,960
But you know, there are other countries.

856
00:59:05,960 --> 00:59:12,440
I mean, in Asia, for example, where I'm 100% sure they are not, you know, they're not going

857
00:59:12,440 --> 00:59:21,640
to be recording the data and or providing that data to like, siteys like to the UN.

858
00:59:21,640 --> 00:59:24,840
You know, so yeah, is that the answer?

859
00:59:24,840 --> 00:59:25,840
Did you have a position on?

860
00:59:25,840 --> 00:59:38,160
Yeah, yeah.

861
00:59:38,160 --> 00:59:42,600
So I think yeah, I think it's as you said, I had my preconceptions and then this kind

862
00:59:42,600 --> 00:59:46,920
of was like, oh, I totally did not expect the US to be so mean, I can kind of see obviously

863
00:59:46,920 --> 00:59:47,920
from the data going through it.

864
00:59:47,920 --> 00:59:51,900
But yeah, I didn't expect to be so dominant.

865
00:59:51,900 --> 00:59:54,840
But then obviously, then you also have to count that and be like, but actually, maybe

866
00:59:54,840 --> 00:59:58,080
there is more data collection and so on.

867
00:59:58,080 --> 00:59:59,920
So it's a balance, I would say.

868
00:59:59,920 --> 01:00:03,320
But yeah, I would definitely if someone like worked on this, it'd be really interesting

869
01:00:03,320 --> 01:00:06,160
to see what other insight people had.

870
01:00:06,160 --> 01:00:10,480
Okay, we're really quickly just going to work through H just to show you that it's not just

871
01:00:10,480 --> 01:00:11,480
visualization.

872
01:00:11,480 --> 01:00:14,480
There's actually actual maths stuff.

873
01:00:14,480 --> 01:00:15,480
Okay, H0.

874
01:00:15,480 --> 01:00:18,520
I'm just going to whack this.

875
01:00:18,520 --> 01:00:21,160
So you can obviously just get out lots of metrics.

876
01:00:21,160 --> 01:00:24,760
There's like edges and you know, so obviously, if you just do G and then you can just do

877
01:00:24,760 --> 01:00:31,160
H and then dots and then look at stuff, you know, there's other things.

878
01:00:31,160 --> 01:00:32,160
H1.

879
01:00:32,160 --> 01:00:34,200
Okay, so I'm not going to read this through.

880
01:00:34,200 --> 01:00:38,800
I'm just going to tell you there are things like centrality functionalities.

881
01:00:38,800 --> 01:00:42,760
So that kind of gives you a sense of which nodes are important.

882
01:00:42,760 --> 01:00:48,200
But based just on like in this case, just based on like how many different people are

883
01:00:48,200 --> 01:00:51,760
they connected to not the volume of their transactions.

884
01:00:52,440 --> 01:00:57,120
Like I said, it is just to show you that there are things, things you can do and then okay,

885
01:00:57,120 --> 01:00:59,120
this one I'll just really quickly show you.

886
01:00:59,120 --> 01:01:01,400
So if you sort that list and just take the top 10.

887
01:01:01,400 --> 01:01:07,520
So this is just about the degree centrality, which means that the US in this case has traded,

888
01:01:07,520 --> 01:01:13,200
like I said, traded any trade number of trades in paranglans with the most other countries.

889
01:01:13,200 --> 01:01:19,480
So in this instance, 91% of the 55 countries in this network, which is 49 countries.

890
01:01:19,520 --> 01:01:22,800
But yeah, the other thing which I sort of mentioned here you'd want to look at is community

891
01:01:22,800 --> 01:01:27,240
detecting algorithms could be a good next step because you'd be like, actually there

892
01:01:27,240 --> 01:01:34,360
was, you know, there are, you know, obviously smaller communities within this.

893
01:01:34,360 --> 01:01:40,320
So US, Japan, Singapore maybe, can't remember what GQ is, not a magazine.

894
01:01:40,320 --> 01:01:42,160
XX is like the unknown.

895
01:01:42,160 --> 01:01:43,640
So you know, there's a portion there.

896
01:01:43,640 --> 01:01:48,520
But yeah, there could be sort of smaller kind of little regional relationships.

897
01:01:48,520 --> 01:01:50,360
So communities you want to look at.

898
01:01:50,360 --> 01:01:55,600
Okay, that is your first exploration, break time.

899
01:01:55,600 --> 01:01:58,800
I think, do you want 10 minutes?

900
01:01:58,800 --> 01:02:00,520
Yeah, okay.

901
01:02:00,520 --> 01:02:04,320
All right, I'll see you in 10 plus 10.

902
01:02:04,320 --> 01:02:08,600
Are we okay to start like now?

903
01:02:08,600 --> 01:02:10,400
Yeah.

904
01:02:10,400 --> 01:02:13,200
Okay, look.

905
01:02:13,200 --> 01:02:21,800
Okay, so I say that like, I've been waiting for you rather than you've been waiting for me.

906
01:02:21,800 --> 01:02:23,480
I hope this microphone wasn't on when I went to the toilet.

907
01:02:23,480 --> 01:02:25,880
That'd be really weird.

908
01:02:25,880 --> 01:02:28,000
Anyway, sorry.

909
01:02:28,000 --> 01:02:31,400
That's a cyber security background, government background coming into play.

910
01:02:31,400 --> 01:02:39,880
Okay, so if you want to load up the carbon fleet exploration notebook, which hopefully you have.

911
01:02:39,880 --> 01:02:42,600
Honestly, I can't believe you all had the stuff.

912
01:02:42,640 --> 01:02:44,440
This is so smooth.

913
01:02:44,440 --> 01:02:48,920
You're so much better than like teenagers.

914
01:02:48,920 --> 01:02:52,400
Sorry, that's like damning with frame praise, isn't it?

915
01:02:52,400 --> 01:02:54,200
We probably do need to check.

916
01:02:54,200 --> 01:02:57,520
So we've got a little bit more data.

917
01:02:57,520 --> 01:03:04,440
So you should have, unsurprisingly, my verbose labeling.

918
01:03:04,440 --> 01:03:07,240
So you've got this CSV.

919
01:03:07,280 --> 01:03:12,840
But you also need to have the, well, this is the shapefile.

920
01:03:15,320 --> 01:03:20,520
Yeah, that's like, there's nothing more I can tell you about that.

921
01:03:20,520 --> 01:03:27,840
So yeah, please make sure you have that somewhere you can access because that's going to help us make pretty maps.

922
01:03:32,280 --> 01:03:33,280
Okay.

923
01:03:34,640 --> 01:03:35,160
Someone's not here.

924
01:03:35,160 --> 01:03:36,840
Okay, anyway, I think we're going to start.

925
01:03:36,840 --> 01:03:42,040
Okay, so welcome to part two.

926
01:03:42,040 --> 01:03:48,640
I think we're going to try and do this by 11 and then have a break just to set your expectations.

927
01:03:48,640 --> 01:03:52,680
So carbon polluters exploration with Python.

928
01:03:52,680 --> 01:04:01,120
Note that you need internet access for section E, which is the interactive JavaScripty map.

929
01:04:01,120 --> 01:04:05,440
So which sample of carbon polluters are we examining?

930
01:04:05,440 --> 01:04:12,520
So it is the university, the US university facilities with large greenhouse gas emissions,

931
01:04:12,520 --> 01:04:20,120
which, according to the EPA, is over 25,000 metric tons of carbon dioxide equivalent per year.

932
01:04:20,120 --> 01:04:30,120
And so that those studies are in our sample if they reach that threshold in any year between 2011 and 2021.

933
01:04:30,160 --> 01:04:41,000
So 2011 is because that's when the GHGRP, Greenhouse Gas Reporting Program was launched in 2021, as I said, the latest reporting year.

934
01:04:41,000 --> 01:04:44,040
Have people heard of the GHGRP?

935
01:04:44,040 --> 01:04:46,120
Because I was going to say I hadn't.

936
01:04:46,120 --> 01:04:54,240
I should also say, even though I work for the UK government supporting foreign policy, I'm actually a US citizen.

937
01:04:54,240 --> 01:04:57,760
So this will come up actually in this tutorial.

938
01:04:58,760 --> 01:05:00,280
Yeah, this is a surprise to me.

939
01:05:00,280 --> 01:05:03,440
I didn't know about the GHGRP, but anyway, lots of really good data.

940
01:05:03,440 --> 01:05:06,800
So I really hope this will incentivize you to look further.

941
01:05:06,800 --> 01:05:08,440
What scientific approaches are we taking?

942
01:05:08,440 --> 01:05:11,520
So we are doing statistical and geospatial approaches.

943
01:05:11,520 --> 01:05:12,880
What outputs will we develop?

944
01:05:12,880 --> 01:05:15,680
Oh, sorry, make this bigger.

945
01:05:15,680 --> 01:05:20,200
Statistical graphs and interactive maths with historical and or regional dimensions.

946
01:05:20,200 --> 01:05:22,040
What will our outputs tell us?

947
01:05:22,040 --> 01:05:26,840
Who and where are the significant US sources of carbon pollution within the higher education sector,

948
01:05:26,880 --> 01:05:30,880
a facility and state level, both recent and since 2011?

949
01:05:32,120 --> 01:05:36,520
Beyond the well-known eco impacts of carbon polluters, climate change.

950
01:05:36,520 --> 01:05:39,160
What makes this sample significant?

951
01:05:39,160 --> 01:05:46,320
So to me, it's the fact that this sector has or individual universities are large fossil fuel burners.

952
01:05:46,320 --> 01:05:52,040
So that might be a surprise seeing the out of sync with any green credentials and reputation they have garnered,

953
01:05:52,040 --> 01:05:54,360
especially relating to clean energy.

954
01:05:54,400 --> 01:05:56,560
And so I also want to point out,

955
01:05:58,320 --> 01:06:06,600
so yeah, after I had sort of done this or proposed this and developed it, I discovered this Reuters article.

956
01:06:06,600 --> 01:06:10,880
Again, I don't know if you're as excited about this as I am, because I was like, this is just really,

957
01:06:10,880 --> 01:06:12,800
I was like, these universities are naughty.

958
01:06:14,880 --> 01:06:21,560
But it turns out that Reuters actually came up, they used different data from a different source,

959
01:06:21,560 --> 01:06:24,240
but they were also, it's like the sentiment is the same.

960
01:06:24,240 --> 01:06:28,000
They're like, oh, look, these universities talk really, they have very secret.

961
01:06:28,000 --> 01:06:33,640
And also I just want to point out this is dated after I like proposed this tutorial.

962
01:06:33,640 --> 01:06:39,040
So I did not take this, but it does corroborate a lot of the things which I thought were interesting.

963
01:06:39,040 --> 01:06:44,320
So I really urge you to have a look because then they do a much more sort of in-depth analysis because they're Reuters.

964
01:06:44,320 --> 01:06:46,200
So they had, you know, resources.

965
01:06:46,200 --> 01:06:49,960
But I also want to point out, this is my personal link to the story.

966
01:06:51,600 --> 01:06:54,680
So I don't know if people know, but I was there.

967
01:06:54,680 --> 01:06:57,760
So this is Boston.

968
01:06:57,760 --> 01:07:07,840
This is a facility, the Cambridge Olsen Blackstone power plant, which Deferred Harvard only bought, acquired in 2005,

969
01:07:07,840 --> 01:07:10,720
I think, was really interesting.

970
01:07:10,720 --> 01:07:14,120
And I guess, so I don't want to dwell on the sentimentality of it.

971
01:07:14,120 --> 01:07:19,320
But what I find really interesting is that doing this tutorial, preparing this tutorial,

972
01:07:19,320 --> 01:07:23,800
I discovered that I actually grew up as a toddler.

973
01:07:23,800 --> 01:07:29,920
I grew up two blocks here from where this photo was taken.

974
01:07:29,920 --> 01:07:37,640
And I did not realize that I grew up under so near a excessive carbon polluter.

975
01:07:37,640 --> 01:07:40,440
So we'll talk about that later.

976
01:07:40,440 --> 01:07:48,920
But that just kind of gives you like, you know, there are real, obviously, I hope you know, there are real world impacts or real world, you know,

977
01:07:49,920 --> 01:07:52,880
factors behind a lot of this data.

978
01:07:52,880 --> 01:07:55,640
It's not just, you know, abstract.

979
01:07:55,640 --> 01:07:59,960
So, yeah, I'm like, great. I breathed lots of fumes.

980
01:07:59,960 --> 01:08:03,040
That's cool. Maybe that explains a lot of things.

981
01:08:03,040 --> 01:08:06,800
Data source. So there's some background stuff if you want to know more about it.

982
01:08:06,800 --> 01:08:10,000
But, you know, it's all mainly like government data.

983
01:08:10,000 --> 01:08:14,040
And that shapefile is from the US Census Bureau. Blah, blah, blah.

984
01:08:14,040 --> 01:08:16,840
I shouldn't say that in my own tutorial.

985
01:08:18,960 --> 01:08:19,960
Sorry.

986
01:08:21,080 --> 01:08:22,480
Why is this?

987
01:08:22,480 --> 01:08:26,080
OK, sorry. I just I wasn't sure why this was already there.

988
01:08:26,080 --> 01:08:30,320
OK, cool. So I'll just go over the table of contents.

989
01:08:30,320 --> 01:08:33,320
So a bit shorter.

990
01:08:34,600 --> 01:08:37,760
Yeah. But like different.

991
01:08:37,760 --> 01:08:40,160
There's a much more variety, I'd say, in this one than the last one.

992
01:08:40,160 --> 01:08:44,360
So A, set up Gif notebook, university, emitters, data set and US state shapefile.

993
01:08:44,360 --> 01:08:48,080
So easier import the required packages and submodules.

994
01:08:50,080 --> 01:08:52,520
But their conventional aliases.

995
01:08:52,520 --> 01:08:56,440
It's important as MP format.

996
01:08:56,880 --> 01:08:58,720
So I thought.

997
01:09:01,760 --> 01:09:04,960
No. Try again.

998
01:09:06,840 --> 01:09:09,880
Again, take this. So if you are new to Jupiter,

999
01:09:10,480 --> 01:09:13,840
I know this seems tedious, but every time every computational notebook

1000
01:09:13,840 --> 01:09:17,440
is, you know, you kind of have to set up your environment all over again.

1001
01:09:17,920 --> 01:09:23,080
So that's why they seem to be boring, but that's a A to we are going to set

1002
01:09:23,080 --> 01:09:26,240
a panda's display option, show all columns, not truncate the display.

1003
01:09:26,760 --> 01:09:29,960
So because if you've got lots of columns,

1004
01:09:30,920 --> 01:09:33,920
pandas will automatically like cut out some of them

1005
01:09:33,920 --> 01:09:36,280
just so you can fit more on the screen and like ellipses,

1006
01:09:37,200 --> 01:09:38,640
which may not be what you want.

1007
01:09:38,640 --> 01:09:41,360
A3 reading the university emitters, data set, column,

1008
01:09:41,360 --> 01:09:44,400
suitors, data and assigned to raw data.

1009
01:09:45,120 --> 01:09:48,000
So PD raw CSP.

1010
01:09:48,000 --> 01:09:51,160
Carbon polluters, data.

1011
01:09:51,160 --> 01:09:53,160
All data.

1012
01:09:53,160 --> 01:09:56,000
And then again, a four.

1013
01:09:56,840 --> 01:09:59,920
If you create that prep data frame,

1014
01:10:00,760 --> 01:10:03,520
although I just want you to be creating a lot of data frames

1015
01:10:04,440 --> 01:10:07,080
in this tutorial for reasons.

1016
01:10:07,960 --> 01:10:12,960
And a five, just the other nagging reminder to please make sure

1017
01:10:12,960 --> 01:10:17,880
that you have that shapefile as a subfolder somewhere you can access.

1018
01:10:18,960 --> 01:10:21,200
I don't know if people have people work with shapefiles before.

1019
01:10:21,920 --> 01:10:23,360
Yeah. OK, cool. Some people. Yeah.

1020
01:10:23,360 --> 01:10:25,840
So if you haven't, I mean, I'm not an expert.

1021
01:10:25,840 --> 01:10:29,440
I, you know, I just use it for.

1022
01:10:29,440 --> 01:10:32,040
I know enough about it to like do the things which I need to do.

1023
01:10:33,480 --> 01:10:36,440
But yeah, if you actually open up, it's got other files in it.

1024
01:10:37,680 --> 01:10:40,880
But that's apparently that is the shapefile.

1025
01:10:41,200 --> 01:10:42,400
So anyway.

1026
01:10:43,680 --> 01:10:46,200
It works. That's the most important thing.

1027
01:10:46,200 --> 01:10:48,720
So it should be inspect the university emitters data set.

1028
01:10:49,360 --> 01:10:52,880
So these are have a look at the data set of large carbon polluting

1029
01:10:52,880 --> 01:10:55,400
university, U.S. university facilities.

1030
01:10:56,240 --> 01:10:57,840
So you have prep.

1031
01:10:59,680 --> 01:11:03,000
Also notes that instead of returning a default number of rows,

1032
01:11:03,120 --> 01:11:05,400
you can start specifying the end argument.

1033
01:11:07,640 --> 01:11:11,120
OK, so comments like the original Pangolin trade data.

1034
01:11:11,160 --> 01:11:14,360
There is missing data we need to handle like this.

1035
01:11:14,720 --> 01:11:18,480
However, unlike the Pangolin trade data, the data requested from the EPA

1036
01:11:18,480 --> 01:11:21,640
flight data source is the exact sample of interest.

1037
01:11:21,640 --> 01:11:23,920
So namely, all the facilities in the U.S.

1038
01:11:23,920 --> 01:11:27,320
university sector with large emissions in any reported year

1039
01:11:27,320 --> 01:11:29,840
between 2011 and 2021.

1040
01:11:29,920 --> 01:11:32,560
So every row is therefore relevant,

1041
01:11:32,560 --> 01:11:35,640
which is not like the case in the previous exploration.

1042
01:11:36,320 --> 01:11:39,960
The required data prep, also called cleaning, munging, rambling,

1043
01:11:41,000 --> 01:11:43,440
is therefore needed to modify the columns,

1044
01:11:44,040 --> 01:11:46,800
not the rows, which is the focus of the next section.

1045
01:11:48,160 --> 01:11:52,040
OK, so B1 find the dimensions of DF prep.

1046
01:11:52,720 --> 01:11:53,960
So shake again.

1047
01:11:53,960 --> 01:11:55,800
So there are 118 U.S.

1048
01:11:55,800 --> 01:11:58,320
university facilities, which are large carbon polluters

1049
01:11:58,320 --> 01:12:01,760
in at least one of the years between 2011 and 2021.

1050
01:12:02,720 --> 01:12:07,040
Did people know, like, I presume, you know, some of you all are studying in the U.S.

1051
01:12:07,480 --> 01:12:11,040
Did you know that they have these big power plants burning?

1052
01:12:11,520 --> 01:12:15,280
What? No, OK. I was going to say, like, unless you're like, yeah, obviously.

1053
01:12:16,560 --> 01:12:18,840
This is like because it really was a surprise to me.

1054
01:12:18,840 --> 01:12:21,440
I don't I think in the UK,

1055
01:12:22,240 --> 01:12:24,720
I don't think, you know, the idea of universities

1056
01:12:24,720 --> 01:12:26,440
having a power plant is really unusual.

1057
01:12:26,440 --> 01:12:29,280
So I didn't know that was just.

1058
01:12:29,280 --> 01:12:32,800
Yeah, where I live, my experiences.

1059
01:12:32,800 --> 01:12:35,720
Anyway, section C, prepare the university and missus data sets.

1060
01:12:36,000 --> 01:12:39,040
So C zero, some of the columns are definitely not needed.

1061
01:12:39,040 --> 01:12:40,160
So let's prepare to drop them.

1062
01:12:40,160 --> 01:12:42,920
And with some efficiency, instead of manually counting,

1063
01:12:42,920 --> 01:12:46,120
let's programmatically find out the index positions of each column.

1064
01:12:47,160 --> 01:12:50,280
So you've got the columns attribute.

1065
01:12:51,320 --> 01:12:53,680
From the FRAP. So that's the list of labels.

1066
01:12:55,600 --> 01:12:56,840
There is obviously a lot.

1067
01:12:56,840 --> 01:12:57,880
And we don't need them all.

1068
01:12:57,880 --> 01:13:02,040
So this is just a really quick way to.

1069
01:13:03,280 --> 01:13:07,200
Find out. The index position of each one.

1070
01:13:08,720 --> 01:13:11,640
So. C1.

1071
01:13:12,520 --> 01:13:16,360
Perform a job operation that moves four particular columns from DF rep in place.

1072
01:13:16,840 --> 01:13:19,360
So subparts change in emissions,

1073
01:13:20,080 --> 01:13:22,200
that one change in emissions and then sectors.

1074
01:13:23,200 --> 01:13:25,080
And review the modification.

1075
01:13:25,080 --> 01:13:27,160
So we're going to do a DF.

1076
01:13:28,560 --> 01:13:31,440
Prep drop methods, we're going to drop.

1077
01:13:32,360 --> 01:13:35,600
Columns and the columns that we are going to drop.

1078
01:13:37,880 --> 01:13:41,240
Have these index.

1079
01:13:41,240 --> 01:13:45,600
Positions, so 10, 22, 23 and 24.

1080
01:13:46,560 --> 01:13:49,600
And then we're going to drop that in place.

1081
01:13:50,360 --> 01:13:53,160
And then we are going to see if they have gone.

1082
01:13:54,160 --> 01:13:55,640
Nope, that's not going to work.

1083
01:13:58,120 --> 01:13:59,080
OK, great.

1084
01:14:00,480 --> 01:14:02,920
And I guess another point to stress,

1085
01:14:02,920 --> 01:14:05,720
as with, I guess, everything in Python is there are lots of different ways to do things.

1086
01:14:06,000 --> 01:14:08,520
This is just a way.

1087
01:14:08,520 --> 01:14:11,200
And I probably also should point out that the index parameter

1088
01:14:12,840 --> 01:14:15,720
is accepted by several Panda methods is used in this tutorial

1089
01:14:15,720 --> 01:14:21,000
where possible for brevity, but its existence is controversial and currently in flux.

1090
01:14:22,000 --> 01:14:25,560
So that's just to say that it's not considered best practice.

1091
01:14:28,040 --> 01:14:31,320
So, yeah, I'm not endorsing it, but it just makes things a lot faster.

1092
01:14:32,360 --> 01:14:36,280
OK, so C2, see what data type Panda's inferred was in each column

1093
01:14:36,280 --> 01:14:38,880
when it originally read in the current polluters data.

1094
01:14:39,520 --> 01:14:41,280
So DF, D types.

1095
01:14:43,400 --> 01:14:47,640
OK, so the comment, Panda's inferences are only partially correct.

1096
01:14:48,640 --> 01:14:53,600
The columns that are essential to correct are the 11 years of reported emissions data.

1097
01:14:53,640 --> 01:14:55,600
These are all currently object D type.

1098
01:14:55,600 --> 01:14:58,560
So basically string data, not numeric as required.

1099
01:15:00,000 --> 01:15:04,520
You can also see here these other ones are not, I mean, like

1100
01:15:06,360 --> 01:15:07,960
what's this one? Yeah, like an ID.

1101
01:15:07,960 --> 01:15:11,960
This is not I mean, it's really a category or something better.

1102
01:15:12,360 --> 01:15:15,400
There's other stuff which is not correct, but we're not going to worry about it

1103
01:15:15,400 --> 01:15:17,200
because we don't need to.

1104
01:15:17,280 --> 01:15:20,880
C3, before we start modifying the 11 reported emissions data columns,

1105
01:15:21,120 --> 01:15:25,280
let's shorten their long cumbersome labels to just the reporting year reference.

1106
01:15:25,720 --> 01:15:27,720
So we're basically taking out that stuff.

1107
01:15:31,040 --> 01:15:32,920
Excuse me. And then review the modification.

1108
01:15:32,920 --> 01:15:35,200
OK, so DFPrep, we're going to rename.

1109
01:15:37,440 --> 01:15:40,680
We're going to rename the columns.

1110
01:15:41,640 --> 01:15:45,800
Um, to basically itself,

1111
01:15:45,840 --> 01:15:48,720
but without this long cumbersome string.

1112
01:15:50,800 --> 01:15:52,440
If it's in there.

1113
01:15:52,800 --> 01:15:56,200
So take out, oops, no, jumps ahead of myself.

1114
01:16:03,480 --> 01:16:06,560
So replace that with nothing.

1115
01:16:06,560 --> 01:16:08,760
And then do that in place.

1116
01:16:10,680 --> 01:16:15,680
OK, so I'm just slightly not confident that I've done that correct.

1117
01:16:15,680 --> 01:16:18,680
So I'm just going to do that again.

1118
01:16:18,680 --> 01:16:22,680
OK, and then let's see what that happens after that.

1119
01:16:25,680 --> 01:16:28,680
Excuse me. String be gone. There we go.

1120
01:16:28,680 --> 01:16:31,680
Much easier. OK, C4.

1121
01:16:32,680 --> 01:16:36,680
Now start the process towards converting these 11 columns to a numeric data type.

1122
01:16:36,680 --> 01:16:39,680
Remove the comma characters from the source data.

1123
01:16:39,680 --> 01:16:42,680
Remove the comma characters from the string data in these 11 columns,

1124
01:16:42,680 --> 01:16:46,680
but not anywhere else in DFPrep, e.g. reported address.

1125
01:16:47,680 --> 01:16:49,680
And then review the modification.

1126
01:16:49,680 --> 01:16:52,680
OK, so does that make sense? So there's these commas which are,

1127
01:16:52,680 --> 01:16:55,680
I mean, I know that it looks nice and readable, but is a pain.

1128
01:16:55,680 --> 01:16:58,680
But we can't just take all the commas because there are actually commas here

1129
01:16:58,680 --> 01:17:00,680
which are useful or relevant.

1130
01:17:00,680 --> 01:17:03,680
Although we're not using that data, but we don't want to touch it.

1131
01:17:03,680 --> 01:17:08,680
So we are going to use the lock operator.

1132
01:17:09,680 --> 01:17:12,680
To do some multi-dimensional indexing.

1133
01:17:14,680 --> 01:17:17,680
So we're going to take all the rows.

1134
01:17:18,680 --> 01:17:21,680
OK, so that would be all the rows and all the columns.

1135
01:17:21,680 --> 01:17:25,680
Right? Just in case people haven't done indexing with the lock operator before.

1136
01:17:26,680 --> 01:17:29,680
Because we're using lock as opposed to ilock,

1137
01:17:29,680 --> 01:17:32,680
we can, well, we have to use labels.

1138
01:17:33,680 --> 01:17:36,680
So we're going to use this label.

1139
01:17:36,680 --> 01:17:42,680
And if I leave it like that, that will slice everything from 2011 onwards.

1140
01:17:42,680 --> 01:17:43,680
Perfect.

1141
01:17:43,680 --> 01:17:47,680
So that's how I'm selecting these 11 missions data columns.

1142
01:17:47,680 --> 01:17:51,680
OK, so now that I've selected them, what do I want to do with it?

1143
01:17:51,680 --> 01:17:54,680
I want to apply apply map.

1144
01:17:54,680 --> 01:18:00,680
So basically take out the commas or replace the values with itself,

1145
01:18:00,680 --> 01:18:02,680
but without the commas.

1146
01:18:02,680 --> 01:18:04,680
So lambda x, x.

1147
01:18:04,680 --> 01:18:05,680
This is not lambda.

1148
01:18:05,680 --> 01:18:09,680
Apply map is not before anyone says, that's really slow.

1149
01:18:09,680 --> 01:18:11,680
It is really slow because it goes through every element.

1150
01:18:11,680 --> 01:18:16,680
But in this instance, it's, you know, we don't need like the fastest thing.

1151
01:18:18,680 --> 01:18:19,680
By itself.

1152
01:18:20,680 --> 01:18:27,680
So that would take away your commas and then reassign to its override.

1153
01:18:27,680 --> 01:18:30,680
OK, and now let's see if that worked.

1154
01:18:30,680 --> 01:18:32,680
Please have worked.

1155
01:18:33,680 --> 01:18:34,680
Great.

1156
01:18:35,680 --> 01:18:37,680
OK, so OK, C4 comments.

1157
01:18:37,680 --> 01:18:41,680
So this is just to tell you that these are just other ways that you could have done

1158
01:18:41,680 --> 01:18:43,680
a site to those columns.

1159
01:18:43,680 --> 01:18:45,680
And there are obviously more beyond that.

1160
01:18:45,680 --> 01:18:49,680
C5, the last string cleanup step is to deal with the dash, dash, dash instances

1161
01:18:49,680 --> 01:18:52,680
in the 11 columns that we assume is EPA notation for nan.

1162
01:18:52,680 --> 01:18:54,680
Sorry, not applicable.

1163
01:18:54,680 --> 01:18:59,680
We will replace these string values in place with nan and then review the modification.

1164
01:18:59,680 --> 01:19:02,680
So this one is easier.

1165
01:19:02,680 --> 01:19:04,680
Just take out those weird dashes.

1166
01:19:04,680 --> 01:19:08,680
You could also do some like fancy regex solutions.

1167
01:19:08,680 --> 01:19:11,680
But, you know, that's not really necessary here.

1168
01:19:11,680 --> 01:19:13,680
So you take out that.

1169
01:19:16,680 --> 01:19:20,680
And take a look.

1170
01:19:21,680 --> 01:19:22,680
Great.

1171
01:19:22,680 --> 01:19:24,680
C6.

1172
01:19:24,680 --> 01:19:30,680
Now convert the 11 columns to a numeric data type and then review the modification by I.

1173
01:19:31,680 --> 01:19:37,680
So we're going to use that lock method of selecting columns.

1174
01:19:37,680 --> 01:19:42,680
So all the rows and then all the columns from 2011 onwards.

1175
01:19:42,680 --> 01:19:43,680
Just that.

1176
01:19:43,680 --> 01:19:49,680
And now we can apply the Panda function to numeric.

1177
01:19:49,680 --> 01:19:51,680
To numeric.

1178
01:19:51,680 --> 01:19:53,680
To numeric.

1179
01:19:58,680 --> 01:19:59,680
It's funny.

1180
01:19:59,680 --> 01:20:04,680
It's only when you're like live coding data wrangling, when you realize it doesn't,

1181
01:20:04,680 --> 01:20:08,680
it's very difficult to make it fun.

1182
01:20:08,680 --> 01:20:10,680
But anyway, it's necessary.

1183
01:20:10,680 --> 01:20:12,680
And I obviously as your adults, you sort of know that.

1184
01:20:12,680 --> 01:20:17,680
And I don't have to tell it to you because you're, again, like I said, not disruptive children.

1185
01:20:17,680 --> 01:20:19,680
Okay, so.

1186
01:20:20,680 --> 01:20:21,680
There we go.

1187
01:20:21,680 --> 01:20:24,680
There's a deprecation warning.

1188
01:20:24,680 --> 01:20:26,680
Like if you wanted to read it more closely.

1189
01:20:26,680 --> 01:20:27,680
It's actually helpful.

1190
01:20:27,680 --> 01:20:31,680
It's basically saying, I think in future you don't have to reassign it.

1191
01:20:31,680 --> 01:20:32,680
It will just do it.

1192
01:20:32,680 --> 01:20:34,680
Anyway, so it sounds good.

1193
01:20:34,680 --> 01:20:36,680
Whatever it's saying.

1194
01:20:36,680 --> 01:20:38,680
But yeah, currently this is how we're doing it.

1195
01:20:38,680 --> 01:20:39,680
And this works.

1196
01:20:39,680 --> 01:20:42,680
So there we go.

1197
01:20:42,680 --> 01:20:45,680
By I, this looks good because it looks like it's a float.

1198
01:20:45,680 --> 01:20:46,680
It's a float.

1199
01:20:46,680 --> 01:20:51,680
But obviously C7, we should double check that that is actually a numeric data type.

1200
01:20:51,680 --> 01:20:52,680
And there we go.

1201
01:20:52,680 --> 01:20:54,680
It is a float.

1202
01:20:54,680 --> 01:20:55,680
Just perfect.

1203
01:20:55,680 --> 01:20:56,680
So C8.

1204
01:20:56,680 --> 01:21:00,680
Now we've got the columns with the 11 years of reported emissions data.

1205
01:21:00,680 --> 01:21:05,680
Now that they are a numeric data type, let's compute some quick summary statistics.

1206
01:21:05,680 --> 01:21:07,680
So describe.

1207
01:21:09,680 --> 01:21:10,680
Use the describe method.

1208
01:21:10,680 --> 01:21:16,680
So as I said, although we do have some columns which shouldn't be numeric, but we could have

1209
01:21:16,680 --> 01:21:17,680
tidied that.

1210
01:21:17,680 --> 01:21:19,680
You could obviously do that.

1211
01:21:19,680 --> 01:21:20,680
We should have more time.

1212
01:21:20,680 --> 01:21:23,680
What is interesting here, I guess, just things to note.

1213
01:21:23,680 --> 01:21:25,680
So count, for example.

1214
01:21:25,680 --> 01:21:30,680
So this is like the number of US university facilities, which met the threshold of being

1215
01:21:30,680 --> 01:21:31,680
considered large.

1216
01:21:31,680 --> 01:21:33,680
In fact, the carbon polluters.

1217
01:21:33,680 --> 01:21:35,680
So 104, 103.

1218
01:21:35,680 --> 01:21:37,680
It kind of went up.

1219
01:21:37,680 --> 01:21:45,680
I mean, again, this is not anything kind of world breaking, but just interesting things.

1220
01:21:45,680 --> 01:21:46,680
It went down.

1221
01:21:46,680 --> 01:21:52,680
But there's no sort of obvious pattern of dipping like 90s, 80s.

1222
01:21:52,680 --> 01:21:53,680
So that's kind of interesting.

1223
01:21:53,680 --> 01:21:55,680
Other things, I guess.

1224
01:21:55,680 --> 01:21:58,680
I guess the mean you could look at.

1225
01:21:58,680 --> 01:22:03,680
Again, you'd be hoping to see these kind of on a downward trend.

1226
01:22:03,680 --> 01:22:07,680
So kind of a little bit, 81,000, 80,077.

1227
01:22:07,680 --> 01:22:10,680
But then starts going back up again.

1228
01:22:10,680 --> 01:22:14,680
Again, I'm not saying this is particularly, it's not statistically significant, but it's

1229
01:22:14,680 --> 01:22:17,680
not the direction you're hoping, right?

1230
01:22:17,680 --> 01:22:18,680
Okay.

1231
01:22:18,680 --> 01:22:19,680
Anyway, we'll look at that in a bit more detail.

1232
01:22:19,680 --> 01:22:23,680
C9, the subset of 11 emissions columns is time series data.

1233
01:22:23,680 --> 01:22:26,680
Generate a quick map plot, lib, line plot.

1234
01:22:26,680 --> 01:22:31,680
So we're going to select columns by a different way now.

1235
01:22:31,680 --> 01:22:36,680
Select from minus 11 position, index position.

1236
01:22:38,680 --> 01:22:49,680
So index df prep, excuse me, by that, which gives you those time series data.

1237
01:22:49,680 --> 01:22:54,680
To do a line plot easily, you need to transpose.

1238
01:22:54,680 --> 01:22:59,680
So you want to have your, each row is the year.

1239
01:22:59,680 --> 01:23:03,680
And then obviously along, this is each university facility that way.

1240
01:23:03,680 --> 01:23:05,680
And then you can easily plot.

1241
01:23:10,680 --> 01:23:11,680
Oh, yeah.

1242
01:23:11,680 --> 01:23:13,680
That's why I said legend equals false.

1243
01:23:15,680 --> 01:23:19,680
So there, again, just a really quick plot just so you can see.

1244
01:23:19,680 --> 01:23:26,680
So yeah, again, like, you know, Reuters and me, like, I think there's something, I don't

1245
01:23:26,680 --> 01:23:32,680
know, this is just surprising that, hey, there's so many, this is the threshold 25,000, we're

1246
01:23:32,680 --> 01:23:35,680
assuming, but yeah, there's just a lot.

1247
01:23:35,680 --> 01:23:38,680
This is really a lot.

1248
01:23:38,680 --> 01:23:39,680
That's actually MSU.

1249
01:23:39,680 --> 01:23:44,680
Even though it's coming down, but it's like, I don't know.

1250
01:23:44,680 --> 01:23:47,680
It was just interesting because I was like, you know, they're all like, oh yeah, look

1251
01:23:47,680 --> 01:23:52,680
at, come in, you know, sign up for our masters on, you know, environmental, and I'm like,

1252
01:23:52,680 --> 01:23:54,680
look at you, you know.

1253
01:23:54,680 --> 01:23:56,680
Anyway, sorry.

1254
01:23:56,680 --> 01:24:01,680
Not like I'm like the perfect, you know, perfect green activist.

1255
01:24:01,680 --> 01:24:02,680
Okay, C9.

1256
01:24:02,680 --> 01:24:03,680
So there we go.

1257
01:24:03,680 --> 01:24:05,680
But I, oh, okay, I said this, didn't I?

1258
01:24:05,680 --> 01:24:06,680
Fine.

1259
01:24:06,680 --> 01:24:07,680
C10.

1260
01:24:07,680 --> 01:24:08,680
Okay.

1261
01:24:08,680 --> 01:24:13,680
You could optionally check, you could check whether all those values are in fact above

1262
01:24:13,680 --> 01:24:14,680
25,000 or nan.

1263
01:24:14,680 --> 01:24:17,680
So you can do it in your own time.

1264
01:24:17,680 --> 01:24:18,680
C11.

1265
01:24:18,680 --> 01:24:21,680
Final task for section C. Create a new cumulative column with the sum of each facility's reported

1266
01:24:21,680 --> 01:24:23,680
emissions data over the 11 years.

1267
01:24:23,680 --> 01:24:24,680
Review the modification.

1268
01:24:24,680 --> 01:24:25,680
Okay.

1269
01:24:25,680 --> 01:24:26,680
So we're making a new column.

1270
01:24:26,680 --> 01:24:37,680
So remember, just like creating a key value pair for a dictionary, give it a label, and

1271
01:24:37,680 --> 01:24:41,680
then we're basically summing those columns.

1272
01:24:41,680 --> 01:24:48,680
So access those columns again, as the same way with the block operator, sum, tell it

1273
01:24:48,680 --> 01:24:55,680
to sum across the columns access as opposed to the rows.

1274
01:24:55,680 --> 01:24:58,680
Seems to be correct.

1275
01:24:58,680 --> 01:25:03,680
Let's find out if that has worked as expected.

1276
01:25:03,680 --> 01:25:05,680
Oh, phew.

1277
01:25:05,680 --> 01:25:06,680
Okay.

1278
01:25:06,680 --> 01:25:07,680
Yay.

1279
01:25:07,680 --> 01:25:12,680
So you should have a cumulative column, excuse me, here, and then you could also see some

1280
01:25:12,680 --> 01:25:19,680
of that if you want to just see how much total carbon pollution these facilities have been

1281
01:25:19,680 --> 01:25:21,680
responsible for creating.

1282
01:25:21,680 --> 01:25:24,680
Oh, in fact, I figured it out for you.

1283
01:25:24,680 --> 01:25:27,680
So C12, 11, Jesus, no.

1284
01:25:27,680 --> 01:25:32,680
118 university, US university facilities are responsible for approximately 96 million tons

1285
01:25:32,680 --> 01:25:35,680
of carbon pollution from 2011 to 2021.

1286
01:25:35,680 --> 01:25:41,680
Now, I don't know if that's, you know, I can't give you any context for that, but that seems

1287
01:25:41,680 --> 01:25:43,680
like a lot.

1288
01:25:43,680 --> 01:25:44,680
Okay.

1289
01:25:44,680 --> 01:25:47,680
Now, the main wrangling cleaning is over.

1290
01:25:47,680 --> 01:25:49,680
We can actually do stuff.

1291
01:25:49,680 --> 01:25:50,680
Phew.

1292
01:25:50,680 --> 01:25:52,680
I'll also just show you where we're going.

1293
01:25:52,680 --> 01:25:58,680
So some basic mapping, then some interactive mapping, and then we do the kind of pandas

1294
01:25:58,680 --> 01:26:04,680
statistical graphs, which I know are less fancy, but probably more informative.

1295
01:26:04,680 --> 01:26:09,680
So D intro, for this mapping section D and E, we use the geographic pandas extension,

1296
01:26:09,680 --> 01:26:12,680
GeoPandas, to create a GeoDataFrame object.

1297
01:26:12,680 --> 01:26:16,680
So a GeoDataFrame is a pandas data frame that has a column with geometry and extends pandas

1298
01:26:16,680 --> 01:26:18,680
functionality in order to make basic maps.

1299
01:26:18,680 --> 01:26:23,680
Some people use GeoPandas, a little bit, yeah, okay.

1300
01:26:23,680 --> 01:26:25,680
Okay, so some people have heard about it.

1301
01:26:25,680 --> 01:26:26,680
That's helpful.

1302
01:26:26,680 --> 01:26:32,680
I'm like, it's really a shame because it's like, it's basically all the JavaScript, like,

1303
01:26:32,680 --> 01:26:37,680
productivity stuff, which really, that's the best way to engage people, like kids with

1304
01:26:37,680 --> 01:26:41,680
Python, not the actual Python, which is the problem.

1305
01:26:41,680 --> 01:26:47,680
Anyway, D0, import GeoPandas with its conventional alias, which is GPD.

1306
01:26:47,680 --> 01:26:49,680
Create a GeoPand, brain.

1307
01:26:49,680 --> 01:26:56,680
D1, create a GeoDataFrame called GeoDF using DF prep, repeat the new object.

1308
01:26:56,680 --> 01:27:01,680
So GPD, Geo, excuse me, DataFrame.

1309
01:27:01,680 --> 01:27:12,680
Okay, so you pass it the prep DataFrame, and then we need to make some geometry.

1310
01:27:12,680 --> 01:27:20,680
In this case, using the longitude and latitude columns in that DataFrame, the previous DataFrame.

1311
01:27:26,680 --> 01:27:30,680
Okay, so this column, longitude.

1312
01:27:30,680 --> 01:27:33,680
So, and also remember, so points from XY.

1313
01:27:33,680 --> 01:27:36,680
So, everyone says like lat long, right?

1314
01:27:36,680 --> 01:27:42,680
Actually, longitude is actually the X axis, and latitude is actually the Y.

1315
01:27:42,680 --> 01:27:48,680
So if you're doing geospatial things, obviously for people who really do it, then I don't want to tell you stuff you already know,

1316
01:27:48,680 --> 01:27:54,680
but for people who it's new, just be aware that you're passing the right thing to the right axis,

1317
01:27:54,680 --> 01:28:02,680
and that will really, you'll get some like weird US plot kind of, not on the right dimensions.

1318
01:28:02,680 --> 01:28:08,680
DF prep, and then give it latitude.

1319
01:28:08,680 --> 01:28:13,680
I'm like, snacks? Yay, thank you.

1320
01:28:13,680 --> 01:28:15,680
Oh, that's service.

1321
01:28:15,680 --> 01:28:17,680
Sorry, anyway.

1322
01:28:17,680 --> 01:28:20,680
Okay, so actually, I'll just run that just to see what, make sure.

1323
01:28:20,680 --> 01:28:22,680
So I haven't assigned that yet, but yeah.

1324
01:28:22,680 --> 01:28:23,680
So there we go.

1325
01:28:23,680 --> 01:28:24,680
You would get the geometry.

1326
01:28:24,680 --> 01:28:30,680
It doesn't look like much because it's just the lat and long, or long and then lat.

1327
01:28:30,680 --> 01:28:34,680
But yeah, the stuff you can do that once you've got that is really cool.

1328
01:28:34,680 --> 01:28:37,680
Geo, heads.

1329
01:28:37,680 --> 01:28:38,680
So there we go.

1330
01:28:38,680 --> 01:28:39,680
Okay, perfect.

1331
01:28:39,680 --> 01:28:42,680
So there we are, points.

1332
01:28:42,680 --> 01:28:43,680
And then now you've got the points.

1333
01:28:43,680 --> 01:28:48,680
So D2, generate a default plot of this new Geo DataFrame, GeoDF,

1334
01:28:48,680 --> 01:28:53,680
then try a customized plot where the color of the points is based on their cumulative column values.

1335
01:28:53,680 --> 01:28:54,680
Okay, sorry, I'll do this.

1336
01:28:54,680 --> 01:28:55,680
So we'll do this in order.

1337
01:28:55,680 --> 01:28:58,680
GFDF, GeoDF plot.

1338
01:28:58,680 --> 01:29:03,680
So this is your kind of quick and, I don't want to say dirty, but quick plot.

1339
01:29:03,680 --> 01:29:11,680
So as you can see, those points just are just like a, you know, 2D, Cartesian space.

1340
01:29:11,680 --> 01:29:16,680
But it does look like in the shape of the US, as it should.

1341
01:29:16,680 --> 01:29:26,680
Then if you actually want those points, for example, to relate to an actual column, you can pass that column.

1342
01:29:26,680 --> 01:29:34,680
So now it varies, but we haven't chosen the colors and they are not very interpretable.

1343
01:29:34,680 --> 01:29:39,680
So then you can pass your own color map.

1344
01:29:39,680 --> 01:29:42,680
Cool.

1345
01:29:42,680 --> 01:29:45,680
So yeah, stuff like that.

1346
01:29:45,680 --> 01:29:48,680
So D3.

1347
01:29:48,680 --> 01:29:54,680
Okay, so evidently GeoDF plot needs a base map to contextualize the points.

1348
01:29:54,680 --> 01:30:00,680
Load one of GeoPanda's available datasets, natural earth low res, assign to base map, then plot.

1349
01:30:00,680 --> 01:30:14,680
So, this is really the basic, you know, you're kind of just using pre-existing sort of toy datasets.

1350
01:30:14,680 --> 01:30:21,680
And then the next session we'll kind of do something more customized.

1351
01:30:21,680 --> 01:30:28,680
But base map.

1352
01:30:28,680 --> 01:30:34,680
But yeah, the point is also to kind of show you that it's like, I'm not saying this is obviously the coolest stuff in the world,

1353
01:30:34,680 --> 01:30:37,680
but, you know, it doesn't take a lot of code.

1354
01:30:37,680 --> 01:30:41,680
You didn't need a lot of resources and you can create something which is, you know, usable.

1355
01:30:41,680 --> 01:30:42,680
So there we go.

1356
01:30:42,680 --> 01:30:46,680
That's your base map.

1357
01:30:46,680 --> 01:30:52,680
And then optionally, just to get a sense of what the geometry data represents and enables.

1358
01:30:52,680 --> 01:30:53,680
Okay, I'm not.

1359
01:30:53,680 --> 01:30:55,680
Actually, okay, I'll let you do that step.

1360
01:30:55,680 --> 01:31:00,680
But this is just to kind of show you, like, you know, those kind of geometries.

1361
01:31:00,680 --> 01:31:04,680
When you look at the, there's me trying to be clever and skip things.

1362
01:31:04,680 --> 01:31:10,680
So when you look at geometry and there's like polygons, multipolygons, that's what those polygons are, right?

1363
01:31:10,680 --> 01:31:13,680
Like they're shapes.

1364
01:31:13,680 --> 01:31:15,680
It's kind of the easiest way I can explain to you.

1365
01:31:15,680 --> 01:31:19,680
But I'm sure there's, you know, geospatial experts who can tell you more.

1366
01:31:19,680 --> 01:31:26,680
Okay, so there's also a CRS thing, which if you were doing more of this, you probably want to look at, but we'll skip that.

1367
01:31:26,680 --> 01:31:27,680
So D6.

1368
01:31:27,680 --> 01:31:32,680
Use mapplotlib to construct a basic map which plots geodf and base map together,

1369
01:31:32,680 --> 01:31:40,680
Featured the location of the 118 large university emitters and the relative size of their cumulative emissions over 2011 and 2021.

1370
01:31:40,680 --> 01:31:46,680
So as you can imagine, we're basically just taking those points and then putting it on that base map.

1371
01:31:46,680 --> 01:31:49,680
And then it actually looks like something meaningful.

1372
01:31:49,680 --> 01:31:53,680
Oh, my favorite.

1373
01:31:53,680 --> 01:31:54,680
Sorry.

1374
01:31:54,680 --> 01:31:56,680
I have to stop having attitude.

1375
01:31:56,680 --> 01:32:03,680
Okay, so let's do set up sort of base bare bones.

1376
01:32:03,680 --> 01:32:06,680
Base mapplot.

1377
01:32:06,680 --> 01:32:10,680
It does need to be on axis though, or else it's not going to show.

1378
01:32:10,680 --> 01:32:12,680
Then so that's your background thing.

1379
01:32:12,680 --> 01:32:15,680
Then your points.

1380
01:32:15,680 --> 01:32:19,680
Then you plot those on top.

1381
01:32:19,680 --> 01:32:21,680
And then so that would work, right?

1382
01:32:21,680 --> 01:32:23,680
Now you'd be like, oh, it really hasn't worked.

1383
01:32:23,680 --> 01:32:31,680
But actually, it has actually plotted those points, but because they're on the same default blue, like the west coast just looks kind of bulgy, right?

1384
01:32:31,680 --> 01:32:35,680
So hence why you need to start doing some customization.

1385
01:32:35,680 --> 01:32:40,680
So as before, column equals cumulative.

1386
01:32:40,680 --> 01:32:42,680
Let's give it a different seam up.

1387
01:32:42,680 --> 01:32:49,680
This is nicer colors.

1388
01:32:49,680 --> 01:32:54,680
What else did I do? Oh, is that it?

1389
01:32:54,680 --> 01:33:02,680
No.

1390
01:33:02,680 --> 01:33:07,680
Sorry.

1391
01:33:07,680 --> 01:33:24,680
Deep plugging.

1392
01:33:24,680 --> 01:33:26,680
Oh, sorry.

1393
01:33:26,680 --> 01:33:28,680
I put it in the wrong call.

1394
01:33:28,680 --> 01:33:29,680
See, why didn't someone.

1395
01:33:29,680 --> 01:33:30,680
I'm joking.

1396
01:33:30,680 --> 01:33:31,680
Your fault.

1397
01:33:31,680 --> 01:33:34,680
No, I'm joking.

1398
01:33:34,680 --> 01:33:36,680
Cool.

1399
01:33:36,680 --> 01:33:44,680
Nothing better than live debugging on a recording.

1400
01:33:44,680 --> 01:33:47,680
Autumn equals R.

1401
01:33:47,680 --> 01:33:50,680
That's not going to work.

1402
01:33:50,680 --> 01:33:55,680
So there, you know, it's not going to set the world alight, but yeah.

1403
01:33:55,680 --> 01:34:01,680
Okay, I should just I'll just make this bigger just to show that is actually usable.

1404
01:34:01,680 --> 01:34:02,680
So yeah.

1405
01:34:02,680 --> 01:34:09,680
So like I said, it's not beautiful, but you didn't have to do a lot of work to get there and does tell you stuff.

1406
01:34:09,680 --> 01:34:10,680
Right.

1407
01:34:10,680 --> 01:34:11,680
Okay.

1408
01:34:11,680 --> 01:34:16,680
So section E, this is where we basically do fancier version.

1409
01:34:16,680 --> 01:34:18,680
Because of JavaScript.

1410
01:34:18,680 --> 01:34:20,680
But you shouldn't say that at a conference.

1411
01:34:20,680 --> 01:34:23,680
So actually, Matt, data set for regional trends.

1412
01:34:23,680 --> 01:34:24,680
And this is the interaction version.

1413
01:34:24,680 --> 01:34:37,680
So he intro in this section, we extend our Gia pandas extension of pandas with folium and optional Gia pandas dependency, which provides interactive mapping from the open source leaflet JS library via panda.

1414
01:34:37,680 --> 01:34:40,680
Python interface.

1415
01:34:40,680 --> 01:34:46,680
So easier and portfolio.

1416
01:34:46,680 --> 01:34:53,680
E one test out the extended Gia pandas functionality that folium now enables so called explore on base map.

1417
01:34:53,680 --> 01:34:54,680
So right.

1418
01:34:54,680 --> 01:34:55,680
This is the same base map as before.

1419
01:34:55,680 --> 01:34:56,680
Right.

1420
01:34:56,680 --> 01:34:58,680
But now you've got folium.

1421
01:34:58,680 --> 01:35:01,680
Now.

1422
01:35:01,680 --> 01:35:02,680
Now it's interactive.

1423
01:35:02,680 --> 01:35:04,680
I mean, that's basically the same data.

1424
01:35:04,680 --> 01:35:05,680
Right.

1425
01:35:05,680 --> 01:35:07,680
But it's just like.

1426
01:35:07,680 --> 01:35:09,680
Flashy.

1427
01:35:09,680 --> 01:35:10,680
And does stuff.

1428
01:35:10,680 --> 01:35:11,680
Okay.

1429
01:35:11,680 --> 01:35:18,680
So, etu, rather than using a world map as a base layer to plot to us only data, let's prepare a regional map.

1430
01:35:18,680 --> 01:35:26,680
Read in the US census states shape file we double checked in section a creating another geo data frame and assign it to us state boundaries.

1431
01:35:26,680 --> 01:35:31,680
Okay, so this is where I've been like, make sure you've got the shape file.

1432
01:35:31,680 --> 01:35:35,680
Because then this will not work if you don't.

1433
01:35:35,680 --> 01:35:44,680
So passing the file path to that shp extension file.

1434
01:35:44,680 --> 01:35:50,680
Like you know I never really understand why this works but it did you know it does it's some sort of magic.

1435
01:35:50,680 --> 01:35:56,680
So, again, thank you jio pandas people.

1436
01:35:56,680 --> 01:36:02,680
Developers.

1437
01:36:02,680 --> 01:36:05,680
So you could run that again you could see what those boundaries.

1438
01:36:05,680 --> 01:36:12,680
You know look like interactively, but you know, as you imagine they are.

1439
01:36:12,680 --> 01:36:15,680
Shapes of the US states.

1440
01:36:15,680 --> 01:36:31,680
So, he for three a plotting routine harnessing folium extended capabilities of jio pandas via jio DF and US state boundaries construct an improved version of our D six basic map, namely an interactive map that visualizes the location of the

1441
01:36:31,680 --> 01:36:39,680
of the 118 large university emitters and the relative size of their cumulative emissions over 2011 and 2021.

1442
01:36:39,680 --> 01:36:53,680
Okay, so we'll do this again, just like bare minimum steps right so base layer equals us state boundaries, explore so it's that census data, like fancier.

1443
01:36:53,680 --> 01:36:55,680
That's your absolute minimum.

1444
01:36:55,680 --> 01:37:04,680
So then you take the geo DF, you know, which has got our points, the actual data we want to plot.

1445
01:37:04,680 --> 01:37:09,680
And then, explore, explore.

1446
01:37:09,680 --> 01:37:13,680
So basically calling explore.

1447
01:37:13,680 --> 01:37:26,680
But we're saying, m equals base labor. So basically, like, put this on an existing map instance, which is that base layer that you just created the line before.

1448
01:37:26,680 --> 01:37:30,680
And then actually that's it, then you can just call base layer.

1449
01:37:30,680 --> 01:37:37,680
I think, as your absolute minimum right. So again default blues.

1450
01:37:37,680 --> 01:37:41,680
So that gives you all the data.

1451
01:37:41,680 --> 01:37:55,680
But yeah, so that does work, but obviously, you know you want to customize that and that's where all these other things are. So I'm not going to go through all them because they are pretty intuitive.

1452
01:37:55,680 --> 01:38:06,680
So if you do that, that kind of like customize as the base layer so that's where you, you know, I've just changed colors, made things like, with your.

1453
01:38:06,680 --> 01:38:08,680
This stuff here.

1454
01:38:08,680 --> 01:38:13,680
These options here for the geo DF explore.

1455
01:38:13,680 --> 01:38:20,680
Or just to make the points more interesting, relevant, less irrelevant.

1456
01:38:20,680 --> 01:38:27,680
So there are so kind of colors things, and then only gives you particular information, not everything.

1457
01:38:27,680 --> 01:38:36,680
No, and then you'll also you can save it as an HTML. Okay, so I'll just take this quick more point to point out.

1458
01:38:36,680 --> 01:38:41,680
So, whilst doing this through doing this tutorial.

1459
01:38:41,680 --> 01:38:43,680
I discovered.

1460
01:38:43,680 --> 01:38:55,680
So here we go so Boston, you've got four university facilities which are large polluters or these you know within this 2011 to 2021 period.

1461
01:38:55,680 --> 01:39:03,680
Which are actually you can't see it right you can't click very well actually if you zoom in too far but they are basically Boston University MIT.

1462
01:39:03,680 --> 01:39:12,680
This is that Harvard facility. There's northeast and I think whatever you get the idea. So as a transpires.

1463
01:39:12,680 --> 01:39:15,680
I discovered that.

1464
01:39:15,680 --> 01:39:19,680
Okay, so

1465
01:39:19,680 --> 01:39:22,680
See the learning through doing so.

1466
01:39:22,680 --> 01:39:32,680
However, so this is that now owned by Harvard, Cambridge Austin Blackstone power plant which featured in that royalties article I showed you.

1467
01:39:32,680 --> 01:39:39,680
So, I grew up as a toddler here in Pima de Terris.

1468
01:39:39,680 --> 01:39:46,680
So, whilst my parents, my dad was a poor grad student, I shouldn't say that recording but yeah so and he couldn't. I should also say that.

1469
01:39:46,680 --> 01:39:48,680
But this is a cheap.

1470
01:39:48,680 --> 01:39:55,680
This is the cheap grad accommodation for Harvard. And this is the expensive apparently accommodation for it.

1471
01:39:55,680 --> 01:40:00,680
Which I don't know I mean obviously it's still within the boundaries of three miles and I say three miles because that's what the EPA.

1472
01:40:00,680 --> 01:40:02,680
So here we go.

1473
01:40:02,680 --> 01:40:14,680
So three miles which is 4828 meters approximately, which is this. I use this radius here because that's what the EPA reference in terms of the impact of looking at the impact of facilities on surrounding communities.

1474
01:40:14,680 --> 01:40:17,680
So I lived.

1475
01:40:17,680 --> 01:40:22,680
I was breathing in that sweet sweet air as a child.

1476
01:40:22,680 --> 01:40:24,680
So we did move out.

1477
01:40:24,680 --> 01:40:35,680
We moved out to Belmont for like, which you know is outside the three miles but you know it's still, you know, there's, there's a lot of cumulative smoke and stuff there which is fun.

1478
01:40:35,680 --> 01:40:38,680
So, yeah, that just kind of.

1479
01:40:38,680 --> 01:40:48,680
It kind of makes this like more real but also like, you know, what about the people who still live there, you know, under this fossil fuel behemoth.

1480
01:40:48,680 --> 01:40:55,680
Anyway, okay, so enough of the sentimentality sentimentality.

1481
01:40:55,680 --> 01:40:57,680
Excuse me, E5.

1482
01:40:57,680 --> 01:41:02,680
So this is that heat map I showed you earlier it looks really pretty.

1483
01:41:02,680 --> 01:41:15,680
It's probably the most impactful but probably the kind of least, the least kind of scientific Python aspect of this. So that's why I said it was optional but again this is just another tool for your toolkit, you know, especially, I shouldn't be mean.

1484
01:41:15,680 --> 01:41:18,680
So non technical stakeholders they love this.

1485
01:41:18,680 --> 01:41:26,680
You know this always really gets them engaged, and then you can like show them like actual science.

1486
01:41:26,680 --> 01:41:27,680
Sorry, I shouldn't be mean.

1487
01:41:27,680 --> 01:41:34,680
So yeah, so you can go through that it's pretty self explanatory you just need points, just sort of a list of points.

1488
01:41:34,680 --> 01:41:38,680
Okay, so section F, how are we doing for time.

1489
01:41:38,680 --> 01:41:40,680
Not bad.

1490
01:41:40,680 --> 01:41:41,680
Okay.

1491
01:41:41,680 --> 01:41:44,680
So data for statistical trends.

1492
01:41:44,680 --> 01:41:47,680
So,

1493
01:41:47,680 --> 01:41:58,680
F0, copy df prep and assign to df trends which we will prep for developing statistical graphs and have a look at the new data frame. So, copy df.

1494
01:41:58,680 --> 01:42:01,680
Create the trends data frame.

1495
01:42:01,680 --> 01:42:06,680
It's exactly what you expect but you know, just

1496
01:42:06,680 --> 01:42:10,680
for best practice. So yeah, but you can see here.

1497
01:42:10,680 --> 01:42:12,680
There's a geometry column.

1498
01:42:12,680 --> 01:42:19,680
I'm not going to be truly transparent. It's kind of weird. I don't know why this, this kind of has been added to this that df prep.

1499
01:42:19,680 --> 01:42:22,680
There might be some sort of hang up so but you do need to.

1500
01:42:22,680 --> 01:42:24,680
Excuse me, do you need to delete that.

1501
01:42:24,680 --> 01:42:28,680
If anyone can tell me why

1502
01:42:28,680 --> 01:42:32,680
geometry was added to a different

1503
01:42:32,680 --> 01:42:38,680
a different object in memory, then please tell me.

1504
01:42:38,680 --> 01:42:53,680
So now you delete that F2, the statistical graphs we're developing plot each facility separately, and also separately within state subsets. It's now useful for the row labels to be meaningful, rather than the integer index created by default by the original pandas read CSV call.

1505
01:42:53,680 --> 01:43:04,680
Set the index of df trends using the existing columns facility and state, making the change in place. Okay, so, I mean this makes more sense if I just show you.

1506
01:43:04,680 --> 01:43:18,680
So, basically now we want those two columns facility and state to be the index, we can then, you know, call rows by their name, as opposed to by like 512 118.

1507
01:43:18,680 --> 01:43:29,680
So set the index to be these two columns facility state

1508
01:43:29,680 --> 01:43:33,680
in place equals true.

1509
01:43:33,680 --> 01:43:39,680
So now, you should see that.

1510
01:43:39,680 --> 01:43:43,680
So there. Now that's multi index.

1511
01:43:43,680 --> 01:43:52,680
I mean, each of those facilities is unique. So, but then obviously you've got the state, and then that kind of tuple, you know, is a unique combo.

1512
01:43:52,680 --> 01:44:02,680
Okay, so, F3 the statistical graphs we're developing only need the columns with stats data. Now the essential non stats data is in the, excuse me, is now the row label.

1513
01:44:02,680 --> 01:44:09,680
Drop the slice of columns from g, h, g, r, p to parent companies.

1514
01:44:09,680 --> 01:44:20,680
So, df trends drop. Again, sorry, this is not exciting data wrangling, but you know, the end result I think is quite interesting. So, you know, worth it.

1515
01:44:20,680 --> 01:44:41,680
So drop that slice of columns, all the rows. So, excuse me, by labels, gh, g, r, p, id, id equals even to parent companies, which is inclusive.

1516
01:44:41,680 --> 01:44:56,680
As you'll see, axis equals one. So remember, it's like, look at the columns, because you're not going to find it in the rows in place equals true.

1517
01:44:56,680 --> 01:45:10,680
Df trends, please have worked. Yep. I couldn't remember what I was supposed to, I couldn't remember what we were supposed to be doing. Yeah, so basically now, that's great. We just now have the stats data.

1518
01:45:10,680 --> 01:45:21,680
Okay, F4, generate one of the target statistical graphs, namely a horizontal stacked bar chart of each facility is reported, year emissions ordering the facilities by their cumulative value.

1519
01:45:21,680 --> 01:45:30,680
That description is really like doesn't really tell you, as it lots of descriptions of code, it doesn't really tell you what you're actually doing.

1520
01:45:30,680 --> 01:45:39,680
But yeah, hopefully this will be more intuitive. So, okay, you're storing these by this cumulative column, which is why we kept it in, but we're not going to plot it.

1521
01:45:39,680 --> 01:45:48,680
So as I said, remember, it's always going to do ascending equals true. So there we go. See, Howard is that, you know, only hit the threshold once and never again.

1522
01:45:48,680 --> 01:45:54,680
She's a little sus to me, but anyway.

1523
01:45:54,680 --> 01:46:03,680
Okay, so, but we actually only want to plot the stats, the time series data. So use the local operator again.

1524
01:46:03,680 --> 01:46:13,680
You just want these columns and only to 2021, not to the end. Right. So then that will just select that.

1525
01:46:13,680 --> 01:46:23,680
Then you can plot tell that you want a stacked bar, a horizontal. Sorry, this is bar H is horizontal bar stacked equals true.

1526
01:46:23,680 --> 01:46:36,680
Is that a stacked horizontal bar? You could run that, but try and put everything in one because this does take a while to render because it is computationally meaty.

1527
01:46:36,680 --> 01:46:53,680
Give us fixed size, take out the legend, make the font size small because you're trying to fit 118 rows.

1528
01:46:53,680 --> 01:46:59,680
So, again, that's not obviously how, you know, like this is not massively readable.

1529
01:46:59,680 --> 01:47:03,680
You would do other things to make that. Oops. See, and that doesn't really work either.

1530
01:47:03,680 --> 01:47:08,680
But yeah, obviously it is interesting. I'll read this for you more. You can see on your own.

1531
01:47:08,680 --> 01:47:17,680
So, yeah, as I said, that was MSU, unfortunately, loads of loads of emissions every year.

1532
01:47:17,680 --> 01:47:25,680
So, yeah, you know, from a statistical perspective, you say it's sort of a, you know, they serve these heavy, really heavy, heavy polluters.

1533
01:47:25,680 --> 01:47:30,680
And then, I don't know, maybe like a actually, you know, like half of the is that half?

1534
01:47:30,680 --> 01:47:35,680
But a lot of the data said actually not not that much.

1535
01:47:35,680 --> 01:47:41,680
Some of them, you know, are every year. Some of them only a few years. So like, who's that? Missouri.

1536
01:47:41,680 --> 01:47:47,680
There's only four years, you know, so there's there's going to be some interesting stuff if you delved into that.

1537
01:47:47,680 --> 01:47:55,680
Anyway, just show you stuff you can do. OK, F5. OK, we're on the final track for the last graph.

1538
01:47:55,680 --> 01:48:00,680
And then we'll have another 10 minute break. F5, prepare for generating the final graph,

1539
01:48:00,680 --> 01:48:09,680
visualizing the time series of each facility, but in subplots by state and only for the 12 states with the worst aggregate cumulative emissions.

1540
01:48:09,680 --> 01:48:16,680
So compute the state level aggregate cumulative emissions.

1541
01:48:16,680 --> 01:48:21,680
So regroup by the states.

1542
01:48:21,680 --> 01:48:27,680
Just know an index so that I don't think does anything. Yeah.

1543
01:48:27,680 --> 01:48:33,680
Pull out the cumulative column, cumulative column, cumulative,

1544
01:48:33,680 --> 01:48:37,680
which is also doesn't give you anything. I always forget what you can see and what doesn't.

1545
01:48:37,680 --> 01:48:44,680
But yeah, then you can sum it and then you've got, you know, that's like all the facilities in each state rolled up to the state level.

1546
01:48:44,680 --> 01:48:50,680
Again, that is alphabetical by default, which, you know, maybe it's sometimes what you want.

1547
01:48:50,680 --> 01:48:54,680
It's not what we want. So F6, reuse the code from F5.

1548
01:48:54,680 --> 01:49:03,680
But this time, sort the default alphabetical output from worst to best, i.e. from large, excuse me, from big to small,

1549
01:49:03,680 --> 01:49:08,680
and access just the first 12 indices and then assign this expression to worst 12 states.

1550
01:49:08,680 --> 01:49:13,680
So what was I doing here?

1551
01:49:13,680 --> 01:49:18,680
It's weird. Okay, sorry. The format is just weird.

1552
01:49:18,680 --> 01:49:26,680
Sort values. So let's now sort the values ascending equals false,

1553
01:49:26,680 --> 01:49:32,680
which is in that. So no surprise Michigan, because it's got MSU and other things.

1554
01:49:32,680 --> 01:49:37,680
Perdu, I think. But then now we just want the 12.

1555
01:49:37,680 --> 01:49:41,680
We just want the index and we just want 12 of these.

1556
01:49:41,680 --> 01:49:48,680
So index 12, which gives you that and then save that down.

1557
01:49:48,680 --> 01:49:53,680
Worst 12 states. Okay. And then you can see that again.

1558
01:49:53,680 --> 01:50:01,680
I mean, you really need to. Okay. F7, assign a copy of DFTrends without the cumulative column to a variable DFTimeSeries.

1559
01:50:01,680 --> 01:50:09,680
So, yeah, sorry. I know this is a very faffy, but, you know, it will all come together in the final graph.

1560
01:50:09,680 --> 01:50:20,680
So we want to drop cumulative. You can just drop it by label because it's just one of them. Copy DFTimeSeries.

1561
01:50:20,680 --> 01:50:27,680
So double check, because this is what we're going to make generate all the plots from.

1562
01:50:27,680 --> 01:50:35,680
So, yeah, perfect. Okay. F8, we're going to test how to select a cross section of DFTimeSeries using the multi index we set in F2,

1563
01:50:35,680 --> 01:50:41,680
specifically returning all the facilities in the state of Pennsylvania and then transpose for the line graphs.

1564
01:50:41,680 --> 01:50:47,680
So, I mean, you can try any, you know, you don't have to do PA. You could try something else.

1565
01:50:47,680 --> 01:50:52,680
But this is just to give you a sense because we're going to use that again in the final plotting routine.

1566
01:50:52,680 --> 01:51:01,680
So I'm just trying to show you the components. So the final result looks less weird. I mean, I'm not understandable.

1567
01:51:01,680 --> 01:51:11,680
So you select. So, yeah, so this obviously is just selected all the facilities in Pennsylvania.

1568
01:51:11,680 --> 01:51:18,680
And then transpose. I mean, obviously, this could be Utah, which is that.

1569
01:51:18,680 --> 01:51:26,680
Okay, so there is a bit of a prep here around how the axes work. You can read that if you need to.

1570
01:51:26,680 --> 01:51:30,680
But we'll just go straight to F now and make the final statistical graph. Yay.

1571
01:51:30,680 --> 01:51:34,680
Use Matplotlib to set up and generate state level time series subplots,

1572
01:51:34,680 --> 01:51:43,680
sharing the 2011 to 2021 emissions for each facility in the 12 states with the worst aggregate cumulative emissions.

1573
01:51:43,680 --> 01:51:51,680
I swear all these titles sound so much lengthier than, you know, it's so much more intuitive just to see it.

1574
01:51:51,680 --> 01:51:57,680
But okay, so subplots. Here we go. Let's do the absolute basic. I mean, that would be nothing in it.

1575
01:51:57,680 --> 01:52:01,680
But okay, let's show you. So remember, we've taken 12 states.

1576
01:52:01,680 --> 01:52:09,680
We're going to arrange that in 12 plots in a four by three effect fee arrangement.

1577
01:52:09,680 --> 01:52:14,680
So n rows equals four. Do I spell that right? Yes. n calls equals three.

1578
01:52:14,680 --> 01:52:22,680
So there we go. So your axes are just your plots. I mean, if you've worked with Matplotlib, you already know this.

1579
01:52:22,680 --> 01:52:31,680
But yeah, so four rows, three columns, and then that loop is going to generate the relevant time series.

1580
01:52:31,680 --> 01:52:37,680
Okay, so this loop state acts in zip.

1581
01:52:37,680 --> 01:52:44,680
So there's 12 more states and the axes, which we flattened as per the note above.

1582
01:52:44,680 --> 01:52:55,680
Flattened. And then we're basically going to loop through. We're going to go df time series, cut it by that state, which is in that.

1583
01:52:55,680 --> 01:53:05,680
That's where you access it in the index. Transpose, plot and plot it on that specific axis.

1584
01:53:05,680 --> 01:53:18,680
What does it look like? It's not defined.

1585
01:53:18,680 --> 01:53:27,680
So that's not very useful for you to see. So I'm going to, that's why I set the fixed size.

1586
01:53:27,680 --> 01:53:34,680
Okay, so that now you should effectively see is close to the end result.

1587
01:53:34,680 --> 01:53:42,680
So, you know, 12 more states, the time series for each facility in each state, and then the rest is just, you know, aesthetics.

1588
01:53:42,680 --> 01:53:51,680
So share why is just to make sure you can actually, you know, those, this actually slides up because obviously, you know, that is not the same as that.

1589
01:53:51,680 --> 01:53:59,680
Even though it looks like it's on the same level because of the scale. So this is just adjustment.

1590
01:53:59,680 --> 01:54:05,680
So share why equals true. Hence why I'm not going to type it. What else is here? So here we go.

1591
01:54:05,680 --> 01:54:13,680
These are just, you know, given a title. So format-y formatting-y things.

1592
01:54:13,680 --> 01:54:21,680
So that kind of just makes it look more, you know, readable. So there we go. Now you've got labels and bits.

1593
01:54:21,680 --> 01:54:28,680
And this is just, this is basically just for the x axis. So that looks kind of presentable or is presentable.

1594
01:54:28,680 --> 01:54:35,680
Oh, it's not going to be presentable there.

1595
01:54:35,680 --> 01:54:45,680
Ta-da, ta-da, ta-da. So, yeah, that's just like I said, just adjust the labels.

1596
01:54:45,680 --> 01:54:50,680
And so F9. So final bit of this session. So comment.

1597
01:54:50,680 --> 01:54:55,680
Different approaches to carbon reporting. This is your, you know, real world interpretation.

1598
01:54:55,680 --> 01:54:58,680
Different approaches to carbon reporting and accountability could reveal different insights.

1599
01:54:58,680 --> 01:55:09,680
Instead of the EPA's GHGRP requiring individual facilities, exceeding the 25,000 carbon dioxide equivalent metric tons threshold to report their position,

1600
01:55:09,680 --> 01:55:13,680
there may be more interesting trends if this requirement was at parent level.

1601
01:55:13,680 --> 01:55:20,680
So I'll just tell you what I was thinking here. This is your sort of boring accountability thing. Accounting even.

1602
01:55:20,680 --> 01:55:28,680
So for example here, like, you know, like Yale, this is the green and the orange. Sorry if anyone's colorblind.

1603
01:55:28,680 --> 01:55:32,680
But yeah, so they both beat the threshold, but they're obviously individual. They're still reported.

1604
01:55:32,680 --> 01:55:37,680
But, you know, obviously if that was at Yale level, it'd be at least the sum of the two.

1605
01:55:37,680 --> 01:55:43,680
Then, of course, you've got all the other things. There could be other facilities that Yale manage, which don't meet the threshold.

1606
01:55:43,680 --> 01:55:48,680
You know, so then you're not seeing that full picture. And maybe that could be like even higher, you know.

1607
01:55:48,680 --> 01:55:56,680
But it's not going to be lower than some of these two. So that's why I'm saying that, you know, I would bet that there's some sort of accounting, you know,

1608
01:55:56,680 --> 01:56:03,680
nuances which don't necessarily make the full impact of university.

1609
01:56:03,680 --> 01:56:12,680
I mean, not just US university facilities like any facilities. Reporting at this level, I think, could hide a lot of trends, which could be pretty interesting.

1610
01:56:12,680 --> 01:56:16,680
Hello. What was your name again? Jackie, sorry.

1611
01:56:16,680 --> 01:56:20,680
Is the threshold for the data or the threshold not available?

1612
01:56:20,680 --> 01:56:28,680
No, correct. Exactly. So they're literally, you're only, it's, so the reporting requirement from 2011 was that, yeah, you meet the threshold.

1613
01:56:28,680 --> 01:56:36,680
You have to mandatory report. And then the threshold is not going to be developed from the rest of the data.

1614
01:56:36,680 --> 01:56:41,680
Yeah, exactly. So there's no, yeah.

1615
01:56:41,680 --> 01:56:51,680
And I guess the other thing I should mention, which is interesting, within that data on the EPA, you can actually see the, excuse me, you can see like more details.

1616
01:56:51,680 --> 01:57:03,680
What are the kind of chemical stuff, which is not my background, but you can actually see that the majority of these facilities, sorry, this isn't necessarily your question, but this is, you can see that these are all through stationary combustion.

1617
01:57:03,680 --> 01:57:11,680
So fossil fueling, you can see the fuel types. So it's basically all natural gas, gas and oil.

1618
01:57:11,680 --> 01:57:18,680
Someone, I think it's North, do I mean North Carolina?

1619
01:57:18,680 --> 01:57:26,680
One of these is coal, really heavy burning coal. Where is Carolina? No, where is Carolina?

1620
01:57:26,680 --> 01:57:34,680
I can't remember. One of these is burning.

1621
01:57:34,680 --> 01:57:41,680
Oh, oh yeah, sorry. Yes, that's it. NC Chapel Hill.

1622
01:57:41,680 --> 01:57:44,680
Sorry. Yes, exactly. Thank you. So this one.

1623
01:57:44,680 --> 01:57:46,680
So yeah, so that's coal.

1624
01:57:46,680 --> 01:57:55,680
That's kind of, you can see other articles online. Someone is burning tires, actually.

1625
01:57:55,680 --> 01:58:06,680
So, you know, there's just, there's stuff. There's like a whole stuff. So, you know, I really hope someone kind of does more reporting and like more insight onto this because, you know, like I said, Reuters and I both found it really fascinating.

1626
01:58:06,680 --> 01:58:14,680
I'm sure Reuters will be pleased to know I thought so. But yeah, anyway, sorry. That is, that's the end of the carbon pollution exploration.

1627
01:58:14,680 --> 01:58:22,680
And if you would like to take 10 minutes, then we will return and do deforestation.

1628
01:58:22,680 --> 01:58:31,680
I explore deforestation. We're not going to do deforestation. That would be very counterintuitive.

1629
01:58:31,680 --> 01:58:51,680
Please make sure you have, I mean, obviously you can manage your files, I'm sure. But yeah, you need to have, or this tutorial is set up, assuming that there is a subfolder called deforestation exp data, which has

1630
01:58:51,680 --> 01:59:05,680
TIFFs in it. So, there's four TIFFs, which hopefully you downloaded. This is the point where, did anyone, sorry, faffing with, okay, that's fine.

1631
01:59:05,680 --> 01:59:11,680
Did people manage to download or install VierX Array?

1632
01:59:11,680 --> 01:59:20,680
Or I guess, did anyone not manage to download VierX Array? Wow, yes. Okay, sorry. I thought that might be. So yes.

1633
01:59:20,680 --> 01:59:26,680
But don't worry, this is not a sort of shame moment. Just because, sorry.

1634
01:59:26,680 --> 01:59:38,680
Because I'll just tell you the issues with VierX Array. So VierX Array, which seems to be where the geospatial community are going in terms of raster import and export.

1635
01:59:38,680 --> 01:59:43,680
So it's kind of, instead of using raster IO, which people might have heard of.

1636
01:59:43,680 --> 01:59:53,680
But it does use, VierX Array does use raster IO. Raster IO requires GDAL, which is a C++ package.

1637
01:59:53,680 --> 02:00:04,680
And that does not work very well with Windows, basically. So to that extent, if you don't have VierX Array, which is fine.

1638
02:00:04,680 --> 02:00:10,680
I just need to tell you now, explain, and also for everyone else.

1639
02:00:10,680 --> 02:00:17,680
So I've set the tutorial, or I've developed the tutorial, so you've basically got like the VierX Array, I think I said this in the message.

1640
02:00:17,680 --> 02:00:21,680
You've got the VierX Array like workflow, which is just your normal stuff.

1641
02:00:21,680 --> 02:00:27,680
But then this is the, there's an alternative, basically as you can say, which doesn't need VierX Array.

1642
02:00:27,680 --> 02:00:30,680
And just effectively a kind of pill, numpy version.

1643
02:00:30,680 --> 02:00:46,680
So for people who are doing the alternative, there is steps, sort of parallel steps for the majority of the workflow, not the last section, which is optional anyway.

1644
02:00:46,680 --> 02:00:55,680
The difference mainly in the outputs is that because you're basically using, you're just basically plotting an array of numbers, there's no geospatial dimensions to it.

1645
02:00:55,680 --> 02:01:03,680
So there's no axes. But hopefully the idea is that, you know, at some point, you know, in the future, you might be able to figure out how to get VierX Array.

1646
02:01:03,680 --> 02:01:10,680
There's some non-official wheels that you can download.

1647
02:01:10,680 --> 02:01:15,680
So anyway, just so people know, so the way I'm going to run through is, I'm not going to go through the sort of numpy version.

1648
02:01:15,680 --> 02:01:19,680
It is there. So what I'll do is, I'll just kind of hide it, right?

1649
02:01:19,680 --> 02:01:23,680
And then people who need to do the alternative, obviously use the alternative.

1650
02:01:23,680 --> 02:01:25,680
Does that make sense? Okay.

1651
02:01:25,680 --> 02:01:32,680
So assuming that you do have this data, then, okay, we'll get started.

1652
02:01:32,680 --> 02:01:36,680
We are actually doing really well on time. Well, I say that now, and then we'll rush at the end.

1653
02:01:36,680 --> 02:01:44,680
So I was going to set the scene. So first of all, do people use spectral data?

1654
02:01:44,680 --> 02:01:49,680
Okay, yeah, great. So one person, this is going to be really boring for you.

1655
02:01:49,680 --> 02:01:56,680
Remote sensing stuff. If it's new, that's kind of great because then I can play you this video and it's kind of worthwhile.

1656
02:01:56,680 --> 02:02:01,680
So instead of me explaining it to you, because I actually am an economics grad,

1657
02:02:01,680 --> 02:02:14,680
I thought I would let the National Ecological Observatory Network explain a little bit of the space in which we're operating.

1658
02:02:14,680 --> 02:02:18,680
So we'll just go.

1659
02:02:18,680 --> 02:02:23,680
So.

1660
02:02:23,680 --> 02:02:27,680
CZ is there.

1661
02:02:27,680 --> 02:02:30,680
Sorry, we'll just do it again.

1662
02:02:30,680 --> 02:02:34,680
If you've ever used a camera, then you know something about spectral remote sensing.

1663
02:02:34,680 --> 02:02:41,680
Spectral related to the electromagnetic spectrum, which includes light that is both visible and invisible to human eyes.

1664
02:02:41,680 --> 02:02:46,680
And remote sensing, which involves measuring the properties of objects without directly touching them.

1665
02:02:46,680 --> 02:02:52,680
The typical camera that you use measures and records visible light that objects like trees and rock reflect.

1666
02:02:52,680 --> 02:02:58,680
This light might come from the sun, but it also might come from other sources like light bulbs.

1667
02:02:58,680 --> 02:03:02,680
While we often use cameras to take selfies and silly pictures of our furry friends,

1668
02:03:02,680 --> 02:03:09,680
scientists use high powered cameras called imaging spectrometers to measure changes in things that impact our environment,

1669
02:03:09,680 --> 02:03:13,680
like water quality or vegetation cover and health.

1670
02:03:13,680 --> 02:03:21,680
Imaging spectrometers mounted on airplanes and satellites help us create maps, like this vegetation cover map for the entire United States.

1671
02:03:21,680 --> 02:03:27,680
But how exactly do scientists measure changes to our environment using reflected light energy?

1672
02:03:27,680 --> 02:03:34,680
To answer this question, let's have a look at the electromagnetic spectrum, which is composed of thousands of wavelengths of energy.

1673
02:03:34,680 --> 02:03:41,680
Visible light, what we see with our eyes, is contained in the blue, green and red portions of the spectrum.

1674
02:03:41,680 --> 02:03:50,680
The rest of the spectrum is not visible to human eyes, but can be detected and recorded by sophisticated camera-like sensors called imaging spectrometers.

1675
02:03:50,680 --> 02:03:54,680
Now, there are thousands of wavelengths to record in the electromagnetic spectrum.

1676
02:03:54,680 --> 02:04:00,680
To deal with all these wavelengths, imaging spectrometers divide the spectrum into groups of wavelengths called bands.

1677
02:04:00,680 --> 02:04:08,680
For example, a band in the near-infrared region of the spectrum could include energy from 800 to 850 nanometers.

1678
02:04:08,680 --> 02:04:11,680
This band is useful to map healthy vegetation.

1679
02:04:11,680 --> 02:04:15,680
The width and number of bands is what we call the spectral resolution of an image.

1680
02:04:15,680 --> 02:04:19,680
Higher spectral resolution means more bands that are spectrally more narrow.

1681
02:04:19,680 --> 02:04:25,680
Lower spectral resolution means fewer bands, each of which covers more of the spectrum.

1682
02:04:25,680 --> 02:04:29,680
Now, imaging spectrometers measure reflected light energy.

1683
02:04:29,680 --> 02:04:36,680
You see, different objects reflect, absorb and transmit light differently, depending on their chemical and structural characteristics.

1684
02:04:36,680 --> 02:04:41,680
For example, plant leaves are green because they reflect more green light than blue or red light.

1685
02:04:41,680 --> 02:04:49,680
On the other hand, Fido the dog reflects more light in the red portion of the spectrum because of the chemical and structural makeup of his fur.

1686
02:04:49,680 --> 02:04:54,680
If Fido's chemical and structural makeup was the same as a plant's, then he would look green.

1687
02:04:54,680 --> 02:04:59,680
Now, when you point your camera towards your favorite canine doing something silly,

1688
02:05:00,680 --> 02:05:05,680
the camera records the amount of light reflected from the dog and its surroundings in the visible,

1689
02:05:05,680 --> 02:05:08,680
or red, green and blue, bands of the electromagnetic spectrum.

1690
02:05:08,680 --> 02:05:13,680
The camera creates what's called an RGB image, which is composed of millions of pixels.

1691
02:05:13,680 --> 02:05:19,680
Each pixel in the image contains a value representing the amount of red, green and blue light reflected.

1692
02:05:19,680 --> 02:05:23,680
We can break the image out into its red, green and blue bands too.

1693
02:05:23,680 --> 02:05:25,680
Here's the red band on its own.

1694
02:05:26,680 --> 02:05:29,680
Brighter pixels mean that more light was reflected by objects in the image

1695
02:05:29,680 --> 02:05:33,680
and recorded by the camera in the red part of the electromagnetic spectrum.

1696
02:05:33,680 --> 02:05:36,680
The darker parts are areas where less light was recorded.

1697
02:05:36,680 --> 02:05:43,680
When we combine the red, green and blue bands together, we get an image that looks similar to what we see through the camera lens.

1698
02:05:43,680 --> 02:05:49,680
We can plot the amount of red, green and blue light recorded in each pixel to create what's called a spectral signature.

1699
02:05:49,680 --> 02:05:54,680
In this signature, the amount of energy reflected in a particular wavelength is shown in the y-axis

1700
02:05:54,680 --> 02:05:57,680
and the full range of wavelengths that were measured by the camera.

1701
02:05:57,680 --> 02:06:01,680
In this case, blue, green and red is on the x-axis.

1702
02:06:01,680 --> 02:06:06,680
The spectral signature for phyto is quite different from the spectral signature for a plant.

1703
02:06:06,680 --> 02:06:09,680
This makes them appear visually different to our eyes too.

1704
02:06:09,680 --> 02:06:16,680
Differences in spectral signatures can help scientists identify different types of surfaces and objects within images.

1705
02:06:16,680 --> 02:06:20,680
Most cameras record light in the visible, or red, green and blue bands.

1706
02:06:21,680 --> 02:06:27,680
However, plants, dogs and other objects on the earth also reflect light that we can't see with our eyes.

1707
02:06:27,680 --> 02:06:33,680
For example, plants reflect up to 60% more light in the near-infrared portion of the electromagnetic spectrum

1708
02:06:33,680 --> 02:06:36,680
than they do in the green portion of the spectrum.

1709
02:06:36,680 --> 02:06:40,680
This is why differences in reflected light in the near-infrared portion of the spectrum

1710
02:06:40,680 --> 02:06:43,680
are important for mapping vegetation on the ground.

1711
02:06:43,680 --> 02:06:48,680
To measure these differences in the non-visible portion of the spectrum, we use imaging spectrometers,

1712
02:06:48,680 --> 02:06:52,680
which record light in both the visible and non-visible parts of the spectrum.

1713
02:06:52,680 --> 02:06:57,680
Imaging spectrometers produce what are called multi- and hyperspectral remote sensing data.

1714
02:06:57,680 --> 02:07:02,680
Multi, meaning many bands, more than three, and hyper, meaning up to hundreds of bands,

1715
02:07:02,680 --> 02:07:05,680
collected at very high spectral resolution.

1716
02:07:05,680 --> 02:07:13,680
We use these multi- and hyperspectral remote sensing datasets to measure light energy reflected from objects on the earth's surface

1717
02:07:13,680 --> 02:07:19,680
and to estimate many physical and chemical properties of objects that we wouldn't see with our own eyes.

1718
02:07:19,680 --> 02:07:23,680
We then use those measurements to classify what's on the ground.

1719
02:07:23,680 --> 02:07:29,680
For example, pixels that have a spectral signature with a lot of near-infrared light energy are often vegetation.

1720
02:07:29,680 --> 02:07:38,680
To review, different objects reflect, absorb and transmit both visible light and light energy that we can't see differently.

1721
02:07:38,680 --> 02:07:43,680
Imaging spectrometers record the amount of light that these objects reflect.

1722
02:07:43,680 --> 02:07:49,680
The amount of light energy reflected by an object throughout the electromagnetic spectrum is called its spectral signature,

1723
02:07:49,680 --> 02:07:53,680
which is driven by the physical structure and chemical makeup of the object.

1724
02:07:53,680 --> 02:07:59,680
We can use that signature to identify different objects in both the photograph and across the earth's surface.

1725
02:07:59,680 --> 02:08:04,680
And that, my friends, is how we use reflected light energy to both map what's on the ground

1726
02:08:04,680 --> 02:08:07,680
and measure changes in our environment.

1727
02:08:09,680 --> 02:08:16,680
Amazing. Okay, so sorry for the person who presumably already knows that, or other people.

1728
02:08:16,680 --> 02:08:25,680
I should probably say that I think that person who made that Lea Blaster, I think they are actually here at the conference doing a maintainers thing, which is really cool.

1729
02:08:25,680 --> 02:08:28,680
So I'm going to go and like fan person them.

1730
02:08:28,680 --> 02:08:36,680
Anyway, so that's kind of, we're using a lot of those concepts, not obviously all that, you know, like multi-structural hypostructure, like not all of them.

1731
02:08:36,680 --> 02:08:42,680
But if that kind of gives you a good sense of good context for what we're actually going to be doing.

1732
02:08:42,680 --> 02:08:47,680
So at this point, I should probably also show you that we...

1733
02:08:49,680 --> 02:08:51,680
Oh yeah, there. I knew I set it up.

1734
02:08:51,680 --> 02:08:55,680
Okay, so I'm just going to give you a sense of where the data came from.

1735
02:08:55,680 --> 02:09:01,680
So I know I showed you this earlier. Has anyone used like Landsat Look? Access TOS? I mean, apart from that person, I'm not sure.

1736
02:09:02,680 --> 02:09:12,680
So I took the data. That data is literally from this portal.

1737
02:09:12,680 --> 02:09:18,680
It's one of these scenes. And then I clipped it just so you know, because these are big images.

1738
02:09:18,680 --> 02:09:26,680
And you'll see they already take quite a while actually to load, even the clipped versions, which are like a fifth of the size of the original ones.

1739
02:09:26,680 --> 02:09:30,680
So let me give you some of the context.

1740
02:09:30,680 --> 02:09:34,680
Okay, so which example of deforestation are we examining?

1741
02:09:34,680 --> 02:09:39,680
So the change from 1984 to 2022 in a 60 square kilometer region of interest, an ROI,

1742
02:09:39,680 --> 02:09:45,680
originally covered mainly by tropical dry forests at the Brazil-Bolivia border within the Amazon River Basin.

1743
02:09:45,680 --> 02:09:48,680
So there's more context here.

1744
02:09:48,680 --> 02:09:56,680
So again, haphly, I'm so proud of myself. So, you know, I came up with the region myself. Sorry, this is a bit of a, hey, yay me.

1745
02:09:56,680 --> 02:10:02,680
And then it turns out that NASA had actually also examined the same region.

1746
02:10:02,680 --> 02:10:08,680
I mean, okay, our region is slightly smaller, is here, like here, but it's that portion.

1747
02:10:08,680 --> 02:10:15,680
But yeah, so, you know, this is obviously a relevant area.

1748
02:10:15,680 --> 02:10:19,680
Okay, what scientific approaches are we taking? So satellite image processing and classification.

1749
02:10:19,680 --> 02:10:24,680
So this is not your, you know, deep learning, you know, fancy bougie hype stuff.

1750
02:10:24,680 --> 02:10:31,680
This is just, you know, handcrafted and experimental, just like I said, as a more like a prototype to show you how what's possible.

1751
02:10:31,680 --> 02:10:36,680
And then for your purposes, you can, you know, scale up as needed.

1752
02:10:36,680 --> 02:10:47,680
So what outputs will we develop? Spectral vegetation indices, but specifically NDVI and thematic maps, specifically land cover or estimated.

1753
02:10:47,680 --> 02:10:52,680
What will our outputs tell us? So they will help quantitatively detect and measure land cover and land use, LCLU.

1754
02:10:52,680 --> 02:10:58,680
Change in this ROI, particularly the clearance of original tropical dry forests since 1984.

1755
02:10:58,680 --> 02:11:03,680
Beyond the well-known eco impacts of deforestation.

1756
02:11:03,680 --> 02:11:06,680
So yeah, the no whatever carbon stores or whatever.

1757
02:11:06,680 --> 02:11:15,680
But what makes this example significant exemplifies the contrasting historical LCLU change in a biome as a consequence of country boundaries and local differences.

1758
02:11:15,680 --> 02:11:18,680
So EG enforced governance, stewardship, et cetera.

1759
02:11:18,680 --> 02:11:25,680
So you can also read that secondary issue, which is just interesting, but not obviously totally relevant.

1760
02:11:25,680 --> 02:11:31,680
But yeah, what I wanted to show you was this.

1761
02:11:31,680 --> 02:11:36,680
Now, of course, I don't know if this is real or not before, you know, caveat, caveat, caveat.

1762
02:11:36,680 --> 02:11:39,680
But I just thought this was really interesting.

1763
02:11:39,680 --> 02:11:47,680
This is this. I'm pretty sure I could identify where this is on our map.

1764
02:11:47,680 --> 02:11:55,680
But yeah, so the dry tropical forest, it seems to be might be called like Sahado, something experts would tell you.

1765
02:11:55,680 --> 02:11:59,680
But yeah, this is the Bolivia side, Bolivian side.

1766
02:11:59,680 --> 02:12:03,680
This is the Brazil side. This is in the state of Hondonia.

1767
02:12:03,680 --> 02:12:06,680
I'm sorry if I pronounce that really badly.

1768
02:12:06,680 --> 02:12:09,680
I pronounce everything like French and Italian.

1769
02:12:09,680 --> 02:12:15,680
So, yeah, and you can see again if this is real and the the river, the Rio.

1770
02:12:15,680 --> 02:12:24,680
Co-opore, what's it? Co-opore is like the delineation of the country.

1771
02:12:24,680 --> 02:12:31,680
And yeah, so if that is real, you know, that is just really interesting to see how, you know, exactly the same biome.

1772
02:12:31,680 --> 02:12:41,680
I mean, basically, you know, how it survives or doesn't survive or, you know, is managed or not managed, you know,

1773
02:12:41,680 --> 02:12:46,680
can really depend on geopolitical differences.

1774
02:12:46,680 --> 02:12:51,680
So anyway, hopefully that gives you a sense of what the region is, not just, you know, pixels.

1775
02:12:51,680 --> 02:12:59,680
OK, so this is the data source. You can look into a bit more and some extra things on remote sensing.

1776
02:12:59,680 --> 02:13:07,680
Because like I said, that is not my background. I'm just telling you enough to be able to do the tutorial.

1777
02:13:07,680 --> 02:13:16,680
OK, A, oh, I should do the table of competence. So this is where we're kind of going.

1778
02:13:16,680 --> 02:13:21,680
Set up Jupyter Notebook and satellite data. So remember, if you are, you've got X-ray and Rio X-ray.

1779
02:13:21,680 --> 02:13:28,680
We use that. If you don't use the alternative. So import glob, globe, glob, I don't know.

1780
02:13:28,680 --> 02:13:42,680
Import NumPy as NP, import X-ray as XR, import Rio X-ray as RXR, import mapplot, libpyplot as PLT.

1781
02:13:42,680 --> 02:13:48,680
Please work. Or else this could, yes, thank you.

1782
02:13:48,680 --> 02:13:53,680
OK, again, just your normal jig, the auto-completion.

1783
02:13:53,680 --> 02:14:03,680
So A2, reading the four tutorial files in the deforestation subfolder, also creating global variables with the same name as their corresponding file name.

1784
02:14:03,680 --> 02:14:07,680
So how you would do your I.O. would be totally up to you.

1785
02:14:07,680 --> 02:14:19,680
So I would not stress about the specifics of how I've done this, but just know that it's basically creating now variables with the same name as the file, just about the extension.

1786
02:14:19,680 --> 02:14:28,680
For the people who are doing the alternative, please note you have to change the extension from TIFF to TIFF for PIL.

1787
02:14:28,680 --> 02:14:31,680
I do not know why, but it works.

1788
02:14:31,680 --> 02:14:35,680
OK, section B, let's inspect satellite data. So B-intro.

1789
02:14:35,680 --> 02:14:38,680
RASTA data is one of two main types of geospatial data.

1790
02:14:38,680 --> 02:14:45,680
The other is vector data. So the points and polygons we handled in the mapping section of the carbon polluters exploration are examples of this.

1791
02:14:45,680 --> 02:14:52,680
So data stored in RASTA format are typically in grid matrix structure, and they render as pixels, picture elements.

1792
02:14:52,680 --> 02:15:01,680
For geospatial RASTA data, each pixel relates to some area on Earth, and each pixel value is a measurement of some real-world phenomenon.

1793
02:15:01,680 --> 02:15:13,680
The four tutorial files are geospatial RASTA datasets, and the pixel values they contain are satellite measurements of amounts of light reflected from a single band of the electromagnetic spectrum.

1794
02:15:13,680 --> 02:15:18,680
So spectral reflectance values, so brightness, so more light, as you saw on that scale.

1795
02:15:18,680 --> 02:15:23,680
Less light, more light. Less red light, more red light.

1796
02:15:23,680 --> 02:15:41,680
OK, quick caveat. I won't read that because it's detailed, but basically because we're using effectively an older satellite or an older sensor and then a new one, so that you have maximum temporal difference.

1797
02:15:41,680 --> 02:15:53,680
So the Landsat 5TM captured a different wavelength to the Landsat, or different wavelengths for the red band and the near-infrared bands compared to the newer.

1798
02:15:53,680 --> 02:15:57,680
I would assume, again, if someone was from NASA, that'd be great if they could tell me.

1799
02:15:57,680 --> 02:16:07,680
I assume this basically was more, you know, the fact that they basically made the bands, I presume, more defined, so it's kind of more accurate, which probably means that this is less accurate.

1800
02:16:07,680 --> 02:16:14,680
But anyway, it's just things to know. They're not exactly like-for-like, but they're still useful for general purposes.

1801
02:16:14,680 --> 02:16:25,680
So B0. So let's check the dimensions of any of the four tutorial RASTAs. I'm going to check the 1984 red band.

1802
02:16:25,680 --> 02:16:33,680
So you know how those variables, because they were created in that load step, so the shape.

1803
02:16:33,680 --> 02:16:42,680
So we basically reduced it down to a two-dimensional 2001 pixels by 2001 pixel.

1804
02:16:42,680 --> 02:16:51,680
In fact, you're in a way. So B1, check the data type of any of the tutorial RASTAs.

1805
02:16:51,680 --> 02:16:58,680
So again, I'm just using the 1984 red band.

1806
02:16:58,680 --> 02:17:08,680
And so that should be in the float, but just be aware that the original data is in, is in from the Landsat Look Portal, is in UINT 16.

1807
02:17:08,680 --> 02:17:16,680
And then there's more about digital numbers and how the raw data was collected, which is way out of scope for this tutorial.

1808
02:17:16,680 --> 02:17:27,680
B2, try rendering the red band reflectance values of the ROI in 1984 using plot, which, of course, uses map.lib.

1809
02:17:27,680 --> 02:17:38,680
So I'll just do this first. RRI plot. OK, now, pass reds, underscore R, so reversed reds as the optional CMAP argument,

1810
02:17:38,680 --> 02:17:45,680
and adjust the size and aspect of the plot to be smaller than the default, so as to be faster to load.

1811
02:17:45,680 --> 02:17:53,680
Because like I said, these are really heavy. You already see these, those data sets are massive.

1812
02:17:53,680 --> 02:18:03,680
Aspect equals 1.3, size equals 4. So again, you could customize that, but just to give you a starting point.

1813
02:18:03,680 --> 02:18:10,680
So, oh, comment, there we go. I'll just load up for it.

1814
02:18:10,680 --> 02:18:22,680
So yeah, so I know it doesn't look like very much we could adjust the scale, but so remember less light, lower reading, darker in this instance.

1815
02:18:22,680 --> 02:18:30,680
More light, so more reflectance, like less red. OK, so just to be clear.

1816
02:18:30,680 --> 02:18:38,680
So that's as that is forest, that should have lower values as it does have low values because spatial signatures,

1817
02:18:38,680 --> 02:18:44,680
the vegetation should have absorbed the chlorophyll should have absorbed more of the red light.

1818
02:18:44,680 --> 02:18:50,680
Then there is firing patterns here. So I'll just show you really quickly that link.

1819
02:18:50,680 --> 02:18:56,680
This is a really interesting NASA resource just to show you different sort of agricultural patterns from space.

1820
02:18:56,680 --> 02:19:02,680
So yeah, I think one here, the one in Hondoña in Brazil looks a lot like the fish bone.

1821
02:19:02,680 --> 02:19:06,680
But again, I'm not an expert, but I'm sure you could find someone who is.

1822
02:19:06,680 --> 02:19:10,680
So B3, there is a range of spatial mass data embedded in our rasters.

1823
02:19:10,680 --> 02:19:14,680
Use rear X-rays bounds method to check the spatial extent of any of the rasters.

1824
02:19:14,680 --> 02:19:20,680
So, you know, basically like the dimensions of of what we're looking at.

1825
02:19:20,680 --> 02:19:26,680
So RIs, rear bounds.

1826
02:19:26,680 --> 02:19:32,680
And there's just a note here that I actually clipped it specifically for these values and they are different.

1827
02:19:32,680 --> 02:19:38,680
Anyone who is not a geospatial expert, I want to have a guess why they may not be exactly the same.

1828
02:19:39,680 --> 02:19:43,680
Why can they not cut exactly how I asked them to?

1829
02:19:43,680 --> 02:19:47,680
This is not the exciting question. So it's because they're like the pixels.

1830
02:19:47,680 --> 02:19:51,680
So maybe like it has to cut on a bound, right?

1831
02:19:51,680 --> 02:19:58,680
Unlike where exactly a pixel is and where I asked for clearly is not exactly where the pixels, the pixel boundary were.

1832
02:19:58,680 --> 02:20:04,680
So these, I presume, are the nearest pixel boundaries.

1833
02:20:04,680 --> 02:20:06,680
So just a little note.

1834
02:20:06,680 --> 02:20:10,680
B4, have a look at some actual reflections values. Extract a sample at the top left corner.

1835
02:20:10,680 --> 02:20:22,680
So from your so here, top left corner of the ROI 1984 red band 3 raster as a numpy subarray, specifically the first five rows and columns.

1836
02:20:22,680 --> 02:20:31,680
So ROI, red band values, which then turns it into a numpy array.

1837
02:20:31,680 --> 02:20:38,680
So multi-dimensional indexing, first five rows, first five columns.

1838
02:20:40,680 --> 02:20:45,680
So the rest are, you know, it's just numbers in a grid format.

1839
02:20:45,680 --> 02:20:50,680
Those are reflections values. Why do I always anticipate myself?

1840
02:20:50,680 --> 02:20:57,680
Okay, so each value, there we go. So it's a specific 30 by 30 meter area at the Brazil-Bolivia border.

1841
02:20:57,680 --> 02:21:03,680
And this one is these are the readings that lands at 5 T.M. measured on August 13th, 1984.

1842
02:21:03,680 --> 02:21:11,680
Be precise. 30 meters represents the spatial resolution of our restors, a metric indicating the ground surface area that forms a single pixel.

1843
02:21:11,680 --> 02:21:20,680
Satellite sensors can have higher or lower spatial resolution. So for example, MODIS, which is another NASA, I think, sensor, isn't it?

1844
02:21:20,680 --> 02:21:27,680
So yeah, that's a higher spatial. So I mean that higher, lower, higher, lower.

1845
02:21:27,680 --> 02:21:33,680
Anyway, there is a larger area covered by each pixel, so it has, you know, less granularity.

1846
02:21:33,680 --> 02:21:43,680
So 30 meters is pretty good, it seems. So B5, try rendering this numpy subarray of red band reflectance values using matplotlib's matshow function.

1847
02:21:43,680 --> 02:21:48,680
So remember, at this point, it's literally just an array of numbers.

1848
02:21:48,680 --> 02:21:57,680
So you can plot those, render those with colors.

1849
02:21:57,680 --> 02:22:16,680
So yeah, which is not massively exciting, but it just shows you that, you know, your image, if you don't do any sort of this kind of digital signal processing stuff, you know, images are just numbers.

1850
02:22:16,680 --> 02:22:23,680
Okay, optionally, this is just again to kind of give you more of a sense of what the data is.

1851
02:22:23,680 --> 02:22:40,680
If you run that, I've just plotted that really quickly so you can, you know, again, I'm just reinforcing the concept that brighter colors are higher spectral reflectance values, and then lower is darker.

1852
02:22:40,680 --> 02:22:50,680
B7, okay. Don't worry, it does get more interesting, I think, but I just kind of need to like give you some sort of basic concepts.

1853
02:22:50,680 --> 02:22:59,680
As the area of the ROI in 1984 covered by the pixels in the top left corner is not overly interesting, let's have a look at the top right corner instead.

1854
02:22:59,680 --> 02:23:07,680
So, we'll do this again, values.

1855
02:23:07,680 --> 02:23:16,680
So this time, top right corner, we're going to look at minus five to the end, CMAP again is reds are.

1856
02:23:16,680 --> 02:23:28,680
Okay, so there's that. Now, as I said, start by visualizing a five by five matrix and then keep increasing the size up to 500 by 500 because, you know, because I've tested it and it looks fun.

1857
02:23:28,680 --> 02:23:38,680
So now you've got 50 by 50, you know, and you can start to see again remember each of these is 30 square meters on the ground.

1858
02:23:38,680 --> 02:23:46,680
And then if you start getting just kind of zooming out. So this is where you can really start to see some of the, remember this is 1984 already.

1859
02:23:46,680 --> 02:24:00,680
So, these are those, I'm going to presume, you know, agricultural driven deforestation, sort of rectangular plots, and that's a fishman pattern.

1860
02:24:00,680 --> 02:24:05,680
And then, you know, you can just, you can move out a little bit more.

1861
02:24:05,680 --> 02:24:14,680
So yeah, again, like I said, we're just, just trying to show you that you know the relationship. Oh, hello.

1862
02:24:14,680 --> 02:24:20,680
Try.

1863
02:24:20,680 --> 02:24:30,680
Oh, I see. Yeah, sorry. So you want to try a different color map. Yeah, of course.

1864
02:24:30,680 --> 02:24:34,680
Underscore Earth, like that.

1865
02:24:34,680 --> 02:24:38,680
Oh, yeah, the gist. Yep.

1866
02:24:38,680 --> 02:24:44,680
That.

1867
02:24:44,680 --> 02:24:47,680
Yeah. So yeah, you could definitely. Yeah.

1868
02:24:47,680 --> 02:25:03,680
Honestly, I was like, Oh, I really want to like, you know, do a sort of kids visualizations or, you know, satellite image art sort of knock off from this because I think there's some really interesting things.

1869
02:25:03,680 --> 02:25:08,680
But yeah, sorry. Anyway, we'll move on. So F7.

1870
02:25:08,680 --> 02:25:11,680
Did I do this agricultural patterns.

1871
02:25:11,680 --> 02:25:14,680
Okay.

1872
02:25:14,680 --> 02:25:23,680
Okay. Yes.

1873
02:25:23,680 --> 02:25:33,680
Yes. Yeah, exactly. So the spectrum, I'll tell you what, actually, I'll just go to the next section because I think that will help reinforce your point.

1874
02:25:33,680 --> 02:25:37,680
But yeah, sorry, I was trying to stress it because it can be confusing.

1875
02:25:37,680 --> 02:25:46,680
So, section C, prepare to calculate a spectral vegetation index. So C, intro, a spectral index or ratio is an indicator of some phenomenon.

1876
02:25:46,680 --> 02:25:52,680
Phenomena, such as biophysical or biochemical properties calculated using the different reflectance properties of different objects.

1877
02:25:52,680 --> 02:25:59,680
So to this person's point, Landsat data products like burn ratios and moisture index are example of spectral indices.

1878
02:25:59,680 --> 02:26:11,680
One type of spectral indices relevant to deforestation are vegetation indices, VI, the most common of which is the normalized difference vegetation index NDVI used to quantify vegetation greenness.

1879
02:26:11,680 --> 02:26:17,680
So NDVI utilizes certain reflectance properties of plants. So chlorophyll strongly absorbs red light.

1880
02:26:17,680 --> 02:26:25,680
So lots of forest means lots of red light is absorbed. So not so much.

1881
02:26:25,680 --> 02:26:31,680
Whilst leaves slash plant structures strongly reflects near infrared light.

1882
02:26:31,680 --> 02:26:34,680
And so that's the spectral signature.

1883
02:26:34,680 --> 02:26:40,680
So the formula to calculate NDVI therefore requires the reflectance values in the red and the near infrared bands.

1884
02:26:40,680 --> 02:26:44,680
So there.

1885
02:26:44,680 --> 02:26:50,680
Yeah, that's I hope that's kind of fairly intuitive there.

1886
02:26:50,680 --> 02:26:53,680
So, or is intuitive. Okay, maybe we should talk about.

1887
02:26:53,680 --> 02:26:56,680
Okay, so.

1888
02:26:56,680 --> 02:27:03,680
So if it's plants, right, if there's like more green, if the surface that 30 by 30 meters just like thick, dense, totally green stuff.

1889
02:27:03,680 --> 02:27:11,680
So it means that it will have the plants because plants and leaves structure strongly reflects near infrared light.

1890
02:27:11,680 --> 02:27:13,680
This will be really high.

1891
02:27:13,680 --> 02:27:16,680
And then if there's plants, the chlorophyll strongly absorbs red light.

1892
02:27:16,680 --> 02:27:18,680
So this should be high. That should be low.

1893
02:27:18,680 --> 02:27:24,680
So there should be, you know, that minus that should be large.

1894
02:27:24,680 --> 02:27:27,680
And then that over that plus that obviously normalizes it.

1895
02:27:27,680 --> 02:27:39,680
And then if it's like, like water or concrete, I think stuff like that, then I think basically they're about the same.

1896
02:27:39,680 --> 02:27:41,680
So then you don't really get a difference.

1897
02:27:41,680 --> 02:27:45,680
So then your reading is much lower than if it was plants.

1898
02:27:45,680 --> 02:27:48,680
But hopefully that will make more sense when we actually do it.

1899
02:27:48,680 --> 02:27:53,680
So by design NDVI values therefore range from minus one to one.

1900
02:27:53,680 --> 02:27:56,680
Negative values to zero indicate no green leaves.

1901
02:27:56,680 --> 02:28:01,680
Whilst values approaching one indicate highest density of green leaves.

1902
02:28:01,680 --> 02:28:03,680
And there's some like NASA, NASA NDVI training.

1903
02:28:03,680 --> 02:28:08,680
I mean, there's lots of NASA training, but yeah, that's one which I think is more accessible.

1904
02:28:08,680 --> 02:28:18,680
In section D, we will calculate NDVI values for ROI to help detect how the existing tropical dry forest cover in 1984 had changed by 2022 as likely deforestation.

1905
02:28:18,680 --> 02:28:25,680
And then just to note that you can get this pre-calculated, but you know, it's better that you do yourself because you understand it more.

1906
02:28:25,680 --> 02:28:36,680
So C0 in advance of calculating NDVI values using the above raster math formula, render the red and near infrared rasters of the ROI from 2022 as subplots.

1907
02:28:36,680 --> 02:28:37,680
So.

1908
02:28:40,680 --> 02:28:48,680
So we're basically plotting the two rasters from 2022.

1909
02:28:50,680 --> 02:28:51,680
Side by side.

1910
02:28:52,680 --> 02:28:59,680
Just so you can get a sense of what the data looks like before we calculate the NDVI.

1911
02:28:59,680 --> 02:29:03,680
So red band, we'll do red band on the left.

1912
02:29:03,680 --> 02:29:04,680
So plot.

1913
02:29:04,680 --> 02:29:09,680
Then we'll do the near infrared band on the right.

1914
02:29:10,680 --> 02:29:11,680
Plot.

1915
02:29:12,680 --> 02:29:17,680
Okay, and I'm just going to copy this because there's no value and you're watching me type that.

1916
02:29:17,680 --> 02:29:18,680
So.

1917
02:29:19,680 --> 02:29:21,680
Lose, lose.

1918
02:29:22,680 --> 02:29:25,680
That also needs to be on that axis and then plot show.

1919
02:29:26,680 --> 02:29:27,680
Show.

1920
02:29:27,680 --> 02:29:28,680
Show.

1921
02:29:30,680 --> 02:29:31,680
No, subplots.

1922
02:29:31,680 --> 02:29:32,680
There we go.

1923
02:29:35,680 --> 02:29:36,680
Schnal, Schnal, Schnal.

1924
02:29:38,680 --> 02:29:39,680
There.

1925
02:29:39,680 --> 02:29:41,680
Like I said, it really does take a long time.

1926
02:29:43,680 --> 02:29:45,680
So yeah, so this is 2022, right?

1927
02:29:45,680 --> 02:29:47,680
So the one you showed you saw earlier was 1984.

1928
02:29:48,680 --> 02:29:51,680
So, I mean, you can see even from the red band, like, I mean,

1929
02:29:51,680 --> 02:29:58,680
I mean, you know, even as like a non-scientist like me, I mean, it's pretty clear this, you know,

1930
02:29:59,680 --> 02:30:00,680
again, this is the Brazil side.

1931
02:30:00,680 --> 02:30:01,680
This is the Bolivia side.

1932
02:30:01,680 --> 02:30:06,680
I'm pretty sure that that photo I showed you, I think it's somewhere possibly here.

1933
02:30:06,680 --> 02:30:08,680
These kind of tributaries.

1934
02:30:08,680 --> 02:30:15,680
So, yeah, it's, yeah, not a lot of trees left on that side, clearly.

1935
02:30:16,680 --> 02:30:19,680
And then, okay, the near infrared, this will not be particularly interesting itself.

1936
02:30:19,680 --> 02:30:22,680
It's like, as we said, the culmination of the two.

1937
02:30:22,680 --> 02:30:26,680
But let's start actually calculating some NDVI.

1938
02:30:27,680 --> 02:30:29,680
And I'll just tell you, so we're going, so we're calculating this.

1939
02:30:29,680 --> 02:30:30,680
We're going to make some maps.

1940
02:30:30,680 --> 02:30:31,680
Then we're going to do some thematic maps.

1941
02:30:31,680 --> 02:30:37,680
And then there's some optional kind of relation to the real world thing at the end if we have time.

1942
02:30:38,680 --> 02:30:46,680
So D0, calculate NDVI values for the ROI in 1984 by performing the required RASTA math with ROI 1984 near band 4,

1943
02:30:46,680 --> 02:30:51,680
then ROI 1984, red band 3, and assigned to NDVI 1984.

1944
02:30:52,680 --> 02:31:01,680
So the kind of most important bit I'd say is actually the easiest because of the power of NumPy and vectorized operations.

1945
02:31:01,680 --> 02:31:03,680
This is a piece of cake.

1946
02:31:03,680 --> 02:31:07,680
And I say that now, and I hope that this doesn't fail.

1947
02:31:08,680 --> 02:31:09,680
I haven't jinxed it.

1948
02:31:10,680 --> 02:31:21,680
So the near infrared band minus the red band over the near infrared band plus the red band, which I'm literally just going to copy that.

1949
02:31:22,680 --> 02:31:25,680
Oh, I'm doing the wrong, I'm doing the wrong date.

1950
02:31:26,680 --> 02:31:33,680
1984, 1984, 1984.

1951
02:31:36,680 --> 02:31:37,680
Okay.

1952
02:31:40,680 --> 02:31:43,680
I knew I said it was the easiest, but I totally jinxed it.

1953
02:31:43,680 --> 02:31:44,680
And then I messed it up.

1954
02:31:44,680 --> 02:31:47,680
Okay. So you've now got NDVI 1984.

1955
02:31:47,680 --> 02:31:50,680
So let's sense check that by looking at a couple of values.

1956
02:31:50,680 --> 02:31:55,680
NDVI values, turn it into a NumPy array.

1957
02:31:55,680 --> 02:31:58,680
Let's just look at some 2x2.

1958
02:31:59,680 --> 02:32:00,680
Just a sense check.

1959
02:32:00,680 --> 02:32:04,680
So yeah, so in that particular corner, that top left corner,

1960
02:32:04,680 --> 02:32:09,680
you're looking at sort of, you know, 0.3, 5, 0.4.

1961
02:32:09,680 --> 02:32:19,680
So that, we'll talk about that later, but that is sort of like some veg, sparse veg, not like super dense, but veg.

1962
02:32:19,680 --> 02:32:20,680
D2.

1963
02:32:20,680 --> 02:32:33,680
So calculate the NDVI values for the ROI in 2022 by performing the required RAS math with the ROI 2022 nearby band and ROI 2022 red band and assigned to NDVI 2022.

1964
02:32:34,680 --> 02:32:40,680
So basically the same thing, but for the other time period.

1965
02:32:41,680 --> 02:32:48,680
So near infrared minus red over near infrared.

1966
02:32:48,680 --> 02:32:51,680
Plus red, that's right.

1967
02:32:54,680 --> 02:32:56,680
Yes. Good.

1968
02:32:56,680 --> 02:32:59,680
D3. So also sense check that.

1969
02:32:59,680 --> 02:33:04,680
2x2.

1970
02:33:04,680 --> 02:33:10,680
So, I mean, just by coincidence, or maybe usefully.

1971
02:33:10,680 --> 02:33:26,680
So these values are lower, you know, which, I mean, I wouldn't draw a massive point about it, but you know, you would basically say that that could indicate that where in 1984, there was more veg, maybe in 2022 in the same spot.

1972
02:33:26,680 --> 02:33:33,680
There looks like there's less veg in these 30 square meter areas on the ground.

1973
02:33:33,680 --> 02:33:37,680
D4. This is just so you know that you can save stuff.

1974
02:33:37,680 --> 02:33:43,680
You can export stuff so you can do that. I already have 5,000 copies of these so I'm not going to.

1975
02:33:43,680 --> 02:33:47,680
Okay, section E. So now let's just make some maps from that data.

1976
02:33:47,680 --> 02:33:49,680
E0.

1977
02:33:49,680 --> 02:34:04,680
The NDVI datasets are still geospatial rasters, i.e. grids of pixels, and still each linked to 30 square meters on Earth. However, the value of these pixels indicate the density of green leaves covering that place on Earth on a scale of minus one to one.

1978
02:34:04,680 --> 02:34:17,680
So not just measurements of light, as before. So let's therefore render both NDVI rasters to help discover how dense vegetation was in our ROI in 1984 compared to 2022.

1979
02:34:17,680 --> 02:34:25,680
So this is your classic before and after.

1980
02:34:25,680 --> 02:34:38,680
Which, I shouldn't ruin this part. It may not be quite what you expect and that's where I'm going to say this is possibly down to the change in band coverage of the different, of the older and the newer sensors.

1981
02:34:38,680 --> 02:34:51,680
However, you know, I mean that's science right like you don't always get the results you're hoping for and if you're ethical you're not going to jig them just to make it show you what you want.

1982
02:34:51,680 --> 02:34:55,680
So plot, plot, plot show.

1983
02:34:55,680 --> 02:34:58,680
Yeah, plot show even.

1984
02:34:58,680 --> 02:35:09,680
So this again is just the same CMAPs, putting on the axis but here I'm just specifying. So instead of actually having one to minus one to one as the scale.

1985
02:35:09,680 --> 02:35:15,680
I'm okay I am jigging a little bit just so the colors stretch a little better.

1986
02:35:15,680 --> 02:35:23,680
Because that is, that's the sort of range of the values in these two rasters, NDVI rasters.

1987
02:35:23,680 --> 02:35:30,680
So,

1988
02:35:30,680 --> 02:35:32,680
Okay.

1989
02:35:32,680 --> 02:35:50,680
So, you know this is real data so you know it's, yeah, obviously I would have liked this to be like really really, you know, really green and that would be really, I don't know, not, but again, you know you're using different data so not like for like

1990
02:35:50,680 --> 02:35:57,680
a whole bunch of data collection, but you know there's still things that you can see. So, what can you see.

1991
02:35:57,680 --> 02:36:13,680
I mean here you can obviously see. So, you know, this is going to be lower NDVI values because this is presumably like earth roads that are created to in order to create the farming plots and then then they've obviously kind of really gone to town

1992
02:36:13,680 --> 02:36:32,680
with more clearing of the forest, but also you know plotting, plotting, growing crops, that's why I meant crops, which are also green so then you know if you want to do more sophisticated analysis, you would, you know, want to try and figure out the difference between, you know, crops,

1993
02:36:32,680 --> 02:36:55,680
green is from like crops and green is from like forest. So I'm sure someone, an expert could tell you that. I think something for me, what I thought was interesting actually was that there does seem to be, so you know it's not just like, you know, you're clearing the forest and you know carbon sinks and stuff like that but also when you don't have trees, then you get more runoff and you know there's more sedimentation, goes into rivers.

1994
02:36:55,680 --> 02:37:12,680
You know, I'm just guessing by eye, like these rivers, they kind of look a lot kind of weaker here. Some of them kind of like the loops are kind of cut off, that would sort of make more sense to me that there's more kind of silt, like affecting river pollution.

1995
02:37:12,680 --> 02:37:19,680
So anyway, things. There are things you can do, things you can see.

1996
02:37:19,680 --> 02:37:35,680
Here we go. This is the caveat reminder, but the thing which we can use is, I'll just read it. So, this is about the NDVI values of what surfaces or what materials have what kind of NDVI values.

1997
02:37:35,680 --> 02:37:46,680
So, areas of barren rock, sand or snow usually show very low NDVI values. Sparse vegetation such as shrubs and grasslands or senescent crops may result in moderate NDVI values.

1998
02:37:46,680 --> 02:37:55,680
High NDVI values correspond to dense vegetation such as that's found in temperate and tropical forests or crops at their peak growth stage.

1999
02:37:55,680 --> 02:37:58,680
Anyway, and then the other interesting things.

2000
02:37:58,680 --> 02:38:15,680
Are there sciencey things? Okay, so E1. So, so far in this exploration we've been handling continuous raster data. However, in preparation for developing a thematic land cover map next section, let's start to consider how we could meaningfully group or bin pixels into NDVI ranges associated with specific land cover.

2001
02:38:15,680 --> 02:38:21,680
So check the distribution of both sets of NDVI values through quick histogram plotting.

2002
02:38:21,680 --> 02:38:29,680
So, let's literally just look at those values on top of each other.

2003
02:38:29,680 --> 02:38:47,680
So, you can just pull that straight away. That's not super useful. Let's give it some colors.

2004
02:38:47,680 --> 02:38:59,680
Colors and then also we're going to give the 2022 plot some transparency with the alpha value just so you can actually see stuff and then the semicolon is just to suppress this weird stuff.

2005
02:38:59,680 --> 02:39:14,680
I mean, great stuff. Thank you, Matplotlib. So, again, I mean, this is, I guess what I was hoping to see when I designed or, you know, came up with this. I was like, oh, hopefully in 1984, you know, these values would be like way over here.

2006
02:39:14,680 --> 02:39:24,680
And then in 2022, they'll like be way over here. And it's not quite like that. You know, I don't know. There's also things on the day, the angles of the satellite, all that kind of stuff.

2007
02:39:24,680 --> 02:39:36,680
But I mean, you can see though, this is a lot, there's a lot more here in this area than there was. I mean, in this NDVI, this range of data than there was in 1984.

2008
02:39:36,680 --> 02:39:44,680
So I'm like, this feels like agricultural bits.

2009
02:39:44,680 --> 02:39:51,680
Okay, so now let's do the classification, the classifying land cover using NDVI and make thematic map.

2010
02:39:51,680 --> 02:40:07,680
Okay, so, this is like a caveat. So this section is designed to introduce the idea of pixel based image classification of land cover using satellite imagery in order to create thematic maps and does not represent best practice.

2011
02:40:07,680 --> 02:40:17,680
Check out more NASA training material. There's lots of it. Although I would like to say though, the NASA training material, so they actually use QGIS mainly.

2012
02:40:17,680 --> 02:40:25,680
So I would like to say this is kind of more, you know, more kind of pythony. Although QGIS is great, I'm sure.

2013
02:40:25,680 --> 02:40:37,680
We will be executing an experimental process trying to develop a meaningful thematic land cover map of our ROI in 2022, leveraging known NDVI values of certain land cover and the distribution of empirical NDVI values.

2014
02:40:37,680 --> 02:40:55,680
So, sorry. Central to this process is performing pixel based classification. We will have a go at producing a map that describes four land cover types by implementing the below experimental classification scheme, whereby every pixel will be assigned to a class based on its NDVI value.

2015
02:40:55,680 --> 02:41:06,680
So like I said, this is really just, you know, just an idea of how you could do it. You could obviously design the classes differently, you know, call them different things.

2016
02:41:06,680 --> 02:41:18,680
But, you know, it's just to give you a sense that actually sometimes simplifying the information. So from continuous to, you know, discrete is actually more useful for being able to interpret things.

2017
02:41:18,680 --> 02:41:38,680
So F0. Find out the official type of the NDVI 2022 object, because we have actually been using X-ray data arrays, but I have not been sort of emphasizing that because we're not going into it because it is a bit confusing if you're just starting out with scientific computing.

2018
02:41:38,680 --> 02:41:54,680
But just know that it's a data array. F1. So we're going to make a copy called LCLU NDVI, which is what we are going to basically bin the pixels.

2019
02:41:54,680 --> 02:42:11,680
F2. Our approach to implementing the pixel classification involves manually binning the subset of pixels that belong in each class, so the process is more transparent. Try calling X-rays where function in order to test replacing the NDVI values in LCLU, which are under 0.3 with 99.

2020
02:42:11,680 --> 02:42:22,680
Okay, so this is just to show you like the method that we're going to use in order to do the binning. There are much more like, there are other ways to do this, but this is kind of a really transparent way.

2021
02:42:22,680 --> 02:42:39,680
So here we're basically saying the NDVI values, which are under 0.3, replace it with 99. I mean, just arbitrary, just, you know, because you want to see. And if it's not under 0.3, just leave it as is.

2022
02:42:39,680 --> 02:42:51,680
Okay, so here you go. This is a data array, which I have not showed you because I didn't want to because it's got things called coordinates, which are not actually like, they're confusing.

2023
02:42:51,680 --> 02:43:04,680
But just so you know, that is what you're working with. And they're very 2,000 by 1 by 2,000, 1 pixel size. So here, actually, it does turn out that actually those values in that top left corner do mainly see as being under 0.3.

2024
02:43:04,680 --> 02:43:16,680
So that's why you get 99. So anyway, once you've tried that, you know how that functionality works. Now we're going to replace, we're going to bin all the pixel values.

2025
02:43:16,680 --> 02:43:31,680
So F3, build the final data array output, LCLU4, through creating a series of incrementally updated data arrays that replace the pixel values assigned to each class with 100, 200, 300, and 400 respectively.

2026
02:43:31,680 --> 02:43:44,680
I wouldn't type this out manually for you, because like I said, the way you might do this is differently. I mean, really, you would probably use NP digitize and then a ufunk, just FYI.

2027
02:43:44,680 --> 02:43:57,680
But this works. And you can see you're basically, you've replaced here the values under 0.15 and then values under 0.25, 4, and so on and so forth.

2028
02:43:57,680 --> 02:44:06,680
So that works. So F4, let's review the fully classified raster LCLU4 representing our land, cover, map by generating a quick plot.

2029
02:44:06,680 --> 02:44:17,680
So now you've literally just got four values, 100, 200, 300, and 400. They're not meaningful. They're not supposed to be. It's just so that you can separate them out and color them.

2030
02:44:17,680 --> 02:44:28,680
And then color them like this. So again, that's, yeah, it's not actually a continuous color. So don't worry about that. But like I said, it's just a quick, dirty plot.

2031
02:44:28,680 --> 02:44:40,680
So you've got the four colors. This is the default. So this is your higher. Yeah, that's right. So this is, so remember, this is like your low NDVI, your highest.

2032
02:44:40,680 --> 02:44:51,680
So that should be your most green, least green. So most green, most green, which is correct because this is like the null comp, the conservation project.

2033
02:44:51,680 --> 02:45:01,680
So there should be forests. Or they're doing a very bad job at conservation. This is actually rock. So that should be low. And then these are like crops.

2034
02:45:01,680 --> 02:45:11,680
So that kind of looks sensible. Not perfect. But like I said, this is just to show you how it could be done. And then you can tweak it yourself.

2035
02:45:11,680 --> 02:45:19,680
F5. So I'll just tell you what we're doing now is we're going to create our own color map and just sort of make a kind of more usable version.

2036
02:45:19,680 --> 02:45:28,680
So F5, let's prepare to construct an upgraded version of this land cover map. Import the listed color map class from mapplotlibcolors.

2037
02:45:28,680 --> 02:45:38,680
So mapplotlibcolors. Colors, colors, import listed color map.

2038
02:45:38,680 --> 02:45:50,680
F6. Create a custom color map consisting of four appropriate named colors called LCLUCMAP. So LCLUCMAP.

2039
02:45:50,680 --> 02:45:56,680
So yeah, so this is like literally the color maps that you've been using, like someone else has actually gone, oh, it's going to be like red, orange, yellow.

2040
02:45:56,680 --> 02:46:02,680
So this is you just making your own, which is a useful skill anyway.

2041
02:46:02,680 --> 02:46:14,680
You could also choose your own selection. This is just, you know, things which seem to look good or appropriate for screen.

2042
02:46:14,680 --> 02:46:24,680
Yep. And then you can make the upgraded land cover map of the ROI from 2020 using the LCLUCMAP and other mapplotlib options to find you.

2043
02:46:24,680 --> 02:46:37,680
Okay, so let's build this up again from basics. FIGX is subplots. FIG size. Just make them all like that.

2044
02:46:37,680 --> 02:46:48,680
8 by 6. So your absolute basic LCLU is you need that final classified raster and UVI.

2045
02:46:48,680 --> 02:46:57,680
We're going to give it that CMAP we just customized. So this would be your absolute, I mean, this will work.

2046
02:46:57,680 --> 02:47:04,680
This will be your classified land cover map with those colors, specified colors.

2047
02:47:04,680 --> 02:47:12,680
And then the rest is just tweaking because, you know, like we don't, like I said, that 100 to 400 were just random values. It could have been anything.

2048
02:47:12,680 --> 02:47:17,680
So this is where the tweaking happens. So I'm not going to type that because it's not very exciting.

2049
02:47:17,680 --> 02:47:22,680
And you might do it differently if you are using a different visualization package.

2050
02:47:22,680 --> 02:47:37,680
So that just gives you some actual labels. And I think that's yeah, you can get ready to, you know, export that as per the other things.

2051
02:47:37,680 --> 02:47:45,680
Yeah. Okay. So in the, we actually can do this last bit. I think this is actually interesting.

2052
02:47:45,680 --> 02:47:53,680
So this is the last section, section G. Transform coordinates from different map projections.

2053
02:47:53,680 --> 02:48:02,680
So I was like, should I read this? Okay. I guess basically the point is it's like, so this is cool. We can do stuff within this.

2054
02:48:02,680 --> 02:48:12,680
So like, if you want to kind of basically like cross references with something actually in the world, you know, so you've got coordinates of this area from some other map, but they're in a different map projection.

2055
02:48:12,680 --> 02:48:19,680
You're like, how do they, you know, how do I, what's the relationship between these coordinates?

2056
02:48:19,680 --> 02:48:28,680
So I'll just kind of show you the, like this is optional, so I'm just going to show you kind of the bare bones of this.

2057
02:48:28,680 --> 02:48:35,680
So what I did was I went to this map biomass.

2058
02:48:35,680 --> 02:48:44,680
This is the Brazilian annual land use and land cover mapping project and basically identified.

2059
02:48:44,680 --> 02:48:49,680
I have to remind my Portuguese. I think it's this one.

2060
02:48:49,680 --> 02:49:07,680
So this, I basically was looking to see what someone knew about this area so that we could then translate it into our analysis and then annotate our land cover map.

2061
02:49:07,680 --> 02:49:10,680
This is really slow.

2062
02:49:10,680 --> 02:49:16,680
But yeah, I mean, if you are looking at this particular area, this is quite interesting.

2063
02:49:16,680 --> 02:49:23,680
And maybe it's a nice change not to look at Jupiter notebook for a second. State.

2064
02:49:23,680 --> 02:49:25,680
Hondoña.

2065
02:49:25,680 --> 02:49:28,680
Just do that.

2066
02:49:28,680 --> 02:49:35,680
Which yeah, I was going to say, this is a really interesting tool that I stumbled on. I remind myself what I need to do. Oh yeah, okay.

2067
02:49:35,680 --> 02:49:49,680
Pasture. I won't go through all that because you've got the steps. But yeah, this is really interesting because it can show you, you know, obviously people who actually research this can tell you what these things are.

2068
02:49:49,680 --> 02:49:56,680
Sorry, let me just remind myself click natural and anthropic use. Deselect anthropic use.

2069
02:49:56,680 --> 02:49:58,680
Okay.

2070
02:49:58,680 --> 02:50:04,680
Okay, that's right. So this is as of 2021.

2071
02:50:04,680 --> 02:50:10,680
So this is where this project said there is forest.

2072
02:50:10,680 --> 02:50:22,680
And this is according to them, which is obviously much better source and you know, me who knows nothing. Oh, hello.

2073
02:50:22,680 --> 02:50:26,680
Oh, well, okay, that's supposed to come up with something.

2074
02:50:26,680 --> 02:50:29,680
I can't see it.

2075
02:50:29,680 --> 02:50:38,680
Okay, anyway, so there's an instruction I can show you. Yeah, in the Jupiter notebook you can see. But yeah, the point was using these maps.

2076
02:50:38,680 --> 02:50:42,680
I identified a point. I think it's here.

2077
02:50:42,680 --> 02:50:44,680
30. I'll just show you here.

2078
02:50:44,680 --> 02:50:48,680
30, 55, 13, 55 and 61.

2079
02:50:48,680 --> 02:50:54,680
30, 55 and 61.

2080
02:50:54,680 --> 02:51:09,680
There was a somewhere here where you could actually see from 2018 to 2021. It looked like it was new pasture. Oh, here. Finally. Seriously, like I'm doing a live coding demo.

2081
02:51:09,680 --> 02:51:13,680
So yeah, so here in 2018, this is it.

2082
02:51:13,680 --> 02:51:23,680
So okay, you can really see like there's bits of. So this is pasture, I'll just tell you. Yeah, there's bits of the forest being cleared for pasture, pasture gem.

2083
02:51:23,680 --> 02:51:28,680
You can actually change it to English. I probably should have done that.

2084
02:51:28,680 --> 02:51:38,680
And then actually as you slice it out long, you know, you can start to see more yellow, more yellow, more yellow.

2085
02:51:38,680 --> 02:51:51,680
So, you know, so anyway, so this coordinate, this is at minus 13, 55 and minus 61. So you're like, okay, well, how does that relate to, you know, this map projection we've been using here?

2086
02:51:51,680 --> 02:52:00,680
Like there is no 13, you know, there's no 13, 55, 61 because it's on a different coordinate system. So this is just really quick steps.

2087
02:52:00,680 --> 02:52:08,680
I won't talk through them because they're not particularly exciting on their own, but this is just to show you, give you a process of how you can convert if you've got coordinates.

2088
02:52:08,680 --> 02:52:17,680
So these coordinates, which are in the very, the standard map projection, which is EPSG 434343436.

2089
02:52:17,680 --> 02:52:23,680
So is it 43204326? I was close.

2090
02:52:23,680 --> 02:52:31,680
So most things are in that. The satellite data isn't.

2091
02:52:31,680 --> 02:52:39,680
So in fact, the satellite data is in this EPSG 32620, which again, you don't particularly need to know, but you just need to know that they are different.

2092
02:52:39,680 --> 02:52:47,680
So it covers this area of land, which is, you know, that Brazil border.

2093
02:52:47,680 --> 02:52:54,680
So this point of interest, pure eye, those are the coordinates.

2094
02:52:54,680 --> 02:53:01,680
So I'll just let you work with it just to show you. This is a method that you could just replace it with whatever other coordinates you're interested in.

2095
02:53:01,680 --> 02:53:04,680
You need to do some sort of transform thing.

2096
02:53:04,680 --> 02:53:07,680
You need to apply the transform thing.

2097
02:53:07,680 --> 02:53:13,680
And then you've actually got your transform coordinates. So there is coordinates minus 13, 55.

2098
02:53:13,680 --> 02:53:20,680
Minus 13, 55 and the 61. I think this is the 61 and then this is the minus 13, 55.

2099
02:53:20,680 --> 02:53:23,680
Right. So remember XY, because this, I'm going to stress it again.

2100
02:53:23,680 --> 02:53:29,680
This is not in XY. This is Y and that is X.

2101
02:53:29,680 --> 02:53:37,680
So you have to remember which way around. Anyway, then just to show you at that coordinate, let's see what the NDVI value is.

2102
02:53:37,680 --> 02:53:44,680
So 0.38. So actually it's quite high. That's surprising because it's pasture.

2103
02:53:44,680 --> 02:53:53,680
But OK, well, it is what it is. And then G8. So you can copy the F7 plotting routine.

2104
02:53:53,680 --> 02:53:58,680
OK, I will do that just to show you how we're annotating because I said we're annotating.

2105
02:53:58,680 --> 02:54:01,680
So the F7 plotting routine.

2106
02:54:02,680 --> 02:54:07,680
There. And I'll just change the size, just make it bigger.

2107
02:54:07,680 --> 02:54:15,680
But literally all we're doing is this annotation here. I mean, you could put it anywhere, but I guess I said I'd put it there.

2108
02:54:15,680 --> 02:54:21,680
So annotate, annotate, annotate. New.

2109
02:54:21,680 --> 02:54:25,680
Deforestation for pasture.

2110
02:54:25,680 --> 02:54:31,680
And then at this XY. And then, yeah, the rest is just kind of like, you know, arrows and bits.

2111
02:54:31,680 --> 02:54:37,680
So I'm not going to. I'm not going to put you through that. I mean, to see that. But yeah.

2112
02:54:37,680 --> 02:54:43,680
Obviously, the point is that you generated the XY coordinates. So now you know where that is.

2113
02:54:45,680 --> 02:54:50,680
Invalid syntax, because it does not have a coding parent.

2114
02:54:50,680 --> 02:54:54,680
Please work. Thank you.

2115
02:54:54,680 --> 02:54:58,680
So, yeah.

2116
02:54:58,680 --> 02:55:08,680
So that is how you can annotate, you know, a way of translating something from, you know, a different map, for example, or a different projection.

2117
02:55:08,680 --> 02:55:17,680
But you want to annotate your satellite data derived output with, you know, a thing.

2118
02:55:17,680 --> 02:55:27,680
And that is, thankfully for me, that is the end of the coding of the tutorial.

2119
02:55:27,680 --> 02:55:36,680
And I think, yeah, so we've got six minutes for wrap up, which I didn't really prepare because I wasn't expecting actually to be able to do wrapping up.

2120
02:55:36,680 --> 02:55:40,680
So, yeah, I guess we should just do questions.

2121
02:55:40,680 --> 02:55:44,680
That's probably more useful than me just like.

2122
02:55:44,680 --> 02:55:47,680
Trying to come up with something interesting.

2123
02:55:47,680 --> 02:55:49,680
Anything.

2124
02:55:49,680 --> 02:55:53,680
Any comments, something, I don't know.

2125
02:55:53,680 --> 02:55:54,680
No.

2126
02:55:54,680 --> 02:55:56,680
Yes.

2127
02:55:56,680 --> 02:56:06,680
So, if you're dealing with two different sets of satellite image data, and you worry that there might be discrepancy with the technology that was used or the quality of the camera or whatever,

2128
02:56:06,680 --> 02:56:15,680
would you consider normalizing dataset one off of dataset two, given an area that you know hasn't changed or something like that?

2129
02:56:15,680 --> 02:56:21,680
Like, would you consider it to be using pre-processing on one, or is that getting a little bit dangerous?

2130
02:56:21,680 --> 02:56:29,680
When you said, so do you mean not using two different satellites?

2131
02:56:29,680 --> 02:56:38,680
Using the two, but let's say you're noticing on one that the colors are coming out a little bit lighter, like there's just kind of across the board, you're not getting the data you would have expected.

2132
02:56:38,680 --> 02:56:50,680
Would you consider comparing an area that you know has a change with satellite image two and be like, okay, so across the board on this one, we should lower values by six or whatever because they seem to be a little bit lighter in this one?

2133
02:56:50,680 --> 02:56:54,680
Oh, I see, yeah. So you're sort of saying like, would that be a valid?

2134
02:56:54,680 --> 02:56:57,680
Yeah, that would be a good research step.

2135
02:56:57,680 --> 02:57:16,680
Yeah, I was going to say, I think there did seem to be a lot of, I mean, obviously, Kevin's tutorial, and I did see there was a lot of people referencing adjustments, so the corrections, and I think that would, it sounds like, often is just going to be on that case by case basis,

2136
02:57:16,680 --> 02:57:45,680
you say like a region that you know, and it's like, actually, maybe we can make that own sort of manual adjustment of, you know, so like, for example, I mean, you could even see that the difference in the wavelengths, so with like the red band, you can see it was like tighter this way, so you know, maybe you could adjust the data and be like, actually, we know the values, you know, maybe some of these values, based on the things we know about the surfaces on the earth, maybe we know that that's kind of over, you know, like over reading, and like, because it's like rock versus plant design.

2137
02:57:46,680 --> 02:57:54,680
So yeah, so yeah, sorry. The end was like, yes, I think so. It seems like that's how people do it. So yeah, I hope that's helpful. Question.

2138
02:57:54,680 --> 02:57:57,680
So,

2139
02:57:57,680 --> 02:58:01,680
another question. Okay. No, that's fine if you don't have.

2140
02:58:01,680 --> 02:58:09,680
Because it's been a long session for me. Anyway, yeah, thank you for coming. I hope that was useful.

2141
02:58:09,680 --> 02:58:16,680
Like if you want to, I don't know if you want to ask me stuff about it. I mean, I, yeah, I'm all over the internet in a professional way.

2142
02:58:16,680 --> 02:58:19,680
So yeah, just feel free to like reach out.

2143
02:58:19,680 --> 02:58:24,680
Yeah, thanks so much for coming and have a great rest of conference.

