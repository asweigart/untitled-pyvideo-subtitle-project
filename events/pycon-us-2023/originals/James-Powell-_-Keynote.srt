1
00:00:00,000 --> 00:00:08,160
So, next we have our next keynote speakers who will be setting up right now.

2
00:00:08,160 --> 00:00:16,720
So, James Powell, who is when I was starting to just becoming starting to in my journey

3
00:00:16,720 --> 00:00:22,360
in the Python community being involved with other Python community members, volunteering,

4
00:00:22,360 --> 00:00:23,360
speaking.

5
00:00:23,360 --> 00:00:29,600
I was impressed seeing James Powell's talk at PyCon Canada many years ago.

6
00:00:29,600 --> 00:00:38,520
And when he talked about how to engage with volunteers and how to align goals of volunteers

7
00:00:38,520 --> 00:00:45,860
who have personal passions and the bigger goal of the community.

8
00:00:45,860 --> 00:00:52,160
And I always found that his talks are super engaging, very unique style.

9
00:00:52,160 --> 00:00:54,720
He's a great educator and very entertaining.

10
00:00:54,720 --> 00:01:00,560
So I really so exciting to introduce James Powell to you all.

11
00:01:00,560 --> 00:01:03,240
Go ahead.

12
00:01:03,240 --> 00:01:07,100
Good morning, everybody.

13
00:01:07,100 --> 00:01:11,560
This is I don't want to be a Python expert.

14
00:01:11,560 --> 00:01:14,960
We are at PyCon US number 20 in Salt Lake City.

15
00:01:14,960 --> 00:01:17,960
It's Saturday, April 22nd, 2023.

16
00:01:17,960 --> 00:01:19,840
I am of course James Powell.

17
00:01:19,840 --> 00:01:22,720
If you want to follow me on social media, on social media, I'm always basically don't

18
00:01:22,720 --> 00:01:23,720
use this code.

19
00:01:23,720 --> 00:01:29,240
This should also serve as a disclaimer for everything that you're about to see.

20
00:01:29,240 --> 00:01:33,920
So I used to give a lot of really crazy talks about doing things like live patching the

21
00:01:33,920 --> 00:01:38,760
Python interpreter to swap out the C eval, pi eval frame x loop.

22
00:01:38,760 --> 00:01:42,040
And people would come up to me after the talk and say, hey, I want to be a Python expert

23
00:01:42,040 --> 00:01:43,040
too.

24
00:01:43,040 --> 00:01:45,400
And my answer to them would be, why bother?

25
00:01:45,400 --> 00:01:47,400
What does this really add to your life?

26
00:01:47,400 --> 00:01:49,400
And I tried to think a little bit more about this.

27
00:01:49,400 --> 00:01:52,440
What does this expertise really add to our lives?

28
00:01:52,440 --> 00:01:57,920
Now, I also gave a talk at Pydata Seattle in 2017 called so you want to be a Python

29
00:01:57,920 --> 00:01:58,920
expert.

30
00:01:58,920 --> 00:02:00,880
Because enough people have been asking me about this.

31
00:02:00,880 --> 00:02:02,280
What does it take to be a Python expert?

32
00:02:02,280 --> 00:02:04,800
And this talk ended up being very popular.

33
00:02:04,800 --> 00:02:06,080
Here's something that's quite interesting.

34
00:02:06,080 --> 00:02:11,360
I gave the exact same talk one week earlier at Pydata Berlin and it was titled advanced

35
00:02:11,360 --> 00:02:14,120
metaphors encoding with Python.

36
00:02:14,120 --> 00:02:16,540
Almost nobody on YouTube have seen that talk.

37
00:02:16,540 --> 00:02:19,640
The clickbait title really works.

38
00:02:19,640 --> 00:02:24,600
And if you think about it, it probably makes sense because that word expert is a very loaded

39
00:02:24,600 --> 00:02:25,600
term.

40
00:02:25,600 --> 00:02:29,840
It means a lot of things to a lot of people and to an audience like this for whom we are

41
00:02:29,840 --> 00:02:34,720
often valuing ourselves in terms of being thought of as being smart or being thought

42
00:02:34,720 --> 00:02:36,560
of as being experts.

43
00:02:36,560 --> 00:02:41,720
This term expertise really has a lot of implicit meaning.

44
00:02:41,720 --> 00:02:45,720
Oftentimes in my own actual work, I'll see a rejection of this idea of expertise.

45
00:02:45,720 --> 00:02:47,760
And it's a very valid rejection.

46
00:02:47,760 --> 00:02:52,000
That is to say I'll work with a scientist or a data scientist or a quantitative modeler

47
00:02:52,000 --> 00:02:54,560
who will say I don't want to be a Python expert.

48
00:02:54,560 --> 00:02:58,080
In fact, I don't really even want to be a Python programmer.

49
00:02:58,080 --> 00:03:01,580
I just want to be somebody who uses Python to get things done.

50
00:03:01,580 --> 00:03:06,680
And I'm extraordinarily sympathetic to that perspective because in the end, what is the

51
00:03:06,680 --> 00:03:08,080
value of the expertise itself?

52
00:03:08,080 --> 00:03:11,640
The value is what you're able to accomplish with that expertise.

53
00:03:11,640 --> 00:03:14,080
And so let's not talk that much about expertise.

54
00:03:14,080 --> 00:03:17,160
In fact, let's start with something very simple.

55
00:03:17,160 --> 00:03:20,360
Let's start with something quite elementary in this presentation today.

56
00:03:20,360 --> 00:03:24,760
We'll even start with something that you might have covered in your elementary education.

57
00:03:24,760 --> 00:03:26,220
Let's start with Newton's method.

58
00:03:26,220 --> 00:03:30,920
And for those of you who do not remember what Newton's method is, it is an iterative approach

59
00:03:30,920 --> 00:03:35,080
for solving or finding the roots of a real valued function.

60
00:03:35,080 --> 00:03:39,560
We often use this to find the roots of a polynomial where there isn't an easy closed form solution

61
00:03:39,560 --> 00:03:41,600
like a quadratic formula.

62
00:03:41,600 --> 00:03:45,000
And even though we're going to talk about things like Newton's method, what we're going

63
00:03:45,040 --> 00:03:49,000
to talk about here is actually broadly relevant to any case where the code that you're writing

64
00:03:49,000 --> 00:03:53,800
is a solver, a simulator, an agent model, even things that might look like back testers

65
00:03:53,800 --> 00:03:57,160
or even things that might look like machine learning training mechanisms.

66
00:03:57,160 --> 00:04:01,640
Well in Python, making use of something like Newton's method is quite easy.

67
00:04:01,640 --> 00:04:05,540
We go into SciPy and we say from SciPy.optimize import Newton.

68
00:04:05,540 --> 00:04:06,540
We give it a function.

69
00:04:06,540 --> 00:04:08,840
We optionally give it the derivative of that function.

70
00:04:08,840 --> 00:04:11,060
And it'll go and it'll find the roots of this polynomial.

71
00:04:11,060 --> 00:04:13,840
And so in this case, it'll find the roots negative two and four.

72
00:04:13,880 --> 00:04:18,800
And it'll tell us that's where that polynomial intersects with the x-axis.

73
00:04:18,800 --> 00:04:24,120
Now this is SciPy and so NumPy and DRA should show up somewhere along the way.

74
00:04:24,120 --> 00:04:25,120
Well in fact it does.

75
00:04:25,120 --> 00:04:29,480
You can provide not just the one guess, not the one initial point, but all of the initial

76
00:04:29,480 --> 00:04:30,480
points.

77
00:04:30,480 --> 00:04:33,920
So if you bracket those two initial points around the two edges of the parabola, you'll

78
00:04:33,920 --> 00:04:36,160
be able to find both of the roots simultaneously.

79
00:04:36,160 --> 00:04:39,560
But that's about as far as the use of the NumPy and DRA really gets into this.

80
00:04:39,560 --> 00:04:45,040
And so when you think about this, the implementation of SciPy.optimize.Newton probably is very

81
00:04:45,040 --> 00:04:47,560
similar to the most naive approach that you might take.

82
00:04:47,560 --> 00:04:49,560
It probably looks something like this.

83
00:04:49,560 --> 00:04:52,760
A simple for loop where you're looping and then applying that iterative step.

84
00:04:52,760 --> 00:04:56,160
And in the case of Newton's method, the iterative step is quite simple.

85
00:04:56,160 --> 00:05:00,600
All you're doing is evaluating whatever your guess is in the function and dividing that

86
00:05:00,600 --> 00:05:06,200
by what the derivative is and then subtracting that until you get close enough to zero.

87
00:05:06,200 --> 00:05:10,800
Of course, when you look at this code, you might say, I'm not that happy with it because

88
00:05:10,800 --> 00:05:12,880
why do I need 50 iterations?

89
00:05:12,880 --> 00:05:16,120
For the polynomial that we just looked at, you don't need 50 iterations to find the roots

90
00:05:16,120 --> 00:05:17,120
of that thing.

91
00:05:17,120 --> 00:05:18,720
You probably only need three or four.

92
00:05:18,720 --> 00:05:20,200
And so we'll parameterize this.

93
00:05:20,200 --> 00:05:24,440
And this is in fact what the API for SciPy.optimize.Newton looks like.

94
00:05:24,440 --> 00:05:27,720
You have a max iter and you can give it the maximum number of iterations that you want

95
00:05:27,720 --> 00:05:28,720
to run for.

96
00:05:28,720 --> 00:05:32,600
But you can think, well, how do I know what the iterations are ahead of time?

97
00:05:32,600 --> 00:05:34,120
Maybe I want to give it a tolerance.

98
00:05:34,120 --> 00:05:37,840
When you get close enough to zero, then you're done.

99
00:05:37,840 --> 00:05:40,440
And if we're going to write this in pure Python, we might make use of the math module.

100
00:05:40,440 --> 00:05:42,640
And here we can implement an absolute tolerance.

101
00:05:42,640 --> 00:05:48,320
But the moment you see is close, abs tall, you think, well, if there's an absolute tolerance,

102
00:05:48,320 --> 00:05:50,280
what about a relative tolerance?

103
00:05:50,280 --> 00:05:53,280
And the keyword arguments start to grow.

104
00:05:53,280 --> 00:05:57,760
Because now we have three keyword arguments, max iter, tolerance, and rtolerance, to implement

105
00:05:57,760 --> 00:05:58,760
this.

106
00:05:58,760 --> 00:06:03,240
And we are now matching very closely to the API of SciPy.optimize.Newton.

107
00:06:03,480 --> 00:06:07,640
If you think about any sort of iterative approach, you might say keep working until there's no

108
00:06:07,640 --> 00:06:09,640
additional improvement.

109
00:06:09,640 --> 00:06:11,000
Don't keep doing work.

110
00:06:11,000 --> 00:06:13,880
Don't burn through my cycles if you're not getting anywhere.

111
00:06:13,880 --> 00:06:18,120
And so we might add yet another keyword argument, one which SciPy.optimize.Newton doesn't have,

112
00:06:18,120 --> 00:06:22,200
which just matches for the previous step to the current step, what is the actual improvement

113
00:06:22,200 --> 00:06:23,200
here?

114
00:06:23,200 --> 00:06:26,540
And we might say if we're going to do the absolute improvement, we should also look

115
00:06:26,540 --> 00:06:28,160
at the relative improvement.

116
00:06:28,160 --> 00:06:32,320
And this thing is beginning to spiral out of control.

117
00:06:32,320 --> 00:06:37,560
Now there is one saving grace for this, which is we were able to write a function which

118
00:06:37,560 --> 00:06:41,960
has a keyword argument titled RIMP for relative improvement.

119
00:06:41,960 --> 00:06:47,500
And I don't know about you, but that just feels very SciPy circa 2007 to me, a keyword

120
00:06:47,500 --> 00:06:49,600
argument called RIMP.

121
00:06:49,600 --> 00:06:53,680
But if you're not convinced that this is beginning to spiral out of control, really think about

122
00:06:53,680 --> 00:06:55,440
this.

123
00:06:55,440 --> 00:06:58,840
In our first iteration from the first variation of the function to the second variation of

124
00:06:59,240 --> 00:07:04,000
we added a keyword argument to match to what SciPy.optimize.Newton was doing.

125
00:07:04,000 --> 00:07:07,600
And if anywhere in the world the very last line of code that you see here where somebody

126
00:07:07,600 --> 00:07:12,240
passing those max iterations as a positional argument, not as a keyword argument, exists,

127
00:07:12,240 --> 00:07:16,040
the moment you made this change to this code, you broke their workflow.

128
00:07:16,040 --> 00:07:18,080
These people don't want to be Python programmers.

129
00:07:18,080 --> 00:07:19,880
They just want to use Python to get things done.

130
00:07:19,880 --> 00:07:24,140
They will get on social media and they will abuse you for breaking their code.

131
00:07:24,140 --> 00:07:25,140
You did something wrong.

132
00:07:26,140 --> 00:07:32,260
you probably should have used keyword-only arguments to save yourself from this debacle.

133
00:07:32,260 --> 00:07:33,780
But there's another hard lesson learned.

134
00:07:33,780 --> 00:07:38,940
If you think about this a little bit, when we look at all the places where somebody might

135
00:07:38,940 --> 00:07:43,300
use this code in the wild, somewhere in the wild one of your users is passing in multiple

136
00:07:43,300 --> 00:07:46,660
modalities, both the maximum number of iterations and the tolerance.

137
00:07:46,660 --> 00:07:47,720
Is this well-defined?

138
00:07:47,720 --> 00:07:48,720
What does this do?

139
00:07:48,720 --> 00:07:50,820
If you change the underlying code, are you going to break their code?

140
00:07:50,820 --> 00:07:53,240
Are you going to get on social media and hurl abuse at you?

141
00:07:53,240 --> 00:07:54,240
You don't know.

142
00:07:54,240 --> 00:07:58,320
It would be a good idea to document what happens when all the interactions of these

143
00:07:58,320 --> 00:07:59,720
keyword arguments occur.

144
00:07:59,720 --> 00:08:00,720
Which you probably won't do.

145
00:08:00,720 --> 00:08:06,820
If you think about the documentation tool we have, we're very encouraged to document

146
00:08:06,820 --> 00:08:09,600
keyword arguments individually and not the interactions of them.

147
00:08:09,600 --> 00:08:12,520
That fits into a block at the end of the thing.

148
00:08:12,520 --> 00:08:16,440
Very likely you're going to preclude this entirely, which I don't think is the right

149
00:08:16,440 --> 00:08:20,880
choice because sometimes you want to run from maximum iterations or until another criteria

150
00:08:20,880 --> 00:08:22,000
is met.

151
00:08:22,640 --> 00:08:28,600
If you really want to be diligent, you need to specify how this works in the form of tests.

152
00:08:28,600 --> 00:08:32,280
You might write a unit test or a property test where you say these are all the different

153
00:08:32,280 --> 00:08:36,400
ways this can be called and I'm going to specify that and that way if I make a change to the

154
00:08:36,400 --> 00:08:41,040
underlying code, my test will break and we'll see not in documentation but in the form of

155
00:08:41,040 --> 00:08:44,440
a test how to specify the way in which this works.

156
00:08:44,440 --> 00:08:48,600
Except the problem here is for five modalities that we have, we need the Cartesian product

157
00:08:48,600 --> 00:08:52,880
of either choosing or not choosing that modality, so we need 32 tests.

158
00:08:52,880 --> 00:08:55,600
And if we had one additional modality, we need to double the number of tests.

159
00:08:55,600 --> 00:08:57,080
This expands geometrically.

160
00:08:57,080 --> 00:09:00,680
This will genuinely spiral out of control.

161
00:09:00,680 --> 00:09:05,120
And we are obligated to do this because what might appear to be an innocuous change to

162
00:09:05,120 --> 00:09:08,800
the way in which this code is written will break user code and practice if we look at

163
00:09:08,800 --> 00:09:13,880
this code and say if they didn't pass in the imp or the rimp, great keyword argument name

164
00:09:13,880 --> 00:09:18,800
if I must say so myself, arguments, we're repeatedly checking in this type inner loop

165
00:09:18,800 --> 00:09:20,480
whether that's set to none or not.

166
00:09:20,480 --> 00:09:22,640
Let's see if we can factor that out of the loop.

167
00:09:22,640 --> 00:09:25,200
But the moment you do that, you've broken people's code and you need that unit test

168
00:09:25,200 --> 00:09:26,480
in place.

169
00:09:26,480 --> 00:09:31,760
And so note that this is already spiraled out of control and we haven't really tested

170
00:09:31,760 --> 00:09:36,320
limits of our imagination because if we can consider all of these ways to do something

171
00:09:36,320 --> 00:09:40,720
as simple and elementary as Newton's method, well, somebody can come to us and say, well,

172
00:09:40,880 --> 00:09:44,960
could you run this for a fixed amount of time like a soft real time limitation, run Newton's

173
00:09:44,960 --> 00:09:47,640
method for two seconds and see how far you get?

174
00:09:47,640 --> 00:09:52,480
Or maybe we could look at the ratio of adjacent terms and we could see if those converge to

175
00:09:52,480 --> 00:09:53,480
something.

176
00:09:53,480 --> 00:09:55,360
A lot of integer sequences converge to particular values.

177
00:09:55,360 --> 00:09:58,840
If you think about something like Fibonacci, adjacent terms of the Fibonacci sequence converge

178
00:09:58,840 --> 00:09:59,840
to the golden mean.

179
00:09:59,840 --> 00:10:03,960
So you could run this until the convergence reaches some particular threshold.

180
00:10:03,960 --> 00:10:08,600
Rat tall I don't think is as good as rimp but we're still on the right track for 2007

181
00:10:08,600 --> 00:10:11,240
to ask sci-pi keyword argument names.

182
00:10:11,240 --> 00:10:16,200
Having said that, if you really think about this, I've given the game away.

183
00:10:16,200 --> 00:10:19,680
The moment I said Fibonacci, half of you out there are thinking this probably should have

184
00:10:19,680 --> 00:10:21,800
been a generator from the beginning.

185
00:10:21,800 --> 00:10:22,800
And you're right.

186
00:10:22,800 --> 00:10:26,600
We should have implemented this Newton's method as just an infinite sequence of steps and

187
00:10:26,600 --> 00:10:30,600
then when somebody says, oh, I want to run this for 50 steps, you say, here's the intertools

188
00:10:30,600 --> 00:10:34,080
module, import iSlices, iSlices 50 steps.

189
00:10:34,080 --> 00:10:37,680
Or when they say, well, I don't want all of the incremental steps, I just want the end,

190
00:10:37,680 --> 00:10:41,920
you say, well, here's the collections module, use collections.deck and throw away everything

191
00:10:41,920 --> 00:10:43,420
except the very last value.

192
00:10:43,420 --> 00:10:47,960
When they say I want this for up until I reach a particular absolute tolerance, that's just

193
00:10:47,960 --> 00:10:49,640
intertools.takewhile.

194
00:10:49,640 --> 00:10:53,000
If you want this for a relative tolerance, that's just intertools.takewhile with a different

195
00:10:53,000 --> 00:10:54,000
lambda.

196
00:10:54,000 --> 00:10:58,160
If you want this for some relative improvement or some absolute improvement, that's just

197
00:10:58,160 --> 00:11:02,420
takewhile on an N-wise where an N-wise is a generalization of the idea of getting overlapping

198
00:11:02,420 --> 00:11:06,920
windows of some particular size of some data which is basically just when you take the

199
00:11:06,920 --> 00:11:11,840
intertools module and you enumerate T, a bunch of iterables, and then you iSlices them

200
00:11:11,840 --> 00:11:14,960
and do them together, of course, for those of you who have seen a talk like this before,

201
00:11:14,960 --> 00:11:16,040
that's just fan service.

202
00:11:16,040 --> 00:11:17,040
You're welcome, Jeff.

203
00:11:17,040 --> 00:11:19,960
In fact, these days you just do an intertools.pairwise.

204
00:11:19,960 --> 00:11:22,920
But whatever the case may be, we're going to sit in a code review somewhere along the

205
00:11:22,920 --> 00:11:27,240
way and we're going to have to either litigate or adjudicate, is this code actually better

206
00:11:27,240 --> 00:11:28,240
than what we started with?

207
00:11:28,240 --> 00:11:31,960
We know it's spiraling out of control, but is the other version any better?

208
00:11:32,120 --> 00:11:37,120
Well, we already know the answer to this because all code reviews are all the same.

209
00:11:37,120 --> 00:11:40,020
We all know what good code is and what bad code is.

210
00:11:40,020 --> 00:11:44,560
Good code is code I wrote and bad code is code you wrote.

211
00:11:44,560 --> 00:11:51,280
But we still have blocked out 30 minutes for the code review session.

212
00:11:51,280 --> 00:11:54,680
We probably should take a couple of notes along the way and let's see if we can litigate

213
00:11:54,680 --> 00:11:56,760
this a little bit more deeply.

214
00:11:56,760 --> 00:12:00,900
Well, if you think about it, the very first version is just adding keyword arguments,

215
00:12:00,900 --> 00:12:04,020
so you do all of the things you want to do with Newton's method in just one line of code.

216
00:12:04,020 --> 00:12:07,580
Whereas the second version, you have to have two lines of code and you have to have an

217
00:12:07,580 --> 00:12:08,580
import.

218
00:12:08,580 --> 00:12:11,940
And if you're a data scientist, you're thinking, you know, why write two lines of code when

219
00:12:11,940 --> 00:12:13,220
I have to write one line of code?

220
00:12:13,220 --> 00:12:16,100
I'm very sympathetic to that attitude, but definitely data scientists who know who you

221
00:12:16,100 --> 00:12:17,100
are.

222
00:12:17,100 --> 00:12:20,900
Additionally, in order to even understand how all of this works, you need to know what

223
00:12:20,900 --> 00:12:21,900
a generator is.

224
00:12:21,900 --> 00:12:23,980
You need to know what the intertools module is.

225
00:12:23,980 --> 00:12:29,180
A set of colleagues of mine have created a framework for data acquisition and data management

226
00:12:29,260 --> 00:12:31,060
around X-ray beam lines.

227
00:12:31,060 --> 00:12:36,740
And the dominating concept for that framework is PEP380 delegation to a subgenerator.

228
00:12:36,740 --> 00:12:41,420
If you think a scientist will complain when you show them a generator and yield, see what

229
00:12:41,420 --> 00:12:44,340
happens when you show them yield from.

230
00:12:44,340 --> 00:12:47,100
There's a bar that you have to meet to be able to use this code.

231
00:12:47,100 --> 00:12:51,140
And the question might be, is it worthwhile for us to inflict those requirements upon

232
00:12:51,140 --> 00:12:52,200
our users?

233
00:12:52,200 --> 00:12:56,100
But on the other side, you might be able to mitigate a little bit of that by creating

234
00:12:56,100 --> 00:12:57,300
a convenience layer.

235
00:12:57,300 --> 00:13:00,460
So the core layer looks one way using all of these advanced functionalities, and there's

236
00:13:00,460 --> 00:13:01,460
a convenience layer.

237
00:13:01,460 --> 00:13:04,900
And when we look at a lot of projects in the in the pie data ecosystem, you see this pattern

238
00:13:04,900 --> 00:13:06,420
of the core and the convenience layer.

239
00:13:06,420 --> 00:13:09,660
Matplotlib and pyplot are very good examples of that.

240
00:13:09,660 --> 00:13:12,660
And maybe that allows you to write tests a little bit better.

241
00:13:12,660 --> 00:13:15,540
The convenience tests can be a little bit more superficial, and the core tests can be

242
00:13:15,540 --> 00:13:16,740
a little bit more exhaustive.

243
00:13:16,740 --> 00:13:18,540
So there might be some benefit there.

244
00:13:18,540 --> 00:13:22,900
But I think one thing that hasn't come up at all in our code review is the design of

245
00:13:23,540 --> 00:13:27,260
or specifically the absence of design.

246
00:13:27,260 --> 00:13:32,580
That is to say, if we are to clumsily define the word design in a way that we don't typically

247
00:13:32,580 --> 00:13:38,160
define it to be any decisions that we make to address questions whose answers are unknowable

248
00:13:38,160 --> 00:13:42,180
or unverifiable, anything that we make, which we say, this is a judgment call.

249
00:13:42,180 --> 00:13:44,220
I think this is how this is going to be used.

250
00:13:44,220 --> 00:13:46,060
I think this is what our users want.

251
00:13:46,060 --> 00:13:48,260
I think this is what people want to do with this.

252
00:13:48,260 --> 00:13:51,500
Well, there's a lot of these calls and there's no right or wrong answer.

253
00:13:51,500 --> 00:13:55,380
Even if you think about the temporal dimension, it may be the case that the right answer today

254
00:13:55,380 --> 00:13:57,220
is the wrong answer tomorrow.

255
00:13:57,220 --> 00:13:58,820
Design is not necessarily timeless.

256
00:13:58,820 --> 00:14:03,940
It's oftentimes very idiosyncratic or very specified to a particular period of time.

257
00:14:03,940 --> 00:14:08,180
Well, of course that makes sense, because if we think about design, we're thinking about,

258
00:14:08,180 --> 00:14:11,720
especially when we talk about APIs, the accommodation to the human requirements.

259
00:14:11,720 --> 00:14:13,400
How is a human being going to use this?

260
00:14:13,400 --> 00:14:17,260
And this necessarily means accommodation to the infinite profundity of the human experience.

261
00:14:17,260 --> 00:14:20,240
So design doesn't really have a right or a wrong answer.

262
00:14:20,240 --> 00:14:24,320
It's just what seems to work and what you can get away with.

263
00:14:24,320 --> 00:14:28,080
And you're always trapped in this puzzle of, well, did I get it right?

264
00:14:28,080 --> 00:14:29,080
Did I get it wrong?

265
00:14:29,080 --> 00:14:30,080
Do I know if I got it right?

266
00:14:30,080 --> 00:14:31,080
Do I know if I got it wrong?

267
00:14:31,080 --> 00:14:34,420
Well, if we're willing to accept the clumsy definition of design, maybe we're willing

268
00:14:34,420 --> 00:14:38,280
to accept a clumsy dichotomy between the idea of design and effort.

269
00:14:38,280 --> 00:14:42,960
Where if design is trying to approach these unknowable questions, effort might be the

270
00:14:42,960 --> 00:14:49,400
processes that we take to do things to solve problems that are knowable and that are verifiable,

271
00:14:49,640 --> 00:14:54,440
where we just know it's just a matter of number of lines of code that we have to write.

272
00:14:54,440 --> 00:14:59,560
And so if we think about this, the core convenience layer dichotomy, I actually don't like that

273
00:14:59,560 --> 00:15:00,560
very much.

274
00:15:00,560 --> 00:15:04,960
Because you're just trading the design at one level for the design at another level.

275
00:15:04,960 --> 00:15:08,680
You're still making a decision for what somebody wants to have available to them, what they

276
00:15:08,680 --> 00:15:12,600
want to see, what modalities they care about, what modalities they don't care about.

277
00:15:12,600 --> 00:15:14,960
And you've narrowed the problem only very slightly.

278
00:15:14,960 --> 00:15:21,460
In fact, I actually think the preferred solution here is to make the scientists use generators.

279
00:15:21,460 --> 00:15:24,520
And to teach them generators and to teach them about the intertools module and to avoid

280
00:15:24,520 --> 00:15:26,440
the design problem entirely.

281
00:15:26,440 --> 00:15:29,620
Don't presume that you know the modalities that they care about.

282
00:15:29,620 --> 00:15:34,480
Just give them a generator and let them supply whatever they want to do.

283
00:15:34,480 --> 00:15:37,340
But this does necessarily introduce some complexity.

284
00:15:37,340 --> 00:15:40,320
And we can take this complexity to the extreme.

285
00:15:40,320 --> 00:15:44,680
Because honestly, I have written this in real code before.

286
00:15:44,680 --> 00:15:47,120
Some of you are looking at this, you have no idea what this is all about.

287
00:15:47,120 --> 00:15:51,800
I am a very strong believer in the idea of pre-pumped generator co-routines.

288
00:15:51,800 --> 00:15:55,480
I have to remind you one more time, don't use this code, folks.

289
00:15:55,480 --> 00:15:59,800
But if we think about this dichotomy that we've set up, clumsy as it is, between design

290
00:15:59,800 --> 00:16:03,220
and effort, we can think that what makes us better at design is judgment.

291
00:16:03,220 --> 00:16:05,840
And what makes us better at effort is expertise.

292
00:16:05,840 --> 00:16:09,940
That is to say, by understanding these complex mechanisms that we have, we can lever our

293
00:16:09,940 --> 00:16:14,000
expertise to turn problems that have an unknowable aspect to them into problems that have a

294
00:16:14,000 --> 00:16:16,260
knowable aspect to them.

295
00:16:16,260 --> 00:16:20,200
And to be honest, I am very skeptical about my own judgment.

296
00:16:20,200 --> 00:16:22,460
After all, look at how I'm dressed.

297
00:16:22,460 --> 00:16:28,660
But I'm much more confident about my ability to leverage expertise because largely the

298
00:16:28,660 --> 00:16:31,900
expertise that we're talking about here, the expertise of using parts of Python that

299
00:16:31,900 --> 00:16:35,700
are considered to be more advanced or considered to be more esoteric, it's largely about a

300
00:16:35,700 --> 00:16:40,220
conceptual expertise that can be very obvious, in fact, and can be methodically constructed

301
00:16:40,220 --> 00:16:43,380
and most importantly can be methodically instructed.

302
00:16:43,380 --> 00:16:45,380
I'll give you an example.

303
00:16:45,380 --> 00:16:48,220
We talk about generator co-routines and we put this in front of a scientist.

304
00:16:48,220 --> 00:16:49,540
They have no idea what you're talking about.

305
00:16:49,540 --> 00:16:51,000
They've never seen this before.

306
00:16:51,000 --> 00:16:54,260
Their familiarity is with mechanisms that they've learned when they first learned programming

307
00:16:54,260 --> 00:16:57,440
using MATLAB or C or maybe even C++.

308
00:16:57,440 --> 00:16:59,660
But you can share with them a very simple idea.

309
00:16:59,660 --> 00:17:01,460
We can represent data in multiple different ways.

310
00:17:01,460 --> 00:17:05,380
We can represent the exact same data, the three entities, A, B, and C, as a string or

311
00:17:05,380 --> 00:17:06,380
as a list.

312
00:17:06,380 --> 00:17:09,540
But beyond the superficialities, whether it's a list or a string, we can see that there's

313
00:17:09,540 --> 00:17:11,260
something a little bit deeper here.

314
00:17:11,260 --> 00:17:15,460
In other words, one of these is an in-band encoding and the other is an out-of-band encoding.

315
00:17:15,460 --> 00:17:19,640
One of these uses a single channel for representing the metadata and the data or the structuring,

316
00:17:19,640 --> 00:17:21,660
and the other one uses distinct channels.

317
00:17:21,660 --> 00:17:27,940
The string conflates the commas which are delineating the data with the actual values

318
00:17:27,940 --> 00:17:31,380
themselves and the list has an out-of-band encoding where there's no way for you to

319
00:17:31,380 --> 00:17:35,580
mistake is this a comma that's part of the data or not.

320
00:17:35,580 --> 00:17:38,900
And we know in-band encodings are fundamentally ambiguous.

321
00:17:38,900 --> 00:17:43,780
And so we run into these problems where is this A, B, C, D, four entities or A, B, C,

322
00:17:43,780 --> 00:17:46,620
comma, D where the comma is part of the entity, three entities.

323
00:17:46,620 --> 00:17:48,940
The out-of-band encodings are fundamentally unambiguous.

324
00:17:48,940 --> 00:17:53,340
Well, in a very similar sense, we can think when we want to disambiguate these in-band

325
00:17:53,340 --> 00:17:55,780
encodings, we have a set of techniques.

326
00:17:55,780 --> 00:17:58,580
And the techniques are almost always the same, partitioning, quoting, escaping.

327
00:17:58,820 --> 00:18:02,420
When you think about partitioning, you think about taking the input data space and designating

328
00:18:02,420 --> 00:18:05,300
certain input values as being only metadata.

329
00:18:05,300 --> 00:18:09,020
So an example of that would be the bit patterns that are NANDs and payload NANDs and IEEE

330
00:18:09,020 --> 00:18:11,220
754 double precision floating point.

331
00:18:11,220 --> 00:18:12,500
You have quoting or escaping.

332
00:18:12,500 --> 00:18:14,540
Of course, CSV is very famous for this.

333
00:18:14,540 --> 00:18:17,340
You have mechanisms like prefixing, which don't show up that much in our programmatic

334
00:18:17,340 --> 00:18:20,860
mechanisms, but if you look at how Git objects are represented, there's a prefixing mechanism

335
00:18:20,860 --> 00:18:24,540
where it says the next number of bytes are the underlying payload itself.

336
00:18:24,540 --> 00:18:26,300
And you see these in network protocols.

337
00:18:26,340 --> 00:18:30,740
And when you think about some of the things that we as data scientists have to deal with

338
00:18:30,740 --> 00:18:35,940
in contemporary versions of tools like Pandas, things like the D type with a capital I in

339
00:18:35,940 --> 00:18:39,740
64, well, this is actually an out-of-band encoding very similar to the NumPy masked

340
00:18:39,740 --> 00:18:45,500
array to represent missing values in the absence of an unambiguous partitioning of integer

341
00:18:45,500 --> 00:18:46,980
data.

342
00:18:46,980 --> 00:18:52,260
Largely, despite all of the verbiage behind this, many of these things are quite obvious.

343
00:18:52,300 --> 00:18:56,900
And oftentimes when you see these core concepts, which are very easy to point out to somebody,

344
00:18:56,900 --> 00:18:58,220
you can't unsee them.

345
00:18:58,220 --> 00:18:59,380
I'll give you an example.

346
00:18:59,380 --> 00:19:03,900
Some of you out there are users of a very, very high quality, very nice package called

347
00:19:03,900 --> 00:19:07,220
X-Array that combines the ideas of NumPy and Pandas together.

348
00:19:07,220 --> 00:19:10,380
And for those of you who aren't that familiar with X-Array, I'll give you a very brief

349
00:19:10,380 --> 00:19:11,380
refresher.

350
00:19:11,380 --> 00:19:15,740
NumPy is all about representing multidimensional data with broadcasting.

351
00:19:15,740 --> 00:19:19,140
Pandas is all about representing index aligned one-dimensional data.

352
00:19:19,380 --> 00:19:22,780
And X-Array is about doing coordinate aligned multidimensional data.

353
00:19:22,780 --> 00:19:26,220
I must and I'm obligated for a very brief aside.

354
00:19:26,220 --> 00:19:29,220
Number one, the Pandas data frame is not two-dimensional.

355
00:19:29,220 --> 00:19:30,820
The Pandas documentation says it is.

356
00:19:30,820 --> 00:19:33,180
The Pandas documentation is wrong.

357
00:19:33,180 --> 00:19:36,140
Pandas data frames are like indexed one-dimensional data.

358
00:19:36,140 --> 00:19:37,140
You heard it here.

359
00:19:37,140 --> 00:19:38,420
I will take that to my grave.

360
00:19:38,420 --> 00:19:42,780
Number two, for those of you who are complaining about Pandas, Gilad, I know you're out there,

361
00:19:42,780 --> 00:19:44,540
the API of Pandas is guaranteed.

362
00:19:44,540 --> 00:19:47,140
It is absolutely very inconsistent.

363
00:19:47,140 --> 00:19:51,740
It sometimes swap underscore levels or drop level with no underscore.

364
00:19:51,740 --> 00:19:56,220
It's very inconsistent, but the core concept behind the tool is incredibly coherent.

365
00:19:56,220 --> 00:20:00,460
And three, the only thing you ever really have to know to be really good at Pandas is

366
00:20:00,460 --> 00:20:01,460
index alignment.

367
00:20:01,460 --> 00:20:03,500
They once asked me to write a book on Pandas.

368
00:20:03,500 --> 00:20:07,140
They asked me for the chapter outline, and I said chapter one, index alignment, chapter

369
00:20:07,140 --> 00:20:09,540
two, everything else, and then the Apple log.

370
00:20:09,540 --> 00:20:11,260
There's only index alignment and nothing else.

371
00:20:11,260 --> 00:20:14,100
That's the only interesting thing about Pandas and the only thing you have to know.

372
00:20:14,100 --> 00:20:15,100
But back to X-Array.

373
00:20:15,900 --> 00:20:19,260
When we talk about X-Array, we're representing multi-dimensional data with some dimension.

374
00:20:19,260 --> 00:20:23,780
So you have maybe a volume metric data and you have an X, a Y, and a Z dimension.

375
00:20:23,780 --> 00:20:28,420
And you can select a slice of this down the X axis or down the Y axis or a combination

376
00:20:28,420 --> 00:20:29,420
of these.

377
00:20:29,420 --> 00:20:32,060
You can even interpolate this if you have missing values.

378
00:20:32,060 --> 00:20:36,100
And because this is a wrapper on top of tools like NumPy, Pandas, and SciPy, you can even

379
00:20:36,100 --> 00:20:37,900
pass an interpolation method.

380
00:20:37,900 --> 00:20:42,180
You can use SciPy interpolation methods, linear or cubic or whatnot, in order to choose how

381
00:20:42,180 --> 00:20:44,180
that interpolation works.

382
00:20:44,180 --> 00:20:49,060
But what if your dimension is called method?

383
00:20:49,060 --> 00:20:52,460
This is fundamentally ambiguous because it's an in-band encoding where you're conflating

384
00:20:52,460 --> 00:20:57,060
the single channel, the keyword arguments you have, to either represent one, the modality

385
00:20:57,060 --> 00:21:01,720
of how you do the interpolation, or two, the data that you're interpolating on.

386
00:21:01,720 --> 00:21:03,260
There is no resolution for this.

387
00:21:03,260 --> 00:21:09,420
This is a flaw in the API and it's as obvious as you cannot unsee it once you see it.

388
00:21:09,420 --> 00:21:12,260
And the solutions are largely quite routine.

389
00:21:12,260 --> 00:21:16,980
You want to find an unambiguous encoding, partitioning, quoting, prefixing.

390
00:21:16,980 --> 00:21:18,500
None of those will work in this approach.

391
00:21:18,500 --> 00:21:20,260
So what you'll do is you'll use an out-of-band encoding.

392
00:21:20,260 --> 00:21:22,940
You'll have two layers of a function, but nobody likes that.

393
00:21:22,940 --> 00:21:27,060
Or you'll do something like pandas.lock and .ilock where you'll create one more layer

394
00:21:27,060 --> 00:21:30,440
using the descriptor protocol or using some other protocols in Python.

395
00:21:30,440 --> 00:21:33,560
And so you might do something like this to say this is a linear interpolation for these

396
00:21:33,560 --> 00:21:34,700
particular axes.

397
00:21:34,700 --> 00:21:39,580
Or you might realize that this is just the problem of a nominal decomposition of a bounded

398
00:21:39,580 --> 00:21:40,580
modality.

399
00:21:40,580 --> 00:21:45,740
In other words, there's only a set number of possible interpolations that you have.

400
00:21:45,740 --> 00:21:48,260
SciPy only supports less than a dozen of these.

401
00:21:48,260 --> 00:21:50,220
You can put a name on each of those.

402
00:21:50,220 --> 00:21:53,520
This is basically the idea behind class method that we do all the time.

403
00:21:53,520 --> 00:21:56,940
You could just have a bunch of methods linear underscore interp and you would have solved

404
00:21:56,940 --> 00:21:58,260
this problem entirely.

405
00:21:58,260 --> 00:22:00,220
Now, once you see the problem, you can't unsee it.

406
00:22:00,220 --> 00:22:03,060
I'm certain that you're going to begin to see these problems in the actual code that

407
00:22:03,060 --> 00:22:04,700
you have.

408
00:22:04,700 --> 00:22:08,940
When you think about this difference between the in-band encoding and the out-of-band encoding,

409
00:22:09,780 --> 00:22:11,660
that's basically what a generator is all about.

410
00:22:11,660 --> 00:22:15,500
The core concepts here are actually quite simple and quite present there.

411
00:22:15,500 --> 00:22:18,780
They're obvious and they're in front of you and they can be methodically thought through.

412
00:22:18,780 --> 00:22:22,020
Because if we have some function that does a bunch of different things, we might as a

413
00:22:22,020 --> 00:22:25,300
human being put step numbering on these.

414
00:22:25,300 --> 00:22:29,340
A function that loads some data, cleans some data, removes outliers and processes some data

415
00:22:29,340 --> 00:22:31,040
contains three steps.

416
00:22:31,040 --> 00:22:35,860
Step one, step two A, step two B, step three, or maybe four steps corresponding to the lines

417
00:22:35,860 --> 00:22:36,860
of code that we have.

418
00:22:37,340 --> 00:22:42,260
But in truth, this is an ambiguous in-band encoding for the structuring of the underlying

419
00:22:42,260 --> 00:22:43,420
computation.

420
00:22:43,420 --> 00:22:47,660
And all a generator is, is an unambiguous out-of-band encoding for the structuring of

421
00:22:47,660 --> 00:22:49,180
computation.

422
00:22:49,180 --> 00:22:52,940
It unambiguously delineates this is where the first step is, this is where the second

423
00:22:52,940 --> 00:22:56,740
step is, this is where the third step is, and this is where the fourth step is.

424
00:22:56,740 --> 00:23:00,540
And the moment you have an out-of-band encoding for the structuring of this function, you

425
00:23:00,540 --> 00:23:03,300
can do things like unambiguously delineate the steps.

426
00:23:03,300 --> 00:23:07,620
Which means you can then create mechanisms for controlling how many steps you run through,

427
00:23:07,620 --> 00:23:11,900
which is the core problem that we had when we were using our various implementations

428
00:23:11,900 --> 00:23:13,860
of scipy.optimized.newton.

429
00:23:13,860 --> 00:23:17,860
We were constantly having to add additional keyword arguments to control the number of

430
00:23:17,860 --> 00:23:20,340
steps of the iterative method that we go through.

431
00:23:20,340 --> 00:23:24,860
Well, we can devolve that entirely with just a very simple conceptual idea.

432
00:23:24,860 --> 00:23:30,180
We can devolve those modalities such that instead of presuming that we know we're going

433
00:23:30,660 --> 00:23:33,420
to run for a maximum number of iterations or into a relative tolerance or an absolute

434
00:23:33,420 --> 00:23:37,140
tolerance, we just say we'll run forever, but we'll structure the computation so that

435
00:23:37,140 --> 00:23:39,260
you can choose how you want to do this.

436
00:23:39,260 --> 00:23:45,580
And we can empower the end users to do things which are not capable with the scipy.optimized.newton

437
00:23:45,580 --> 00:23:48,660
implementation that we have today, which of course I don't want to criticize too much

438
00:23:48,660 --> 00:23:51,700
because there's a lot of historical baggage to these tools and many reasons why they're

439
00:23:51,700 --> 00:23:53,020
written the way they are.

440
00:23:53,020 --> 00:23:57,660
But we can devolve those modalities to allow things like complex combinations of these

441
00:23:57,660 --> 00:24:01,580
stopping conditions that are otherwise impossible to easily represent in the form of just keyword

442
00:24:01,580 --> 00:24:02,820
arguments.

443
00:24:02,820 --> 00:24:07,540
From this perspective, we can actually come to an answer for why bother with the expertise

444
00:24:07,540 --> 00:24:08,540
in the first place.

445
00:24:08,540 --> 00:24:14,140
If we reframe the idea of expertise as the methodical approach to devolving design into

446
00:24:14,140 --> 00:24:18,380
effort, to taking questions which cannot be answered because they are fundamentally a

447
00:24:18,380 --> 00:24:24,620
consequence of adapting to some human requirement where we have to make assumptions about, well,

448
00:24:24,620 --> 00:24:25,620
are they going to use it this way?

449
00:24:25,620 --> 00:24:26,860
Are they going to use it that way?

450
00:24:26,860 --> 00:24:27,860
Are they going to want to do this?

451
00:24:27,860 --> 00:24:29,060
Are they going to want to do that?

452
00:24:29,060 --> 00:24:32,220
And we discover through the advanced mechanisms that are available in a programming language

453
00:24:32,220 --> 00:24:37,420
like Python, mechanisms like generators or context managers or meta classes or even some

454
00:24:37,420 --> 00:24:41,460
of the more esoteric mechanisms that are available when you start digging deeper like import

455
00:24:41,460 --> 00:24:46,380
hooks and whatnot, we can oftentimes devolve that design into effort.

456
00:24:46,380 --> 00:24:50,880
And we can remove the unknowable quantity of design.

457
00:24:50,880 --> 00:24:56,500
We can then just implement some mechanism that allows us to not have to guess, are we

458
00:24:56,500 --> 00:25:01,620
going to get this right or wrong and not have to risk spiraling into this unknowable,

459
00:25:01,620 --> 00:25:03,660
uncontrollable future.

460
00:25:03,660 --> 00:25:07,860
Because if you really ask me, I don't want to be a Python expert.

461
00:25:07,860 --> 00:25:09,620
I don't even want to be a Python programmer.

462
00:25:09,620 --> 00:25:12,060
I don't even want to be a programmer at all.

463
00:25:12,060 --> 00:25:16,300
I do want to be somebody who uses programming to get something done.

464
00:25:16,300 --> 00:25:22,000
But the answer of expertise and the motivation for this is really, can I be more effective

465
00:25:23,000 --> 00:25:28,360
in the work that I do via a deliberate methodical approach to developing expertise?

466
00:25:28,360 --> 00:25:32,860
And I think I've made a compelling case for why that may be.

467
00:25:32,860 --> 00:25:35,000
This has been I don't want to be a Python expert.

468
00:25:35,000 --> 00:25:36,000
I'm James Powell.

469
00:25:36,000 --> 00:25:37,000
Thank you all.

470
00:25:37,000 --> 00:25:37,020
Applause.

