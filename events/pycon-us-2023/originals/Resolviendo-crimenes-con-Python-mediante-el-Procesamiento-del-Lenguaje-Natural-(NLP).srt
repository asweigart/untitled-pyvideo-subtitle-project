1
00:00:00,000 --> 00:00:09,280
Hola, hola, hola. Entonces, seguimos con la segunda charla de la tarde. La segunda charla

2
00:00:09,280 --> 00:00:14,800
de la tarde, le damos la bienvenida a Carolina. Ella viene de Argentina, nos va a estar presentando

3
00:00:14,800 --> 00:00:19,920
y resolviendo crímenes con Python mediante el procesamiento de lenguaje natural. Un aplauso

4
00:00:19,920 --> 00:00:20,920
para ella.

5
00:00:20,920 --> 00:00:31,600
Bueno, buenas tardes a todos los presentes. Bueno, como me presentó recién mi Session

6
00:00:31,600 --> 00:00:37,040
Runner, me llamo Carolina Pasarello, yo vengo de Argentina, soy ingeniera en sistemas y

7
00:00:37,040 --> 00:00:42,960
también profesora en disciplinas industriales. Actualmente yo me desempeño como perito informático

8
00:00:42,960 --> 00:00:47,400
en el área penal, o sea, en el área criminal. Así que un poquito de lo que les voy a contar

9
00:00:47,400 --> 00:00:53,960
hoy y voy a compartir con ustedes es un desarrollo que está orientado plenamente a un tipo de

10
00:00:53,960 --> 00:00:59,200
crimen de delito que en nuestro país se llama grumina. Ahora más adelante les voy a explicar

11
00:00:59,200 --> 00:01:06,040
un poquito. En principio yo les voy a introducir algunos conceptos básicos como para que puedan

12
00:01:06,040 --> 00:01:12,560
entender la función, entonces se puede entender también el desarrollo. La informática forense

13
00:01:12,560 --> 00:01:18,040
básicamente es la investigación criminal en donde interviene algún dispositivo informático.

14
00:01:18,040 --> 00:01:25,840
Es decir, nosotros siempre tratamos de guiarnos en la norma ISO IEC 27.037. Es una orientación,

15
00:01:25,840 --> 00:01:31,520
es una guía, no dice exactamente qué es o cómo es lo que hay que hacer, pero sí introduce

16
00:01:31,520 --> 00:01:38,280
normas básicas como para tener en cuenta en todo el proceso de la recolección de la evidencia.

17
00:01:38,280 --> 00:01:44,360
Nosotros hablamos de la evidencia digital, siempre nos vamos a referir a toda la información que

18
00:01:44,360 --> 00:01:51,360
esté guardada o almacenada en un dispositivo informático. Pero ¿para qué nos sirve? O sea,

19
00:01:51,360 --> 00:01:55,880
¿para qué nos sirve esta información? Tiene que ser admisible judicialmente, es decir,

20
00:01:55,880 --> 00:02:02,600
tiene que valer como prueba en un proceso judicial. O sea, no toda la información que está almacenada

21
00:02:02,640 --> 00:02:08,960
tiene valor probatorio en un juicio. Entonces lo que nosotros necesitamos buscar es esta evidencia

22
00:02:08,960 --> 00:02:15,880
para que sea justamente una fuente, diríamos, probatoria para una condena en un juicio.

23
00:02:17,680 --> 00:02:25,920
Les voy a explicar así muy en términos generales las etapas del procedimiento. Cuando se me presenta

24
00:02:25,920 --> 00:02:30,240
un caso, por lo general una fiscalía de investigación solicita una investigación

25
00:02:30,240 --> 00:02:36,880
puntual acerca de un delito. Entonces tiene varias etapas este procedimiento. En principio

26
00:02:36,880 --> 00:02:42,680
se realiza el relevamiento, es decir, se identifican las fuentes de posibles evidencias

27
00:02:42,680 --> 00:02:47,840
digitales. Es decir, necesitamos identificar qué dispositivos pueden contener esa evidencia digital

28
00:02:47,840 --> 00:02:54,600
tan buscada. Luego lo que se hace es la recolección, es decir, la recolección es justamente reunir

29
00:02:54,600 --> 00:03:00,080
todos los objetos en donde tienen esa posible evidencia digital. Esto por lo general se hace

30
00:03:00,080 --> 00:03:06,160
siempre en la escena del crimen. Y después se realiza la adquisición, es decir, la adquisición

31
00:03:06,160 --> 00:03:11,240
es plenamente la extracción de la información. Van a escuchar muchas veces el término por ahí de

32
00:03:11,240 --> 00:03:18,480
copia forense, imagen forense, copia espejo, extracción de datos. Son conceptos similares.

33
00:03:18,480 --> 00:03:25,720
Esto significa que se hace una copia, un duplicado, pero la copia bit a bit no es una copia común,

34
00:03:25,720 --> 00:03:33,840
donde se duplica todo el contenido de ese dispositivo para luego poder hacer el análisis.

35
00:03:33,840 --> 00:03:40,680
Luego de la adquisición se realiza la preparación, es decir, podemos ahí determinar qué herramientas

36
00:03:40,680 --> 00:03:45,960
vamos a necesitar para hacer el posterior análisis. En el análisis lo que hacemos es

37
00:03:45,960 --> 00:03:52,480
el informe pericial en sí y la extracción de la tan ansiada evidencia digital que estamos buscando.

38
00:03:52,560 --> 00:03:58,760
Para luego hacer la presentación justamente al fiscal y que después se pueda elevar esto a un

39
00:03:58,760 --> 00:04:05,000
juicio y poder encontrar, diríamos, la condena, diríamos, a un culpable de un delito.

40
00:04:07,160 --> 00:04:13,840
Siempre la adquisición se realiza, se puede realizar por medio de herramientas de hardware

41
00:04:13,840 --> 00:04:21,120
o de software. Cuando hacemos la adquisición, que hoy les comentaba que siempre se habla de

42
00:04:21,120 --> 00:04:27,440
la copia forense o imagen forense, siempre también se conoce mucho el término de hash.

43
00:04:27,440 --> 00:04:35,360
El hash es una herramienta que sirve para poder identificar esa información, es decir,

44
00:04:35,360 --> 00:04:42,200
el contenido de esa información que nosotros vamos a hacer la extracción no debería presentar una

45
00:04:42,200 --> 00:04:47,520
variabilidad. Entonces, con ese hash nosotros podemos determinar si esa evidencia pudo haber

46
00:04:47,520 --> 00:04:56,240
sido alterada en algún momento del proceso. Luego, una de las principales herramientas que

47
00:04:56,240 --> 00:05:02,280
utilizamos para hacer el análisis es la de autopsie, entre otras. Yo simplemente hice

48
00:05:02,280 --> 00:05:08,160
una especie de resumen porque en realidad hay muchas herramientas, algunas propietarias,

49
00:05:08,160 --> 00:05:16,960
otras no. Entonces, en donde se filtra cada imagen, texto, lo que sea que se busque,

50
00:05:16,960 --> 00:05:26,960
en esa línea de investigación. Concretamente, mi trabajo en que se basa, en el delito de grooming.

51
00:05:26,960 --> 00:05:33,600
No sé si alguien sabe de los presentes a qué se refiere el grooming. Les explico cómo para que

52
00:05:33,600 --> 00:05:37,920
entiendan. Fíjense que la imagen, creo que lo hice toda una imagen, vale más que mil palabras.

53
00:05:37,920 --> 00:05:44,680
En las dos imágenes hay un niño, una niña, la otra están enfrente de una pantalla. Esa pantalla

54
00:05:44,680 --> 00:05:50,160
es representativa, puede ser un teléfono, un dispositivo cualquiera. Y fíjense que detrás hay

55
00:05:50,160 --> 00:05:56,560
una persona que está como en penumbras porque no se sabe quién es. Pero en la pantalla principal se

56
00:05:56,560 --> 00:06:04,080
refleja como si fuera un niño o un par. Entonces, es claramente que el niño, el menor de edad,

57
00:06:04,080 --> 00:06:11,880
está pensando, está creciendo, que es un par, un niño, donde pueden tablar una relación de amistad

58
00:06:12,440 --> 00:06:21,440
o de confianza y en realidad no lo es. En nuestro país esto está penado por el código nuestro y

59
00:06:21,440 --> 00:06:28,440
dice que va a ser una pena de seis meses a cuatro años. Y fíjense que ahí determina que el medio

60
00:06:28,440 --> 00:06:34,400
de comunicación es cualquier tipo de tecnología de transmisión. O sea, puede ser redes sociales,

61
00:06:34,400 --> 00:06:41,640
aplicaciones de mensajería. No especifica porque pone en un conjunto todo tipo de comunicaciones

62
00:06:41,640 --> 00:06:47,480
electrónicas. Siempre este delito, diríamos, cuál tiene la finalidad o el propósito cometer,

63
00:06:47,480 --> 00:06:55,480
diríamos, un abuso en sí sobre la integridad sexual del menor. Ese es el fin último.

64
00:06:56,520 --> 00:07:01,840
En el procedimiento tradicional, por eso hoy les he introducido justamente todas las etapas

65
00:07:01,840 --> 00:07:07,640
del procedimiento. ¿Cómo se haría? Se hace la denuncia del delito, se entrega el dispositivo

66
00:07:07,640 --> 00:07:14,200
por parte del responsable y si no puede ser la otra opción, que por ejemplo hay denuncias de

67
00:07:14,200 --> 00:07:20,800
organizaciones del tipo ONG, que por ejemplo en redes de pedofilia o en tipos de abuso están

68
00:07:20,800 --> 00:07:25,960
monitoreando, diríamos, las direcciones IP, entonces se ganan a las fiscalías de investigación estas

69
00:07:25,960 --> 00:07:30,640
denuncias y ahí se hacen justamente los sancionamientos en los domicilios bajo orden

70
00:07:30,640 --> 00:07:36,320
judicial y se obtienen los dispositivos que luego después analizamos. Una vez que se obtiene el

71
00:07:36,320 --> 00:07:42,360
dispositivo, está ahí representado como un teléfono porque en este trabajo se asinca a pie en lo

72
00:07:42,360 --> 00:07:49,160
que es la herramienta WhatsApp, que es una de las principales herramientas utilizadas para cometer

73
00:07:49,160 --> 00:07:55,720
este delito, entre otras. Se adquieren los datos de ese celular y se obtiene toda la cadena de

74
00:07:55,720 --> 00:08:02,760
mensajes. Eso sería el procedimiento tradicional y se analiza. ¿Cuál es la idea de este trabajo? La

75
00:08:02,800 --> 00:08:08,280
idea de este trabajo es que se haga un análisis automático del significado de esos mensajes de

76
00:08:08,280 --> 00:08:16,400
toda esa cadena de WhatsApp. Cuando esta persona mayor de edad está tratando de llegar a ganar

77
00:08:16,400 --> 00:08:25,440
confianza con el menor de edad, no siempre tiene un lenguaje explícito. Es decir, como va tratando

78
00:08:25,440 --> 00:08:32,640
de ganar esa confianza, va hablando de cosas de interés común o de interés del menor y va

79
00:08:32,640 --> 00:08:38,720
introduciéndolo a que pueda llegar a mandarle fotografías, videos y demás, pero no siempre

80
00:08:38,720 --> 00:08:45,320
dice explícitamente un pedido de, por ejemplo, de una fotografía o de un desnudo o de un vídeo. No

81
00:08:45,320 --> 00:08:50,960
siempre dice eso. Entonces la idea es tratar de entender el significado de cada mensaje para ver

82
00:08:50,960 --> 00:08:58,920
si esa, diríamos, conversación en donde incluye toda puede ser una conversación de días, de meses.

83
00:08:58,920 --> 00:09:05,720
Imagínense lo largo que puede llegar a ser intentar entender todo eso y el tiempo que puede llevar.

84
00:09:08,920 --> 00:09:13,480
Bueno, a través entonces del análisis automático de esa cadena de WhatsApp,

85
00:09:14,480 --> 00:09:20,600
yo diseñé por medio de Python y de NLP un procedimiento que pueda llegar a analizar

86
00:09:20,600 --> 00:09:27,960
toda esta conversación. No sé si saben en general o si están por ahí más inmersos en el tema del

87
00:09:27,960 --> 00:09:32,800
procesamiento del lenguaje natural, pero siempre tenemos varias etapas bien definidas, aunque estas

88
00:09:32,800 --> 00:09:39,120
pueden modificarse, pero en realidad siempre va a haber una etapa de preprocesamiento, de capacitación

89
00:09:39,120 --> 00:09:45,000
y de inferencia o de predicción. Explicándolo así a grandes rasgos porque por ahí el procesamiento

90
00:09:45,000 --> 00:09:49,840
del lenguaje natural es mucho más que eso, pero como para que se entienda para aquellos que no

91
00:09:49,840 --> 00:09:55,440
están muy inmersos en el tema. Entonces mediante lo que es el procesamiento del lenguaje natural

92
00:09:55,440 --> 00:10:01,320
podemos clasificar esta cadena de mensajes y ver si realmente es tendiente al grooming.

93
00:10:01,320 --> 00:10:10,040
Fíjense que yo elegí dos líneas, diríamos, un poquito distintas. Una es la parte del

94
00:10:10,040 --> 00:10:16,120
aprendizaje supervisado y la otra es la de modelos preentrenados. En el aprendizaje supervisado,

95
00:10:16,120 --> 00:10:24,480
yo definí dos algoritmos para poder aplicarlos a este problema puntual. Puede haber muchos más,

96
00:10:24,480 --> 00:10:29,760
sí, pero estos por ahí son los más recomendados para hacer este tipo de procesamiento y

97
00:10:29,760 --> 00:10:35,760
clasificación. Uno es el algoritmo de máquina de vectores de soporte y el otro es el algoritmo

98
00:10:35,760 --> 00:10:42,480
de Naive Batches. Por ahí no quiero ahondar, diríamos, en el funcionamiento porque no nos va

99
00:10:42,480 --> 00:10:52,360
a alcanzar el tiempo. Y por otro lado es el modelo preentrenado y en particular yo utilicé

100
00:10:52,360 --> 00:10:58,560
la librería de transformers para poder hacer esta clasificación. Como en todo modelo de

101
00:10:58,560 --> 00:11:04,280
aprendizaje supervisado siempre tenemos información conocida, en donde se entrena

102
00:11:04,280 --> 00:11:09,840
ese algoritmo y luego con información desconocida lo que se realiza son las predicciones para ver

103
00:11:09,840 --> 00:11:15,640
a qué categoría pertenecen. Eso es como cualquier otro modelo de clasificación. Siempre vamos a

104
00:11:15,640 --> 00:11:22,880
tener estas etapas. Se adquieren los datos etiquetados, se hace el preprocesamiento y la

105
00:11:22,880 --> 00:11:28,840
vectorización. Después se divide en conjunto de datos de entrenamiento y de pruebas, se entrena

106
00:11:28,840 --> 00:11:36,040
el modelo, se obtienen medidas de rendimiento y se pone en producción. Por lo general esta etapa

107
00:11:36,040 --> 00:11:44,480
que es la parte de, diríamos, de poner en producción es la etapa que más tenemos que tener precaución

108
00:11:44,480 --> 00:11:51,800
porque en este caso, a ver, estamos evaluando una conducta que puede llevar a una condena,

109
00:11:51,800 --> 00:11:59,960
a una persona. O sea, es algo que es muy importante de ver las métricas y la evolución en sí del

110
00:11:59,960 --> 00:12:09,680
algoritmo porque son datos vitales en donde uno no puede equivocarse, diríamos. Y bueno, y por otro

111
00:12:09,680 --> 00:12:15,120
lado están los modelos preentrenados que a grandes rasgos y a líneas generales, diríamos, siempre el

112
00:12:15,120 --> 00:12:20,720
modelo preentrenado lo que hace es, se entrena a valga redundancia con un conjunto de datos muy

113
00:12:20,720 --> 00:12:26,760
grandes y después se hace una predicción respecto de un área específica y se hace un

114
00:12:26,760 --> 00:12:35,440
fine tuning de un conjunto de datos muy específicos. Lo que recién les comento es, muy en términos

115
00:12:35,440 --> 00:12:44,280
generales, como para ver y entender, diríamos, este objetivo de este trabajo. Acá entra una cuestión

116
00:12:44,280 --> 00:12:52,480
muy importante porque, como recién hablábamos en el conjunto de datos, yo necesitaba entender,

117
00:12:52,480 --> 00:13:00,840
diríamos, cómo podría ser un lenguaje que sea orientado totalmente al sexismo porque en definitiva

118
00:13:00,840 --> 00:13:09,560
eso es lo que esta persona mayor de edad intenta con el menor de edad. Entonces me base en este

119
00:13:09,760 --> 00:13:16,160
conjunto de datos que se llama Xist, que es un conjunto de datos que fue desarrollado por

120
00:13:16,160 --> 00:13:20,120
investigadores de diferentes universidades de España, que ahí tienen la dirección por si

121
00:13:20,120 --> 00:13:28,040
les interesa saber, que es un conjunto de tweets en inglés y en español, en donde, fíjense, que

122
00:13:28,040 --> 00:13:36,960
tiene dos categorizaciones. Una, la principal, si es sexista o no sexista, y la otra, dependiendo

123
00:13:36,960 --> 00:13:43,840
del tipo, si es, por ejemplo, desigualdad, si es dominancia, objetificación, violencia sexual o

124
00:13:43,840 --> 00:13:50,200
misoginia. O sea, hay una subcategorización que puede ser muy importante. Después, más adelante,

125
00:13:50,200 --> 00:13:57,800
le voy a explicar otra aplicación de esto. Ahí hay un ejemplito, no sé si se alcanza a ver,

126
00:13:57,800 --> 00:14:07,840
cómo aparece el dataset y está sobre el final, fíjense que dice sexista o no sexista, y después

127
00:14:07,840 --> 00:14:13,960
lo vuelve a categorizar en violencia sexual o demás. Entonces, para que se pueda entender

128
00:14:13,960 --> 00:14:22,680
en qué se basa. ¿Cómo los llevé a la práctica? Yo principalmente utilicé Collab porque por ahí

129
00:14:22,680 --> 00:14:27,680
es más versátil para escribir código y porque se puede ejecutar directamente en el navegador,

130
00:14:27,680 --> 00:14:33,680
desde cualquier dispositivo, desde cualquier lugar y seguir escribiendo código en cualquier momento.

131
00:14:33,680 --> 00:14:40,960
Y además que tiene un uso gratuito de gpus y por ahí tiene varias librerías que son muy importantes

132
00:14:40,960 --> 00:14:46,800
para hacer este tipo de desarrollos en lo que es procesamiento del lenguaje natural.

133
00:14:46,800 --> 00:14:57,600
Fíjense, yo detallé un poquito de código, pero principalmente está sobre uno de los costados,

134
00:14:57,600 --> 00:15:05,000
de los laterales, está definido más o menos la función principal de cada bloque. Este es el

135
00:15:05,000 --> 00:15:11,960
conjunto de datos, como él explicaba, que tiene las dos categorizaciones. Una vez que se carga

136
00:15:12,720 --> 00:15:17,920
el dataset y se inspecciona directamente,

137
00:15:20,960 --> 00:15:27,520
directamente sí, están las categorías y las subcategorías. Fíjense la cantidad de datos que

138
00:15:27,520 --> 00:15:35,320
tiene este dataset. Entonces, directamente, como todo conjunto de código, diríamos lo que es

139
00:15:35,320 --> 00:15:44,080
aprendizaje supervisado, lo divido en entrenamiento y en test y lo que hago principalmente,

140
00:15:44,080 --> 00:15:49,200
como está orientado al lenguaje español, eliminó los tweets, porque son básicamente tweets,

141
00:15:50,680 --> 00:15:56,160
del lenguaje inglés y los dejo solamente a los de interés que son el lenguaje en español.

142
00:15:56,320 --> 00:16:06,400
Luego, lo que se hace acá es el preprocesamiento del dataset. Fíjense que esto, por lo general,

143
00:16:06,400 --> 00:16:12,360
acá hay dos formas, una más abreviada y otra un poquito más larga, que siempre era lo que hoy les

144
00:16:12,360 --> 00:16:16,920
explicaba. En la parte de procesamiento del lenguaje natural, que siempre se hace el preprocesamiento,

145
00:16:16,920 --> 00:16:24,680
se remueven, por ejemplo, los signos de puntuación, los stop words, se pasa todo a minúscula,

146
00:16:25,280 --> 00:16:32,360
se sacan, por ejemplo, todo tipo de acentos, de espacios, como para que quede texto.

147
00:16:33,680 --> 00:16:38,840
Luego se realiza la tokenización, que era lo que les explicaba hoy. La tokenización,

148
00:16:38,840 --> 00:16:47,280
yo elegí el algoritmo TFIDF, que lo que hace es expresa en realidad una medida de importancia,

149
00:16:47,280 --> 00:16:52,360
diríamos, de la relevancia de la palabra dentro del documento. Ustedes recuerden que un algoritmo

150
00:16:52,360 --> 00:16:59,840
no entiende el contenido de una palabra, si entiende por ahí números. Entonces, nosotros de

151
00:16:59,840 --> 00:17:06,400
alguna manera tenemos que convertir esas palabras en numeración para que el algoritmo pueda tomar y

152
00:17:06,400 --> 00:17:13,760
entender. Y, bueno, así, después de hacer todo el preprocesamiento, lo que hace el código es iniciar

153
00:17:13,760 --> 00:17:19,040
los clasificadores y entrenar los modelos. Como les decía, yo elegí los dos modelos que por ahí

154
00:17:19,040 --> 00:17:23,240
más se adaptan a este tipo de tareas de procesamiento del lenguaje natural, los que tienen por ahí un

155
00:17:23,240 --> 00:17:31,000
mejor rendimiento. Y una vez que los entreno a los modelos, después realizo las predicciones.

156
00:17:32,680 --> 00:17:41,160
Fíjense en el lateral derecho que ahí están las medidas de rendimiento y hay uno, por ejemplo,

157
00:17:41,160 --> 00:17:46,680
que es un poquito mejor que el otro. Acá yo les presento la matriz de confusión, donde justamente

158
00:17:47,560 --> 00:17:53,760
determina que a ver cuántos casos, es decir, como que con cuántos casos acertó a lo que realmente

159
00:17:53,760 --> 00:18:00,720
era así. O sea, cuántos positivos eran cuando realmente eran positivos y cuántos negativos eran

160
00:18:00,720 --> 00:18:08,760
cuando realmente eran negativos. Fíjense que en el caso de Naive-Balles da un 60%, que sería esta,

161
00:18:08,760 --> 00:18:16,360
para que tengan en cuenta este pedacito de la matriz, que son casos positivos, predichos y casos

162
00:18:16,360 --> 00:18:26,020
positivos que estaban, diríamos, en la realidad. Y el otro algoritmo da un 62%. Esas métricas,

163
00:18:26,020 --> 00:18:32,800
diríamos, son al parecer, a simple vista uno dice es bastante bajo, pero en realidad es bastante

164
00:18:32,800 --> 00:18:40,120
alto para este tipo de problemas. Porque recuerden que se está tratando de entender el contenido de

165
00:18:40,120 --> 00:18:47,520
un mensaje, diríamos, se está tratando de entender palabras. Entonces, una vez, diríamos,

166
00:18:47,520 --> 00:18:56,440
que se entrenó los dos clasificadores con este conjunto de Xist, lo que se tiene que hacer ahora

167
00:18:56,440 --> 00:19:02,360
es analizar el dispositivo que está secuestrado. Es decir, qué es lo que a nosotros nos interesa,

168
00:19:02,360 --> 00:19:08,200
obtener la evidencia que hoy les comentaba, la evidencia digital que se encuentra almacenada

169
00:19:08,200 --> 00:19:16,200
en ese dispositivo. Entonces, una de las librerías que se utilizan para pasar, por ejemplo,

170
00:19:16,200 --> 00:19:25,480
mensajes de WhatsApp a un DataFrame es la librería Wattstk. Esta librería directamente

171
00:19:25,480 --> 00:19:33,080
traduce toda la cadena de mensajes de WhatsApp a un DataFrame en donde nosotros podemos directamente

172
00:19:33,080 --> 00:19:39,240
hacer el preprocesamiento y vectorizar para después poder hacer la predicción. Entonces,

173
00:19:39,240 --> 00:19:45,140
una vez que hacemos el preprocesamiento, hacemos la vectorización, ahí directamente hacemos la

174
00:19:45,140 --> 00:19:53,240
predicción y fíjense que sobre el lado lateral derecho el clasificador lo que emite son ceros y

175
00:19:53,240 --> 00:20:00,960
unos. Es decir, emite justamente la cantidad de mensajes, es como que clasifica cada mensaje si

176
00:20:00,960 --> 00:20:07,520
fueron positivos o no para esa conducta sexista. Entonces, simplemente después se hace un conteo

177
00:20:07,520 --> 00:20:18,440
de los chats porque sería cada mensaje si fue positivo y con eso uno puede tratar de entender si

178
00:20:18,440 --> 00:20:28,160
ese chat fue tendiente a realizar, diríamos, una conversación tendiente a una forma sexista.

179
00:20:31,600 --> 00:20:37,920
Después lo que implementé es otra corriente, como él les explicaba, la del modelo preentrenado.

180
00:20:37,920 --> 00:20:44,240
Y ahí me basé en el ecosistema de Huguenface, en donde justamente es una plataforma en donde

181
00:20:44,240 --> 00:20:49,600
permite a los usuarios compartir cientos de modelos. Hay creo que más de 30.000 modelos

182
00:20:49,600 --> 00:20:56,920
preentrenados y creo que un poquito más. Y principalmente están orientados al uso en NLP,

183
00:20:57,200 --> 00:21:03,120
en lo que es clasificación de texto, lo que es audio, lo que es clasificación de imágenes.

184
00:21:03,120 --> 00:21:09,520
Es realmente muy interesante para hacer todo este tipo de tareas porque por ahí presenta

185
00:21:09,520 --> 00:21:17,880
algunos pipelines que están determinados y es por ahí muy sencillo, diríamos, correr estos

186
00:21:17,880 --> 00:21:24,400
pipelines para poder hacer una tarea que por ahí es bastante compleja. Y entonces acá una vez más

187
00:21:25,360 --> 00:21:31,880
hacemos referencia al conjunto de datos que hoy les comentaba, al de Exist. ¿Por qué? Porque una

188
00:21:31,880 --> 00:21:36,640
vez que el modelo está preentrenado y que está en el ecosistema de Huguenface, yo en realidad

189
00:21:36,640 --> 00:21:42,240
necesito hacer un fine tuning con el modelo de datos de aplicación en este problema puntual.

190
00:21:42,240 --> 00:21:50,840
Entonces, una vez que elijo el modelo, que en este caso yo elegí el modelo Roberta porque es,

191
00:21:51,840 --> 00:21:59,080
diríamos, es como una especie de compendio, diríamos, de lo que es BERT, pero en realidad

192
00:21:59,080 --> 00:22:08,600
es más orientado al español. Entonces, fíjense que hasta acá sería lo mismo, nada más que se

193
00:22:08,600 --> 00:22:18,920
carga el dataset de entrenamiento y puntualmente yo selecciono lo que nos interesa es el texto,

194
00:22:19,560 --> 00:22:25,120
el contenido del mensaje y la tarea. Por ahora yo elimino, diríamos, la subcategorización porque

195
00:22:25,120 --> 00:22:34,120
este modelo preentrenado me exige, diríamos, me pide dos tipos de datos, el texto y la etiqueta.

196
00:22:35,360 --> 00:22:43,400
Fíjense que una cosa puntual, también el modelo no acepta un data frame, sino que acepta un

197
00:22:44,040 --> 00:22:52,920
data tick, es decir, un tipo en particular de estructura para que pueda el modelo entender

198
00:22:52,920 --> 00:23:03,040
estos datos. Entonces, una vez que yo selecciono, diríamos, esta forma de estructura, lo que hago

199
00:23:03,040 --> 00:23:10,080
es, una vez que se instala la librería de Transformers, tokenizo con los datos que el

200
00:23:10,080 --> 00:23:15,960
tokenizador me provee, porque esta librería ya tiene justamente un tokenizador que está definido,

201
00:23:15,960 --> 00:23:24,800
fíjense acá en la parte de abajo, que me va ya directamente a determinar la etiqueta, el texto,

202
00:23:24,800 --> 00:23:32,480
y da dos parámetros más que el modelo necesita para poder hacer la clasificación. Luego lo que

203
00:23:32,480 --> 00:23:39,280
hago es, defino justamente el modelo Roberta y luego defino los argumentos del entrenamiento.

204
00:23:39,280 --> 00:23:46,080
Y luego las métricas de rendimiento. Hasta allí sería muy parecido a la parte del aprendizaje

205
00:23:46,080 --> 00:23:52,280
supervisado, pero simplemente que, como es un modelo preentrenado, ya tiene muchos valores que

206
00:23:52,280 --> 00:24:05,240
ya están pre-seteados y no hay que estar modificando. Una vez que directamente se pasa

207
00:24:05,240 --> 00:24:12,360
esta etapa, en este modelo se usa mucho la clase Trainer, en donde se definen todos los

208
00:24:12,360 --> 00:24:19,400
parámetros de entrenamiento y directamente se pueden definir bien determinados parámetros que

209
00:24:19,400 --> 00:24:26,720
uno quiere. Por ejemplo, yo definí tres hip-hop, o sea, tres corridas, diríamos, del algoritmo.

210
00:24:26,720 --> 00:24:32,200
Porque fíjense que igualmente tarda un poquito, por más que la idea del modelo preentrenado,

211
00:24:32,200 --> 00:24:39,760
cuál es que uno utilice, justamente código que ya está armado, y que no tenga que estar entrenándolo

212
00:24:39,760 --> 00:24:45,480
totalmente de cero, sino solamente haciendo una aplicación del conjunto de datos que uno necesita.

213
00:24:45,480 --> 00:24:56,840
En este caso era el Xist. Y fíjense que en la segunda corrida del algoritmo da un 73% el accuracy.

214
00:24:57,800 --> 00:25:07,200
Es un muy buen valor, inclusive supera el valor de los otros algoritmos. Una vez que se realiza

215
00:25:07,200 --> 00:25:13,400
el entrenamiento, es opcional subir al Hub de Hacking Face y poder después directamente

216
00:25:13,400 --> 00:25:19,680
ocupar la API desde ese ecosistema. Es muy fácil poder compartir después el modelo para

217
00:25:19,680 --> 00:25:25,280
cualquier otro usuario que tenga por ahí algún tipo de problema similar que quiera resolver con

218
00:25:25,280 --> 00:25:31,800
ese modelo preentrenado. Si hay que subir desde cero el modelo, lo que hay que hacer es repetir

219
00:25:31,800 --> 00:25:39,720
todos los pasos anteriores y subir directamente el modelo al Hub In Face. Una vez que tenemos el

220
00:25:39,720 --> 00:25:47,040
modelo, yo lo que hago es definir el pipeline. Yo en este caso seleccioné el pipeline de análisis

221
00:25:47,040 --> 00:25:54,680
de sentimiento con el modelo entrenado, con este problema puntual. Y fíjense que hasta acá,

222
00:25:55,440 --> 00:26:03,680
lo que sería es, una vez que yo tengo el chat, la cadena de chats de esa aplicación de WhatsApp,

223
00:26:03,680 --> 00:26:11,480
se hace todo el preprocesamiento y se hace una especie de predicción con ese pip que yo

224
00:26:11,480 --> 00:26:20,160
determiné. Y fíjense cómo clasifica el sistema con los labels 1 o 0, dependiendo si es o no es,

225
00:26:20,760 --> 00:26:32,760
ese chat con una tendencia destinada al grooming. Entonces, hasta ahí hay dos corrientes,

226
00:26:32,760 --> 00:26:38,640
pero puede haber muchas más. Estas son las que yo al menos encontré y definí para poder resolver

227
00:26:38,640 --> 00:26:46,080
este problema y no gastar demasiado tiempo en leer. Porque imagínense lo difícil que puede ser para

228
00:26:46,080 --> 00:26:53,040
los operadores de justicia estar leyendo línea por línea de un chat que puede tener cientos de

229
00:26:53,040 --> 00:27:00,320
mensajes. Entonces, uno de los próximos desafíos en lo que estoy pensando como para poder aplicar,

230
00:27:00,320 --> 00:27:07,800
porque tiene características muy similares, es por ejemplo poder detectar violencia doméstica y poder

231
00:27:07,800 --> 00:27:15,440
determinar antes de que ocurra, por ejemplo, un femicidio que en nuestro país hay muchos,

232
00:27:15,440 --> 00:27:21,400
muchos casos de femicidio, poder determinar si, por ejemplo, una mujer tiene, por ejemplo,

233
00:27:21,400 --> 00:27:27,680
una relación de violencia, porque ahí podemos ocupar la subcategorización de este dataset y

234
00:27:27,680 --> 00:27:34,760
poder determinar por ahí un poquito más finamente, diríamos, qué tipo de violencia puede estar

235
00:27:34,760 --> 00:27:40,080
sufriendo antes de que pueda ocurrir el femicidio o una vez que haya ocurrido y poder, diríamos,

236
00:27:40,720 --> 00:27:47,640
tener una herramienta más para poder condenar, diríamos, al culpable. Así que, bueno, por ahora

237
00:27:47,640 --> 00:27:53,800
esto es lo que quería compartir con ustedes y, bueno, decirles sobre el final que, bueno,

238
00:27:53,800 --> 00:28:01,560
estoy muy, muy feliz de poder compartir este trabajo con ustedes en esta conferencia. Así

239
00:28:01,560 --> 00:28:07,080
que si tienen preguntas los escucho y si no pueden, después de que termine la sesión,

240
00:28:07,320 --> 00:28:10,120
podemos charlar de lo que ustedes quieran. Gracias.

241
00:28:19,280 --> 00:28:26,320
Hola, muchas gracias. Hola. Es super interesante. Mi pregunta es, qué tan fácil es encontrar los

242
00:28:26,320 --> 00:28:32,440
datasets, o sea, de conversaciones en español, tanto bueno lo de grooming o femicidio,

243
00:28:32,760 --> 00:28:39,120
¿cómo encontrarías eso? Vos me decís como para entrenar, diríamos, el modelo o para poder

244
00:28:39,120 --> 00:28:46,240
definir. O primero tienes que tú conseguir todo el dataset para entrenar y luego poder... Claro,

245
00:28:46,240 --> 00:28:52,760
bueno, eso es lo que justamente explicaba. Este dataset es muy puntual, o sea, si después lo

246
00:28:52,760 --> 00:29:00,080
descargas y lo analizas, tiene mucho contenido que está orientado a todo este tipo de conducta,

247
00:29:00,080 --> 00:29:07,160
pero que no es un lenguaje totalmente explícito. O sea, en los mensajes nos vas a encontrar una

248
00:29:07,160 --> 00:29:13,720
línea que diga, por ejemplo, no sé, voy a asesinar a una persona, sino que es una conducta a la que

249
00:29:13,720 --> 00:29:22,240
está haciendo referencia. Entonces, este es un excelente dataset para probar este tipo de crímenes en particular.

250
00:29:22,240 --> 00:29:28,200
Aquí al fondo tenemos otra pregunta.

251
00:29:31,840 --> 00:29:36,520
Primero que todo, Carolina, muchas gracias por la presentación. De nada. Muy bacano ver proyectos

252
00:29:36,520 --> 00:29:40,680
de tecnología aplicados a temas sociales. Tengo varias preguntas, pero voy a intentar hacer

253
00:29:40,680 --> 00:29:47,240
solo dos y después podemos conversar. Tomar una base de datos como Twitter sirve para un primer

254
00:29:47,240 --> 00:29:53,040
approach, pero sabemos que las conversaciones es diferente tuitear a tener una conversación con

255
00:29:53,040 --> 00:29:58,640
alguien. No sé si internamente ustedes han pensado empezar a generar una base de datos

256
00:29:58,640 --> 00:30:03,920
propia que se pueda utilizar en Latinoamérica para este tipo de tecnología, como una propuesta de

257
00:30:03,920 --> 00:30:09,040
ustedes como equipo. Exactamente. Bueno, en la actualidad yo estoy armando, por mi propia cuenta,

258
00:30:09,040 --> 00:30:15,720
como nosotros recibimos mucho de este tipo de delitos, sobre todo grooming y otros tipos de

259
00:30:15,720 --> 00:30:21,240
delitos relacionados, por ejemplo, a redes de pedofilia. Tenemos mucho material. El tema es que

260
00:30:21,240 --> 00:30:27,040
hay una cuestión también legal. Porque esto recuerden que nosotros tenemos, por ejemplo,

261
00:30:27,040 --> 00:30:33,800
una orden de un juez de garantías en donde nosotros estamos autorizados a poder leer esa

262
00:30:33,800 --> 00:30:39,840
cadena de mensajes, esa información. Entonces, ahí habría un tema que habría que realmente

263
00:30:40,160 --> 00:30:46,960
preguntar, consultar en la parte legal, diríamos, cómo poder publicar este tipo de cuestiones. Porque

264
00:30:46,960 --> 00:30:54,120
si uno anonimiza, diríamos, y sirve para un bien común, yo creo que se podría intentar hacer esto.

265
00:30:54,120 --> 00:31:01,160
Pero yo, por mi cuenta, diríamos, estoy armando muchas, a ver, oraciones en que se pueden encontrar,

266
00:31:01,160 --> 00:31:08,080
por ejemplo, porque una de las principales cuestiones es cuando esta persona adulta lo

267
00:31:08,080 --> 00:31:15,080
cita al menor para cometer, en fin, en sí el delito. Entonces, eso por ahí no está definido en este

268
00:31:15,080 --> 00:31:21,120
conjunto de datos y es muy importante porque, en definitiva, eso es lo que quiere lograr esta

269
00:31:21,120 --> 00:31:27,520
persona maliciosa. Entonces, yo, por mi cuenta, estoy armando, aparte de toda esta, diríamos,

270
00:31:27,520 --> 00:31:35,680
esta forma, diríamos, de comentarios relacionados a la parte sexista, comentarios relacionados con

271
00:31:35,680 --> 00:31:42,080
encuentros y con formas diferentes de pedir información. Hoy por hoy sabemos que los

272
00:31:42,080 --> 00:31:48,600
adolescentes y los preadolescentes tienen mucho léxico y mucho lenguaje muy específico de niños,

273
00:31:48,600 --> 00:31:55,760
que por ahí no es el mismo que los adultos. Y los adultos que están intentando entrar en confianza

274
00:31:55,760 --> 00:32:02,320
con los niños utilizan también este lenguaje que tal vez otros no estén conociendo. No sé si responde

275
00:32:02,320 --> 00:32:06,280
un poquito a tu pregunta. Sí, total, total. Lo segundo no es una pregunta, es más como una

276
00:32:06,280 --> 00:32:12,600
sugerencia porque la idea es generar más contenido en español. Creo que tenemos que apoyarnos mucho

277
00:32:12,600 --> 00:32:17,400
como comunidad. No solamente es traducir lo que está en inglés porque, al final, para este tipo

278
00:32:17,400 --> 00:32:23,400
de aplicaciones no funciona. Pues como resolviendo el problema, pero sería muy bueno también tener

279
00:32:23,400 --> 00:32:28,480
en cuenta que en cada país se habla un léxico diferente con palabras específicas. Exactamente.

280
00:32:28,680 --> 00:32:35,440
Y lo otro que quería sugerir era el uso de modelos que tomen más contexto. No solamente,

281
00:32:35,440 --> 00:32:40,520
bueno, ese ejemplo de Transformer con Huginface está bien, pero de pronto intentar buscar modelos

282
00:32:40,520 --> 00:32:45,960
que no clasifiquen oraciones, sino que busquen generar contexto como LLM, lo que estamos viendo

283
00:32:45,960 --> 00:32:50,620
ahorita con GPT y todo esto, permitiría también tener mejores soluciones. Y por último, una

284
00:32:50,620 --> 00:32:56,040
sugerencia de pronto no sea a nivel legal como sea, pero sería muy interesante y si yo tuviese un

285
00:32:56,040 --> 00:33:02,520
hijo, lo pensaría incluso, de coger algún plugin ya que WhatsApp es encriptado en tuén, muy bacano

286
00:33:02,520 --> 00:33:07,880
sería agregarle un plugin a los niños que sea, digamos, que aceptado por el padre, que le permita

287
00:33:07,880 --> 00:33:13,440
tener como una especie de filtro donde coloques este tipo de modelos en esa aplicación. Eso es

288
00:33:13,440 --> 00:33:20,960
lo que justamente en un próximo desafío se puede realizar, pero eso ya sería, diríamos, a nivel

289
00:33:21,920 --> 00:33:29,000
familiar, por así decirlo, porque nadie puede obligar ni a un mayor ni a un niño a tener,

290
00:33:29,000 --> 00:33:36,320
pero sería una idea sumamente interesante de poder inclusive ir analizando, no sé si diariamente,

291
00:33:36,320 --> 00:33:43,640
pero con un periodo de tiempo para que se pueda determinar y detectar a tiempo antes de que suceda.

292
00:33:43,640 --> 00:33:50,880
En nuestro país hay mucho de este tipo de delito que después justamente no solamente termina en

293
00:33:50,880 --> 00:33:56,440
un delito contra la interés sexual, sino en secuestros y hasta asesinatos inclusive. Así que

294
00:33:56,440 --> 00:34:00,680
es muy interesante el área como para seguir investigando y ahondando un poquito más.

295
00:34:02,680 --> 00:34:10,560
Bueno, muchísimas gracias y un recordatorio último para la foto grupal de la gente latina

296
00:34:10,560 --> 00:34:16,400
aquí mismo a las cinco y media. Así que un aplauso y muchísimas gracias y continuemos.

