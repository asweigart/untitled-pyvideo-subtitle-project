1
00:00:00,000 --> 00:00:03,000
Alright, good afternoon everyone.

2
00:00:04,000 --> 00:00:05,000
Right on the dot.

3
00:00:05,000 --> 00:00:08,000
Thank you all very much for coming to my presentation.

4
00:00:08,000 --> 00:00:14,000
Today I've lured you into talking or attending a talk about Pokemon.

5
00:00:14,000 --> 00:00:22,000
But yeah, the project I'll be talking about is how to transform a Juketrainer notebook into a root-reducible ML pipeline.

6
00:00:22,000 --> 00:00:26,000
Just to give you a bit of an idea of myself, my name is Rob.

7
00:00:26,000 --> 00:00:28,000
I'm from Juketrax in the Netherlands.

8
00:00:28,000 --> 00:00:33,000
I used to be a developer advocate for InternetShip, although I was part of the layout a little while back.

9
00:00:33,000 --> 00:00:37,000
And important for this talk, I may want to talk about Pokemon training.

10
00:00:37,000 --> 00:00:50,000
So a while back in IJuild, where I was part of NetfieData, there I presented projects to create a machine learning model to classify Pokemon.

11
00:00:50,000 --> 00:00:54,000
And that's nothing to become the very best like no one ever was.

12
00:00:54,000 --> 00:01:01,000
And from there on, I wanted to figure out, okay, we've done this, can we do some other Pokemon related stuff?

13
00:01:01,000 --> 00:01:06,000
That's a fun step project that will also help showcase some cool technologies.

14
00:01:06,000 --> 00:01:09,000
And that's what I'll be talking about today.

15
00:01:09,000 --> 00:01:18,000
So you'll probably have heard that StableDiffusion and other text-to-image models are quite huge nowadays.

16
00:01:18,000 --> 00:01:28,000
So my idea was to create a pipeline with which I could create new Pokemon artwork and create some concept art for Pokemon for upcoming games.

17
00:01:28,000 --> 00:01:30,000
So that was the goal of the project.

18
00:01:30,000 --> 00:01:46,000
The approach would be to do a StableDiffusion or use that as a base model, one for Pokemon to be precise, and frame a Laura to adapt the model into actually generating real proper Pokemon projects.

19
00:01:46,000 --> 00:01:52,000
So for those of you who don't know, Laura is an appreciation for low-ranked adoption.

20
00:01:52,000 --> 00:02:00,000
And it's the current beta in trying to get your text-to-image models to produce the best possible output.

21
00:02:00,000 --> 00:02:10,000
And the great thing about this is that you can frame a relatively cheap and quick model that you just put on top of the base model.

22
00:02:10,000 --> 00:02:20,000
And that's something that you can do from your laptop, make the entire pipeline work on my local machine because it's cheap and because it's convenient.

23
00:02:20,000 --> 00:02:33,000
So the implementation, as I think many of you will do here, the first thing I do when I cut a beta-type project is to start working on the Jupyter Notebook because they're great for prototyping.

24
00:02:34,000 --> 00:02:39,000
And if we move over here, I'll quickly take you through the Notebook.

25
00:02:39,000 --> 00:02:42,000
So it's pretty straightforward.

26
00:02:42,000 --> 00:02:44,000
We do our imports and parameters.

27
00:02:44,000 --> 00:02:48,000
This is some housekeeping behind the project rules.

28
00:02:48,000 --> 00:02:51,000
We set some of the model parameters.

29
00:02:51,000 --> 00:02:57,000
So here I'm interested in starting all Pokemon types, like it also changes to water or grass or dragon.

30
00:02:57,000 --> 00:03:00,000
And here we've got some model parameters.

31
00:03:00,000 --> 00:03:07,000
So the max frame stats or the max inference stats for the model is going a little bit, I think it's 5,000 or something.

32
00:03:07,000 --> 00:03:09,000
And that's some stuff for generation.

33
00:03:09,000 --> 00:03:12,000
So text-to-image works with text as an input.

34
00:03:12,000 --> 00:03:14,000
And this is where the prompt comes in.

35
00:03:14,000 --> 00:03:18,000
And as you can see here, we're using the LoRa beta-type trained in the pipeline.

36
00:03:18,000 --> 00:03:23,000
So then we need the diffusers repository from the handling phase.

37
00:03:23,000 --> 00:03:26,000
We need to install the requirements and run a beta prompt text.

38
00:03:26,000 --> 00:03:28,000
These are all stuff you need to do once.

39
00:03:28,000 --> 00:03:32,000
Then I straight the Pokemon images from the Pokemon website.

40
00:03:32,000 --> 00:03:36,000
So one Bulbasaur and an Ice-Taur and a Heem-Taur.

41
00:03:36,000 --> 00:03:39,000
And those are the official concept art images.

42
00:03:39,000 --> 00:03:42,000
Actually, I think that the story goes right here.

43
00:03:42,000 --> 00:03:49,000
If you take a look at our journal data, then these are the kind of images that we're interested in generating.

44
00:03:49,000 --> 00:03:55,000
Having done that, we can get a subset of the relevant Pokemon.

45
00:03:55,000 --> 00:03:59,000
So way of the bath fire is to say how you can set it to only do one of five Pokemon.

46
00:03:59,000 --> 00:04:02,000
So now we'll just do each and every Pokemon.

47
00:04:02,000 --> 00:04:05,000
We need to resize the images.

48
00:04:05,000 --> 00:04:09,000
And then we get the extra font bar, which is training the LoRa.

49
00:04:09,000 --> 00:04:12,000
So this is a beta command.

50
00:04:12,000 --> 00:04:13,000
And these are the settings.

51
00:04:13,000 --> 00:04:21,000
And as you can see here, I'm importing the parameters as we use them in the rest of the notebook.

52
00:04:21,000 --> 00:04:24,000
From there, I just straight forward to set up the pipeline.

53
00:04:24,000 --> 00:04:31,000
So we take the base model, which is set to Fusion 1.5, and we then load the LoRa on top of the model.

54
00:04:31,000 --> 00:04:34,000
And then we can use it to generate images.

55
00:04:34,000 --> 00:04:35,000
So that's something I've already done here.

56
00:04:35,000 --> 00:04:37,000
And we can display those images.

57
00:04:37,000 --> 00:04:42,000
So this is the first result of creating a Pokemon that doesn't exist based on Pokemon that do exist.

58
00:04:42,000 --> 00:04:45,000
Is it any good? I'll let you be the judge of that.

59
00:04:46,000 --> 00:04:57,000
But to be honest, I'm quite happy that at least the art style is fairly similar to what we're getting from the actual Pokemon engine.

60
00:04:57,000 --> 00:05:03,000
So if we then take a look at this implementation.

61
00:05:03,000 --> 00:05:11,000
So these are the results for the same font and exactly the same settings if I only use the base model, set it to Fusion.

62
00:05:11,000 --> 00:05:14,000
And these are the results we get when using the LoRa.

63
00:05:14,000 --> 00:05:18,000
So again, you can be the judge of whether these Pokemon are in use.

64
00:05:18,000 --> 00:05:24,000
But especially the first one, I think it looks like an excellent, but it does reflect Pokemon in effect.

65
00:05:24,000 --> 00:05:27,000
And this is how powerful LoRa can be.

66
00:05:27,000 --> 00:05:33,000
Because with about 20 minutes of training on my own laptop, I get really different and really targeted results.

67
00:05:33,000 --> 00:05:36,000
I'm quite happy with these, I think, in initial experiments.

68
00:05:36,000 --> 00:05:42,000
So then moving on, what I started in from here was experiments to find the best settings to generate the best Pokemon.

69
00:05:42,000 --> 00:05:47,000
And in general, this is something you'll see time and time again in machine learning projects.

70
00:05:47,000 --> 00:05:52,000
Where you just keep experimenting, you keep tweaking some parameters to get to the best Pokemon.

71
00:05:52,000 --> 00:05:54,000
Or to get to the best predictions.

72
00:05:54,000 --> 00:05:58,000
Or more generally, to get to the best or the most performant model.

73
00:05:58,000 --> 00:06:04,000
And there's probably a few data scientists in the room today.

74
00:06:04,000 --> 00:06:07,000
This is what you will be doing as a data scientist.

75
00:06:07,000 --> 00:06:14,000
You're tweaking parameters, you're changing data sets, pushing back and forth to see if we can improve our models.

76
00:06:14,000 --> 00:06:20,000
Because you rarely get the opportunity to just produce a model and keep it in production.

77
00:06:20,000 --> 00:06:22,000
We have to experiment all the time.

78
00:06:22,000 --> 00:06:29,000
Even when we get a performant model and we put it into production, there can still be changes to the business requirements.

79
00:06:30,000 --> 00:06:37,000
We may need to change the context of our model, there may be some data derailment, we just want to keep optimizing.

80
00:06:37,000 --> 00:06:40,000
There are plenty of reasons for us to keep experimenting.

81
00:06:40,000 --> 00:06:45,000
But experimenting gets real messy if we don't keep proper track of what's going on.

82
00:06:45,000 --> 00:06:49,000
So for the Pokemon images I showed you earlier, I can't recreate those right now.

83
00:06:49,000 --> 00:06:53,000
Because I don't know which precise settings I use when generating these images.

84
00:06:53,000 --> 00:06:59,000
And that's not particularly a problem for creating Pokemon sprites or Pokemon artwork.

85
00:06:59,000 --> 00:07:05,000
But it can be an issue when you're doing actually high-stakes model development.

86
00:07:05,000 --> 00:07:08,000
So maybe a quick show of hands.

87
00:07:08,000 --> 00:07:14,000
Who here has been guilty of keeping track of parameters and results in NFL speeds or maybe even a physical note set?

88
00:07:14,000 --> 00:07:18,000
I sure have. That's mostly the room, right?

89
00:07:19,000 --> 00:07:24,000
Because that's easy. You just go back to the form and you tweak some stuff and you write it down.

90
00:07:24,000 --> 00:07:33,000
But it's messier. It gets even messier when you need to work together with your colleagues or your teammates on these projects.

91
00:07:33,000 --> 00:07:40,000
So a while back I was in Berlin and I talked to someone, I think it was roughly similar to this one.

92
00:07:40,000 --> 00:07:46,000
And they actually told me that a while back he was the head of a engineering team for a bank.

93
00:07:46,000 --> 00:07:49,000
And they put a model into prediction about four years ago.

94
00:07:49,000 --> 00:07:54,000
And someone from IRS came up to him and said, hey, you know that model that we had back then?

95
00:07:54,000 --> 00:07:56,000
It makes some funny predictions and we're in a bit of trouble.

96
00:07:56,000 --> 00:08:00,000
So we need to reconstruct what precisely went into that model.

97
00:08:00,000 --> 00:08:05,000
So which data were used to train the model, what parameters, which choices were made.

98
00:08:05,000 --> 00:08:11,000
And the entire team had to spend about two weeks of their time trying to reconstruct that model.

99
00:08:11,000 --> 00:08:15,000
Which is not something you want to do.

100
00:08:15,000 --> 00:08:21,000
And the more models you keep in production, the more difficult it gets to keep track of.

101
00:08:21,000 --> 00:08:25,000
So that's why we need reproducibility.

102
00:08:25,000 --> 00:08:32,000
And it's not enough to just track the model and track the results because then you know what the outcomes of your experiments are.

103
00:08:32,000 --> 00:08:34,000
It's not reproducibility of the experiment.

104
00:08:34,000 --> 00:08:38,000
And just like in science and data science, reproducibility is very important.

105
00:08:38,000 --> 00:08:42,000
So what do we need to do to get to full reproducibility?

106
00:08:43,000 --> 00:08:52,000
If we want to get there, my pitch to you is that we should define an experiment as a specific combination of data, code and parameters.

107
00:08:52,000 --> 00:09:02,000
Because if you have the data, code and parameters, then you can rerun your pipeline, you can rerun your model training, you can rerun your predictions and get the same deterministic outcome.

108
00:09:02,000 --> 00:09:06,000
Or at least that's what we're aiming for.

109
00:09:06,000 --> 00:09:08,000
But this is quite difficult to do.

110
00:09:08,000 --> 00:09:11,000
Or at least for some of the parts, it's difficult to do.

111
00:09:11,000 --> 00:09:14,000
Because for code, this is very much a small problem.

112
00:09:14,000 --> 00:09:24,000
If we look towards data sharing or more broadly software engineering, then of course we'll have Git to keep track of our code.

113
00:09:24,000 --> 00:09:26,000
And Git works really well.

114
00:09:26,000 --> 00:09:27,000
You get it free.

115
00:09:27,000 --> 00:09:32,000
But it only works really well if your file size is relatively small.

116
00:09:32,000 --> 00:09:36,000
So it's great to keep track of changes to a stack.

117
00:09:36,000 --> 00:09:41,000
But maybe less so when you're trying to version your beta test.

118
00:09:41,000 --> 00:09:50,000
So it could be something that's Git for data and that defines the 50 and the size limit in Git.

119
00:09:50,000 --> 00:09:54,000
So some of you may now think, oh, you could use Git LFS for that.

120
00:09:54,000 --> 00:09:55,000
And that's true.

121
00:09:55,000 --> 00:09:58,000
But Git LFS requires a separate server.

122
00:09:58,000 --> 00:10:03,000
And I'm here to give you a product that doesn't require that, which is VPC.

123
00:10:03,000 --> 00:10:08,000
So remember how I told you that I used to work for the greatest VPC of it.

124
00:10:08,000 --> 00:10:10,000
Take that into account.

125
00:10:10,000 --> 00:10:12,000
That's my full disclosure to you.

126
00:10:12,000 --> 00:10:14,000
The good thing is VPC is free of the stores.

127
00:10:14,000 --> 00:10:16,000
So you can give it a go.

128
00:10:16,000 --> 00:10:19,000
And they let me off, so I'll be giving an honest opinion here.

129
00:10:22,000 --> 00:10:24,000
VPC, its main take is data version control.

130
00:10:24,000 --> 00:10:26,000
But there's a little more than that.

131
00:10:26,000 --> 00:10:30,000
Its main features boil down to three components.

132
00:10:30,000 --> 00:10:33,000
So you've got data version control, pipelines and experiments.

133
00:10:33,000 --> 00:10:40,000
And I'll now go through those three components and then show you an implementation of a pipeline made in VPC.

134
00:10:40,000 --> 00:10:43,000
So first, the data version control.

135
00:10:43,000 --> 00:10:46,000
This is a Git repo, as you may recognize it.

136
00:10:46,000 --> 00:10:48,000
So we've got our list of commits.

137
00:10:48,000 --> 00:10:52,000
And in a given commit, we have a data status code form.

138
00:10:52,000 --> 00:10:56,000
So you receive fancy and laptops and catapults.

139
00:10:56,000 --> 00:11:00,000
And those are part of a Git project.

140
00:11:00,000 --> 00:11:02,000
Or sorry, a virtual resource garden.

141
00:11:02,000 --> 00:11:09,000
Now those images, we don't really want to drag in Git itself.

142
00:11:09,000 --> 00:11:13,000
So if we start using VPC, we run vpmit.

143
00:11:13,000 --> 00:11:18,000
And we replace the physical images with a metadata file.

144
00:11:18,000 --> 00:11:27,000
And the metadata file, the data.vp, contains a hash for the images, the size and some other information, the number of files.

145
00:11:27,000 --> 00:11:30,000
And it points towards the VPC cache.

146
00:11:30,000 --> 00:11:34,000
And the VPC cache is where the physical images are actually stored on your password.

147
00:11:34,000 --> 00:11:38,000
And as you can see, the images have moved to the VPC cache.

148
00:11:38,000 --> 00:11:41,000
Their names have completely scrambled up because they're not hashed.

149
00:11:41,000 --> 00:11:45,000
And we don't want to keep track of that manually anyway.

150
00:11:45,000 --> 00:11:51,000
So the VPC cache may look a little odd if you actually dive into the file system.

151
00:11:51,000 --> 00:12:00,000
But you can see it handles the translation between the metadata file in your Git repo and the files in your VPC cache.

152
00:12:00,000 --> 00:12:06,000
And now the beauty of this is that if we create a new commit, so here you can see that the device has changed.

153
00:12:07,000 --> 00:12:15,000
So we've got a new dataset that points towards a different specification in the VPC cache.

154
00:12:15,000 --> 00:12:21,000
So here we removed the bottom Pokemon and we added Ampharos because for now we're currently in Generation 2 of Pokemon.

155
00:12:21,000 --> 00:12:26,000
And the others in Pokemon are still part of the new commit.

156
00:12:26,000 --> 00:12:29,000
So Kenshi and Lepros are part of both commits.

157
00:12:29,000 --> 00:12:35,000
But they don't get duplicated in the cache, which saves you a lot of time, storage and also money.

158
00:12:35,000 --> 00:12:40,000
And then we have this cache, which lives on our local system, in my case, my MacBook.

159
00:12:40,000 --> 00:12:48,000
And we can mirror that to a remote storage, which can be an S3 bucket, a Google Drive, an SSTP server, anything you'd like to do.

160
00:12:50,000 --> 00:13:02,000
So once we mirror that and we apply the same basic principles of versioning our data as we do for code, we can start using that in some more interesting contexts.

161
00:13:02,000 --> 00:13:08,000
So we can just do data versioning, but you can also automate that based on Python.

162
00:13:08,000 --> 00:13:12,000
So this is the setup I showed you earlier in the notebook.

163
00:13:12,000 --> 00:13:16,000
Roughly, we've got cohesive sets of codes.

164
00:13:16,000 --> 00:13:26,000
So first we set up the user, then we download the Pokemon stats, we straight the images, we resize those images, then we train Laura and we generate the set data.

165
00:13:26,000 --> 00:13:32,000
And if we go from top to bottom, much like you would in your notebook, then you get the results of that.

166
00:13:32,000 --> 00:13:37,000
But each and every one of those stages produce an output or multiple outputs.

167
00:13:37,000 --> 00:13:45,000
So here we see, for example, that the resize Pokemon in a stage creates new Pokemon styles of a new size.

168
00:13:45,000 --> 00:13:52,000
And if we specify those outputs, we can also use them as dependencies for downstream stages in each stage.

169
00:13:53,000 --> 00:14:09,000
So if we then tell the train Laura stage that the process Pokemon directly is a dependency, then we can make sure that the train Laura stage only triggers once the images have been resized and placed in the process directory.

170
00:14:11,000 --> 00:14:17,000
And what's great about this is that oftentimes you won't change all of the stages at once.

171
00:14:18,000 --> 00:14:24,000
So for example, if I change the train Laura stage, then that doesn't affect all of your buff stages.

172
00:14:24,000 --> 00:14:30,000
And we don't need to rerun those, and you can cache the outcome of it and just feed it to our model train.

173
00:14:32,000 --> 00:14:42,000
So we can then restructure this as a DAG, where each of the stages is dependent on the outcome of the stages that are treated.

174
00:14:43,000 --> 00:14:48,000
So that's the pipeline. And then we can start using that pipeline to run experiments.

175
00:14:49,000 --> 00:14:53,000
So this is our pipeline where we do some stuff, or we do some inputs and outputs.

176
00:14:53,000 --> 00:15:05,000
So the input is the code, the data, and the parameters, and the outputs can be the model itself, but maybe also some plots, some metrics, anything that's the result of our model train.

177
00:15:06,000 --> 00:15:10,000
And as we discussed, we want to version each and every one of those components with either this or this.

178
00:15:10,000 --> 00:15:19,000
So as we've written some small files, we versioned in Git, and the larger files, which is the images, are in the mobile cell tree version with these keys.

179
00:15:19,000 --> 00:15:28,000
And if we do all of that together, then we can consider one pipeline run as an experiment, or more technically speaking, as a Git commit.

180
00:15:28,000 --> 00:15:35,000
And now if we want to go back through our history to find our pre-hint experiments, we can simply do a Git checkout.

181
00:15:36,000 --> 00:15:40,000
So here we see that parameters changed for one of the previous experiments.

182
00:15:41,000 --> 00:15:47,000
The other stuff stays the same, but because the parameters changed, we've got an effect that models plots metrics.

183
00:15:48,000 --> 00:15:53,000
And with Git checkout and then the Git checkout, we can quickly pull out those results.

184
00:15:55,000 --> 00:15:56,000
So, implementation number two.

185
00:15:56,000 --> 00:15:57,000
So, implementation number two.

186
00:15:57,000 --> 00:15:59,000
And this is where we get to the fun part, the code.

187
00:16:00,000 --> 00:16:03,000
So I will pull up the code.

188
00:16:03,000 --> 00:16:05,000
Is this big enough for all of you to see?

189
00:16:06,000 --> 00:16:07,000
Good.

190
00:16:09,000 --> 00:16:10,000
So let's take a look here.

191
00:16:12,000 --> 00:16:14,000
We are in our first four environments.

192
00:16:14,000 --> 00:16:19,000
And the first thing I did, so we have the notebook still here.

193
00:16:19,000 --> 00:16:24,000
I could remove it at this point, but I split this up into separate files from my list.

194
00:16:24,000 --> 00:16:27,000
So if we go to SST, for example, we've got the straight-flow font initiative.

195
00:16:28,000 --> 00:16:40,000
This has got precisely the same content roughly as the notebook, but with some more boilerplate so that we can run this module from our command line.

196
00:16:43,000 --> 00:16:52,000
So if we then use that command, we can use that command in a DSTMF file.

197
00:16:52,000 --> 00:16:55,000
So these are the pages, as we showed them earlier.

198
00:16:55,000 --> 00:16:58,000
And of course, without having to use users, we can create Pokemon images.

199
00:16:58,000 --> 00:17:00,000
Let's put a little bit down.

200
00:17:00,000 --> 00:17:02,000
So for example, the Resized Pokemon image is here.

201
00:17:02,000 --> 00:17:04,000
It simply runs this command.

202
00:17:04,000 --> 00:17:06,000
So it's a Python pre-thread.

203
00:17:06,000 --> 00:17:08,000
It runs Resized Pokemon images for five.

204
00:17:08,000 --> 00:17:11,000
And it passes the parameters from the grounds that Yamal has.

205
00:17:11,000 --> 00:17:14,000
And in DST, we can also specify our dependencies.

206
00:17:14,000 --> 00:17:18,000
So that's the existence of the Python module.

207
00:17:18,000 --> 00:17:25,000
But also the existence of these files so that we don't get almost high data.

208
00:17:25,000 --> 00:17:29,000
And it's got a number of outputs that are the result of this page.

209
00:17:29,000 --> 00:17:33,000
And then we pass the parameters, which are passed in some grounds by Yamal.

210
00:17:33,000 --> 00:17:35,000
So here we have our overview.

211
00:17:35,000 --> 00:17:36,000
We can change the seeds.

212
00:17:36,000 --> 00:17:37,000
We can change the learning rate.

213
00:17:37,000 --> 00:17:40,000
We can change the maximum set.

214
00:17:40,000 --> 00:17:46,000
And then with these two combined, we can run the DeepFight line from our command file.

215
00:17:46,000 --> 00:17:51,000
So for example, let's change the seed of our int generation.

216
00:17:51,000 --> 00:17:53,000
So we're a Python 25.3.

217
00:17:53,000 --> 00:17:56,000
So let's change it to that.

218
00:17:56,000 --> 00:18:01,000
I think we'll be fine just generating maybe three Pokemon right now.

219
00:18:01,000 --> 00:18:05,000
Let's go with this one.

220
00:18:05,000 --> 00:18:09,000
I will speed it up a little by doing fewer and fewer.

221
00:18:29,000 --> 00:18:32,000
Yeah.

222
00:18:32,000 --> 00:18:33,000
Yeah.

223
00:18:33,000 --> 00:18:34,000
OK.

224
00:18:34,000 --> 00:18:35,000
Cool.

225
00:18:35,000 --> 00:18:36,000
Thanks.

226
00:18:36,000 --> 00:18:42,000
So if we now do DeepFight repro, which stands for reproduce, we can...

227
00:18:42,000 --> 00:18:44,000
Oh, hey, there we go.

228
00:18:44,000 --> 00:18:48,000
We can now use DeepFight repro to reproduce our Python.

229
00:18:48,000 --> 00:18:55,000
And you see, as you will see, it has passed the underlying stages, so it's kicking up.

230
00:18:55,000 --> 00:18:58,000
And then taking it up where we generate our test data.

231
00:18:58,000 --> 00:19:02,000
And we can see the images come in in our output folder.

232
00:19:02,000 --> 00:19:05,000
It will take a little while.

233
00:19:05,000 --> 00:19:08,000
So two steps.

234
00:19:08,000 --> 00:19:12,000
I shouldn't forget to put the mic on as well.

235
00:19:16,000 --> 00:19:17,000
There we go.

236
00:19:17,000 --> 00:19:24,000
And this one returns an entirely black image because apparently state diffusion thinks that this is not suitable for work content.

237
00:19:24,000 --> 00:19:37,000
If you've been around the Internet in the past few months, then you will have seen that state diffusion and our test image models are gradually being used to generate much suitable for work content.

238
00:19:37,000 --> 00:19:40,000
They are trying to comb that.

239
00:19:40,000 --> 00:19:42,000
But yeah, you also get some false positives.

240
00:19:42,000 --> 00:19:45,000
So this is the first result.

241
00:19:45,000 --> 00:19:47,000
I don't know what type of Pokemon we're looking at.

242
00:19:47,000 --> 00:19:49,000
Maybe teal, maybe dark.

243
00:19:49,000 --> 00:19:50,000
Could be ice.

244
00:19:50,000 --> 00:19:53,000
I don't know.

245
00:19:53,000 --> 00:19:57,000
But yeah, fairly happy with at least our style.

246
00:19:57,000 --> 00:19:59,000
This one's quite good.

247
00:19:59,000 --> 00:20:00,000
It's got ice.

248
00:20:00,000 --> 00:20:05,000
It's got an appropriate amount of lint.

249
00:20:05,000 --> 00:20:13,000
I think this might be flying grass if anyone wants to pitch them in for the concept Pokemon hitting up after the show.

250
00:20:13,000 --> 00:20:16,000
So we've got our free image generated.

251
00:20:16,000 --> 00:20:22,000
And now we could do a git gist.

252
00:20:22,000 --> 00:20:23,000
There we go.

253
00:20:23,000 --> 00:20:25,000
Git commit.

254
00:20:25,000 --> 00:20:26,000
Oh, sorry.

255
00:20:26,000 --> 00:20:28,000
I should have said git after for us.

256
00:20:28,000 --> 00:20:30,000
That's for the audience.

257
00:20:30,000 --> 00:20:32,000
Git commit.

258
00:20:32,000 --> 00:20:41,000
And generate Pokemon with 25, 32.

259
00:20:41,000 --> 00:20:43,000
There we go.

260
00:20:43,000 --> 00:20:46,000
And then we could reach out to our remote.

261
00:20:46,000 --> 00:20:55,000
And now if we take a look at our git log, we can see our different commits that we generated.

262
00:20:55,000 --> 00:20:58,000
So we ran a few of these experiments before coming here.

263
00:20:58,000 --> 00:21:08,000
So right now you'll see that first of all, rams.yml has the speeds that we specified and the images are there.

264
00:21:08,000 --> 00:21:13,000
Now if we go back to one of the experiments that I ran earlier.

265
00:21:13,000 --> 00:21:19,000
So for example, the speed with, let's take this on speeds 1500.

266
00:21:19,000 --> 00:21:21,000
So quick.

267
00:21:21,000 --> 00:21:24,000
And then git checkout.

268
00:21:24,000 --> 00:21:26,000
And on hash.

269
00:21:26,000 --> 00:21:31,000
Then we can see that rams.yml has been updated.

270
00:21:31,000 --> 00:21:34,000
And we now have the speeds from the previous experiment.

271
00:21:34,000 --> 00:21:38,000
Now I can see that the output still hasn't changed.

272
00:21:38,000 --> 00:21:43,000
And that's because those are checked by the EC, so we also need to run these speed checkout.

273
00:21:43,000 --> 00:21:46,000
And if you like, you can automate this.

274
00:21:46,000 --> 00:21:51,000
Whenever you run git checkout, git speed checkout gets run as well.

275
00:21:51,000 --> 00:21:57,000
So to do these speed checkout, we retrieved the images from the cache.

276
00:21:57,000 --> 00:22:01,000
And hash comes out the Pokemon that we created earlier.

277
00:22:01,000 --> 00:22:06,000
Also just found one here.

278
00:22:06,000 --> 00:22:08,000
Let's see if there's anything else I would like to show.

279
00:22:08,000 --> 00:22:10,000
I think that's the most important part.

280
00:22:10,000 --> 00:22:14,000
I could quickly show the dbc cache.

281
00:22:14,000 --> 00:22:15,000
So here we've got the cache.

282
00:22:15,000 --> 00:22:23,000
And as you see, it's split up in nonsensical directories where we've got files based on the hash.

283
00:22:23,000 --> 00:22:25,000
Which you can see here.

284
00:22:25,000 --> 00:22:34,000
Then if you're a user of VS Code, you may also be interested in the dbc extension for VS Code.

285
00:22:34,000 --> 00:22:44,000
It's not the most useful here because our results are in the system, our outputs, and the difficulty ratios.

286
00:22:44,000 --> 00:22:49,000
So we don't get an automatic score to see how each experiment performs.

287
00:22:49,000 --> 00:22:57,000
But if you do, so for example, if your target is an Apple 1-4, then you can specify that as a metric.

288
00:22:57,000 --> 00:23:01,000
And we can compare those experiments in our experiment table.

289
00:23:01,000 --> 00:23:12,000
So for example, we can see what parameters we changed and then which metrics are the results.

290
00:23:12,000 --> 00:23:18,000
And from here we can also have done new experiments for example.

291
00:23:18,000 --> 00:23:27,000
So yeah, that's a more visual approach to what you can also do on the command line.

292
00:23:27,000 --> 00:23:29,000
So much for the implementation.

293
00:23:29,000 --> 00:23:32,000
Then the recap and takeaways.

294
00:23:32,000 --> 00:23:35,000
I hope this has been somewhat insightful.

295
00:23:35,000 --> 00:23:40,000
The takeaways I'd like you to take home is in data science we experiment constantly.

296
00:23:40,000 --> 00:23:44,000
And so we rarely get to just put a model into production and leave it there.

297
00:23:44,000 --> 00:23:50,000
To do proper experimenting, we need free-to-use ability because otherwise we're just messing around.

298
00:23:50,000 --> 00:23:55,000
Much like science, we need to be able to reproduce the results for them to have any value.

299
00:23:55,000 --> 00:24:00,000
And Jutri notebooks are great for prototyping but not so much for read-to-use ability.

300
00:24:00,000 --> 00:24:05,000
I don't think I actually highlight this, but let me just, I've got a little bit of time.

301
00:24:05,000 --> 00:24:09,000
Why Jutri notebooks aren't great for read-to-use ability.

302
00:24:09,000 --> 00:24:13,000
First of all, whenever you run them, their metadata changes.

303
00:24:13,000 --> 00:24:19,000
So you'll get a completely new file in your GIF repository.

304
00:24:19,000 --> 00:24:23,000
And there are ways to mitigate that, but it's not a nice way of working.

305
00:24:23,000 --> 00:24:30,000
Also, you can jump back and forth arbitrarily between cells, which makes it non-deterministic.

306
00:24:30,000 --> 00:24:34,000
Yeah, and the file size thing gets quite large in notebooks.

307
00:24:34,000 --> 00:24:38,000
Again, I'm really not basking you for this. I think you're a great tool.

308
00:24:38,000 --> 00:24:45,000
But once you get to the point where you have a working prototype or you have something that you're happy with

309
00:24:45,000 --> 00:24:49,000
and you want to quickly run some test experiments,

310
00:24:49,000 --> 00:24:54,000
my suggestion would be to move over to a pipeline,

311
00:24:54,000 --> 00:24:59,000
which we can run with a single command rather than getting through this process.

312
00:24:59,000 --> 00:25:04,000
So that's all we've been doing. We can achieve this combination on GIF and VPC.

313
00:25:04,000 --> 00:25:09,000
And then we can track the data, the code, and the parameters.

314
00:25:09,000 --> 00:25:15,000
VPC is then used for the data version control and the pipeline and the experience management.

315
00:25:15,000 --> 00:25:21,000
That concludes my talk. Thank you very much for attending and for your effort and attention.

316
00:25:21,000 --> 00:25:23,000
I hope you take something away from this.

317
00:25:23,000 --> 00:25:28,000
As I mentioned, I'm open to work, so if you have an exciting opportunity, this is all about that.

318
00:25:28,000 --> 00:25:30,000
I've got a few further resources.

319
00:25:30,000 --> 00:25:36,000
So the easiest one is to go to roplinit.nl, my personal website, and the slides are there,

320
00:25:36,000 --> 00:25:39,000
so you can take a look at the further resources.

321
00:25:39,000 --> 00:25:46,000
The other one, dbc.org for the docs, and dbc.org for the Discord community.

322
00:25:46,000 --> 00:25:51,000
They actually do the community part really well, and it's easy.

323
00:25:51,000 --> 00:25:54,000
We can help if you're starting out.

324
00:25:54,000 --> 00:25:59,000
And you will also find the links in the slides of our Discord, so I use the created project.

325
00:25:59,000 --> 00:26:01,000
Thank you very much.

