1
00:00:00,000 --> 00:00:13,240
Hello. First, I want to thank the organizers of PyTexas 2023. Thank you so much for putting

2
00:00:13,240 --> 00:00:19,800
on this conference. It's great to be in Austin. And I want to thank you for attending PyTexas.

3
00:00:19,800 --> 00:00:25,760
Thank you. This is my talk, Recursion for Beginners, a Beginner's Guide to Recursion.

4
00:00:25,920 --> 00:00:30,320
Actually, this is my talk, Recursion for Beginners, a Beginner's Guide to Recursion.

5
00:00:31,600 --> 00:00:36,240
My name is Al Swigert. I'm mostly known as the author of Automate the Boring Stuff with Python,

6
00:00:36,240 --> 00:00:42,160
but I have a new book that is out now. It's the Recursive Book of Recursion. And you can read it

7
00:00:42,160 --> 00:00:49,760
for free under a Creative Commons license on my website, inventwithpython.com. So what is

8
00:00:49,840 --> 00:00:54,000
recursion? Let's ask that website that knows all of our private thoughts.

9
00:00:54,720 --> 00:01:01,200
Okay. Uh-huh. Uh-huh. Yeah. So according to these suggestions, recursion is hard, confusing,

10
00:01:01,760 --> 00:01:09,840
magic, and bad. All right. Okay. So let's start with a basic definition. A recursive thing

11
00:01:09,840 --> 00:01:16,160
is something whose definition includes itself. So for example, here's a fractal, which is a

12
00:01:16,160 --> 00:01:20,400
recursive shape. This is called a Sierpinski Triangle. It kind of looks like the Triforce

13
00:01:20,400 --> 00:01:26,400
from Legend of Zelda. I drew this one using the turtle module that comes with Python. So turtle

14
00:01:26,400 --> 00:01:31,520
is this old school drawing library that lets you programmatically create these Etch-a-Sketch style

15
00:01:31,520 --> 00:01:37,600
pictures. The shape we draw here is a triangle with an upside down triangle in the middle,

16
00:01:37,600 --> 00:01:42,560
which forms three new triangles. And then you draw upside down triangles inside those triangles

17
00:01:42,560 --> 00:01:49,120
and so on forever. A Sierpinski Triangle is made of three Sierpinski Triangles. Its definition

18
00:01:49,120 --> 00:01:55,280
includes itself. So my book gives you the source code for a lot of turtle programs that generate

19
00:01:55,280 --> 00:01:59,360
recursive artwork. They're surprisingly short. They're like 40 lines of code or something like

20
00:01:59,360 --> 00:02:04,960
that. This is a Sierpinski carpet made of squares within squares. You can also make a 3D version of

21
00:02:04,960 --> 00:02:11,680
this in Minecraft, in which case it's a Sierpinski Cube. You can draw lots of these fractals with

22
00:02:11,680 --> 00:02:18,000
Python's turtle module. Here's a recursive tree. Each branch splits into two self-similar branches.

23
00:02:18,000 --> 00:02:23,600
This one looks almost too perfect, though. But if we make the branches sprout random branches

24
00:02:23,600 --> 00:02:30,400
instead of self-similar branches, we end up with a much more natural looking tree. There are some

25
00:02:30,400 --> 00:02:36,000
fractal curves we can draw. This is the coke curve. You split a line into three parts,

26
00:02:36,000 --> 00:02:40,720
and then you change the middle part into a bump. And then you repeat this by adding more bumps

27
00:02:40,720 --> 00:02:44,880
to the new parts. And if you do this to the three sides of a triangle, you end up with a

28
00:02:44,880 --> 00:02:50,400
coke snowflake. Notice that when you add a bump to a line, you're actually making the line one

29
00:02:50,400 --> 00:02:57,760
third longer. And you can add bumps forever. So this is a fractal whose finite area contains an

30
00:02:57,760 --> 00:03:03,840
infinitely long line. There's a bunch of these curves. This one's called the Hilbert curve.

31
00:03:03,840 --> 00:03:08,000
You just take this shape, and then you make three copies of it, and you rotate them around and

32
00:03:08,000 --> 00:03:12,000
connect them. And then that forms the new shape, and you just make three copies of that and rotate

33
00:03:12,000 --> 00:03:16,400
them around and connect them. But if you keep doing that on some graph paper, you have a

34
00:03:16,400 --> 00:03:22,480
contiguous line that touches every square of the graph paper. These are called space filling curves.

35
00:03:22,480 --> 00:03:27,680
All of these are drawn in Python. And that's just the well-known fractals. You can invent your own

36
00:03:27,680 --> 00:03:32,320
fractals. One of the projects in the recursion book is a generic fractal maker. You just start

37
00:03:32,320 --> 00:03:37,680
with any shape, like this triangle, and then you specify what the recursive step is. So in this

38
00:03:37,680 --> 00:03:42,960
case, we're creating a new triangle to the left, right, and bottom, and we also resize and rotate

39
00:03:42,960 --> 00:03:47,600
them a little bit. And that becomes the new shape that you start drawing to the left, right, and

40
00:03:47,600 --> 00:03:54,000
bottom. And if you do that for several more steps, you create a brand-new, never-before-seen fractal.

41
00:03:55,360 --> 00:03:59,520
So here's the square. And in the recursive step, we draw four more squares in the corners, but we

42
00:03:59,520 --> 00:04:04,400
also toggle the color between white and gray. And I don't even know what this is, but it looks kind

43
00:04:04,400 --> 00:04:09,440
of cool. Or we can do it with three corners instead of four, in which case, if you tilt your head

44
00:04:09,440 --> 00:04:16,160
about 135 degrees, it kind of looks like a Sierpinski triangle almost. There's no limit to the

45
00:04:16,160 --> 00:04:21,360
fractals that you can just come up with by just messing around. We're not just limited to geometric

46
00:04:21,360 --> 00:04:27,920
shapes either. You can apply recursion to images as well. This is a tin of a Dutch brand of cocoa

47
00:04:27,920 --> 00:04:34,960
called Drost Cocoa. I actually have one of these tins right here. This image is recursive. The image

48
00:04:34,960 --> 00:04:41,280
contains itself. So we can create our own by using Python and the Pillow Image Library.

49
00:04:42,240 --> 00:04:48,000
So this is my friend at the Menil Museum in Houston. First, I add an area of magenta pixels.

50
00:04:48,000 --> 00:04:51,680
Magenta is really nice because it sticks out, and it tends to not be something that naturally

51
00:04:51,680 --> 00:04:57,440
occurs in most photos. So our Python program identifies the size of the magenta area,

52
00:04:57,440 --> 00:05:03,360
and then shrinks a copy of the photo and replaces all the magenta pixels with the smaller photo.

53
00:05:03,360 --> 00:05:07,760
But of course, this smaller photo has its own magenta area. So you keep repeating this process

54
00:05:07,760 --> 00:05:13,760
over and over again, and you end up with a Drost effect photo. So the code that does this is in the

55
00:05:13,760 --> 00:05:21,040
recursion book. Right, Al, I thought you said that this was a talk for beginners. Yeah, okay, that

56
00:05:21,040 --> 00:05:25,920
all, I know that looks really complicated and fancy and everything, but I won't say that recursion

57
00:05:25,920 --> 00:05:31,600
is easy, but I will say that recursion isn't as hard as you think. Let's get a simple definition

58
00:05:31,600 --> 00:05:38,800
specific to programming. In programming, recursion is when a function calls itself. So here is the

59
00:05:38,800 --> 00:05:44,320
shortest possible recursive function. All it does is call itself. And that's like, it's kind of

60
00:05:44,320 --> 00:05:50,480
weird, right? Like, does that work? And the answer is no, no, it does not work. The error it gives

61
00:05:50,480 --> 00:05:55,680
you is recursion error, maximum recursion depth exceeded. And this kind of error is called a stack

62
00:05:55,680 --> 00:06:04,080
overflow. Hey, that's the name of that website. Okay, so there's this joke that everyone always

63
00:06:04,080 --> 00:06:10,080
says whenever you mention recursion, to understand recursion, you must first understand stack data

64
00:06:10,080 --> 00:06:15,600
structures and function calls. Yeah, so this is the main reason why recursion is tricky, because

65
00:06:15,600 --> 00:06:21,920
teachers don't explain these two concepts first. Let's start with stacks. Stacks are one of the

66
00:06:22,000 --> 00:06:27,520
simplest data structures in computer science. A stack is a data structure that holds an ordered

67
00:06:27,520 --> 00:06:33,760
sequence of data and only lets you interact with the topmost item. So for example, you can think

68
00:06:33,760 --> 00:06:39,440
of a stack as a stack of playing cards. We can add cards to the top of the stack and we can remove

69
00:06:39,440 --> 00:06:44,480
cards from the top of the stack, but you can't insert them into the middle. So if you think about

70
00:06:44,480 --> 00:06:50,400
it, the first card that you put on the stack will be the last card to be removed. So we call a stack

71
00:06:50,400 --> 00:06:56,560
a phylo data structure, because the first thing in will be the last thing out. Okay, so stacks have

72
00:06:56,560 --> 00:07:01,680
their own terminology. Adding data to the top of a stack is called pushing. Removing data from the

73
00:07:01,680 --> 00:07:12,400
top of a stack is called popping. And conversations can be like a stack. So yes, there we go.

74
00:07:12,400 --> 00:07:17,840
Conversations can be like a stack. So I want to tell you a story about my friend Alice, but before

75
00:07:17,840 --> 00:07:21,600
I tell you that, I got to tell you about my other friend Bob, but before I can tell you about Bob,

76
00:07:21,600 --> 00:07:25,520
I need to tell you about his wife Carol. So then I tell you about Carol, and then I get back to my

77
00:07:25,520 --> 00:07:30,000
story about Bob, I finish that story, and then I get back to my story about Alice. So that

78
00:07:30,000 --> 00:07:35,520
conversation has a stack-like structure. The story I'm currently telling you will be the one that's

79
00:07:35,520 --> 00:07:41,920
at the top of the stack. So in fact, you've already worked with stacks. Python lists act the same way

80
00:07:41,920 --> 00:07:48,640
as stacks, as long as you restrict yourself to just append and pop. So in this case, the last item

81
00:07:48,640 --> 00:07:55,600
in the list is the top of the stack. So here's, we're appending some strings to a list, Alice,

82
00:07:55,600 --> 00:08:02,320
then Bob, then Carol, then we pop the list, which returns Carol, and then if we check the list there,

83
00:08:02,320 --> 00:08:08,320
you can see that Bob is now the top of the stack, or rather the end of the list. So that's how stacks

84
00:08:08,320 --> 00:08:12,960
work. There's not much to them. The second thing you need to know about are function calls.

85
00:08:13,520 --> 00:08:19,920
Now, you already kind of know this, but it helps to have someone explicitly tell you when you call

86
00:08:19,920 --> 00:08:25,040
a function, you're not just going on a one-way trip into the function call. The Python interpreter

87
00:08:25,040 --> 00:08:30,640
needs to remember where to return to when the function call returns. So if we have a function

88
00:08:30,640 --> 00:08:36,480
A that calls function B, that calls function C, when C returns, it goes back to B, which goes

89
00:08:36,480 --> 00:08:41,920
back to A, which goes back to the global scope. Now, the way that the Python interpreter keeps

90
00:08:41,920 --> 00:08:49,680
track of function calls is with a stack, and this stack is called the call stack. So Python puts

91
00:08:49,680 --> 00:08:54,720
frame objects on the call stack, and frame objects contain the data of where the execution should

92
00:08:54,720 --> 00:08:59,840
return to after the function call returns. So you can think of a frame object as representing a

93
00:08:59,840 --> 00:09:05,440
function call. We push a new frame object onto the call stack when a function is called, and we pop

94
00:09:05,440 --> 00:09:11,120
it off the call stack when the function returns. The topmost frame object is the function call the

95
00:09:11,120 --> 00:09:18,400
execution is currently in. You know, but when we look at our code, you might wonder, where's the

96
00:09:18,400 --> 00:09:22,960
call stack exactly? Because you can't see it. This is something that the Python interpreter

97
00:09:22,960 --> 00:09:27,920
handles for you automatically behind the scenes. So you can't point to your program anywhere and

98
00:09:27,920 --> 00:09:33,520
say, there, that's the call stack. It's invisible. And if your teacher is not telling you about this,

99
00:09:34,080 --> 00:09:40,240
recursion is just going to seem like some mysterious invisible thing. Okay. So that's stacks

100
00:09:40,240 --> 00:09:48,320
and function calls. But one more thing, recursion is overrated. Or at least recursion is overused.

101
00:09:48,320 --> 00:09:53,120
You know, people like to use recursion when they don't have to. It doesn't make the code simpler.

102
00:09:53,120 --> 00:09:57,520
It, in fact, does the opposite. But programmers will do this anyway because one of the most

103
00:09:57,520 --> 00:10:02,560
irritating things programmers do regularly is feel so good about learning a hard thing that they

104
00:10:02,560 --> 00:10:09,360
don't look for ways to make it easy or even oppose things that would do so. This is so true.

105
00:10:09,360 --> 00:10:16,320
I'm going to have it tattooed to my forehead. And I think it's really telling that there are two

106
00:10:16,320 --> 00:10:22,480
algorithms every recursion tutorial uses. And they are both terrible examples of recursion.

107
00:10:23,760 --> 00:10:31,600
Yes. The classic algorithms. Factorial and Fibonacci. Okay. So this is factorial. It's

108
00:10:31,600 --> 00:10:39,200
a math thing. 5 factorial is 5 times 4 times 3 times 2 times 1 or 120. 2 factorial is 2 times

109
00:10:39,200 --> 00:10:44,800
1. 4 factorial is 4 times 3 times 2 times 1. You can see the pattern. The interesting thing about

110
00:10:44,800 --> 00:10:52,160
factorial is if you look at it, especially 5 factorial, that's the same as 5 times 4 factorial.

111
00:10:52,160 --> 00:10:58,560
We can generalize this pattern. The factorial of any number is that number times the factorial of

112
00:10:58,560 --> 00:11:05,440
that number minus 1. So the definition of factorial includes itself. It has a recursive nature.

113
00:11:06,160 --> 00:11:10,320
So we can translate this into Python code. Let's make a factorial function and it returns the

114
00:11:10,320 --> 00:11:15,200
number parameter times the factorial of number minus 1. And this seems kind of weird. Does this

115
00:11:15,200 --> 00:11:20,880
actually work? And the answer is no. No, it does not. This will crash with a stack overflow. So

116
00:11:21,440 --> 00:11:26,880
why does that happen? Well, if you think about it, this is 5 factorial. But our factorial function

117
00:11:26,880 --> 00:11:33,120
is actually doing this. We forgot to tell it to stop at 1. So it just keeps going. So if you ever

118
00:11:33,120 --> 00:11:39,840
have a stack overflow, the problem is that your algorithm never stopped recursing. Programs can't

119
00:11:39,840 --> 00:11:44,400
make recursive calls forever because every function call adds a frame object to the call stack and

120
00:11:44,400 --> 00:11:48,880
that takes up a little bit of memory. So an infinite recursion would eventually eat up all

121
00:11:48,880 --> 00:11:53,280
of your computer's available memory and Python goes ahead and just cuts it off after about

122
00:11:53,920 --> 00:11:58,960
at 1,000 function calls without any return. So this is why the stack trace right here

123
00:11:58,960 --> 00:12:06,320
has four function calls and then it says repeated 996 more times. Now, to fix the stack overflow

124
00:12:06,320 --> 00:12:12,880
problem, we want to stop recursing when the number argument is 1. So here's a hint. One factorial

125
00:12:12,880 --> 00:12:18,160
is always 1. So let's add some code that checks if number is 1. And in that case, we can have it

126
00:12:18,160 --> 00:12:24,240
return 1. And this case is called the base case. The base case is the circumstance under which you

127
00:12:24,240 --> 00:12:30,720
stop making more recursive function calls. And then the recursive case is when we make a recursive

128
00:12:30,720 --> 00:12:38,640
function call. Your recursive function must always have at least one base case and one recursive case.

129
00:12:39,520 --> 00:12:43,360
This kind of makes sense if you think about it because if you don't have a base case,

130
00:12:43,360 --> 00:12:47,680
then your recursive function is just going to recurse forever and cause a stack overflow.

131
00:12:47,680 --> 00:12:52,640
And if your recursive function doesn't have a recursive case, it's not a recursive function.

132
00:12:52,640 --> 00:12:58,400
It's never actually calling itself. So at least one base case and one recursive case.

133
00:12:58,400 --> 00:13:04,640
You might still look at this function and think, yeah, OK. I see how that works kind of. But where

134
00:13:04,640 --> 00:13:14,560
does the 5 times 4 times 3 times 2 times 1 happen? So it kind of happens across several function

135
00:13:14,560 --> 00:13:19,040
calls of the call stack. That's a really bad way of describing it. You need to keep in mind

136
00:13:19,040 --> 00:13:25,520
that in recursion, all the function calls are for the same function. The call stack doesn't contain

137
00:13:26,160 --> 00:13:31,520
frame objects that represent functions. They represent function calls. And this is a very

138
00:13:31,520 --> 00:13:36,480
subtle distinction. But maybe this will help. Let's use a stack of cards to represent the call stack

139
00:13:36,480 --> 00:13:43,040
and frame objects. This is a timeline of what the call stack looks like. So we first call factorial

140
00:13:43,040 --> 00:13:48,640
with an argument of 5. We push a new frame object card onto the call stack. This frame object

141
00:13:48,640 --> 00:13:54,720
represents a function call that returns 5 times the factorial of 4. But it can't return yet. It

142
00:13:54,720 --> 00:14:01,360
has to call factorial. So we add another frame object with another function call to factorial

143
00:14:01,360 --> 00:14:08,080
here, this time with an argument of 4. This function call pushes another frame object on the

144
00:14:08,080 --> 00:14:14,320
stack. Now there are two cards on the stack. But notice that this new frame object has its own

145
00:14:14,320 --> 00:14:20,560
local variable named number. The other number variable is still there. It's just on the card

146
00:14:20,560 --> 00:14:26,160
below. So local variables are stored in these frame objects. And one thing that you really need

147
00:14:26,160 --> 00:14:31,440
to understand is that there are multiple local variables named number. They have the same name,

148
00:14:31,440 --> 00:14:36,320
but they're existing at the same time. We haven't replaced the old number variable. This is another

149
00:14:36,320 --> 00:14:41,600
thing that makes recursion really confusing if nobody points this out to you explicitly.

150
00:14:42,640 --> 00:14:46,560
Anyway, we continue with more function objects pushed to the call stack until we reach the base

151
00:14:46,560 --> 00:14:52,160
case, which just returns 1. And when that function call returns, we pop the frame object off the call

152
00:14:52,160 --> 00:14:56,320
stack. So the call stack starts getting smaller. We're back to the function call where the number

153
00:14:56,320 --> 00:15:00,720
parameter was 2. But now we have all the information we need to return. So that card gets popped off

154
00:15:00,720 --> 00:15:08,560
the call stack and so on and so on and so on until the last card returns 5 times 24, which is 120,

155
00:15:08,560 --> 00:15:13,920
which is the factorial of 5. After that, the call stack is empty and the execution is back

156
00:15:13,920 --> 00:15:22,800
in the global scope. So where does the 5 times 4 times 3 times 2 times 1 happen? It's hard to

157
00:15:22,800 --> 00:15:27,680
imagine all of this because it's sort of the call stack is changing across time. But here's another

158
00:15:27,680 --> 00:15:32,720
way that we can represent it. Let's just hard code our recursive function as multiple separate

159
00:15:32,720 --> 00:15:39,280
functions. So factorial 5 function returns 5 times factorial 4 functions return value,

160
00:15:39,280 --> 00:15:45,600
and factorial 4 returns 4 times factorial 3's return value and so on until we get to factorial

161
00:15:45,600 --> 00:15:51,920
1 function, which just returns 1. So if you want to know, here is where 5 times 4 times 3 times 2

162
00:15:51,920 --> 00:15:57,840
times 1 happens. It's just that in our recursive example, all of this is in one function.

163
00:15:59,760 --> 00:16:04,720
Now, a non-recursive algorithm is called an iterative algorithm. So some programmers might

164
00:16:04,720 --> 00:16:09,120
tell you that like, oh, well, there's some things that you can only do with recursion,

165
00:16:09,120 --> 00:16:15,040
and that is completely wrong. Anything you can do with recursion, you can do with a loop and a stack.

166
00:16:15,040 --> 00:16:21,280
Look, I'll prove it. So you can write an iterative factorial algorithm, and you can write a

167
00:16:21,280 --> 00:16:27,920
recursive factorial algorithm. Here is an iterative factorial algorithm that emulates a recursive

168
00:16:27,920 --> 00:16:32,640
factorial algorithm. Notice it's not a recursive function. There's no functions in here. I'm not

169
00:16:32,640 --> 00:16:37,600
going to explain all of this. This is way too complicated. But I emulate a call stack with a

170
00:16:37,600 --> 00:16:42,800
Python list, and I emulate frame objects with these dictionaries that contain the local variables,

171
00:16:42,800 --> 00:16:47,840
and I emulate the function calls by pushing and popping the emulated frame objects to the

172
00:16:47,840 --> 00:16:52,400
emulated call stack. Emulated stops sounding like a real word when you say it so often.

173
00:16:53,840 --> 00:16:59,520
This is completely ridiculous. But technically, the code works. This will print out 120,

174
00:16:59,520 --> 00:17:06,160
5 factorial at the end of it. Yeah, anything you can do with recursion, you can do with a loop

175
00:17:06,160 --> 00:17:11,280
and a stack. If you know where the Ackerman function is, yes, even recursive Ackerman can

176
00:17:11,280 --> 00:17:15,760
be implemented iteratively by using a loop and a stack. Here's the code for that.

177
00:17:16,640 --> 00:17:22,480
So if we don't need recursion, and recursion is often confusing, when should we actually

178
00:17:22,480 --> 00:17:27,280
use recursion? So I thought about this, and I came up with an answer, and then I thought

179
00:17:27,280 --> 00:17:32,720
about it some more, and I came up with a better answer. We should use recursion when your problem

180
00:17:32,720 --> 00:17:38,800
has both a tree-like structure and backtracking. So this is a tree data structure. It's used a

181
00:17:38,800 --> 00:17:42,880
lot in computer science. You have a root node at top, and it branches out to other nodes.

182
00:17:42,880 --> 00:17:49,040
And those nodes will branch out to other nodes, so trees have a recursive structure. Yes, I

183
00:17:49,040 --> 00:17:53,440
realize that the tree is upside down. That's because the root node is the start, and on paper,

184
00:17:53,440 --> 00:17:58,320
we write things from top to bottom. It's fine. Lots of things in programming are upside down.

185
00:17:59,120 --> 00:18:03,120
So recursion is really suited to working with tree graphs because they have a recursive nature,

186
00:18:03,680 --> 00:18:08,080
especially like when you need to move down the tree graph, but then you also have to backtrack

187
00:18:08,080 --> 00:18:12,800
up. There's a lot of problems that you can sort of map onto trees and then use recursion to solve.

188
00:18:12,800 --> 00:18:17,680
For example, a maze can be solved with recursion because a maze is just really a tree data

189
00:18:17,680 --> 00:18:22,400
structure. The entrance is the root node, and then every time you come to an intersection,

190
00:18:22,400 --> 00:18:26,400
it branches off into multiple other nodes, and the exit is going to be one of the other nodes.

191
00:18:26,400 --> 00:18:31,440
So if you backtrack from the exit back to the entrance, that's the solution of the maze.

192
00:18:32,480 --> 00:18:35,840
Now, I don't have time to go into any tree traversal algorithms, but the recursion book

193
00:18:35,840 --> 00:18:40,640
has the code. Just take my word for it that it's actually simpler to implement this as a recursive

194
00:18:40,640 --> 00:18:45,360
function than doing it with a loop and a stack, but otherwise, you should not use recursion.

195
00:18:46,880 --> 00:18:52,720
Here's a problem with recursive factorial, though. If you try to calculate the factorial of 1,001,

196
00:18:52,720 --> 00:18:57,280
you're going to get a stack overflow because it needs more than 1,000 function calls.

197
00:18:57,280 --> 00:19:02,640
Now, there is a way around this. It's called tail call optimization. Long story short. The

198
00:19:02,640 --> 00:19:08,320
Python interpreter can mess with the call stack and prevent stack overflows. It's just you have to

199
00:19:08,320 --> 00:19:13,120
make the recursive call the last thing in the recursive function because if there's no code

200
00:19:13,120 --> 00:19:16,800
after the recursive call, you don't have to hang on to the local variables, which means you don't

201
00:19:16,800 --> 00:19:20,480
have to hang on to the frame object, and you can prematurely pop it off the stack, and then the

202
00:19:20,480 --> 00:19:28,160
call stack doesn't grow. Tail call optimization is this way that you can stop stack overflows.

203
00:19:28,880 --> 00:19:35,440
But there's another problem. This recursive factorial function can't be tail call optimized

204
00:19:35,440 --> 00:19:40,480
because you notice there's this one little bit of code that happens after the recursive call.

205
00:19:41,120 --> 00:19:47,360
So now you have to rewrite all of your code to use this thing called an accumulator and change

206
00:19:47,360 --> 00:19:51,840
the base case around. This is just becoming more and more confusing. And then there's another

207
00:19:51,840 --> 00:19:58,320
problem on top of that, and that's the Python interpreter doesn't implement tail call optimization,

208
00:19:58,320 --> 00:20:04,080
and it never will. Guido van Rossum has a couple of blog posts giving his reasons, but he's not

209
00:20:04,080 --> 00:20:10,320
alone. Most JavaScript engines and the Java virtual machine from Oracle also don't implement

210
00:20:10,320 --> 00:20:15,280
tail call optimization. You can write tail recursion if you want. It's not actually going to happen

211
00:20:15,920 --> 00:20:22,640
by the compiler or the interpreter. So despite the fact that factorial is the most popular example

212
00:20:22,640 --> 00:20:27,920
of recursion, you never actually want to use recursion to calculate factorials in the real world

213
00:20:27,920 --> 00:20:34,480
ever. The other popular example of recursion is the Fibonacci sequence. This is another math thing.

214
00:20:35,760 --> 00:20:39,840
You probably know this. The sequence starts with the numbers one and one, and the next number is

215
00:20:39,840 --> 00:20:45,840
always the sum of the previous two numbers. So you can easily write a function that uses a loop

216
00:20:45,840 --> 00:20:51,600
to calculate these. But if you're too clever for your own good, you'll notice that the nth Fibonacci

217
00:20:51,600 --> 00:20:57,680
number is the sum of the two previous Fibonacci numbers. So this definition includes itself,

218
00:20:57,680 --> 00:21:02,560
and you can write a recursive algorithm for it. The base case is that the first two numbers,

219
00:21:02,560 --> 00:21:08,800
one and two, are always going to be one. But notice that every recursive function call results

220
00:21:08,800 --> 00:21:15,360
in two more recursive function calls. So here's a tree diagram. If you try to find the sixth Fibonacci

221
00:21:15,360 --> 00:21:21,440
number, you're going to end up with all of these other calls in exponentially growing number of

222
00:21:21,440 --> 00:21:26,720
function calls. And a lot of those are redundant. You're recalculating the same Fibonacci number

223
00:21:26,720 --> 00:21:32,160
over and over again. And to prevent this, there's a technique called memoization.

224
00:21:32,880 --> 00:21:38,880
Long story short, you can just cache the return value the first time a function is called, and

225
00:21:38,880 --> 00:21:43,040
then that way you don't have to repeat the calculation and blah, blah, blah. This is all

226
00:21:43,040 --> 00:21:48,880
just more hacks that you have to put on top of complicated code just to make recursion work at

227
00:21:48,880 --> 00:21:55,040
all. And you can avoid all of it just by not using recursion. I don't even know why people

228
00:21:55,040 --> 00:22:02,880
use recursion. It's just so confusing and frustrating. And I hate it. I hate recursion.

229
00:22:02,880 --> 00:22:08,960
I hate it so much. I hate it so much that I'm going to write an entire book on recursion and

230
00:22:08,960 --> 00:22:13,120
then I'm going to give it away for free on the internet just so people can find out how terrible

231
00:22:13,120 --> 00:22:19,840
it is. You should never use recursion. It's so pointless. Except there is one area where recursion

232
00:22:19,840 --> 00:22:25,760
comes in handy. This is the Python instruction two plus three. We call this an expression.

233
00:22:26,560 --> 00:22:31,440
Now, an expression is made up of values connected by operators. Two and three are values. The plus

234
00:22:31,440 --> 00:22:38,800
operator is an operator. So we can define an expression as value operator value. But

235
00:22:38,800 --> 00:22:44,000
expressions can be more complicated than this. This expression is two plus three times three.

236
00:22:44,320 --> 00:22:51,200
In this case, our expression is a value operator and another expression. And a value by itself

237
00:22:52,080 --> 00:22:56,960
is also an expression. It's just that a value is an expression that evaluates to itself.

238
00:22:57,920 --> 00:23:04,000
Now, wait a second. This looks familiar. The definition of expression includes itself. Not

239
00:23:04,000 --> 00:23:08,320
only that, but this is a recursive case and a base case. It turns out if you want to create

240
00:23:08,320 --> 00:23:13,600
your own programming language, you need to understand recursion. Now, creating your own

241
00:23:13,600 --> 00:23:18,800
programming language is something that most programmers never even think of themselves

242
00:23:18,800 --> 00:23:25,840
as capable of doing. It just seems too big and too advanced. Where would you even start? I guess

243
00:23:25,840 --> 00:23:32,320
you would start with recursion. But it's not just making your own programming language, though.

244
00:23:32,320 --> 00:23:37,760
There's lots of things in programming that we feel like we're just not qualified to work on

245
00:23:37,760 --> 00:23:43,760
because they seem too advanced. But if you start dabbling in these weird little areas of theoretical

246
00:23:43,760 --> 00:23:50,160
computer science, you begin to see that they're not just theory. You start getting ideas on how

247
00:23:50,160 --> 00:23:54,640
to build these much greater things that you would have never thought possible before.

248
00:23:55,760 --> 00:24:04,160
Understanding recursion lets you have bigger dreams. In conclusion, recursion is a hack that

249
00:24:04,160 --> 00:24:09,040
produces an over-engineered mess, just that insufferable programmers can show off how smart

250
00:24:09,040 --> 00:24:17,200
they are. And recursion is an amazing concept that allows you to see new things in the field

251
00:24:17,200 --> 00:24:23,200
of programming. It's something that you don't need to be a genius to understand. It is subtle,

252
00:24:23,200 --> 00:24:34,640
it is complex, it is beautiful, and it's worth your time and effort to understand. Thank you.

