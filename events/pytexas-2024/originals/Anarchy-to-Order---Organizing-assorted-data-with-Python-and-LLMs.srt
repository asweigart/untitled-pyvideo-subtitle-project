1
00:00:00,160 --> 00:00:01,000
Thank you, Brad.

2
00:00:04,260 --> 00:00:06,080
As Brad mentioned, my name is Jason Ku.

3
00:00:06,080 --> 00:00:09,020
I am a developer advocate for Neo4j,

4
00:00:09,020 --> 00:00:11,060
a graph database company.

5
00:00:11,060 --> 00:00:14,420
And I will be talking about using large language models

6
00:00:14,420 --> 00:00:16,740
because there's no way you're gonna get away from Gen.ai,

7
00:00:16,740 --> 00:00:21,300
even here, using it to create a knowledge graph.

8
00:00:21,300 --> 00:00:25,080
Now, before I dive deep into what I'm gonna present here,

9
00:00:25,080 --> 00:00:28,360
I would like to start off with a confession.

10
00:00:28,360 --> 00:00:32,720
And that confession is I have an amazing ability

11
00:00:32,720 --> 00:00:34,480
to forget pretty much everything.

12
00:00:34,480 --> 00:00:37,920
I am probably, maybe arguably, if Laura is not in here,

13
00:00:37,920 --> 00:00:40,760
arguably probably the person with the worst memory possible.

14
00:00:40,760 --> 00:00:45,760
I have managed to, in 20 feet, go from buying a movie ticket

15
00:00:46,720 --> 00:00:49,360
to losing that ticket before I got to the person

16
00:00:49,360 --> 00:00:53,680
that rips it, and then subsequently losing 20 more dollars

17
00:00:53,680 --> 00:00:55,780
to get that movie ticket.

18
00:00:55,780 --> 00:01:00,780
Okay, so, sample of chaos is if you can't remember anything.

19
00:01:01,140 --> 00:01:04,860
Okay, so, I was super excited, oop,

20
00:01:06,140 --> 00:01:09,100
super excited when media works.

21
00:01:12,160 --> 00:01:16,000
If not, okay, so, years ago.

22
00:01:17,860 --> 00:01:19,620
Oh, we'll just show everything at once.

23
00:01:19,620 --> 00:01:20,460
Yeah, let's.

24
00:01:20,460 --> 00:01:21,300
Screen, do you want, and this one?

25
00:01:21,300 --> 00:01:24,340
Pay no attention to the elves behind the scene.

26
00:01:24,340 --> 00:01:25,420
Mirroring everything?

27
00:01:25,940 --> 00:01:27,420
Let's do, not that one.

28
00:01:29,580 --> 00:01:31,060
This, I believe, is my presentation.

29
00:01:31,060 --> 00:01:33,660
Okay, yes, so, a couple years ago,

30
00:01:33,660 --> 00:01:34,820
actually a lot of years ago now,

31
00:01:34,820 --> 00:01:37,580
there was a whole spate of second brain apps

32
00:01:37,580 --> 00:01:39,020
that came out, right?

33
00:01:39,020 --> 00:01:43,100
Notion, Roam, and my favorite, Obsidian.

34
00:01:43,100 --> 00:01:44,180
And it was great, right?

35
00:01:44,180 --> 00:01:46,580
As a developer, I could write all my notes in Markdown,

36
00:01:46,580 --> 00:01:48,900
and then using just some special syntax,

37
00:01:48,900 --> 00:01:52,160
kind of link those documents together, right?

38
00:01:52,160 --> 00:01:56,080
So, my favorite thing was this graph view, right?

39
00:01:56,080 --> 00:02:01,080
And I think I can actually show you my Obsidian right here.

40
00:02:01,120 --> 00:02:04,800
So, this view is, I think, very awesome.

41
00:02:06,440 --> 00:02:07,940
Of course, how do I close this?

42
00:02:09,440 --> 00:02:11,020
All right, I'm not gonna do all this too long.

43
00:02:11,020 --> 00:02:15,060
But, anyways, you can see the sort of connection

44
00:02:15,060 --> 00:02:17,200
between your documents, and I thought this was great, right?

45
00:02:17,200 --> 00:02:20,160
It gives you a little bit of, not quite context,

46
00:02:20,160 --> 00:02:21,680
but like memory, like, oh, okay,

47
00:02:21,680 --> 00:02:23,960
so I met this person at this event,

48
00:02:23,960 --> 00:02:26,340
and I also met this person at some other event.

49
00:02:26,340 --> 00:02:31,080
It started to help me, like, remember folks

50
00:02:31,080 --> 00:02:32,160
that I would run into a lot,

51
00:02:32,160 --> 00:02:35,880
or events that I went to, or places, right?

52
00:02:35,880 --> 00:02:40,280
So, question then, is this a knowledge graph

53
00:02:40,280 --> 00:02:42,620
inside Obsidian?

54
00:02:43,680 --> 00:02:46,480
Almost, it's not quite a knowledge graph,

55
00:02:46,480 --> 00:02:50,240
because those links between the documents are,

56
00:02:50,240 --> 00:02:52,480
they're kind of inferred relationships,

57
00:02:52,480 --> 00:02:55,760
but the relationship itself isn't explicitly defined, right?

58
00:02:55,760 --> 00:02:58,520
So, I've got one doc that links to another doc,

59
00:02:58,520 --> 00:03:01,480
but what does that link mean, right?

60
00:03:01,480 --> 00:03:03,120
It's like looking at a crime board

61
00:03:03,120 --> 00:03:05,900
where you've got a victim, and then a killer,

62
00:03:05,900 --> 00:03:07,120
and then a place, and a receipt,

63
00:03:07,120 --> 00:03:10,240
and they got that red line joining everything, right?

64
00:03:10,240 --> 00:03:12,880
You, as an audience, you know what the red line means,

65
00:03:12,880 --> 00:03:14,240
because the whole rest of the show

66
00:03:14,240 --> 00:03:16,060
was telling you what those connections are.

67
00:03:16,060 --> 00:03:18,680
Oh, this is a receipt from that store

68
00:03:18,680 --> 00:03:21,480
that connects the, you know, whoever to the other person.

69
00:03:23,000 --> 00:03:25,440
So, just like that, in Obsidian,

70
00:03:25,440 --> 00:03:28,240
those lines aren't explicit enough.

71
00:03:28,240 --> 00:03:33,240
So, that's where knowledge graph is a little bit different,

72
00:03:33,720 --> 00:03:37,480
right, it takes those kind of unknown relationships

73
00:03:37,480 --> 00:03:39,920
and defines them, right?

74
00:03:39,920 --> 00:03:44,920
So, like, we here today, we make up a knowledge graph,

75
00:03:45,040 --> 00:03:47,480
right, we make up the structure of information, right?

76
00:03:47,480 --> 00:03:49,800
So, I'm here, I'm talking to you,

77
00:03:49,800 --> 00:03:52,840
you're listening to me, we are all as a group

78
00:03:52,840 --> 00:03:57,840
at a session that is itself a part of an abstract thing,

79
00:03:57,940 --> 00:04:00,920
right, Pi Texas, which is located here

80
00:04:00,920 --> 00:04:03,240
at this public library, right?

81
00:04:03,240 --> 00:04:06,280
And you can map that all out in a knowledge graph.

82
00:04:07,160 --> 00:04:10,120
Now, why is that interesting?

83
00:04:10,120 --> 00:04:15,060
A knowledge graph gives you some extra abilities, right?

84
00:04:15,060 --> 00:04:17,000
It gives you context.

85
00:04:17,000 --> 00:04:22,000
So, okay, I'll come back to context.

86
00:04:22,800 --> 00:04:26,280
So, the links that go between us,

87
00:04:26,280 --> 00:04:28,360
they are basically like little invisible threads

88
00:04:28,360 --> 00:04:29,240
you can kind of pull on, right?

89
00:04:29,240 --> 00:04:30,900
So, this kind of goes to the second part,

90
00:04:30,900 --> 00:04:32,640
the searchability, right?

91
00:04:32,640 --> 00:04:36,840
So, Carol, only she is from Encinitas.

92
00:04:36,840 --> 00:04:41,400
Encinitas is in San Diego County, or maybe just outside.

93
00:04:41,400 --> 00:04:42,600
It's in Southern California,

94
00:04:42,600 --> 00:04:45,480
very close to San Diego where I live.

95
00:04:45,480 --> 00:04:47,400
Great, maybe there's a chance

96
00:04:47,400 --> 00:04:49,840
we have a circle of friends close together,

97
00:04:49,840 --> 00:04:53,920
but we're both here at Pi Texas, we both like Python.

98
00:04:53,920 --> 00:04:56,600
So, very likely, we've got a circle of friends

99
00:04:56,600 --> 00:04:59,160
that overlap pretty strongly, right?

100
00:04:59,160 --> 00:05:02,100
So, that's something you can discover in a knowledge graph.

101
00:05:02,100 --> 00:05:05,280
Also, because knowledge graphs are inherently

102
00:05:05,280 --> 00:05:08,000
based on relationships and entities, it's very flexible.

103
00:05:08,000 --> 00:05:13,000
So, you can iterate on knowledge graphs a lot.

104
00:05:14,000 --> 00:05:15,960
All right, so, great.

105
00:05:15,960 --> 00:05:18,080
So, you've got a structure

106
00:05:18,080 --> 00:05:20,800
for containing context and information.

107
00:05:20,800 --> 00:05:22,560
How does that help us as developers?

108
00:05:22,560 --> 00:05:24,660
What can store a knowledge graph?

109
00:05:25,560 --> 00:05:27,040
Graph databases are really good

110
00:05:27,040 --> 00:05:28,120
for storing knowledge graphs,

111
00:05:28,120 --> 00:05:31,240
because the relationships that I've been talking about,

112
00:05:31,240 --> 00:05:33,080
that is part of the data store.

113
00:05:33,080 --> 00:05:35,400
So, unlike some older databases

114
00:05:35,400 --> 00:05:39,760
where you have to temporarily create like a join,

115
00:05:39,760 --> 00:05:41,840
the relationship is explicitly stored

116
00:05:41,840 --> 00:05:45,760
as a first class data component inside a graph database.

117
00:05:45,760 --> 00:05:48,840
And these are ranking, or this is a short list

118
00:05:48,840 --> 00:05:51,800
of available graph databases out in the market.

119
00:05:51,800 --> 00:05:56,800
Each has their own unique abilities, features, pros and cons.

120
00:05:58,640 --> 00:06:03,600
Neo4j, in particular, is a type of graph database

121
00:06:03,600 --> 00:06:06,720
known as a property graph database.

122
00:06:06,720 --> 00:06:10,760
What that means is the nodes, or the entities,

123
00:06:10,760 --> 00:06:13,520
they can contain properties, just like a row of data,

124
00:06:14,500 --> 00:06:18,120
but also the relationships can contain properties.

125
00:06:18,120 --> 00:06:21,880
So, not just names, but you could put in time info,

126
00:06:21,880 --> 00:06:24,560
you could put in weights and values, right?

127
00:06:24,560 --> 00:06:29,180
So, all of us, we all know Python, right?

128
00:06:29,180 --> 00:06:31,120
That's sort of a shared thing.

129
00:06:31,120 --> 00:06:34,280
But to what degree do we know Python, right?

130
00:06:34,280 --> 00:06:37,600
Like, Ali, I would say, is probably like,

131
00:06:37,600 --> 00:06:39,960
if we had to turn it into a float value,

132
00:06:39,960 --> 00:06:42,680
probably like a .99, maybe a 1.0,

133
00:06:42,680 --> 00:06:44,440
like all the way up at the top.

134
00:06:44,440 --> 00:06:48,860
And me, I'm probably more like a .01, maybe?

135
00:06:48,860 --> 00:06:53,020
So, you can add these weights to a knowledge graph,

136
00:06:53,020 --> 00:06:54,560
to that data, right?

137
00:06:54,560 --> 00:06:57,180
And if you come from the machine learning background,

138
00:06:57,180 --> 00:06:59,760
you know that's very useful for lifting

139
00:06:59,760 --> 00:07:01,800
and creating ML models with.

140
00:07:01,800 --> 00:07:03,820
You can do that with data from a graph database,

141
00:07:03,820 --> 00:07:07,280
which is already in the form of what more or less

142
00:07:07,280 --> 00:07:09,040
looks like kind of a neural network.

143
00:07:10,400 --> 00:07:14,640
Okay, so, other advantages of graph databases in general.

144
00:07:14,640 --> 00:07:16,160
No foreign keys.

145
00:07:16,160 --> 00:07:19,480
Like, the relationship itself, because it is stored,

146
00:07:19,480 --> 00:07:22,600
it knows which two nodes it connects to.

147
00:07:22,600 --> 00:07:26,160
And often, the nodes are written close together.

148
00:07:26,160 --> 00:07:30,160
So, when the system is traversing through the relationships,

149
00:07:30,160 --> 00:07:31,560
it's going very fast, right?

150
00:07:31,560 --> 00:07:35,560
It's not a heavy lift to ask really deep,

151
00:07:35,560 --> 00:07:36,720
many-to-many questions,

152
00:07:36,720 --> 00:07:38,320
which is kind of the third benefit, right?

153
00:07:38,320 --> 00:07:41,620
Which is, because the information is interconnected,

154
00:07:41,620 --> 00:07:43,960
presumably, you can have a sparse graph

155
00:07:43,960 --> 00:07:45,240
where you're just putting in entities

156
00:07:45,240 --> 00:07:46,820
and they're not connected,

157
00:07:46,820 --> 00:07:50,640
in which case a graph database will not do you any favors,

158
00:07:50,640 --> 00:07:52,040
use something else.

159
00:07:52,040 --> 00:07:55,120
But if you are using the relationships, great.

160
00:07:55,120 --> 00:07:57,800
And then, of course, it's very flexible,

161
00:07:57,800 --> 00:07:59,240
just like a knowledge graph.

162
00:07:59,240 --> 00:08:01,240
You can just add entities.

163
00:08:01,240 --> 00:08:03,240
You can add relationships.

164
00:08:03,240 --> 00:08:06,800
You can modify those relationships.

165
00:08:07,120 --> 00:08:11,320
So long as you are not destroying relationships

166
00:08:11,320 --> 00:08:13,260
from old data, you can iterate.

167
00:08:13,260 --> 00:08:15,440
So, you could create a whole data model,

168
00:08:15,440 --> 00:08:17,820
whole populated graph database,

169
00:08:17,820 --> 00:08:19,960
have a whole system of querying it,

170
00:08:19,960 --> 00:08:22,400
and then you're like, oh, wait, I have a better way.

171
00:08:22,400 --> 00:08:25,440
I should create, instead of having six hops

172
00:08:25,440 --> 00:08:28,720
from a vendor all the way to a customer,

173
00:08:28,720 --> 00:08:30,400
I just wanna connect them directly.

174
00:08:30,400 --> 00:08:31,760
You can add that.

175
00:08:31,760 --> 00:08:34,960
And then, all your new queries can take advantage

176
00:08:34,960 --> 00:08:36,680
of those new relationships.

177
00:08:36,680 --> 00:08:38,980
But your old queries will still work

178
00:08:38,980 --> 00:08:41,880
so long as you haven't destroyed those old relationships.

179
00:08:41,880 --> 00:08:46,880
So, you could have basically many operating schemas

180
00:08:48,600 --> 00:08:51,760
on top of one graph system, one knowledge graph.

181
00:08:53,240 --> 00:08:55,160
Okay, I'm gonna skip past this.

182
00:08:56,080 --> 00:08:58,080
Because it's in all good fashion, LLM's,

183
00:08:59,720 --> 00:09:02,080
the testing did not work earlier, so I'm just gonna skip.

184
00:09:02,080 --> 00:09:06,040
And go right to talking about the main part of my talk,

185
00:09:06,040 --> 00:09:09,960
which is how do you get your existing data

186
00:09:09,960 --> 00:09:11,400
into a knowledge graph?

187
00:09:11,400 --> 00:09:15,560
Okay, so one option is to use large language models,

188
00:09:15,560 --> 00:09:18,120
which makes things quicker.

189
00:09:19,080 --> 00:09:21,240
And so, the stack I'm gonna talk about today

190
00:09:21,240 --> 00:09:26,240
is using Lang chain to act as sort of this AI orchestrator.

191
00:09:27,080 --> 00:09:30,160
If you haven't played with Gen.AI yet,

192
00:09:30,160 --> 00:09:33,980
there are a couple tools like Lang chain, Llama index,

193
00:09:33,980 --> 00:09:36,780
that try to make it easier to work

194
00:09:36,780 --> 00:09:38,820
with different components, right?

195
00:09:38,820 --> 00:09:41,740
So, I'll demonstrate how that looks.

196
00:09:41,740 --> 00:09:46,460
And I'm gonna use OpenAI, because everyone uses OpenAI.

197
00:09:46,460 --> 00:09:49,340
GPT-4 is still one of the better models.

198
00:09:49,340 --> 00:09:53,740
And then, I'll show how to push that into a Neo4j database.

199
00:09:53,740 --> 00:09:57,460
Okay, so I'll try to go through all three of these workflows

200
00:09:57,460 --> 00:09:58,820
so you get a sense of this.

201
00:09:58,820 --> 00:10:02,140
So, we've got our data, which I'll talk about in a minute.

202
00:10:02,140 --> 00:10:05,620
And the manual process would be to just take that data,

203
00:10:05,620 --> 00:10:09,020
chunk it up, and have it fit into this data model

204
00:10:09,020 --> 00:10:12,500
that I've got in my head, and put it into the database.

205
00:10:12,500 --> 00:10:15,860
The two LLM options with Lang chain

206
00:10:15,860 --> 00:10:18,780
is kind of this three step process.

207
00:10:18,780 --> 00:10:21,120
You're gonna take a file, and you're gonna put it

208
00:10:21,120 --> 00:10:23,300
into what is called a document loader.

209
00:10:23,300 --> 00:10:25,420
It is just a general object for Lang chain

210
00:10:25,420 --> 00:10:30,220
for consuming text data, basically.

211
00:10:30,220 --> 00:10:33,060
So, it could be a YouTube transcript,

212
00:10:33,060 --> 00:10:36,260
could be a PDF, CSV, whatever.

213
00:10:36,260 --> 00:10:38,300
And when you put it into a document loader,

214
00:10:38,300 --> 00:10:40,700
it then becomes kind of this generic object

215
00:10:40,700 --> 00:10:43,100
that other parts of the chain can make use of.

216
00:10:44,020 --> 00:10:46,220
Okay, and then I've got two options here.

217
00:10:46,220 --> 00:10:48,980
I'm gonna use a vector only approach,

218
00:10:48,980 --> 00:10:53,700
and then also a new module that was added by Lang chain

219
00:10:53,700 --> 00:10:56,100
called the graph transformer.

220
00:10:56,100 --> 00:10:59,380
So, the graph transformer is a module

221
00:10:59,380 --> 00:11:02,180
that will take in this text document

222
00:11:02,180 --> 00:11:04,700
from the document loader, and will attempt to break it up

223
00:11:04,700 --> 00:11:07,820
into entities and relationships, okay.

224
00:11:09,500 --> 00:11:12,100
All right, the data I'm going to work with,

225
00:11:12,100 --> 00:11:14,860
or I'm just gonna showcase is a CSV

226
00:11:14,860 --> 00:11:17,500
of the agenda data that we have.

227
00:11:17,500 --> 00:11:20,340
So, I used the diff bot to take a first crack

228
00:11:20,340 --> 00:11:23,060
at kind of converting this into a CSV.

229
00:11:23,060 --> 00:11:24,140
It got kind of close.

230
00:11:24,140 --> 00:11:25,940
I had to manually kind of massage it.

231
00:11:27,220 --> 00:11:28,660
What I probably should have done

232
00:11:28,660 --> 00:11:33,660
was just ask the organizers for their copy of the CSV data.

233
00:11:33,660 --> 00:11:35,500
That's gonna be easier, but I thought

234
00:11:35,500 --> 00:11:37,340
I'd give diff bot a try.

235
00:11:37,340 --> 00:11:40,460
And then the other piece of data is just a link to video,

236
00:11:41,660 --> 00:11:43,820
or YouTube video, which translates

237
00:11:43,820 --> 00:11:45,740
to a transcript of the video.

238
00:11:45,740 --> 00:11:49,020
Okay, so this is the part where everything breaks.

239
00:11:50,780 --> 00:11:53,700
Okay, if you can still hear me, excellent.

240
00:11:53,700 --> 00:11:57,060
Okay, so what I've got up and running here

241
00:11:57,060 --> 00:12:00,580
is I've got a local instance of Neo4j,

242
00:12:00,580 --> 00:12:03,180
and this is what the desktop looks like.

243
00:12:03,180 --> 00:12:06,020
You can basically spin up a bunch of databases,

244
00:12:06,020 --> 00:12:10,820
and here I spun up one for PyTexas, so it's an instance,

245
00:12:10,820 --> 00:12:13,300
and the instance itself has several databases

246
00:12:13,300 --> 00:12:17,580
so I can toy with manual and LLM approaches.

247
00:12:17,580 --> 00:12:21,220
Okay, so I'm going to use the main database,

248
00:12:22,780 --> 00:12:26,860
pardon me, and just show you that it is empty.

249
00:12:26,900 --> 00:12:27,740
I hope it's empty.

250
00:12:28,780 --> 00:12:31,900
Okay, so no records, this is the empty database.

251
00:12:31,900 --> 00:12:36,900
And what I've done is I built this really simple importer

252
00:12:37,020 --> 00:12:41,900
that is just a Streamlit app that lets me

253
00:12:41,900 --> 00:12:45,060
choose my target Neo4j database,

254
00:12:45,060 --> 00:12:48,940
and then lets me select one of various

255
00:12:48,940 --> 00:12:51,740
experimental uploaders, right?

256
00:12:51,740 --> 00:12:52,900
All right, so the first thing I'm gonna try

257
00:12:52,900 --> 00:12:55,780
is this graph-simple approach.

258
00:12:55,780 --> 00:13:00,780
And I'm gonna take the agenda CSV and put it in there.

259
00:13:01,780 --> 00:13:05,140
And that data looks like, where am I looking?

260
00:13:12,540 --> 00:13:14,100
All right, so it's just a CSV,

261
00:13:14,100 --> 00:13:15,980
I guess I don't really have to find it,

262
00:13:15,980 --> 00:13:17,340
but I really wanna find it.

263
00:13:17,340 --> 00:13:18,180
Here it is, okay.

264
00:13:19,540 --> 00:13:23,380
Okay, so CSV, probably should open that in a Excel sheet.

265
00:13:23,380 --> 00:13:26,300
So it just has title, description, speaker, bio.

266
00:13:26,300 --> 00:13:28,020
And I'm just gonna import that in.

267
00:13:28,020 --> 00:13:30,420
How the code looks is,

268
00:13:33,700 --> 00:13:36,340
so here I'm not using Lang chain at all.

269
00:13:36,340 --> 00:13:38,180
So what I'm doing is taking the file

270
00:13:38,180 --> 00:13:40,180
that Streamlit has handed me,

271
00:13:40,180 --> 00:13:45,180
and just going to throw it into a pandas read CSV function,

272
00:13:46,020 --> 00:13:48,300
and then just go through every row,

273
00:13:48,300 --> 00:13:52,500
and basically pull out the row headers and values.

274
00:13:52,500 --> 00:13:55,640
So I'm gonna turn that into properties.

275
00:13:55,640 --> 00:13:56,480
Well, actually not properties,

276
00:13:56,480 --> 00:13:57,980
I'm gonna turn those into nodes.

277
00:13:57,980 --> 00:14:01,540
And then just push that into a Neo4j instance.

278
00:14:04,000 --> 00:14:05,120
So yeah, just reading the rows,

279
00:14:05,120 --> 00:14:09,220
and then basically writing into Cypher.

280
00:14:10,300 --> 00:14:13,980
Cypher is the query language that Neo4j wrote

281
00:14:13,980 --> 00:14:17,140
to interface with graph databases.

282
00:14:17,140 --> 00:14:19,720
Interestingly, oh, sorry, interestingly,

283
00:14:20,080 --> 00:14:24,720
the ISO standard for interfacing with graph databases,

284
00:14:24,720 --> 00:14:27,060
so basically the ISO version of SQL,

285
00:14:28,440 --> 00:14:31,360
came out, let's see, yesterday, two days ago,

286
00:14:31,360 --> 00:14:32,180
so just recently.

287
00:14:32,180 --> 00:14:35,920
So now there's a standard for even modifying SQL

288
00:14:35,920 --> 00:14:40,520
or Postgres databases to be able to query graph systems.

289
00:14:40,520 --> 00:14:43,040
So there's a whole standard in spec.

290
00:14:43,040 --> 00:14:47,000
Now, their reference material was also Cypher,

291
00:14:47,000 --> 00:14:49,880
which is what I'm cobbling together here.

292
00:14:49,880 --> 00:14:52,120
So if you start with Cypher,

293
00:14:52,120 --> 00:14:53,960
which there's gonna be more material on Cypher

294
00:14:53,960 --> 00:14:57,940
than the new GQL, graph query language,

295
00:14:57,940 --> 00:15:02,940
which as a sidebar, is not the same as GraphQL,

296
00:15:03,300 --> 00:15:06,360
which is the REST alternative, right?

297
00:15:06,360 --> 00:15:09,240
So the acronyms are both the same for both.

298
00:15:09,240 --> 00:15:10,400
And to make it more confusing,

299
00:15:10,400 --> 00:15:12,240
if you have worked with GraphQL,

300
00:15:12,240 --> 00:15:15,960
is GraphQL is a good way to actually interface with data

301
00:15:15,960 --> 00:15:18,760
in a graph database, if you're just pulling data.

302
00:15:20,640 --> 00:15:23,640
But yes, so anyways, two different languages.

303
00:15:23,640 --> 00:15:26,120
So I digress, if you start with Cypher,

304
00:15:26,120 --> 00:15:30,480
you will find the on-ramp to GQL not too difficult

305
00:15:30,480 --> 00:15:33,060
because they borrowed a lot from Cypher.

306
00:15:33,060 --> 00:15:35,280
So the two actually look quite similar.

307
00:15:35,280 --> 00:15:37,800
And because Neo4j was also on the,

308
00:15:37,800 --> 00:15:40,440
or had a representative on the ISO board,

309
00:15:40,440 --> 00:15:41,740
anytime they decided like, hey,

310
00:15:41,740 --> 00:15:44,600
we're gonna add this feature to GQL,

311
00:15:44,600 --> 00:15:46,640
Neo4j went like, okay, we're gonna add that as well too,

312
00:15:46,640 --> 00:15:49,840
so that there's an interoperability that will happen.

313
00:15:49,840 --> 00:15:51,960
Okay, all right.

314
00:15:51,960 --> 00:15:53,000
Slightly forgot where we went.

315
00:15:53,000 --> 00:15:54,300
Okay, so I'm just gonna run this

316
00:15:54,300 --> 00:15:55,960
to show you what this looks like.

317
00:16:00,600 --> 00:16:02,280
Okay, so uploaded.

318
00:16:08,080 --> 00:16:09,840
At least I thought I uploaded, oh, okay.

319
00:16:09,840 --> 00:16:12,580
So what I did is I uploaded it to the wrong database.

320
00:16:13,420 --> 00:16:14,540
Let me try this again.

321
00:16:20,500 --> 00:16:23,860
Oh, let's see if that worked or not.

322
00:16:25,460 --> 00:16:28,580
Clearly I did not pay, oh, all right, nevermind.

323
00:16:28,580 --> 00:16:31,380
Okay, so this is what that CSV looks like

324
00:16:32,660 --> 00:16:35,500
using this very manual process.

325
00:16:35,500 --> 00:16:38,420
All right, so I've got the document,

326
00:16:38,420 --> 00:16:40,620
the agenda CSV, and all the pieces.

327
00:16:40,620 --> 00:16:44,540
So basically what this did was it broke up each row

328
00:16:44,540 --> 00:16:49,540
and then decided from there like, okay, what...

329
00:16:49,540 --> 00:16:52,300
So basically made a node for each record.

330
00:16:52,300 --> 00:16:53,580
This in terms of knowledge graph

331
00:16:53,580 --> 00:16:55,520
is not really a great knowledge graph,

332
00:16:55,520 --> 00:16:57,680
but it shows you how you can quickly create one

333
00:16:57,680 --> 00:16:59,020
just from even a CSV file.

334
00:16:59,020 --> 00:17:01,660
You can do it from JSON, text, et cetera.

335
00:17:01,660 --> 00:17:04,120
Okay, now going back to here.

336
00:17:05,300 --> 00:17:10,300
Now I'm gonna show you the graph trends

337
00:17:10,620 --> 00:17:13,700
transformer, oh, actually, let me show you the...

338
00:17:13,700 --> 00:17:15,260
Actually, yeah, I'll do graph transformer.

339
00:17:15,260 --> 00:17:17,260
We might skip the vector today.

340
00:17:17,260 --> 00:17:18,780
Okay, so the graph transformer.

341
00:17:18,780 --> 00:17:23,100
So this is Lang chain's new fantastic module

342
00:17:23,100 --> 00:17:27,220
for automatically creating nodes and edges for you.

343
00:17:27,220 --> 00:17:31,980
Okay, so very similar function starting off

344
00:17:31,980 --> 00:17:35,380
except this bit here.

345
00:17:36,460 --> 00:17:40,260
So part of Streamlit is for the CSV loader to work,

346
00:17:40,260 --> 00:17:41,260
it needs a path.

347
00:17:41,260 --> 00:17:43,360
So I can't just give the file.

348
00:17:43,360 --> 00:17:46,580
I had to basically temporarily create a location

349
00:17:46,580 --> 00:17:48,620
for the file just to get the path

350
00:17:48,620 --> 00:17:51,380
to then feed to the CSV document loader.

351
00:17:52,980 --> 00:17:54,260
So as you're working with Lang chain

352
00:17:54,260 --> 00:17:55,780
and these sort of modules,

353
00:17:55,780 --> 00:17:59,740
be aware that they expect like very certain things

354
00:17:59,740 --> 00:18:02,160
and it's not always well documented.

355
00:18:02,160 --> 00:18:06,380
So be open to experimenting a lot with this stuff.

356
00:18:06,380 --> 00:18:08,480
Okay, so here's the CSV loader,

357
00:18:08,480 --> 00:18:10,180
which is like Lang chain component.

358
00:18:11,060 --> 00:18:12,260
It takes the CSV and it basically chunks up

359
00:18:12,260 --> 00:18:15,720
each of the rows and headers and properties.

360
00:18:15,720 --> 00:18:20,720
Now I take that loaded CSV and using OpenAI as the LLM,

361
00:18:24,340 --> 00:18:27,720
it's going to do some magic here

362
00:18:27,720 --> 00:18:30,900
and cut that up into what it thinks

363
00:18:30,900 --> 00:18:32,820
that CSV should turn into.

364
00:18:32,820 --> 00:18:34,980
And then I'm just gonna add whatever it gives me

365
00:18:34,980 --> 00:18:37,260
into a Neo4j instance.

366
00:18:37,260 --> 00:18:40,860
Okay, so that's this guy.

367
00:18:43,220 --> 00:18:46,980
What I'm gonna do is I'm gonna reset this database

368
00:18:46,980 --> 00:18:48,500
so that it's blank.

369
00:18:48,500 --> 00:18:52,820
So this is what it looks like manually.

370
00:18:52,820 --> 00:18:56,860
I'm gonna wipe this out and then reload this.

371
00:18:58,380 --> 00:19:00,220
And this one I'm just going to upload

372
00:19:00,220 --> 00:19:02,440
like I think three of the sessions

373
00:19:02,440 --> 00:19:06,060
because every time I've tried to load the entire agenda,

374
00:19:06,140 --> 00:19:10,340
the LLM decides not to quit somewhere along the way.

375
00:19:13,100 --> 00:19:18,100
Okay, so this is probably a little small for folks.

376
00:19:21,500 --> 00:19:25,020
Let me, so anyways, so this is an example

377
00:19:25,020 --> 00:19:26,620
of what Cypher looks like, right?

378
00:19:27,540 --> 00:19:32,020
So match is a common keyword versus select.

379
00:19:32,020 --> 00:19:33,800
And then maybe I'll showcase this later,

380
00:19:33,800 --> 00:19:37,360
but afterwards it's this sort of ASCII art syntax, right?

381
00:19:37,360 --> 00:19:39,640
So anything in a parens is a node,

382
00:19:39,640 --> 00:19:42,480
anything in a bracket is a relationship.

383
00:19:42,480 --> 00:19:44,360
In this case, I'm asking it to give me

384
00:19:44,360 --> 00:19:47,760
every single node that it's got, right?

385
00:19:47,760 --> 00:19:52,760
And actually this looked pretty good, right?

386
00:19:52,760 --> 00:19:57,760
So we've got the CSV file and it decided to break it up.

387
00:19:57,840 --> 00:19:59,440
All right, for each row.

388
00:19:59,440 --> 00:20:02,240
So actually this looks quite similar to the manual process.

389
00:20:03,240 --> 00:20:04,080
Oh yeah?

390
00:20:07,240 --> 00:20:08,240
I think you're right.

391
00:20:08,240 --> 00:20:13,160
Yes, no wonder that I was like, wow, that looked really good.

392
00:20:13,160 --> 00:20:15,160
I never got that before.

393
00:20:15,160 --> 00:20:17,200
Okay, all right, try this again.

394
00:20:17,200 --> 00:20:22,200
All right, changes to transformer and let it run.

395
00:20:24,120 --> 00:20:26,320
You'll also notice that any time you add

396
00:20:26,320 --> 00:20:28,400
a large language model to any part of your process,

397
00:20:28,400 --> 00:20:32,080
the time takes much, much longer.

398
00:20:32,080 --> 00:20:34,720
Another reason, ah, okay.

399
00:20:34,720 --> 00:20:38,000
So I had this problem earlier with the full file.

400
00:20:38,000 --> 00:20:42,040
Let me just, sometimes it will just work though.

401
00:20:51,320 --> 00:20:53,040
All right, I'm only gonna give this one other try.

402
00:20:53,040 --> 00:20:55,520
Otherwise I'll just kind of talk through it.

403
00:20:55,520 --> 00:21:00,520
Okay, I will talk through it instead.

404
00:21:03,960 --> 00:21:06,960
So what I have is, boop.

405
00:21:12,400 --> 00:21:17,040
So I'm gonna switch to this other database,

406
00:21:17,040 --> 00:21:21,160
which I thought I had preloaded this prior.

407
00:21:22,040 --> 00:21:27,040
Okay, so this bit here was what the LLM had given me

408
00:21:30,480 --> 00:21:31,960
the last time I ran this.

409
00:21:31,960 --> 00:21:35,840
So you can see it created a bunch of nodes

410
00:21:35,840 --> 00:21:36,800
and relationships.

411
00:21:36,800 --> 00:21:38,400
A good chunk of it is connected,

412
00:21:38,400 --> 00:21:41,920
but you have these sort of orphaned bits

413
00:21:41,920 --> 00:21:44,280
and they're not connected to this at all, right?

414
00:21:44,280 --> 00:21:47,280
So you would normally think if we as a human

415
00:21:47,280 --> 00:21:49,360
were creating this, we would have at least one node

416
00:21:49,400 --> 00:21:52,200
that was, this is the source document

417
00:21:52,200 --> 00:21:54,440
and tie everything in together.

418
00:21:54,440 --> 00:21:57,320
But this graph transformer doesn't seem to be built

419
00:21:57,320 --> 00:21:59,640
to do that, so it'll just create a bunch of nodes.

420
00:21:59,640 --> 00:22:03,280
And so if you were to do this with a lot of files,

421
00:22:03,280 --> 00:22:04,960
you would probably come up with a really like,

422
00:22:04,960 --> 00:22:08,120
kind of like, like DNA that's been broken up.

423
00:22:08,120 --> 00:22:10,200
Just a lot of floaties floating around.

424
00:22:10,200 --> 00:22:14,200
So I'm glad that Langchain has started

425
00:22:14,200 --> 00:22:16,480
building this graph transformer,

426
00:22:16,480 --> 00:22:18,640
but as you can see, it's still very early on.

427
00:22:18,640 --> 00:22:20,080
So it's gonna take a little work

428
00:22:20,080 --> 00:22:23,200
before this kind of competes with local stuff.

429
00:22:24,520 --> 00:22:26,880
All right, let me zoom back.

430
00:22:31,760 --> 00:22:33,480
Oh, I guess while we're here,

431
00:22:33,480 --> 00:22:35,880
I have just a wee bit of time.

432
00:22:35,880 --> 00:22:40,880
Vectors, so the whole retrieval augmented generation

433
00:22:41,720 --> 00:22:46,280
the whole retrieval augmented generation rag architecture

434
00:22:46,280 --> 00:22:48,880
has been created over the last year

435
00:22:48,880 --> 00:22:52,360
to help large language models deal with two main things.

436
00:22:52,360 --> 00:22:55,160
A, that they hallucinate a lot,

437
00:22:55,160 --> 00:22:58,800
and two, they have a limited context window.

438
00:22:58,800 --> 00:23:01,600
So if you are working on a project

439
00:23:01,600 --> 00:23:04,800
that requires some sort of permanent memory store

440
00:23:04,800 --> 00:23:08,000
for the large language model to compare against,

441
00:23:08,000 --> 00:23:11,600
vector databases have become kind of the mainstay, right,

442
00:23:11,600 --> 00:23:12,720
of what you would use.

443
00:23:14,040 --> 00:23:18,360
Now, you can use vectors with graph databases.

444
00:23:18,360 --> 00:23:20,760
So this is a great combination

445
00:23:20,760 --> 00:23:24,240
because vectors are fantastic with unstructured data, right?

446
00:23:24,240 --> 00:23:25,280
Like lots of texts, it's like,

447
00:23:25,280 --> 00:23:28,280
okay, what's the feeling about a thing?

448
00:23:28,280 --> 00:23:30,040
Vectors are great at pulling that.

449
00:23:30,040 --> 00:23:34,000
But vectors are, unlike a lot of traditional databases,

450
00:23:34,000 --> 00:23:36,400
really terrible at math, right?

451
00:23:36,400 --> 00:23:38,000
So if you want to ask a vector database,

452
00:23:38,000 --> 00:23:40,360
hey, how many records do you have?

453
00:23:40,360 --> 00:23:41,960
It will just choose a number

454
00:23:41,960 --> 00:23:44,320
from any one of the documents it has.

455
00:23:44,320 --> 00:23:45,920
So unless somebody wrote a document

456
00:23:45,920 --> 00:23:48,480
that says how many files you've got in the database,

457
00:23:48,480 --> 00:23:49,560
you won't know.

458
00:23:49,560 --> 00:23:52,840
But a graph database and basically any other database

459
00:23:52,840 --> 00:23:54,920
can give you those answers, right?

460
00:23:54,920 --> 00:23:59,160
So sidebar, if you're working on a large language project,

461
00:24:00,120 --> 00:24:02,200
it's okay to mix and match different technologies.

462
00:24:02,200 --> 00:24:04,800
You will get much better results.

463
00:24:04,800 --> 00:24:06,320
Okay, all right.

464
00:24:06,320 --> 00:24:11,000
Okay, so that's my demo, basically,

465
00:24:11,000 --> 00:24:13,720
since I got kind of moderate results

466
00:24:13,720 --> 00:24:15,280
with the large language model.

467
00:24:17,640 --> 00:24:20,800
Yeah, I guess we could just jump right to questions,

468
00:24:20,800 --> 00:24:22,600
which I'm assuming people will have.

469
00:24:25,880 --> 00:24:26,720
Oh.

470
00:24:26,720 --> 00:24:27,540
Oh.

471
00:24:27,540 --> 00:24:28,380
Oh.

472
00:24:28,380 --> 00:24:29,220
Oh.

473
00:24:29,220 --> 00:24:30,240
Off the first question,

474
00:24:30,240 --> 00:24:34,520
how does a graph database differ from a vector database?

475
00:24:34,520 --> 00:24:35,360
Great question.

476
00:24:35,800 --> 00:24:38,440
So in a nutshell,

477
00:24:38,440 --> 00:24:42,640
vector databases take some data and turn it into a vector,

478
00:24:42,640 --> 00:24:44,600
or you take a vector embedding,

479
00:24:44,600 --> 00:24:47,760
which is basically a list of numbers, right?

480
00:24:47,760 --> 00:24:49,360
And you put that and you store it

481
00:24:49,360 --> 00:24:52,800
in kind of this vector space.

482
00:24:52,800 --> 00:24:54,660
So if you imagine, it's not quite accurate,

483
00:24:54,660 --> 00:24:57,080
but if you imagine the 3D box,

484
00:24:57,080 --> 00:24:59,960
each embedding basically takes a dot,

485
00:24:59,960 --> 00:25:01,920
a point in that space.

486
00:25:01,920 --> 00:25:04,920
And when a vector database is asked to pull information,

487
00:25:04,920 --> 00:25:08,640
oftentimes you'll grab an embedding

488
00:25:08,640 --> 00:25:10,020
and try to find one that's similar to that.

489
00:25:10,020 --> 00:25:12,640
So example, you have some text,

490
00:25:12,640 --> 00:25:14,560
it's turned into embedding that represents

491
00:25:14,560 --> 00:25:18,280
the semantic meaning of that text.

492
00:25:18,280 --> 00:25:19,940
Then when you ask a question,

493
00:25:19,940 --> 00:25:22,360
that is turned into an embedding as well.

494
00:25:22,360 --> 00:25:23,880
And then those two are compared,

495
00:25:23,880 --> 00:25:25,840
and anything that's kind of close

496
00:25:25,840 --> 00:25:29,160
to the question embedding is pulled up, right?

497
00:25:29,160 --> 00:25:32,000
But each one of those dots,

498
00:25:32,000 --> 00:25:34,560
pieces of data in a vector database, they're independent.

499
00:25:34,560 --> 00:25:36,840
They're not linked, right?

500
00:25:36,840 --> 00:25:38,040
You can add in some metadata,

501
00:25:38,040 --> 00:25:41,820
but there is no relationship between different embeddings.

502
00:25:42,800 --> 00:25:45,580
But a graph database, it stores that relationship.

503
00:25:45,580 --> 00:25:48,440
So if you imagine it as a 3D space,

504
00:25:48,440 --> 00:25:51,520
it kind of looks not quite like a brain,

505
00:25:51,520 --> 00:25:54,640
but you can imagine like a branch,

506
00:25:54,640 --> 00:25:56,680
like a very dense tree branch

507
00:25:56,680 --> 00:25:59,600
is what a graph database would kind of look like.

508
00:25:59,600 --> 00:26:01,400
Hopefully that answers that question.

509
00:26:01,400 --> 00:26:02,360
I got some of that.

510
00:26:03,920 --> 00:26:06,680
Okay, so the next question,

511
00:26:06,680 --> 00:26:07,960
I don't even understand the question,

512
00:26:07,960 --> 00:26:09,460
but I think you probably will.

513
00:26:10,360 --> 00:26:12,080
And hopefully the answer will make sense.

514
00:26:12,080 --> 00:26:15,840
So how do you avoid LLM hallucinations when adding,

515
00:26:15,840 --> 00:26:19,460
how do you avoid LLM hallucinations adding or removing data

516
00:26:19,460 --> 00:26:21,620
when entering into the database?

517
00:26:21,620 --> 00:26:22,700
Ah, okay.

518
00:26:22,700 --> 00:26:26,080
So whether you're using like SQL or a graph database,

519
00:26:26,080 --> 00:26:30,080
you can use text to SQL or text to cipher modules.

520
00:26:31,440 --> 00:26:33,840
So what you're doing is you're not letting the LLM

521
00:26:33,840 --> 00:26:36,200
directly interact with your database.

522
00:26:36,200 --> 00:26:38,560
What you're doing is you're taking like a question

523
00:26:38,560 --> 00:26:42,600
and using the LLM to convert that into a query, right?

524
00:26:42,600 --> 00:26:45,160
And then you run the query against the database,

525
00:26:45,160 --> 00:26:46,360
the answer comes back,

526
00:26:46,360 --> 00:26:49,000
and then the LLM interprets that answer.

527
00:26:49,000 --> 00:26:50,980
So you can shield your database

528
00:26:50,980 --> 00:26:54,420
from being hopefully errantly like messed up.

529
00:26:55,840 --> 00:26:57,960
But yeah, that's generally the process.

530
00:26:57,960 --> 00:26:59,320
I actually did understand that answer.

531
00:26:59,320 --> 00:27:00,160
That's helpful.

532
00:27:00,200 --> 00:27:01,600
Okay.

533
00:27:01,600 --> 00:27:04,080
Next one, any best practices

534
00:27:04,080 --> 00:27:05,940
when building a knowledge graph database,

535
00:27:05,940 --> 00:27:07,900
anything in particular to be aware of

536
00:27:07,900 --> 00:27:11,280
when you're building one specifically for LLM use?

537
00:27:11,280 --> 00:27:12,560
Oh, okay.

538
00:27:12,560 --> 00:27:13,440
So just in general,

539
00:27:13,440 --> 00:27:15,520
when you're building like a graph database

540
00:27:15,520 --> 00:27:16,840
or a knowledge graph,

541
00:27:16,840 --> 00:27:19,800
is you wanna think about your data model,

542
00:27:19,800 --> 00:27:22,080
what it's gonna look like at first.

543
00:27:22,080 --> 00:27:24,460
Don't fret that it has to be perfect.

544
00:27:24,460 --> 00:27:25,720
It's going to change.

545
00:27:25,720 --> 00:27:27,280
Everyone who works with knowledge graphs,

546
00:27:27,280 --> 00:27:28,680
it's constantly iterating.

547
00:27:28,680 --> 00:27:30,520
So you start with your best thing,

548
00:27:30,520 --> 00:27:32,760
and then you kinda import and work with that.

549
00:27:32,760 --> 00:27:35,520
When it comes to large language models,

550
00:27:35,520 --> 00:27:37,920
we haven't found anything specific yet

551
00:27:37,920 --> 00:27:40,400
that really gets great.

552
00:27:40,400 --> 00:27:41,500
Oh no, I take it back.

553
00:27:42,680 --> 00:27:46,400
So you want to have the relationships use words

554
00:27:46,400 --> 00:27:49,240
that are very common and make sense.

555
00:27:49,240 --> 00:27:52,520
So don't use relationship names that are very complicated.

556
00:27:52,520 --> 00:27:56,760
And if you have very complex paths

557
00:27:56,760 --> 00:27:59,600
between two entities that you always ask questions about.

558
00:27:59,600 --> 00:28:02,480
Like, hey, my ultimate question is this person,

559
00:28:02,480 --> 00:28:04,840
does this person like red shoes?

560
00:28:04,840 --> 00:28:05,880
But the path to finding out,

561
00:28:05,880 --> 00:28:07,400
maybe they purchased this, that,

562
00:28:07,400 --> 00:28:09,000
and the other thing, they know this person.

563
00:28:09,000 --> 00:28:11,440
Just create a relationship between the two,

564
00:28:11,440 --> 00:28:13,200
and then you ask the LLM.

565
00:28:13,200 --> 00:28:15,360
Because the LLM also has difficulty

566
00:28:15,360 --> 00:28:19,400
in reasoning very complex paths.

567
00:28:19,400 --> 00:28:23,080
Even if you give an LLM the schema,

568
00:28:23,080 --> 00:28:25,680
I found that maybe only 60, 70% of the time,

569
00:28:25,680 --> 00:28:27,360
it actually looks at the schema and goes like,

570
00:28:27,360 --> 00:28:30,080
yes, I'm gonna write a query that matches that.

571
00:28:30,080 --> 00:28:32,040
The other 40, 50% of the time,

572
00:28:32,040 --> 00:28:34,240
it's like, meh, I'm just gonna write up

573
00:28:34,240 --> 00:28:38,040
my own query sentence, and then it won't work at all.

574
00:28:38,040 --> 00:28:41,120
Gotcha, so explicitly to find that linkage relationship,

575
00:28:41,120 --> 00:28:42,760
and it can parse it.

576
00:28:42,760 --> 00:28:45,720
Yes, so if you go in and you kinda simplify things for it.

577
00:28:45,720 --> 00:28:48,120
Yeah, it works, that makes sense.

578
00:28:48,120 --> 00:28:49,760
So we're running a little bit ahead,

579
00:28:49,760 --> 00:28:51,080
so I'm gonna ask one more question,

580
00:28:51,080 --> 00:28:52,480
and then we'll hand it off.

581
00:28:53,480 --> 00:28:55,600
Are relationships only extracted

582
00:28:55,600 --> 00:28:56,960
if made explicit in the document,

583
00:28:56,960 --> 00:29:00,240
or can it add implicit relationships known to the LLM

584
00:29:00,240 --> 00:29:01,080
that could be useful?

585
00:29:01,080 --> 00:29:03,200
So that kinda ties off what we were just talking about.

586
00:29:03,200 --> 00:29:06,160
So, okay, so is the question asking, can it?

587
00:29:06,160 --> 00:29:08,520
Yeah, are they only extracted if they're made explicit,

588
00:29:08,520 --> 00:29:11,280
or basically can it infer some of those?

589
00:29:11,280 --> 00:29:13,240
And that sounds kinda like where we were already.

590
00:29:13,240 --> 00:29:16,040
Yes, yeah, so sometimes it can.

591
00:29:16,040 --> 00:29:17,640
I've not found it consistent.

592
00:29:18,600 --> 00:29:22,000
It's just, yeah, it's kind of roll of the dice at the moment.

593
00:29:22,000 --> 00:29:23,200
Fair enough, okay.

594
00:29:23,200 --> 00:29:24,880
All right, well thank you so much.

595
00:29:24,880 --> 00:29:25,700
Thank you, Brad.

596
00:29:25,700 --> 00:29:26,540
Everyone, Jason.

597
00:29:26,540 --> 00:29:27,380
Jason.

