1
00:00:00,000 --> 00:00:10,240
Hello. Hello, everybody. Today we're going to be resting easy with JupyRest. I tried

2
00:00:10,240 --> 00:00:15,900
to find, so I know a lot of cool open source projects have like a mascot or a logo, so

3
00:00:15,900 --> 00:00:23,440
I used some AI to come up with what a logo would be, so that's, I'm calling him Jupy

4
00:00:23,440 --> 00:00:30,760
and he's asleep, so he's resting. All right, and who here has used a Jupyter notebook

5
00:00:30,760 --> 00:00:40,600
before? Yeah, okay, great. We love notebooks. So a bit about me. I am an engineer at Microsoft.

6
00:00:40,600 --> 00:00:48,920
I work on the Azure Cosmos DB database. It's a distributed NoSQL database and it's a lot

7
00:00:48,920 --> 00:00:56,840
of C++. So on the side, nights and weekends, I call myself a code artisan where I explore

8
00:00:56,840 --> 00:01:01,360
in more fun things like Python and that's what I'm here to talk to you about. There's

9
00:01:01,360 --> 00:01:08,920
no databases today. So before I get into what this whole thing is, I want to talk about

10
00:01:08,920 --> 00:01:16,800
this concept of serverless. So if you don't know, serverless is this new way of deploying

11
00:01:16,800 --> 00:01:24,160
your code and making it available to everyone. You have products like Azure Functions, AWS

12
00:01:24,160 --> 00:01:30,880
Lambda, et cetera, and what it is really is nowadays, if you just want to deploy your

13
00:01:30,880 --> 00:01:38,280
code as a web service, you can take your main.py, your Flask app, Fast API and literally upload

14
00:01:38,280 --> 00:01:46,760
it somewhere and someone will take that and make it a web service all over the world and

15
00:01:46,800 --> 00:01:52,640
you don't have to worry about how much memory your server needs or what the CPU is, none

16
00:01:52,640 --> 00:02:00,360
of that stuff. It's so-called serverless. And it's been a pretty popular paradigm for

17
00:02:00,360 --> 00:02:07,320
deploying web applications. These people, they handle the scaling, authentication, monitoring

18
00:02:07,320 --> 00:02:15,080
and a whole lot of other really annoying things. So the problem is that I like to write code

19
00:02:15,080 --> 00:02:21,840
in Jupyter notebooks, especially Python code. To me, it's the superior development experience.

20
00:02:21,840 --> 00:02:27,520
I mean, it's the only place where you can actually interleave code with documentation

21
00:02:27,520 --> 00:02:34,240
and have interactive widgets, tables, charts. It's just as approachable for a beginner as

22
00:02:34,240 --> 00:02:40,680
it is to an experienced developer. So it really is a wonderful way to write code, share code

23
00:02:41,080 --> 00:02:48,080
and visualize what you're doing. I think it's amazing. But there's no way to take a notebook

24
00:02:48,320 --> 00:02:52,760
and really productionize it. I mean, once you've written a notebook, it kind of stays

25
00:02:52,760 --> 00:02:59,760
in that prototype, you know, POC kind of mode. If you really wanted to turn it into a product

26
00:03:00,400 --> 00:03:04,720
or turn it into a website, you'd have to rewrite it, you'd have to strip away all the goodness

27
00:03:05,160 --> 00:03:11,000
that is the notebook. So that's where I came up with this thing called Jupy rest. It's

28
00:03:11,000 --> 00:03:18,000
a tool to turn your Jupyter notebooks into rest APIs, hence the rest. So I like to call

29
00:03:20,280 --> 00:03:25,440
these Jupyter notebooks as notebook functions. What the library will do is it will let you

30
00:03:25,440 --> 00:03:32,440
define some inputs and outputs for your Jupyter notebooks. This library I developed working

31
00:03:32,960 --> 00:03:39,600
at Microsoft starting around early 2020, and now it's used extensively by pretty much all

32
00:03:39,600 --> 00:03:46,160
of Azure for various different things. And I've built it in a way that you can deploy

33
00:03:46,160 --> 00:03:51,520
it as your fast API or Azure functions or really however you want, even just running

34
00:03:51,520 --> 00:03:58,520
it on your own laptop works as well. So there's no like lock-in or any proprietary stuff.

35
00:03:59,240 --> 00:04:04,000
About a year and a half ago, I got the approval to open source this under MIT license, so

36
00:04:04,000 --> 00:04:10,560
now anyone can use it, which is why I'm able to talk to you about it today. So what is

37
00:04:10,560 --> 00:04:16,000
a notebook function? So a notebook function is basically like any other function. It's

38
00:04:16,000 --> 00:04:23,000
got an ID, an input schema, and an output schema, just like any, you know, web endpoint.

39
00:04:23,600 --> 00:04:29,520
So I'm going to show you how you take a very basic notebook here and turn it into a notebook

40
00:04:29,520 --> 00:04:36,520
function. So I've got a Hello World notebook. It doesn't do very much. You have your name

41
00:04:41,640 --> 00:04:48,640
world here, which is basically like your input, and then you have an output here. And you

42
00:04:49,160 --> 00:04:56,160
can see here in that last code cell, we're importing the save output function from JupyRest.

43
00:04:57,720 --> 00:05:03,240
And whatever you put into that save output function becomes your notebook's output, or

44
00:05:03,240 --> 00:05:09,680
it's like return type. Imagine you're writing a normal function. So now that we have our

45
00:05:09,680 --> 00:05:16,560
input and output marked in our notebook, the next thing we need to do is to define the

46
00:05:16,600 --> 00:05:23,600
input and output schemas. So in order to do that, you need to go write this config.json

47
00:05:24,160 --> 00:05:28,720
file alongside your notebook. Basically, it just needs to have the same name. That's how

48
00:05:28,720 --> 00:05:35,560
the library knows what it is. The first part of this file is the ID, the name of your notebook

49
00:05:35,560 --> 00:05:42,560
function. The next part is the input schema. If anyone's used Swagger or OpenAPI, this

50
00:05:43,480 --> 00:05:49,720
should be familiar to you. It's the JSON schema here. So it's basically saying this function

51
00:05:49,720 --> 00:05:56,720
takes an object where the name is a string, and it's required. And same thing for the

52
00:05:57,080 --> 00:06:02,080
output. We also have a JSON schema spec here. So you include all these things, and now you've

53
00:06:02,080 --> 00:06:09,080
successfully turned your notebook into a notebook function. So in order to start the JupyRest

54
00:06:10,080 --> 00:06:17,080
server, I've added a little code snippet here. But rather than go and explain all this stuff,

55
00:06:17,880 --> 00:06:24,880
let's go do some demos. Okay. So I have this notebook here, because of course I'll do a

56
00:06:25,560 --> 00:06:32,080
demo in a notebook. All of this is on the GitHub page, by the way, the full example

57
00:06:32,120 --> 00:06:39,120
project. So I'm just literally taking and running this as is. This piece of code here

58
00:06:39,120 --> 00:06:46,120
is just some helper functions for this presentation. But essentially what we're doing is we're

59
00:06:46,240 --> 00:06:53,240
instantiating our JupyRest client. That Hello World notebook I was showing before is right

60
00:06:54,280 --> 00:07:00,780
here. And so we're just going to demo how we can invoke our notebook function.

61
00:07:00,780 --> 00:07:07,780
So this client, it lets us get a list of all of our available notebook functions. It

62
00:07:08,900 --> 00:07:14,940
also lets us get the details about any notebook function, like right here we've got the Hello

63
00:07:14,940 --> 00:07:21,940
World notebook and the input and output schema. Now let's try and execute this notebook here.

64
00:07:23,400 --> 00:07:30,400
So what I'm doing intentionally is providing a set of parameters that is invalid. Remember

65
00:07:30,400 --> 00:07:36,520
we needed a name, and here I'm passing a foo. So as you'd expect, we're getting an

66
00:07:36,520 --> 00:07:43,520
error here. And let's fix this. What's that? Okay. Now let's actually execute this notebook

67
00:07:47,840 --> 00:07:53,400
with the proper schema. And so what this is doing, the library, it's taking our notebook,

68
00:07:53,400 --> 00:07:59,380
it's adding our input parameters to the notebook, and then it's running the notebook from top

69
00:07:59,420 --> 00:08:06,420
to bottom. And when that happens, we're going to get our output here. Hopefully this runs

70
00:08:11,100 --> 00:08:18,100
a little bit faster. I think it's running. This is the fun part about demos. Let me,

71
00:08:18,100 --> 00:08:25,100
oh, I think it finished actually. Okay. Okay. Okay. Anyways, it finished. So here we can

72
00:08:36,140 --> 00:08:43,140
see we've got our JSON here of our completed execution. And I have this little helper thing

73
00:08:43,140 --> 00:08:50,140
here for us to visualize. The first thing we get when we execute any notebook is that

74
00:08:51,380 --> 00:08:58,380
JSON that I just showed you, pretty standard. The next thing we get is the full HTML output

75
00:08:58,620 --> 00:09:05,140
of the notebook. So you can see here, I've, the parameters that I passed into that execute

76
00:09:05,140 --> 00:09:10,780
notebook function, they've been added as a code cell into my notebook and then run from

77
00:09:10,780 --> 00:09:16,460
top to bottom. So now my inputs have now shown up, you know, my notebook's running with the

78
00:09:16,460 --> 00:09:23,460
inputs that I configured. The next thing we get that I'll show you here is the output.

79
00:09:24,260 --> 00:09:31,260
And so what this is, is this is actually whatever we pass into that save output command, we

80
00:09:31,680 --> 00:09:38,580
get that back as JSON. So I pass in, you know, hello, PyTexas in the save output command.

81
00:09:38,580 --> 00:09:44,900
And so now I'm able to get that as a JSON output. So I've effectively converted my

82
00:09:44,900 --> 00:09:51,900
Jupyter notebook into a REST API. So it's got the JSON in, JSON out. But in addition,

83
00:09:51,940 --> 00:09:58,940
I also get the full notebook HTML as well. It's an extra benefit of the notebook. So

84
00:09:59,620 --> 00:10:06,620
any charts, graphs, even documentation I can put in here, I get that as well. So you get

85
00:10:06,780 --> 00:10:13,780
both the input output as well as the notebook itself. So these are some of the, you know,

86
00:10:14,820 --> 00:10:19,300
artifacts I just mentioned. The other two here. So this is the HTML report, which is

87
00:10:19,300 --> 00:10:26,620
just the same thing as the HTML, but it has all the code cells removed. So this you could,

88
00:10:26,620 --> 00:10:30,020
it's kind of like a report if you don't, if someone doesn't know, doesn't need to look

89
00:10:30,020 --> 00:10:37,020
at the code. So the output here, I already showed you, but you can basically get that

90
00:10:39,180 --> 00:10:45,140
output JSON from your notebook. So now the next notebook I'm going to execute here is

91
00:10:45,140 --> 00:10:51,540
a notebook that I've purposely put in an error. So as we know, when you deploy or write any

92
00:10:51,540 --> 00:10:56,980
code, you're going to have exceptions. So I have a notebook here that is going to fail.

93
00:10:57,660 --> 00:11:02,740
We see that it's failed. Now, normally when you debug a web service and there's some error

94
00:11:02,740 --> 00:11:09,740
happens on the server, you have to go scroll through your logs, look up some telemetry,

95
00:11:10,300 --> 00:11:15,940
try to find out what happened and then try to reproduce it on your laptop and then make

96
00:11:15,940 --> 00:11:23,060
a fix. With this, it's way easier. So now I've executed this notebook and it's failed.

97
00:11:23,060 --> 00:11:28,460
First thing, I get the HTML. So I don't need to go look at any telemetry. I can just look

98
00:11:28,460 --> 00:11:35,460
at what happened in the notebook. Secondly, I get the actual IPI and B. So this is your

99
00:11:35,780 --> 00:11:42,300
notebook JSON file. If I want to reproduce this error, I can download this file, open

100
00:11:42,300 --> 00:11:47,880
it up in JupyterLab and try writing it on my computer. I don't need to do anything more

101
00:11:47,880 --> 00:11:53,080
than that. It's very easy to reproduce. So even that, even just by using the notebook

102
00:11:53,080 --> 00:11:59,360
as the function unit, we get all the benefits of the notebook. Debugging in a notebook is

103
00:11:59,360 --> 00:12:06,200
way easier than debugging using Datadog or some log system, looking for all the red text

104
00:12:06,200 --> 00:12:13,200
and try to figure out what the heck happened. So with this ease of use and ease of debugging

105
00:12:14,200 --> 00:12:19,600
and ease of authoring has made this library very popular within Microsoft. We've enabled

106
00:12:19,600 --> 00:12:25,320
lots of data scientists and people who normally don't know how to write production code. We've

107
00:12:25,320 --> 00:12:32,320
enabled them to now share their logic as notebooks to the rest of the company, which has been

108
00:12:32,640 --> 00:12:39,640
great and it's really made the notebook so much more powerful. So what happens is when

109
00:12:40,080 --> 00:12:45,640
you have, let's say, hundreds of notebooks that you've deployed, what you end up wanting

110
00:12:45,640 --> 00:12:50,160
is to put some structure to your API. So what I'm going to go over here is a little bit

111
00:12:50,160 --> 00:12:57,160
advanced, but when you see how cool it is, I think you'll appreciate just how awesome

112
00:12:58,200 --> 00:13:03,560
this feature is. So we have this ability to share input and output models across your

113
00:13:03,560 --> 00:13:08,880
notebooks. So what I've done for this example, I've taken a notebook straight out of a GitHub

114
00:13:08,880 --> 00:13:15,880
repository here. It does some portfolio analysis, and I want this notebook not to take in just

115
00:13:16,360 --> 00:13:21,320
JSON, but I actually want it to take in a Python object as input. So I've defined a

116
00:13:21,320 --> 00:13:28,440
Python object here called portfolio. It has a start date, end date, and some holdings.

117
00:13:28,440 --> 00:13:35,440
And in my portfolio analysis.config.json, what I'm going to do is I'm actually going to reference

118
00:13:36,240 --> 00:13:42,360
this portfolio object here. So basically what this is is I've given it a name here in the

119
00:13:42,360 --> 00:13:49,360
application builder, and in my portfolio analysis.config.json, I'm referencing the name of that model.

120
00:13:52,240 --> 00:13:59,240
So what does that mean? So when I get this notebook schema, you can see here the input

121
00:13:59,240 --> 00:14:06,240
schema is actually getting resolved to a still standard JSON schema. So it's your definitions,

122
00:14:07,640 --> 00:14:13,640
and the portfolio object here is this is all very standard JSON schema. So from the client,

123
00:14:13,640 --> 00:14:18,640
it has no idea that this input is a Python object. So now let's go and execute this. So I'm

124
00:14:18,640 --> 00:14:25,640
executing this notebook. I'm passing in straight JSON, and I'm going to pass in a JSON, and

125
00:14:26,440 --> 00:14:33,440
I'm passing in straight JSON, and this JSON is adhering to the schema of my Python object.

126
00:14:34,840 --> 00:14:41,840
And what will happen is, you know, we're going to be parameterizing this notebook with the

127
00:14:42,600 --> 00:14:49,600
Python object that I just provided here. So let's take a look. When I open this up, you

128
00:14:50,600 --> 00:14:57,600
can see this is the, these are the input parameters I just passed into the notebook, but they've

129
00:14:57,680 --> 00:15:04,440
actually been converted into Python code. So this notebook does not need to know it's

130
00:15:04,440 --> 00:15:11,440
actually being used as a web API. All it knows is Python. So it's Python in, Python out.

131
00:15:11,700 --> 00:15:17,320
But from the client side, the client is sending JSON. This is not a Python, this is just JSON.

132
00:15:17,320 --> 00:15:21,520
So what Jupyter.js is doing is it's smart enough to say, okay, you're passing in this

133
00:15:21,520 --> 00:15:28,480
portfolio object. I'm going to convert it into this Python object that you want me to,

134
00:15:28,480 --> 00:15:32,920
and then in your notebook, I'll make it so that when you run it, you're just, you're

135
00:15:32,920 --> 00:15:37,800
getting your Python object as is. There's no JSON serialization or any kind of, any

136
00:15:37,800 --> 00:15:44,800
of that stuff. Which is great. So this notebook, it's a little bit more involved. It has a

137
00:15:45,400 --> 00:15:51,720
bunch of stock stuff here. Honestly, I don't actually know what any of this means, but

138
00:15:51,720 --> 00:15:58,720
there's some nice graphs. And you see here, I've, I'm also saving some output. So just

139
00:15:59,360 --> 00:16:06,360
like the other notebooks, I'm able to get a JSON output as well. So if all you want

140
00:16:06,880 --> 00:16:13,760
is to just look at some condensed information from a, from your notebook function, you get

141
00:16:14,360 --> 00:16:17,680
that. But if you want to see the details of, you know, how the sausage was made, you can

142
00:16:17,680 --> 00:16:24,360
actually go and see exactly how the notebook arrived to that final result. So it gives

143
00:16:24,360 --> 00:16:31,360
you a superior introspection to your web APIs. It also lets you write your web APIs in a

144
00:16:32,160 --> 00:16:38,200
much more Pythonic way. I'm just dealing with Python objects here. And it lets you hold

145
00:16:38,200 --> 00:16:43,280
on to all the amazingness of the Jupyter notebook while still being able to deploy

146
00:16:43,280 --> 00:16:50,280
your code as a web API. So that's pretty much all I had for the demo here. I will say, just

147
00:16:56,040 --> 00:17:03,040
for context, this, while this is a very popular library, it definitely has, it is good for

148
00:17:03,960 --> 00:17:08,560
certain things and not good for certain things. So you definitely wouldn't want to use this

149
00:17:08,560 --> 00:17:15,320
for any performance critical service. Like if you really need like 10 millisecond response

150
00:17:15,320 --> 00:17:21,600
times, this is not the thing to use. But if you're, if you're trying to build something

151
00:17:21,600 --> 00:17:28,240
and share some analysis or share some notebook with other people where you're, you're okay

152
00:17:28,840 --> 00:17:34,600
waiting maybe like 10 to 20 seconds for each of these notebooks to execute, it could be

153
00:17:34,600 --> 00:17:41,600
a great way to take any of your work and share it with other people. So it's a great tool

154
00:17:43,240 --> 00:17:50,240
for prototyping. It's a great tool for automated reporting. And it's, I think it just makes,

155
00:17:50,280 --> 00:17:56,720
it makes writing in Jupyter notebooks even that more powerful. So that's all I had for

156
00:17:56,720 --> 00:18:03,720
you today. Feel free to check us out on GitHub. Give us a star and, you know, find me on LinkedIn

157
00:18:03,720 --> 00:18:08,720
if you want to hit me up after that. That's, that's I guess the social media I use. So

158
00:18:08,720 --> 00:18:11,720
thanks, everyone.

159
00:18:11,720 --> 00:18:18,720
Awesome. Thank you. We have a bunch of questions. People are excited. This is good. So let's

160
00:18:18,720 --> 00:18:25,720
run through some of these. The first question opens. Very cool. Thanks. Which is not the

161
00:18:30,920 --> 00:18:35,560
question but had to pass that along. Okay. Now the actual question. How's the tooling

162
00:18:35,560 --> 00:18:41,080
around diffs for code reviews of notebooks? Also, how do you test notebooks?

163
00:18:41,080 --> 00:18:47,660
Great question. So let me show you. In our GitHub, so diffing notebooks is always, that's

164
00:18:47,780 --> 00:18:52,980
always a pain, right? Because they're just JSON. So in the example project that I have

165
00:18:52,980 --> 00:18:58,860
here, I've actually included this pre-commit hook. And what this pre-commit hook does is

166
00:18:58,860 --> 00:19:05,860
that any time you commit a notebook, it commits the, it generates a Python file, you know,

167
00:19:07,220 --> 00:19:11,160
of your notebook. So all the Python code is also alongside your notebook. So any time

168
00:19:11,160 --> 00:19:15,940
you're doing a code review, you'll of course get the diffs for your IPY and V. But really

169
00:19:16,100 --> 00:19:23,100
the more readable diffs will be for this Python file here. So that's how I've gotten around

170
00:19:23,540 --> 00:19:29,140
that problem. I know there are other tools for that. But just for myself and, you know,

171
00:19:29,140 --> 00:19:36,140
at Microsoft, this is how we solve that problem. The other thing is testing notebooks. So that's

172
00:19:36,700 --> 00:19:43,500
a good question. I know, you know, you could do two ways. One way is you could still use

173
00:19:43,580 --> 00:19:50,140
PyTest, you know, any individual modules or libraries you use in your notebook. Of course

174
00:19:50,140 --> 00:19:56,660
you can test those with unit tests in PyTest. The other way is actually in the JupyRest

175
00:19:56,660 --> 00:20:03,660
source, I do have a way to do integration tests. So in our, this CONF test here, I have

176
00:20:06,380 --> 00:20:13,380
a thing that just starts up the local HTTP server and then I can use that same client

177
00:20:13,500 --> 00:20:16,500
to execute the notebooks and test them.

178
00:20:16,500 --> 00:20:23,500
All right. Sorry. So the next question. How, see, Josh keeps moving them on me right as

179
00:20:27,220 --> 00:20:31,900
I go to answer them. How does JupyRest deal with interactive components like a plotly

180
00:20:31,900 --> 00:20:34,060
graph or Jupyter widgets?

181
00:20:34,060 --> 00:20:40,860
Yeah, that's a good question. So for plotly graphs, you'll have to make sure doing, you

182
00:20:40,860 --> 00:20:47,860
know, as long as all the data is saved in the notebook, then the interactivity can work.

183
00:20:51,420 --> 00:20:56,240
The problem is that, you know, this HTML file that you get, of course there's no running

184
00:20:56,240 --> 00:21:01,000
Jupyter kernel in the back. So if you're going to click something and it's expecting to call

185
00:21:01,000 --> 00:21:07,920
some Python function in the kernel, that won't work. So if it's something that's static or

186
00:21:08,000 --> 00:21:13,000
something, like I know plotly charts, you can, as long as all the data is in the notebook,

187
00:21:13,000 --> 00:21:20,000
then you can filter it and zoom in and out. So you are limited to that. But yeah, that

188
00:21:20,640 --> 00:21:22,400
would be how that would work.

189
00:21:22,400 --> 00:21:28,440
Okay. I like, oh, there it went. I like this one. What original problem were you working

190
00:21:28,440 --> 00:21:30,720
on when this idea came to you?

191
00:21:30,720 --> 00:21:37,720
Yeah, good question. So the problem I was working on, so I'm a site reliability engineer

192
00:21:38,200 --> 00:21:44,720
and as a SRE, we have a lot of these runbooks that we have to follow whenever a certain

193
00:21:44,720 --> 00:21:50,240
incident comes about. And you go anywhere and most companies will have a set of these

194
00:21:50,240 --> 00:21:56,400
runbooks, usually are markdown documents or whatever, word documents, something like that.

195
00:21:56,400 --> 00:22:02,420
And you just have to follow these step by step to resolve an incident. The issue I found

196
00:22:02,420 --> 00:22:06,720
was that a lot of times I'm going there and copying, pasting code snippets, changing a

197
00:22:06,880 --> 00:22:11,480
few things about the timestamps and then running them. So I thought, okay, why don't we just

198
00:22:11,480 --> 00:22:16,760
make this into a Jupyter Notebook? And then I thought even more like, okay, if I have

199
00:22:16,760 --> 00:22:22,240
to, if I'm already going to be writing this as an executable Jupyter Notebook, let me

200
00:22:22,240 --> 00:22:28,400
slap some parameters on there. And then basically what I did is I built this and then I hooked

201
00:22:28,400 --> 00:22:33,920
it up to our internal incident system. So any time an incident was raised, one of these

202
00:22:33,920 --> 00:22:40,160
Jupyter Notebooks would be executed with the parameters of the incident. So then if

203
00:22:40,160 --> 00:22:46,320
I was on call, by the time I get out of bed and go to my laptop, a bunch of these runbooks

204
00:22:46,320 --> 00:22:50,400
are already executed for me. So I don't need to go do any of that. So I can just open them

205
00:22:50,400 --> 00:22:57,560
up and see like, oh, this is the problem or maybe a graph of some CPU history or whatever.

206
00:22:57,560 --> 00:23:02,480
It'll just tell me what I need to do. And it makes it so much easier for onboarding

207
00:23:02,640 --> 00:23:07,320
because now I don't need to, I can now test my runbooks. I can now make sure that they

208
00:23:07,320 --> 00:23:13,880
work in like our staging environment, our dev environment. So that was the original

209
00:23:13,880 --> 00:23:18,240
problem. But then it, you know, a lot of other people started using it for various other

210
00:23:18,240 --> 00:23:21,240
things. But that was the original intent behind this.

211
00:23:21,240 --> 00:23:26,120
Okay. That is cool. I do have a few more questions. I'm going to unplug while they're setting

212
00:23:26,120 --> 00:23:30,320
up. But I do have more questions for you while they're setting up because we're getting some

213
00:23:30,320 --> 00:23:33,360
really good questions in. Thank you all. You're being creative. I don't know if it's like

214
00:23:33,360 --> 00:23:38,280
the after lunch, the sugar, but y'all are helping. This is awesome. Since you open source

215
00:23:38,280 --> 00:23:44,640
this, are there any uses that have surprised or delighted you?

216
00:23:44,640 --> 00:23:54,960
I don't, I think the, I mean, there's a lot of people who are using it to automate whatever

217
00:23:54,960 --> 00:24:00,040
like AI stuff that they want to do. So of course, you know, notebooks, you can, because

218
00:24:00,040 --> 00:24:04,920
they're in Python, you can, you know, every AI library is in Python. So it's like a really

219
00:24:04,920 --> 00:24:12,840
simple way of turning an AI notebook into like an AI web app. So that was something.

220
00:24:12,840 --> 00:24:18,720
Of course, you would need to run this on a platform that had GPUs and such. So it's much

221
00:24:18,720 --> 00:24:23,480
more resource intensive. But I thought that was an interesting, I mean, especially recently,

222
00:24:23,480 --> 00:24:26,520
that was an interesting, you know, four years ago, no one was really doing that, but now

223
00:24:26,520 --> 00:24:29,800
they are. Awesome. Last one for you.

224
00:24:29,800 --> 00:24:34,200
It looks like a lot of extra artifacts are created per request compared to what you would

225
00:24:34,200 --> 00:24:40,840
often see from like IPINB or with the IPINB file and all of that. Do you have any concerns

226
00:24:40,840 --> 00:24:47,880
about that at scale? You know, like I said, you can't, at scale,

227
00:24:47,880 --> 00:24:52,600
I haven't really seen any problems. Like all these artifacts are being stored in, you know,

228
00:24:52,600 --> 00:24:58,040
Azure Blob storage or S3. So those are pretty cheap. And, you know, those are pretty, you

229
00:24:58,040 --> 00:25:03,800
can store a lot of data in those systems without any problem. The only thing is just

230
00:25:03,800 --> 00:25:09,480
make sure, keep in mind that running a notebook, there is some latency there. So as long as

231
00:25:09,480 --> 00:25:14,720
you're okay waiting, you know, up to a minute for your notebook to execute, then, you know,

232
00:25:14,720 --> 00:25:18,520
you should be okay. Awesome. Thank you so much, Kaushik, everyone.

233
00:25:18,520 --> 00:25:19,640
Thank you.

