1
00:00:00,000 --> 00:00:01,440
All right, Lauren.

2
00:00:01,440 --> 00:00:03,760
Teachers about system design on easy mode.

3
00:00:03,760 --> 00:00:04,720
Hi, folks.

4
00:00:04,720 --> 00:00:05,480
I'm Lauren.

5
00:00:05,480 --> 00:00:07,360
I came here from Brooklyn, where we

6
00:00:07,360 --> 00:00:10,160
don't have scooters everywhere.

7
00:00:10,160 --> 00:00:13,160
It's so nice in Austin that anywhere I go,

8
00:00:13,160 --> 00:00:15,080
I can take a scooter and go around.

9
00:00:15,080 --> 00:00:18,720
And it's such a nice, easy way to move my body around.

10
00:00:18,720 --> 00:00:21,120
So thank you, Austin, for having scooters, allowing them

11
00:00:21,120 --> 00:00:21,880
on your streets.

12
00:00:21,880 --> 00:00:25,360
Thank you to Mason and the PyTaxis team for having me.

13
00:00:25,360 --> 00:00:26,840
Thank you all for your attention.

14
00:00:26,840 --> 00:00:30,280
I'm happy to be here to share about something called

15
00:00:30,280 --> 00:00:33,560
durable execution and how it substantially simplifies

16
00:00:33,560 --> 00:00:37,080
a wide range of system design problems.

17
00:00:37,080 --> 00:00:37,640
So I'm Lauren.

18
00:00:37,640 --> 00:00:39,560
I'm a consultant and open source maintainer.

19
00:00:39,560 --> 00:00:41,920
Previously, I worked on Temporal's JavaScript runtime

20
00:00:41,920 --> 00:00:43,880
and wrote a book on GraphQL with John Resig

21
00:00:43,880 --> 00:00:46,240
called The GraphQL Guide.

22
00:00:46,240 --> 00:00:49,160
Today, I'll start out by defining what durable execution is,

23
00:00:49,160 --> 00:00:50,800
talk about some new possibilities

24
00:00:50,800 --> 00:00:53,360
for how you can code that it opens up,

25
00:00:53,360 --> 00:00:55,000
talk a little bit about how it works,

26
00:00:55,000 --> 00:00:56,560
and then go through some system design patterns.

27
00:00:56,560 --> 00:00:58,320
And I won't assume knowledge of any of them,

28
00:00:58,320 --> 00:01:00,960
so I'll try to give a concise summary of what it is

29
00:01:00,960 --> 00:01:04,680
before I talk about how durable execution either obviates it,

30
00:01:04,680 --> 00:01:08,200
makes it unnecessary, or makes it easy to do.

31
00:01:08,200 --> 00:01:10,760
So what the heck is this thing called durable execution?

32
00:01:10,760 --> 00:01:12,880
So an important property of normal execution

33
00:01:12,880 --> 00:01:14,800
is that functions fail to complete executing

34
00:01:14,800 --> 00:01:16,160
in a number of different situations.

35
00:01:16,160 --> 00:01:17,880
For instance, the process crashes, maybe it

36
00:01:17,880 --> 00:01:20,800
divided by 0 or unhandled exception.

37
00:01:20,800 --> 00:01:22,920
Maybe the process is killed by the OS or the pod

38
00:01:22,920 --> 00:01:26,120
is killed by the Kubernetes node because it used

39
00:01:26,120 --> 00:01:28,880
too much CPU or RAM.

40
00:01:28,880 --> 00:01:30,080
The machine could lose power.

41
00:01:30,080 --> 00:01:31,440
I might deploy new code, and usually I

42
00:01:31,440 --> 00:01:34,760
have a graceful shutdown period for the old code

43
00:01:34,760 --> 00:01:37,080
to finish running before I switch over to the new.

44
00:01:37,080 --> 00:01:39,720
But maybe I'm doing something that takes a long time,

45
00:01:39,720 --> 00:01:41,520
and I'm still running by the time

46
00:01:41,520 --> 00:01:44,200
I get the SIG kill at the end of the shutdown window.

47
00:01:44,200 --> 00:01:46,000
So then there's lots of transient failures

48
00:01:46,000 --> 00:01:48,000
that could happen, seeing downstream dependencies,

49
00:01:48,000 --> 00:01:50,720
maybe the database I'm talking to.

50
00:01:50,720 --> 00:01:52,920
It can't reach the moment, or some downstream service,

51
00:01:52,920 --> 00:01:54,480
or a third-party API.

52
00:01:54,480 --> 00:01:58,640
And maybe I need to retry that.

53
00:01:58,640 --> 00:02:00,240
And if I take a long time retrying,

54
00:02:00,240 --> 00:02:03,640
then maybe I'll get cut off when I get a new code deploy.

55
00:02:03,640 --> 00:02:05,440
So it's more likely, the longer I take,

56
00:02:05,440 --> 00:02:07,240
that I won't be able to finish.

57
00:02:07,240 --> 00:02:09,840
And then, or if I don't handle the failure,

58
00:02:09,840 --> 00:02:13,680
then I might have a crashed process.

59
00:02:13,680 --> 00:02:15,680
So in durable execution, functions are guaranteed

60
00:02:15,680 --> 00:02:18,040
to complete executing.

61
00:02:18,040 --> 00:02:20,800
So if I have this process order function with three steps

62
00:02:20,800 --> 00:02:22,400
reserved from the inventory service

63
00:02:22,400 --> 00:02:26,120
and then charge some payment and then send a package,

64
00:02:26,120 --> 00:02:29,000
if the first two steps run successfully

65
00:02:29,000 --> 00:02:31,200
and then the process running this function dies,

66
00:02:31,200 --> 00:02:32,760
I'm guaranteed this function will

67
00:02:32,760 --> 00:02:36,600
continue running on line four in a different process.

68
00:02:36,600 --> 00:02:38,320
So I'm guaranteed that no matter what

69
00:02:38,320 --> 00:02:40,520
happens to the process running this,

70
00:02:40,520 --> 00:02:43,760
it will continue running and complete.

71
00:02:43,760 --> 00:02:46,040
And then when it continues running on the new process,

72
00:02:46,040 --> 00:02:48,960
all of the state, like what's happened previously

73
00:02:48,960 --> 00:02:52,000
and local variables, call stack threads,

74
00:02:52,000 --> 00:02:54,160
everything is intact.

75
00:02:54,160 --> 00:02:56,600
Also in durable execution, transient failures

76
00:02:56,600 --> 00:02:57,680
are automatically retried.

77
00:02:57,680 --> 00:02:59,400
So let's say in the charge step, I'm

78
00:02:59,400 --> 00:03:02,200
trying to talk to the Stripe API and it's temporarily down.

79
00:03:02,200 --> 00:03:05,720
Then it'll automatically be timed out and retried.

80
00:03:05,720 --> 00:03:08,480
By default, exponential will back off forever.

81
00:03:08,480 --> 00:03:10,920
And then whenever that completes, that charge step,

82
00:03:10,920 --> 00:03:14,040
maybe it took minutes or days.

83
00:03:14,040 --> 00:03:17,960
Whenever that completes, you'll reliably

84
00:03:17,960 --> 00:03:23,320
run the next line four and send the package.

85
00:03:23,320 --> 00:03:25,160
So durable execution is coding at a higher level

86
00:03:25,160 --> 00:03:26,120
of abstraction.

87
00:03:26,120 --> 00:03:28,560
Sort of like in high-leveling language like Python,

88
00:03:28,560 --> 00:03:30,480
you don't have to worry about memory management

89
00:03:30,480 --> 00:03:34,280
like you do in a level language like C. Durable code

90
00:03:34,280 --> 00:03:36,280
is a higher level abstraction than normal code.

91
00:03:36,280 --> 00:03:38,480
You don't have to be concerned about the infrastructure

92
00:03:38,480 --> 00:03:42,300
that the code is running on or the availability of anything

93
00:03:42,300 --> 00:03:44,000
downstream that you depend on.

94
00:03:44,000 --> 00:03:45,680
Because everything that you depend on,

95
00:03:45,680 --> 00:03:47,600
if it's not reachable now, it'll automatically

96
00:03:47,600 --> 00:03:52,360
be retried until it is reachable.

97
00:03:52,360 --> 00:03:55,000
So there are a lot of ways in which

98
00:03:55,000 --> 00:03:59,360
we code that is predicated on the fact that what we're

99
00:03:59,360 --> 00:04:01,880
working with is this primitive of a normal volatile function

100
00:04:01,880 --> 00:04:02,920
that might die any time.

101
00:04:02,920 --> 00:04:04,080
So we don't trust functions.

102
00:04:04,080 --> 00:04:09,280
We don't trust that some set of statements will complete.

103
00:04:09,280 --> 00:04:12,040
We only trust things that we've stored to disk,

104
00:04:12,040 --> 00:04:17,040
have we persisted, probably replicated on multiple disks.

105
00:04:17,040 --> 00:04:19,880
And that has a big effect on how we write code.

106
00:04:22,760 --> 00:04:26,320
And when you have the primitive of a durable function,

107
00:04:26,320 --> 00:04:29,460
it changes a lot about how you write code.

108
00:04:29,460 --> 00:04:31,720
And it opens up some new possibilities, one of which

109
00:04:31,720 --> 00:04:33,680
is you can sleep for an arbitrary period of time.

110
00:04:33,680 --> 00:04:35,200
So here, we're sleeping for one month.

111
00:04:35,200 --> 00:04:36,480
And normally, you can't do that because you

112
00:04:36,480 --> 00:04:38,080
don't have confidence that your process will

113
00:04:38,080 --> 00:04:39,120
be around in one month.

114
00:04:39,120 --> 00:04:40,720
And you don't want to take up resources for that time.

115
00:04:40,720 --> 00:04:42,840
Let's say like one thread per sleep.

116
00:04:42,840 --> 00:04:45,640
I'm going to run out of threads.

117
00:04:45,640 --> 00:04:49,960
And in durable code, you can write this in a production

118
00:04:49,960 --> 00:04:52,600
function, and it will work fine.

119
00:04:52,600 --> 00:04:55,400
You're guaranteed that this sleep will resolve in one month,

120
00:04:55,400 --> 00:04:57,160
and then you'll go to the next line of code.

121
00:04:57,160 --> 00:05:00,880
And you also don't need to take up resources during that time,

122
00:05:00,880 --> 00:05:03,640
except for like a timer entry in a database.

123
00:05:03,640 --> 00:05:07,240
The system will automatically unload this code.

124
00:05:07,240 --> 00:05:09,760
And whenever that timer goes off in the DB,

125
00:05:09,760 --> 00:05:11,760
it will rebuild the state of the function

126
00:05:11,760 --> 00:05:14,760
and continue running.

127
00:05:14,760 --> 00:05:16,180
Once I have these functions in production

128
00:05:16,180 --> 00:05:17,680
that are running for very long periods of time,

129
00:05:17,680 --> 00:05:19,120
I might want to be able to send them RPCs.

130
00:05:19,120 --> 00:05:21,580
They might want to tell them, hey, do something different

131
00:05:21,580 --> 00:05:23,320
or do something new now.

132
00:05:23,320 --> 00:05:25,400
And I might want to get their state, like, hey,

133
00:05:25,400 --> 00:05:27,320
what's your current state of your function?

134
00:05:27,320 --> 00:05:30,720
So you can send RPCs to durable code executions.

135
00:05:30,720 --> 00:05:32,120
They can also run forever.

136
00:05:32,120 --> 00:05:36,000
So I don't need to return at the end of the function.

137
00:05:36,000 --> 00:05:39,240
I could wait for an RPC to come, or I

138
00:05:39,240 --> 00:05:42,000
can wait for this sleep to happen in a loop,

139
00:05:42,000 --> 00:05:44,600
like I'm modeling a subscription.

140
00:05:44,600 --> 00:05:46,820
And I sleep for one month in a loop

141
00:05:46,820 --> 00:05:50,400
and charge the user every month for the lifetime of the user.

142
00:05:50,400 --> 00:05:52,920
So it lasts indefinitely.

143
00:05:52,920 --> 00:05:55,160
I also don't have to use a database in many cases,

144
00:05:55,160 --> 00:05:58,600
because I can send information to this function

145
00:05:58,600 --> 00:06:00,360
and get information out of it.

146
00:06:00,360 --> 00:06:02,840
And the function can, like, in Python,

147
00:06:02,840 --> 00:06:05,240
it's modeled as an annotated class.

148
00:06:05,240 --> 00:06:07,920
And each function execution is like an instance of a class

149
00:06:07,920 --> 00:06:11,760
with a run method and other methods for each RPC handler.

150
00:06:11,760 --> 00:06:14,160
So you might save some state in the run method

151
00:06:14,160 --> 00:06:16,900
in an instance variable, and then access it,

152
00:06:16,900 --> 00:06:20,560
change it in the RPC handler methods.

153
00:06:20,560 --> 00:06:25,200
So you could have some data that you return from, like,

154
00:06:25,200 --> 00:06:29,120
a get current state RPC and not have to use the database.

155
00:06:29,120 --> 00:06:31,920
You're storing it in a local variable or instance variable,

156
00:06:31,920 --> 00:06:33,760
and you don't need to store it in the database.

157
00:06:33,760 --> 00:06:38,600
And you're guaranteed that for the life of this function,

158
00:06:38,600 --> 00:06:42,400
and even afterward, that value will be correct,

159
00:06:43,400 --> 00:06:45,560
always be there and always exist and always be correct,

160
00:06:45,560 --> 00:06:48,200
based on whatever has happened to that function previously,

161
00:06:48,200 --> 00:06:49,960
like whatever the arguments were when you started

162
00:06:49,960 --> 00:06:53,240
or whatever RPCs you sent since then.

163
00:06:53,240 --> 00:06:55,640
So in summary, Drupal execution is process-independent

164
00:06:55,640 --> 00:06:57,800
with automatic retries and timeouts,

165
00:06:57,800 --> 00:07:00,360
sleep for arbitrary periods of time, send it RPCs,

166
00:07:00,360 --> 00:07:01,920
have functions that run forever,

167
00:07:01,920 --> 00:07:03,880
and you can use local variables or instance variables

168
00:07:03,880 --> 00:07:05,000
instead of a database.

169
00:07:05,000 --> 00:07:06,600
But how the heck does this work?

170
00:07:09,200 --> 00:07:12,120
So here is a system diagram of temporal,

171
00:07:12,120 --> 00:07:13,680
which is the one I'm most familiar with

172
00:07:13,680 --> 00:07:15,000
and where I used to work.

173
00:07:15,000 --> 00:07:17,600
There are a number of different durable execution systems,

174
00:07:17,600 --> 00:07:21,480
and most of them have a similar diagram.

175
00:07:21,480 --> 00:07:23,000
On the left side, we have application developers,

176
00:07:23,000 --> 00:07:24,880
so us writing our application code.

177
00:07:24,880 --> 00:07:26,600
And on the right, we have a platform team

178
00:07:26,600 --> 00:07:30,920
that hosts the open source temporal service cluster

179
00:07:30,920 --> 00:07:32,840
of Go services and databases,

180
00:07:32,840 --> 00:07:35,920
and each part of this is MIT licensed open source.

181
00:07:35,920 --> 00:07:37,800
And the temporal service side

182
00:07:37,800 --> 00:07:39,800
takes care of the durability for you.

183
00:07:40,640 --> 00:07:43,680
So if I want to start a durable function,

184
00:07:43,680 --> 00:07:45,520
I'll use the client library in the top left,

185
00:07:45,520 --> 00:07:47,280
somewhere in my application,

186
00:07:47,280 --> 00:07:49,680
like I've got a new user subscribing,

187
00:07:49,680 --> 00:07:52,400
I wanna start a subscription function.

188
00:07:52,400 --> 00:07:54,720
You connect to the service,

189
00:07:54,720 --> 00:07:56,400
and you say, okay, I wanna start this thing.

190
00:07:56,400 --> 00:07:58,080
The service adds it to a queue,

191
00:07:58,080 --> 00:08:03,080
and there's workers that you have pulling on the queue.

192
00:08:03,160 --> 00:08:04,240
They pick up, okay, I need to,

193
00:08:04,240 --> 00:08:07,040
and then the workers have your durable code.

194
00:08:07,040 --> 00:08:08,080
So they pick up the task, okay,

195
00:08:08,080 --> 00:08:09,320
I need to run the subscription function.

196
00:08:09,360 --> 00:08:10,280
And here's the arguments,

197
00:08:10,280 --> 00:08:13,040
like the user and the payment method,

198
00:08:13,040 --> 00:08:15,440
and it will run that code.

199
00:08:15,440 --> 00:08:16,920
And any step that it takes,

200
00:08:16,920 --> 00:08:21,520
like a sleep or other things,

201
00:08:21,520 --> 00:08:23,400
it reports back to the service what happened,

202
00:08:23,400 --> 00:08:24,760
so the service adds it to the log

203
00:08:24,760 --> 00:08:28,680
of everything that has happened to this function,

204
00:08:28,680 --> 00:08:31,120
or anything this function has done.

205
00:08:31,120 --> 00:08:32,840
And whenever new things happen,

206
00:08:32,840 --> 00:08:34,560
like a sleep timer goes off,

207
00:08:34,560 --> 00:08:36,320
or you get an RPC from a client,

208
00:08:37,200 --> 00:08:38,880
it gets added to a queue,

209
00:08:38,880 --> 00:08:41,800
the worker picks it up and continues running.

210
00:08:41,800 --> 00:08:44,720
So for instance, if it gets a RPC,

211
00:08:44,720 --> 00:08:48,920
it'll run that method handler.

212
00:08:50,320 --> 00:08:52,320
So here's a family tree

213
00:08:52,320 --> 00:08:54,600
of some of the main durable execution systems.

214
00:08:54,600 --> 00:08:55,800
It was invented at Amazon,

215
00:08:55,800 --> 00:08:58,040
so they were one of the early adopters of microservices.

216
00:08:58,040 --> 00:08:59,200
They realized that, okay,

217
00:08:59,200 --> 00:09:00,320
I can't call synchronously

218
00:09:00,320 --> 00:09:05,320
between microservices reliably in production,

219
00:09:05,320 --> 00:09:07,240
so they went to a vendor for an architecture

220
00:09:07,240 --> 00:09:09,680
communicating asynchronously through queues,

221
00:09:09,680 --> 00:09:10,960
and they were like, oh crap,

222
00:09:10,960 --> 00:09:13,080
that gets really complicated really fast,

223
00:09:13,080 --> 00:09:15,400
and they developed something called

224
00:09:15,400 --> 00:09:17,000
Simple Workflow Service,

225
00:09:17,000 --> 00:09:19,400
which is EWS-SWF,

226
00:09:19,400 --> 00:09:23,000
which was the first version of durable code,

227
00:09:23,000 --> 00:09:26,160
and a much nicer way of communicating between services.

228
00:09:28,200 --> 00:09:29,120
Azure Durable Functions

229
00:09:29,120 --> 00:09:31,440
has a similar durable execution service.

230
00:09:31,440 --> 00:09:33,680
Cadence is used by Uber

231
00:09:33,720 --> 00:09:38,720
to communicate across over 1,000 of their microservices,

232
00:09:38,720 --> 00:09:43,160
and Cadence was forked in 2019 to become Temporal,

233
00:09:43,160 --> 00:09:44,000
which is now a company

234
00:09:44,000 --> 00:09:46,480
with over 200 people working on improving it.

235
00:09:48,080 --> 00:09:49,160
It's used by a ton of companies,

236
00:09:49,160 --> 00:09:51,360
including Stripe, HashiCorp, Netflix.

237
00:09:51,360 --> 00:09:53,680
Every SnapStory is a durable function,

238
00:09:53,680 --> 00:09:56,120
every Airbnb booking, Coinbase transaction.

239
00:09:58,600 --> 00:10:00,760
So the last section, system design patterns.

240
00:10:01,440 --> 00:10:03,840
We have 10 minutes.

241
00:10:03,840 --> 00:10:04,760
Let's see.

242
00:10:04,760 --> 00:10:07,440
So I highly recommend microservices.io

243
00:10:07,440 --> 00:10:09,120
for listing distributed system patterns,

244
00:10:09,120 --> 00:10:12,400
and Byte by Go is a great newsletter for system design.

245
00:10:13,360 --> 00:10:14,200
Circle breakers.

246
00:10:14,200 --> 00:10:17,800
Let's say I have a service-oriented architecture,

247
00:10:17,800 --> 00:10:20,080
and I'm secretly calling between services.

248
00:10:20,080 --> 00:10:22,000
Service A calls me, I'm Service B,

249
00:10:22,000 --> 00:10:23,320
and I call Service E.

250
00:10:23,320 --> 00:10:24,480
When I get a request from Service A,

251
00:10:24,480 --> 00:10:26,840
I need to do something and then call C,

252
00:10:26,840 --> 00:10:29,880
and if C is taking a long time to respond,

253
00:10:29,880 --> 00:10:34,160
then I might, let's say, have a thread per open request,

254
00:10:34,160 --> 00:10:37,000
then I might build up open requests or threads

255
00:10:37,000 --> 00:10:38,520
until I have some resource exhausted,

256
00:10:38,520 --> 00:10:39,360
like number of threads,

257
00:10:39,360 --> 00:10:41,960
and then I'm gonna stop responding

258
00:10:41,960 --> 00:10:43,800
to requests from Service A.

259
00:10:43,800 --> 00:10:46,600
So then A will get backed up and resource exhausted,

260
00:10:46,600 --> 00:10:48,080
and you can have a cascading failure.

261
00:10:48,080 --> 00:10:50,640
So one solution to this is called the circle breaker pattern.

262
00:10:50,640 --> 00:10:51,560
So I'm Service B.

263
00:10:51,560 --> 00:10:53,240
Instead of directly calling Service C,

264
00:10:53,240 --> 00:10:56,840
I will have a proxy that forwards,

265
00:10:56,840 --> 00:10:59,240
usually, the request to Service C for me,

266
00:10:59,240 --> 00:11:02,440
and it'll keep track of how often C is timing out

267
00:11:02,440 --> 00:11:05,760
and stop sending, stop forwarding on requests to C.

268
00:11:05,760 --> 00:11:09,760
The proxy will immediately return failure to Service B,

269
00:11:11,040 --> 00:11:12,080
and then set a timer,

270
00:11:12,080 --> 00:11:15,040
and then after a while, try doing requests again.

271
00:11:15,040 --> 00:11:17,000
So it gives a break on Service C,

272
00:11:17,000 --> 00:11:19,720
and it gets immediate failures from me and Service B.

273
00:11:21,080 --> 00:11:24,000
In a durable execution, you don't need to do this,

274
00:11:24,000 --> 00:11:26,040
because every call that you make

275
00:11:26,040 --> 00:11:29,560
is automatically retried for you with exponential backup.

276
00:11:32,680 --> 00:11:34,280
Event-driven architecture.

277
00:11:34,280 --> 00:11:36,200
So we saw one of the problems

278
00:11:36,200 --> 00:11:38,240
with synchronously calling between services.

279
00:11:38,240 --> 00:11:40,240
So a common solution to this

280
00:11:40,240 --> 00:11:42,440
is to have them communicate asynchronously

281
00:11:42,440 --> 00:11:43,880
by a message of bus,

282
00:11:43,880 --> 00:11:45,160
and that's event-driven architecture.

283
00:11:45,160 --> 00:11:46,080
Here's an example.

284
00:11:46,080 --> 00:11:48,080
A client on the top left creates an order.

285
00:11:48,080 --> 00:11:48,920
You post a slash orders.

286
00:11:48,920 --> 00:11:51,840
You have the API server that writes order created event

287
00:11:51,840 --> 00:11:52,880
to the message bus,

288
00:11:52,880 --> 00:11:54,700
and then there's a payment service that listens,

289
00:11:54,700 --> 00:11:56,340
consumes that event, order created event,

290
00:11:56,340 --> 00:11:59,420
does something, sends the order paid event to the bus.

291
00:11:59,420 --> 00:12:01,620
Fulfillment service listens to that event,

292
00:12:01,620 --> 00:12:04,540
does the fulfillment, and sends order fulfilled to the bus.

293
00:12:04,540 --> 00:12:06,100
And there's other services,

294
00:12:06,100 --> 00:12:09,380
like the analytics service that consumes all of them.

295
00:12:10,980 --> 00:12:13,460
A great part of this, a great aspect of this,

296
00:12:13,460 --> 00:12:15,860
is that it's very decoupled at runtime.

297
00:12:15,860 --> 00:12:17,940
So in this scenario,

298
00:12:17,940 --> 00:12:20,060
the fulfillment service can go down,

299
00:12:20,060 --> 00:12:22,780
and the payment service can continue running.

300
00:12:22,780 --> 00:12:24,740
In the synchronous case of like service B,

301
00:12:24,740 --> 00:12:28,460
it's not finished until it successfully calls service C.

302
00:12:28,460 --> 00:12:31,460
So it's like depending on service C being up and running.

303
00:12:31,460 --> 00:12:33,500
Here, it's not depending.

304
00:12:33,500 --> 00:12:35,060
Payment service can continue doing its work

305
00:12:35,060 --> 00:12:36,980
and publishing order paid events to the bus,

306
00:12:36,980 --> 00:12:38,460
even if the fulfillment service is down

307
00:12:38,460 --> 00:12:39,520
and not consuming them.

308
00:12:39,520 --> 00:12:43,340
And the fulfillment service isn't missing work,

309
00:12:43,340 --> 00:12:44,540
because when it comes back up,

310
00:12:44,540 --> 00:12:46,980
it can go through the backlog of order paid events.

311
00:12:48,780 --> 00:12:50,140
So in Drupal execution,

312
00:12:50,140 --> 00:12:53,740
you also have decoupled runtime.

313
00:12:53,740 --> 00:12:55,420
You don't need any particular step

314
00:12:56,340 --> 00:12:59,580
or downstream service or dependency to be up at the time,

315
00:12:59,580 --> 00:13:03,700
because you'll have retries with exponential backoff

316
00:13:03,700 --> 00:13:06,620
that'll eventually get this to work.

317
00:13:07,700 --> 00:13:09,700
And so you have decoupled runtime,

318
00:13:09,700 --> 00:13:13,300
but you also have much a better developer experience

319
00:13:13,300 --> 00:13:16,820
at design time when you're building.

320
00:13:16,820 --> 00:13:19,660
So an issue with EDA at design time is that

321
00:13:20,900 --> 00:13:23,460
it's not decoupled, it's like tightly coupled.

322
00:13:23,460 --> 00:13:25,100
You have to like make changes in lockstep.

323
00:13:25,100 --> 00:13:26,760
So if I'm the API server

324
00:13:26,760 --> 00:13:28,940
and I wanna change my order created event

325
00:13:28,940 --> 00:13:31,140
to like a order submitted event

326
00:13:31,140 --> 00:13:33,560
or make some breaking chains to the data format,

327
00:13:33,560 --> 00:13:35,660
then I have to figure out all of the other teams

328
00:13:35,660 --> 00:13:37,780
in my company that are depending on this event

329
00:13:37,780 --> 00:13:40,540
and ask them to update their code and push it to production.

330
00:13:40,540 --> 00:13:42,140
And then I can make my change.

331
00:13:43,580 --> 00:13:46,700
So you have to do things in lockstep,

332
00:13:46,700 --> 00:13:48,320
and it's also hard to understand

333
00:13:48,320 --> 00:13:50,020
what's happening in the system.

334
00:13:50,860 --> 00:13:52,380
Like here, there's only one business process

335
00:13:52,380 --> 00:13:54,680
and I lead it out like sequentially for you.

336
00:13:54,680 --> 00:13:55,860
But in reality, in production,

337
00:13:55,860 --> 00:13:57,020
you're gonna have lots of services,

338
00:13:57,020 --> 00:13:59,980
lots of different events that are hard to observe.

339
00:13:59,980 --> 00:14:02,020
Like hopefully you have distributed tracing set up

340
00:14:02,020 --> 00:14:04,820
and you can see, but sort of like

341
00:14:04,820 --> 00:14:07,580
the behavior is emergent and complex

342
00:14:07,580 --> 00:14:08,980
and can be hard to understand.

343
00:14:08,980 --> 00:14:11,360
First is in the durable execution land,

344
00:14:11,360 --> 00:14:14,900
you can look at a business process logic in code

345
00:14:14,900 --> 00:14:16,540
and read and see what it does.

346
00:14:16,540 --> 00:14:21,540
And you also have a log of every production function

347
00:14:22,420 --> 00:14:26,500
execution so you can see what each function does

348
00:14:26,500 --> 00:14:28,300
and every step that it took.

349
00:14:28,300 --> 00:14:29,660
Or currently running functions,

350
00:14:29,660 --> 00:14:31,260
what step they're currently on.

351
00:14:31,260 --> 00:14:35,680
So it's much easier to rock and understand and edit.

352
00:14:35,680 --> 00:14:39,740
Edit your code, change what steps happen when,

353
00:14:39,740 --> 00:14:40,580
and redeploy.

354
00:14:41,600 --> 00:14:44,860
So easier to change, understand, evolve,

355
00:14:44,860 --> 00:14:46,320
and work with than EDA.

356
00:14:46,540 --> 00:14:49,960
So sagas.

357
00:14:51,940 --> 00:14:54,020
Let's see, oh 15 minutes, okay great.

358
00:14:54,020 --> 00:14:57,100
Sagas are long running transactions.

359
00:14:57,100 --> 00:15:00,700
They are when I have some data that I need to update

360
00:15:00,700 --> 00:15:03,260
and the data isn't in like a single partition

361
00:15:03,260 --> 00:15:04,100
of a single database.

362
00:15:04,100 --> 00:15:05,620
So I can't use a transaction,

363
00:15:05,620 --> 00:15:08,500
like a database level transaction to update it.

364
00:15:08,500 --> 00:15:12,420
I need to split up these state updates into multiple steps

365
00:15:12,420 --> 00:15:16,340
and if any discrete step fails,

366
00:15:17,180 --> 00:15:20,020
then I undo all the previous steps that happened.

367
00:15:20,020 --> 00:15:22,260
What are called compensating actions.

368
00:15:22,260 --> 00:15:24,520
Compensate for this failure by undoing

369
00:15:24,520 --> 00:15:26,100
each of the previous steps.

370
00:15:26,100 --> 00:15:29,420
So it's a type of transaction that is an atomic

371
00:15:29,420 --> 00:15:32,300
and doesn't hold blocks and is eventually consistent.

372
00:15:32,300 --> 00:15:34,820
So it's a way of updating data that's across multiple

373
00:15:34,820 --> 00:15:37,060
like databases or services.

374
00:15:38,140 --> 00:15:40,660
And the main two ways of implementing sagas

375
00:15:40,660 --> 00:15:42,100
are with choreography and orchestration.

376
00:15:42,100 --> 00:15:43,860
Choreography is the event of an architecture way

377
00:15:43,860 --> 00:15:45,500
where you're writing messages to a bus.

378
00:15:45,540 --> 00:15:47,380
Orchestration is like a central orchestrator

379
00:15:47,380 --> 00:15:49,640
that has the logic of like what the steps are

380
00:15:49,640 --> 00:15:52,020
and it takes care of scheduling, executing

381
00:15:52,020 --> 00:15:53,540
and retrying each of the steps.

382
00:15:55,540 --> 00:15:58,180
Chris Richardson in the book Microservice Patterns

383
00:15:58,180 --> 00:16:00,300
recommends using orchestration for all

384
00:16:00,300 --> 00:16:02,460
but the simplest of sagas

385
00:16:02,460 --> 00:16:05,820
because of how complex it can get, choreography can get

386
00:16:05,820 --> 00:16:06,900
as we talked about earlier

387
00:16:06,900 --> 00:16:08,900
in the event of an architecture section.

388
00:16:10,620 --> 00:16:12,940
So recommends using orchestration

389
00:16:12,940 --> 00:16:15,460
and the problem with orchestration is that

390
00:16:16,460 --> 00:16:18,540
you are defining logic in a DSL

391
00:16:18,540 --> 00:16:20,660
like a YAML file or a JSON file.

392
00:16:20,660 --> 00:16:22,100
You have like this step and this step

393
00:16:22,100 --> 00:16:26,060
like if, thens and loops are all done in like JSON.

394
00:16:26,060 --> 00:16:28,740
And that's not nice to work with.

395
00:16:28,740 --> 00:16:33,300
It's hard to write and read and debug and run.

396
00:16:33,300 --> 00:16:36,220
And it's much better to when you're defining logic

397
00:16:36,220 --> 00:16:37,580
to define logic in code

398
00:16:37,580 --> 00:16:39,900
because you have the full expressivity

399
00:16:39,900 --> 00:16:41,460
of a Turing complete language

400
00:16:41,460 --> 00:16:44,180
and you can use your normal software development lifecycle.

401
00:16:44,180 --> 00:16:45,220
You can run it locally.

402
00:16:45,980 --> 00:16:47,220
You can debug it locally.

403
00:16:47,220 --> 00:16:51,820
So much nicer DX to use code than a DSL

404
00:16:51,820 --> 00:16:56,820
and durable code is basically automatically orchestrated

405
00:16:58,900 --> 00:16:59,740
for you.

406
00:16:59,740 --> 00:17:04,220
Each step is scheduled and retried for you.

407
00:17:04,220 --> 00:17:06,620
So you can think of durable code

408
00:17:06,620 --> 00:17:10,740
as code-based automatic orchestration

409
00:17:11,860 --> 00:17:13,020
and it's a great way to do sagas.

410
00:17:13,660 --> 00:17:16,700
So we have this process order function process

411
00:17:16,700 --> 00:17:18,220
from before with three steps.

412
00:17:18,220 --> 00:17:19,900
If we wanna make this into a saga,

413
00:17:19,900 --> 00:17:22,420
then we need to add compensating actions.

414
00:17:22,420 --> 00:17:26,900
We need to catch any failures and undo previous steps.

415
00:17:28,140 --> 00:17:30,180
So we try and catch.

416
00:17:30,180 --> 00:17:33,660
Let's say the reserve step on line two succeeds

417
00:17:33,660 --> 00:17:35,820
and then charge succeeds and then we have to send package

418
00:17:35,820 --> 00:17:36,660
and it has a failure.

419
00:17:36,660 --> 00:17:39,660
And it's not like an intermittent retryable failure.

420
00:17:39,660 --> 00:17:42,300
It's some application level non-retryable failure

421
00:17:42,300 --> 00:17:46,900
like USPS returned address doesn't exist.

422
00:17:46,900 --> 00:17:49,340
So this isn't gonna work through retrying.

423
00:17:49,340 --> 00:17:53,300
So instead of continuing to retry, it throws.

424
00:17:53,300 --> 00:17:56,020
I catch it on line nine, I refund.

425
00:17:56,020 --> 00:17:58,100
So I undo the charge step and then I raise

426
00:17:58,100 --> 00:18:01,020
and then I catch and then I unreserve the inventory

427
00:18:01,020 --> 00:18:03,740
that I reserved in line two.

428
00:18:03,740 --> 00:18:05,700
So if this is a durable function,

429
00:18:05,700 --> 00:18:10,700
this is a accurate complete transaction or accurate saga.

430
00:18:10,900 --> 00:18:12,060
Or accurate saga.

431
00:18:12,060 --> 00:18:13,740
If this is a normal function, then it's not

432
00:18:13,740 --> 00:18:16,500
because it's not correct because I could say

433
00:18:16,500 --> 00:18:18,020
the process could die after line seven

434
00:18:18,020 --> 00:18:20,620
and then I never refund the user

435
00:18:20,620 --> 00:18:23,220
and never unreserve the inventory.

436
00:18:23,220 --> 00:18:24,740
So saga is really easy to implement

437
00:18:24,740 --> 00:18:26,660
when you have a durable function.

438
00:18:28,100 --> 00:18:29,740
Transitional outboxes, okay.

439
00:18:30,740 --> 00:18:35,740
So if I'm doing EDA, oftentimes if I'm a service

440
00:18:36,920 --> 00:18:40,020
and I get an event, I make some state update

441
00:18:40,020 --> 00:18:42,260
to my local state in my database

442
00:18:42,260 --> 00:18:46,540
and then after that I submit another message to the bus.

443
00:18:47,700 --> 00:18:52,700
The issue is that if after I do my local state update,

444
00:18:53,260 --> 00:18:56,300
I crash, then I'm gonna fail to write the message

445
00:18:56,300 --> 00:18:59,180
to the bus and everything after me

446
00:18:59,180 --> 00:19:01,620
that depends on that message won't happen.

447
00:19:01,620 --> 00:19:05,020
So my system will be like an inconsistent state.

448
00:19:05,020 --> 00:19:07,340
For example, if I'm the payment service,

449
00:19:07,380 --> 00:19:11,740
I write my successful payment record to my DB

450
00:19:11,740 --> 00:19:15,060
and then I crash before I send the order paid event,

451
00:19:15,060 --> 00:19:17,340
then fulfillment service won't have to fulfill.

452
00:19:17,340 --> 00:19:19,900
So I'll have a user without a package

453
00:19:19,900 --> 00:19:21,380
but having been paid.

454
00:19:22,340 --> 00:19:24,300
And a solution to this is called

455
00:19:24,300 --> 00:19:27,820
a transactional outbox or transfer queue.

456
00:19:27,820 --> 00:19:31,700
So in the payment service, in a transaction,

457
00:19:31,700 --> 00:19:36,700
when I update my local state like adding a payment record,

458
00:19:37,260 --> 00:19:40,540
in that same, in the transaction, in the same partition,

459
00:19:40,540 --> 00:19:45,340
I'm gonna add the event that I want eventually

460
00:19:45,340 --> 00:19:48,660
to get to the bus in a sort of mini queue

461
00:19:48,660 --> 00:19:51,380
in that for each partition has its own mini queue

462
00:19:51,380 --> 00:19:52,540
and then have some separate process

463
00:19:52,540 --> 00:19:54,940
that goes through all of the transfer queues

464
00:19:54,940 --> 00:19:57,060
into each of the partitions in my data store

465
00:19:57,060 --> 00:20:00,500
and reads them and sends them to the bus

466
00:20:00,500 --> 00:20:02,300
and if it successfully sends to the bus,

467
00:20:02,300 --> 00:20:05,420
then it takes it off that transfer queue

468
00:20:05,420 --> 00:20:09,580
and you have deduplication and retries on failure.

469
00:20:09,580 --> 00:20:12,540
So assuming you implemented that correctly,

470
00:20:12,540 --> 00:20:14,340
then you have this guarantee that

471
00:20:15,340 --> 00:20:16,540
because it's in a transaction

472
00:20:16,540 --> 00:20:19,300
and because it eventually gets sent to the bus

473
00:20:19,300 --> 00:20:23,660
that you have like this eventually consistent thing.

474
00:20:24,620 --> 00:20:27,700
So that's a transfer queue or a transactional outbox

475
00:20:27,700 --> 00:20:29,660
and you don't need to do it in durable code

476
00:20:29,660 --> 00:20:33,580
because the entire pattern is predicated on the fact

477
00:20:33,580 --> 00:20:35,980
that I don't know when I have multiple steps

478
00:20:35,980 --> 00:20:38,340
that all of the steps will complete running.

479
00:20:39,940 --> 00:20:42,300
So when, thank you a lot,

480
00:20:43,620 --> 00:20:45,060
when I have a durable function

481
00:20:45,060 --> 00:20:47,580
and I have one step is right to my local database

482
00:20:47,580 --> 00:20:50,020
and next step is published to the bus,

483
00:20:50,020 --> 00:20:52,540
then that next step is guaranteed to happen.

484
00:20:52,540 --> 00:20:54,820
So I don't need a transactional outbox.

485
00:20:57,060 --> 00:20:58,740
Event sourcing.

486
00:20:58,740 --> 00:21:01,340
So this is a way of like storing state.

487
00:21:01,340 --> 00:21:04,700
On the top, we have the normal way without event sourcing.

488
00:21:04,700 --> 00:21:05,540
This is in three rows.

489
00:21:05,540 --> 00:21:07,460
This is a single row in three different states.

490
00:21:07,460 --> 00:21:11,540
So I insert a row with order ID 1001, quantity five,

491
00:21:12,420 --> 00:21:15,300
and then I update the quantity to six,

492
00:21:15,300 --> 00:21:17,260
and then I update the state to paid.

493
00:21:17,260 --> 00:21:19,460
And so I'm left with one row with quantity six

494
00:21:19,460 --> 00:21:20,860
and state paid.

495
00:21:20,860 --> 00:21:23,660
With event sourcing, instead of doing these updates,

496
00:21:23,660 --> 00:21:28,420
I am appending events to an immutable log

497
00:21:28,420 --> 00:21:31,020
and each event is like what happens.

498
00:21:31,260 --> 00:21:34,820
A new order row is the event ID 2001,

499
00:21:34,820 --> 00:21:38,380
and then I modify order event and then order payment event.

500
00:21:38,380 --> 00:21:41,300
So a downside to that is in order to know the state

501
00:21:41,300 --> 00:21:43,460
of this order, I can't look at the last event

502
00:21:43,460 --> 00:21:44,780
because it doesn't have the quantity.

503
00:21:44,780 --> 00:21:46,540
I have to read through all the past events

504
00:21:46,540 --> 00:21:48,740
for a certain domain model.

505
00:21:50,220 --> 00:21:52,180
So you usually have some other view,

506
00:21:52,180 --> 00:21:54,380
like a read view or materialized view

507
00:21:54,380 --> 00:21:56,980
where you're reading the current state of the world.

508
00:21:56,980 --> 00:22:00,500
But some benefits that event sourcing gets you

509
00:22:00,500 --> 00:22:03,300
is that you have a complete visibility or audit log

510
00:22:03,300 --> 00:22:07,100
of what happened to this business object in the past.

511
00:22:07,100 --> 00:22:09,580
And you can also replay to any point in time

512
00:22:09,580 --> 00:22:11,820
to see what the state of the world was.

513
00:22:11,820 --> 00:22:15,540
And most durable execution systems

514
00:22:15,540 --> 00:22:18,980
are implemented with event sourcing under the hood.

515
00:22:18,980 --> 00:22:23,100
So each production function execution has this event log

516
00:22:23,100 --> 00:22:24,580
and so you can see what happened.

517
00:22:24,580 --> 00:22:28,180
And you can also, you have some bug

518
00:22:28,180 --> 00:22:29,580
that's hard to diagnose in production.

519
00:22:29,580 --> 00:22:31,180
You can download that event log

520
00:22:32,460 --> 00:22:34,460
and run it locally against your code

521
00:22:34,460 --> 00:22:37,180
and replay your code to see what happened

522
00:22:37,180 --> 00:22:38,460
and run it in a debugger.

523
00:22:39,380 --> 00:22:42,220
So you get great visibility and great debuggability

524
00:22:42,220 --> 00:22:46,020
with sort of like automatically event sourced

525
00:22:46,020 --> 00:22:47,340
function execution.

526
00:22:49,420 --> 00:22:52,420
CQRS, we'll skip in the interest of time,

527
00:22:53,740 --> 00:22:56,740
separating the commands of the writes from the queries,

528
00:22:57,740 --> 00:23:02,380
depending on which level you're applying this to durable code.

529
00:23:02,380 --> 00:23:06,380
Either it's unnecessary or it's done for you.

530
00:23:07,620 --> 00:23:08,700
Distributed cron jobs.

531
00:23:08,700 --> 00:23:11,260
Let's say I want something to happen periodically.

532
00:23:13,100 --> 00:23:16,460
I can have a cron tab on analytics machine in production.

533
00:23:16,460 --> 00:23:17,380
Issues with that are like,

534
00:23:17,380 --> 00:23:19,140
it depends on this one machine being up

535
00:23:19,140 --> 00:23:20,500
and has limited throughput.

536
00:23:20,500 --> 00:23:23,860
So if I want something to be reliable and scalable,

537
00:23:23,860 --> 00:23:26,140
then I want some distributed cron solution.

538
00:23:26,660 --> 00:23:28,340
Durable execution is a great fit for this

539
00:23:28,340 --> 00:23:31,500
because it scales horizontally in the number of executions.

540
00:23:31,500 --> 00:23:33,420
So I can have billions of executions

541
00:23:33,420 --> 00:23:35,460
and all of them could be sleeping

542
00:23:35,460 --> 00:23:36,420
for arbitrary periods of time.

543
00:23:36,420 --> 00:23:39,420
So waking up whenever I want them to run the next job.

544
00:23:40,820 --> 00:23:41,660
Task queues.

545
00:23:41,660 --> 00:23:46,660
So there was a article from last year

546
00:23:47,900 --> 00:23:50,260
that was voted up on Hacker News

547
00:23:50,260 --> 00:23:53,100
called Too Many Problems with Celery.

548
00:23:53,100 --> 00:23:55,660
And one of them was Celery prefetches jobs

549
00:23:55,660 --> 00:23:56,860
so it gets four at a time.

550
00:23:56,860 --> 00:23:58,900
And if the first one takes like a day,

551
00:23:58,900 --> 00:23:59,940
the next three are delayed,

552
00:23:59,940 --> 00:24:02,140
even if they're like take a few minutes

553
00:24:02,140 --> 00:24:04,740
because it's working on one at a time and gets four.

554
00:24:05,740 --> 00:24:10,740
In durable execution, you have many slots in parallel

555
00:24:11,380 --> 00:24:13,020
that a worker can be running,

556
00:24:13,020 --> 00:24:16,780
like many function executions that can be doing.

557
00:24:16,780 --> 00:24:21,380
And it only fetches one at a time.

558
00:24:21,380 --> 00:24:24,980
So it's much better in this scenario.

559
00:24:24,980 --> 00:24:26,860
Celery loses jobs by default.

560
00:24:26,860 --> 00:24:30,660
So if a task raises an exception or a worker process dies,

561
00:24:30,660 --> 00:24:32,700
then you lose that task.

562
00:24:32,700 --> 00:24:35,380
In durable execution, you don't.

563
00:24:36,580 --> 00:24:37,660
Whenever there's a failure,

564
00:24:37,660 --> 00:24:40,260
it'll automatically get timed out and rescheduled.

565
00:24:41,660 --> 00:24:43,740
Celery retried defaults are bad.

566
00:24:44,620 --> 00:24:47,220
So they recommend doing exponential back off,

567
00:24:47,220 --> 00:24:49,620
which is what durable execution does by default.

568
00:24:51,580 --> 00:24:53,220
No transactional job enqueuing.

569
00:24:53,220 --> 00:24:55,620
So talking about the transactional outbox pattern,

570
00:24:55,620 --> 00:24:58,860
and author says like, don't use Celery if you need this

571
00:24:58,860 --> 00:24:59,820
because you can't.

572
00:25:00,780 --> 00:25:03,100
You don't need it with durable code.

573
00:25:03,100 --> 00:25:06,020
Canvas cores and friends encourage brittle pipelines.

574
00:25:06,020 --> 00:25:08,100
So if you have some pipeline of multiple jobs

575
00:25:08,100 --> 00:25:10,500
that you need to happen together, like in a chain,

576
00:25:11,660 --> 00:25:13,500
the author says it's a recipe for losing jobs

577
00:25:13,500 --> 00:25:14,860
or having broken workflows

578
00:25:14,860 --> 00:25:18,060
because Celery doesn't have transactional job enqueuing.

579
00:25:18,060 --> 00:25:21,580
So you could have like the first step in a chain happen,

580
00:25:21,580 --> 00:25:25,620
but the rest won't happen in various error states.

581
00:25:26,420 --> 00:25:31,020
So it's like, they're like, don't use Celery for this.

582
00:25:32,060 --> 00:25:34,060
Don't use these EPIs.

583
00:25:34,060 --> 00:25:35,100
Versus if in durable code,

584
00:25:35,100 --> 00:25:36,460
if you have a function with multiple steps,

585
00:25:36,460 --> 00:25:39,380
they're guaranteed that they will all complete.

586
00:25:39,380 --> 00:25:43,100
Another complaint was that the EPI isn't Pythonic.

587
00:25:44,420 --> 00:25:46,500
And I don't know about all durable execution systems,

588
00:25:46,500 --> 00:25:50,740
but for temporal, the Python runtime is very Pythonic.

589
00:25:50,740 --> 00:25:52,340
Talk to Chad who built it,

590
00:25:52,340 --> 00:25:54,060
who's at the temporal booth today.

591
00:25:57,100 --> 00:25:58,260
State machines.

592
00:25:58,260 --> 00:26:02,380
So a common pattern is I have some business process

593
00:26:02,380 --> 00:26:04,580
that has multiple states that it's in,

594
00:26:04,580 --> 00:26:06,620
and I want it to be done reliably.

595
00:26:06,620 --> 00:26:09,700
So I split this process into multiple steps

596
00:26:09,700 --> 00:26:10,900
that I put on job queues,

597
00:26:10,900 --> 00:26:14,660
and I update the current state of this process

598
00:26:14,660 --> 00:26:16,180
after every step.

599
00:26:16,180 --> 00:26:19,660
And that can be a lot of work, a lot of code to write,

600
00:26:19,660 --> 00:26:23,180
like in queuing and polling and updating a database.

601
00:26:23,180 --> 00:26:28,180
And I guess it's a lot of code to write

602
00:26:30,220 --> 00:26:31,820
and to get correct.

603
00:26:31,820 --> 00:26:34,300
Versus in durable code,

604
00:26:34,300 --> 00:26:38,500
you don't need to do all that plumbing work

605
00:26:38,500 --> 00:26:40,940
of talking to the database or talking to a queue.

606
00:26:40,940 --> 00:26:44,620
You can structure your code if you want as a state machine,

607
00:26:44,620 --> 00:26:49,620
but you don't need to be talking yourself to a database.

608
00:26:53,460 --> 00:26:56,020
So to recap, we defined what durable execution is,

609
00:26:56,020 --> 00:26:58,020
talked about some new possibilities for how to program

610
00:26:58,020 --> 00:27:00,260
that it opens up, a little bit about how it works,

611
00:27:00,260 --> 00:27:02,780
and then some distributed system patterns

612
00:27:02,780 --> 00:27:07,340
and how temporal either makes them unnecessary or easier.

613
00:27:07,340 --> 00:27:10,500
So we had circuit breakers don't need to do,

614
00:27:10,500 --> 00:27:11,820
event-driven architecture,

615
00:27:12,820 --> 00:27:16,340
same decoupled at runtime, better DX.

616
00:27:16,340 --> 00:27:17,740
Sagas, really easy to do,

617
00:27:17,740 --> 00:27:21,420
transactional outboxes, don't need to do.

618
00:27:21,420 --> 00:27:23,540
Event sourcing, done for you automatically.

619
00:27:23,540 --> 00:27:27,180
CQRS, partially don't need, partially done for you.

620
00:27:27,180 --> 00:27:29,940
Distributed cron jobs, really easy to do.

621
00:27:29,940 --> 00:27:32,460
Task queues, automatically done for you

622
00:27:32,460 --> 00:27:35,060
in a better way than celery's defaults.

623
00:27:35,060 --> 00:27:37,500
And state machines, easy to do.

624
00:27:38,340 --> 00:27:41,540
And Timbroil.io for more info.

625
00:27:41,540 --> 00:27:44,220
I'm at laurendcr on Twitter if you have any questions.

626
00:27:44,220 --> 00:27:47,220
Also laurenagraphql.guide is my email.

627
00:27:48,100 --> 00:27:49,220
I'm a consultant with Bandwidth,

628
00:27:49,220 --> 00:27:51,860
so if you'd like any help building your thing,

629
00:27:51,860 --> 00:27:54,180
I'd be happy to take a look and see if I can help.

630
00:27:54,180 --> 00:27:56,180
And those are the slides.

631
00:27:56,180 --> 00:27:59,820
(*audience applauds*)

632
00:27:59,820 --> 00:28:00,660
Awesome.

633
00:28:01,580 --> 00:28:03,660
I've got a couple of questions for you here

634
00:28:03,660 --> 00:28:04,540
that have been coming through.

635
00:28:04,540 --> 00:28:06,420
And by the way, Lauren is also on the Discord,

636
00:28:06,420 --> 00:28:09,060
so you can chat with him there as well.

637
00:28:09,060 --> 00:28:11,620
Okay, first off, how can you tell

638
00:28:11,620 --> 00:28:14,180
if a failure is transient or non-transient?

639
00:28:15,300 --> 00:28:17,380
What's your criteria there?

640
00:28:17,380 --> 00:28:22,380
Sure, so I guess each step is like a normal Python function.

641
00:28:26,540 --> 00:28:29,620
And if you let something throw,

642
00:28:29,620 --> 00:28:33,140
it's treated as a retrivable error.

643
00:28:33,140 --> 00:28:35,460
If you catch something,

644
00:28:35,460 --> 00:28:39,100
then you can throw a non-retrivable error failure.

645
00:28:39,100 --> 00:28:40,900
So it's a class that you import from the library

646
00:28:40,900 --> 00:28:43,620
to indicate that whatever happened is not retriable,

647
00:28:43,620 --> 00:28:45,060
don't try to reschedule this.

648
00:28:45,980 --> 00:28:46,820
Okay.

649
00:28:47,740 --> 00:28:49,820
Can you talk about the data persistence layer

650
00:28:49,820 --> 00:28:53,980
and any concerns around PCI, PII, GDPR rights,

651
00:28:53,980 --> 00:28:56,380
and any of those things that need to be considered?

652
00:28:56,380 --> 00:29:01,380
So I guess there's a number of different options

653
00:29:04,300 --> 00:29:07,300
for persistence layer for Temporal at least.

654
00:29:07,300 --> 00:29:09,140
Like I don't know about some of the hosted services

655
00:29:09,140 --> 00:29:12,020
like AWS, SWF, or other drivable functions,

656
00:29:12,020 --> 00:29:13,580
like whether they're PCI compliant

657
00:29:13,580 --> 00:29:15,660
or what database they use.

658
00:29:15,660 --> 00:29:20,660
But for Temporal, you can use MySQL or Postgres or Cassandra,

659
00:29:22,140 --> 00:29:25,780
usually Cassandra for higher rate throughput and scale.

660
00:29:25,780 --> 00:29:30,780
And I mean, if you want to go through PCI and GDPR

661
00:29:33,100 --> 00:29:36,220
in that open source cluster that you host,

662
00:29:36,220 --> 00:29:37,380
you can do that.

663
00:29:37,380 --> 00:29:38,940
Wander over this way with me.

664
00:29:40,340 --> 00:29:42,860
How do durable execution workers know

665
00:29:42,860 --> 00:29:45,820
what function to pick up and in what order?

666
00:29:45,820 --> 00:29:46,700
Sorry, say it again.

667
00:29:46,700 --> 00:29:49,380
How do durable execution workers know

668
00:29:49,380 --> 00:29:51,580
what function to pick up and in what order?

669
00:29:52,600 --> 00:29:55,340
How do they keep track of the state of what needs to be?

670
00:29:55,900 --> 00:30:00,900
So the workers don't need to keep up much state.

671
00:30:03,300 --> 00:30:08,300
The service is taking care of when to add things to the queue

672
00:30:09,500 --> 00:30:14,500
and the first, and like all the workers are polling

673
00:30:14,940 --> 00:30:16,260
whenever they have like an open slot,

674
00:30:16,260 --> 00:30:19,860
like I can do a hundred executions in parallel.

675
00:30:20,860 --> 00:30:23,180
If I have one of those open, I will pull.

676
00:30:23,180 --> 00:30:28,180
And whichever the first one that gets a new task on the queue,

677
00:30:30,420 --> 00:30:31,260
we'll get that.

678
00:30:31,260 --> 00:30:32,100
Well, I'll take care of that.

679
00:30:32,100 --> 00:30:32,920
Yeah.

680
00:30:32,920 --> 00:30:33,900
Okay.

681
00:30:33,900 --> 00:30:35,960
How does the durable execution handle it

682
00:30:35,960 --> 00:30:38,860
if the code has changed while the function was suspended?

683
00:30:41,580 --> 00:30:44,140
Sure, so if you are changing the code

684
00:30:44,140 --> 00:30:49,140
of a execution running in production,

685
00:30:49,380 --> 00:30:52,540
there are a couple of different ways to do it.

686
00:30:52,540 --> 00:30:57,540
You can, so if the code, if the execution

687
00:31:03,500 --> 00:31:07,220
hasn't gotten to this point of code,

688
00:31:07,220 --> 00:31:08,380
then you can just update it.

689
00:31:08,380 --> 00:31:10,540
If it's already gone through it, then you can't update it

690
00:31:10,540 --> 00:31:13,420
because the way the system is implemented

691
00:31:13,420 --> 00:31:16,180
is that it has to, in order to rebuild the state of a function,

692
00:31:16,180 --> 00:31:19,380
has to replay all previous events.

693
00:31:19,420 --> 00:31:22,700
And if you try to replay the event log on different code,

694
00:31:22,700 --> 00:31:24,460
it'll not work.

695
00:31:24,460 --> 00:31:26,340
So there's a couple of different ways you can solve this.

696
00:31:26,340 --> 00:31:29,300
One is you can deploy a separate worker

697
00:31:29,300 --> 00:31:32,660
that only takes the new version of the code

698
00:31:32,660 --> 00:31:35,580
that only takes new production function executions.

699
00:31:35,580 --> 00:31:38,460
So all the existing ones will run in the old code.

700
00:31:38,460 --> 00:31:41,300
Then whenever those are done, you can retire the old code.

701
00:31:41,300 --> 00:31:44,580
Another way is to like have an if-then statement,

702
00:31:44,580 --> 00:31:48,340
depending on what, like if version is one,

703
00:31:48,340 --> 00:31:51,020
do this logic, otherwise do some other logic.

704
00:31:51,020 --> 00:31:52,700
OK.

705
00:31:52,700 --> 00:31:57,860
How do you see durable execution affecting game development?

706
00:31:57,860 --> 00:31:58,500
Game development.

707
00:31:58,500 --> 00:32:03,420
So I guess like for the trade off for durable execution

708
00:32:03,420 --> 00:32:06,100
is that you are writing to disk a lot.

709
00:32:06,100 --> 00:32:12,340
So you have a higher latency than if you

710
00:32:12,340 --> 00:32:13,780
weren't persisting anything.

711
00:32:13,780 --> 00:32:15,620
So there are certain things like for real time gaming

712
00:32:15,620 --> 00:32:17,140
where you wouldn't want to use it.

713
00:32:17,140 --> 00:32:23,740
But for anything where you can wait like 20 milliseconds,

714
00:32:23,740 --> 00:32:27,540
like I don't know the information about the user

715
00:32:27,540 --> 00:32:31,380
account, anything in non-real time

716
00:32:31,380 --> 00:32:35,460
you could use a durable function for in gaming.

717
00:32:35,460 --> 00:32:37,300
I think that also helps answer the question,

718
00:32:37,300 --> 00:32:40,180
is durable execution used in real time critical systems

719
00:32:40,180 --> 00:32:42,540
like air and spacecraft and their support systems?

720
00:32:42,540 --> 00:32:43,700
And if not, why not?

721
00:32:43,700 --> 00:32:46,580
I would guess that the high latency

722
00:32:46,620 --> 00:32:49,460
would probably make them not well suited for that.

723
00:32:49,460 --> 00:32:51,700
Yeah, I mean, it depends on how you

724
00:32:51,700 --> 00:32:55,580
think of as high latency, like tens of milliseconds is fine.

725
00:32:55,580 --> 00:32:57,940
But if you're trying to do like single digit milliseconds,

726
00:32:57,940 --> 00:32:59,300
then it would be hard.

727
00:32:59,300 --> 00:33:01,380
Right, right.

728
00:33:01,380 --> 00:33:03,820
All right, I'll do one more here.

729
00:33:03,820 --> 00:33:06,460
How can I trust that the durable execution workers are not

730
00:33:06,460 --> 00:33:07,980
malfunctioning?

731
00:33:07,980 --> 00:33:09,700
How can you trust the workers are not malfunctioning?

732
00:33:09,700 --> 00:33:10,420
I guess the system.

733
00:33:10,420 --> 00:33:11,060
The workers.

734
00:33:11,060 --> 00:33:11,580
Pardon?

735
00:33:11,580 --> 00:33:14,260
Who watches the workers?

736
00:33:14,260 --> 00:33:17,740
It's fine for the system designed

737
00:33:17,740 --> 00:33:21,580
to not trust workers, to only trust what's in the database.

738
00:33:21,580 --> 00:33:25,580
So if a worker dies, everything that the worker does,

739
00:33:25,580 --> 00:33:28,420
every task that it picks up has a timeout associated with it.

740
00:33:28,420 --> 00:33:33,180
So the server will notice that this task hasn't been had.

741
00:33:33,180 --> 00:33:35,500
There's no result from this task in a while.

742
00:33:35,500 --> 00:33:39,140
So it'll treat it as failed and reschedule it.

743
00:33:39,140 --> 00:33:41,060
I sent this assignment out a little while ago,

744
00:33:41,060 --> 00:33:42,180
and it never returned.

745
00:33:42,660 --> 00:33:45,540
Guess I should dispatch that again.

746
00:33:45,540 --> 00:33:45,980
Nice.

747
00:33:45,980 --> 00:33:47,180
OK, well, thank you, Lauren.

748
00:33:47,180 --> 00:33:47,540
Sure.

749
00:33:47,540 --> 00:33:48,140
Fantastic.

750
00:33:48,140 --> 00:33:48,940
Thanks, everybody.

751
00:33:48,940 --> 00:33:49,500
Thanks.

752
00:33:49,500 --> 00:33:51,060
Thanks.

